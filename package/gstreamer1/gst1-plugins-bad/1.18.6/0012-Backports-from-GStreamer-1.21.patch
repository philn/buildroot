From d3e628039193180c709489618f6063f34f4dfc41 Mon Sep 17 00:00:00 2001
From: Philippe Normand <philn@igalia.com>
Date: Thu, 19 Jan 2023 14:52:31 +0000
Subject: [PATCH] Backports from GStreamer 1.21.

---
 ext/dtls/gstdtlsagent.c                       |    2 +-
 ext/dtls/gstdtlsagent.h                       |    6 +-
 ext/dtls/gstdtlscertificate.c                 |   16 +
 ext/dtls/gstdtlsconnection.c                  |   26 +-
 ext/dtls/gstdtlsconnection.h                  |   10 +-
 ext/dtls/gstdtlsdec.c                         |   15 +-
 ext/dtls/gstdtlselement.c                     |   44 +
 ext/dtls/gstdtlselements.h                    |   38 +
 ext/dtls/gstdtlsenc.c                         |   23 +-
 ext/dtls/gstdtlssrtpbin.c                     |    3 +-
 ext/dtls/gstdtlssrtpdec.c                     |   16 +-
 ext/dtls/gstdtlssrtpdemux.c                   |    4 +
 ext/dtls/gstdtlssrtpenc.c                     |   39 +-
 ext/dtls/meson.build                          |    2 +-
 ext/dtls/plugin.c                             |   27 +-
 ext/sctp/gstsctpdec.c                         |   17 +-
 ext/sctp/gstsctpdec.h                         |    1 +
 ext/sctp/gstsctpenc.c                         |   67 +-
 ext/sctp/gstsctpenc.h                         |    1 +
 ext/sctp/gstsctpplugin.c                      |   11 +-
 ext/sctp/meson.build                          |    1 -
 ext/sctp/sctpassociation.c                    |    3 +-
 ext/sctp/usrsctp/meson.build                  |    3 +-
 ext/srtp/gstsrtp.c                            |   23 -
 ext/srtp/gstsrtpdec.c                         |   70 +-
 ext/srtp/gstsrtpdec.h                         |    3 +-
 ext/srtp/gstsrtpelement.c                     |   41 +
 ext/srtp/gstsrtpelements.h                    |   63 +
 ext/srtp/gstsrtpenc.c                         |   19 +-
 ext/srtp/gstsrtpenc.h                         |    2 -
 ext/srtp/gstsrtpplugin.c                      |   45 +
 ext/srtp/meson.build                          |    4 +-
 ext/webrtc/fwd.h                              |   12 -
 ext/webrtc/gstwebrtcbin.c                     | 4661 +++++++++++++----
 ext/webrtc/gstwebrtcbin.h                     |   26 +-
 ext/webrtc/gstwebrtcstats.c                   |  975 +++-
 ext/webrtc/gstwebrtcstats.h                   |    3 +-
 ext/webrtc/meson.build                        |   37 +-
 ext/webrtc/transportreceivebin.c              |  186 +-
 ext/webrtc/transportreceivebin.h              |    1 +
 ext/webrtc/transportsendbin.c                 |  271 +-
 ext/webrtc/transportsendbin.h                 |   27 +-
 ext/webrtc/transportstream.c                  |  170 +-
 ext/webrtc/transportstream.h                  |   39 +-
 ext/webrtc/utils.c                            |   61 +-
 ext/webrtc/utils.h                            |   25 +-
 ext/webrtc/webrtcdatachannel.c                |  467 +-
 ext/webrtc/webrtcdatachannel.h                |   13 +-
 ext/webrtc/webrtcsctptransport.c              |  251 +
 ext/webrtc/webrtcsctptransport.h              |   74 +
 ext/webrtc/webrtcsdp.c                        |   61 +-
 ext/webrtc/webrtcsdp.h                        |    3 +-
 ext/webrtc/webrtctransceiver.c                |   47 +-
 ext/webrtc/webrtctransceiver.h                |   18 +-
 gst-libs/gst/codecparsers/gstav1parser.c      |  610 ++-
 gst-libs/gst/codecparsers/gstav1parser.h      |   59 +-
 gst-libs/gst/codecparsers/gsth264bitwriter.c  | 1642 ++++++
 gst-libs/gst/codecparsers/gsth264bitwriter.h  |   88 +
 gst-libs/gst/codecparsers/gsth264parser.c     |  303 +-
 gst-libs/gst/codecparsers/gsth264parser.h     |  157 +-
 gst-libs/gst/codecparsers/gsth265bitwriter.c  | 2307 ++++++++
 gst-libs/gst/codecparsers/gsth265bitwriter.h  |   93 +
 gst-libs/gst/codecparsers/gsth265parser.c     |  747 ++-
 gst-libs/gst/codecparsers/gsth265parser.h     |   65 +-
 .../gst/codecparsers/gstjpeg2000sampling.c    |    6 +-
 .../gst/codecparsers/gstjpeg2000sampling.h    |   30 +-
 gst-libs/gst/codecparsers/gstvp8parser.c      |    2 +
 gst-libs/gst/codecparsers/gstvp9parser.c      |    1 +
 gst-libs/gst/codecparsers/gstvp9parser.h      |    3 +-
 gst-libs/gst/codecparsers/meson.build         |    7 +-
 gst-libs/gst/codecparsers/nalutils.c          |  102 +-
 gst-libs/gst/codecparsers/nalutils.h          |    3 +
 gst-libs/gst/webrtc/datachannel.c             |   60 +-
 gst-libs/gst/webrtc/datachannel.h             |   69 +-
 gst-libs/gst/webrtc/dtlstransport.c           |   38 +-
 gst-libs/gst/webrtc/dtlstransport.h           |   33 -
 gst-libs/gst/webrtc/ice.c                     |  622 +++
 gst-libs/gst/webrtc/ice.h                     |  261 +
 gst-libs/gst/webrtc/icestream.c               |  137 +
 gst-libs/gst/webrtc/icestream.h               |   61 +
 gst-libs/gst/webrtc/icetransport.c            |    8 +-
 gst-libs/gst/webrtc/icetransport.h            |    9 +-
 gst-libs/gst/webrtc/meson.build               |   26 +-
 gst-libs/gst/webrtc/nice/meson.build          |   48 +
 gst-libs/gst/webrtc/nice/nice.c               | 1677 ++++++
 gst-libs/gst/webrtc/nice/nice.h               |   67 +
 gst-libs/gst/webrtc/nice/nice_fwd.h           |   17 +
 gst-libs/gst/webrtc/nice/nicestream.c         |  334 ++
 gst-libs/gst/webrtc/nice/nicestream.h         |   63 +
 gst-libs/gst/webrtc/nice/nicetransport.c      |  426 ++
 gst-libs/gst/webrtc/nice/nicetransport.h      |   71 +
 gst-libs/gst/webrtc/rtpreceiver.c             |   54 +-
 gst-libs/gst/webrtc/rtpreceiver.h             |   30 -
 gst-libs/gst/webrtc/rtpsender.c               |  101 +-
 gst-libs/gst/webrtc/rtpsender.h               |   34 +-
 gst-libs/gst/webrtc/rtptransceiver.c          |   99 +-
 gst-libs/gst/webrtc/rtptransceiver.h          |   31 -
 gst-libs/gst/webrtc/sctptransport.c           |   79 +
 gst-libs/gst/webrtc/sctptransport.h           |   42 +
 gst-libs/gst/webrtc/webrtc-priv.h             |  274 +
 gst-libs/gst/webrtc/webrtc.c                  |   35 +
 gst-libs/gst/webrtc/webrtc.h                  |    2 +
 gst-libs/gst/webrtc/webrtc_fwd.h              |  187 +-
 gst/videoparsers/gstav1parse.c                | 2135 ++++++++
 gst/videoparsers/gstav1parse.h                |   34 +
 gst/videoparsers/gstdiracparse.c              |    3 +
 gst/videoparsers/gsth263parse.c               |    4 +
 gst/videoparsers/gsth264parse.c               |  288 +-
 gst/videoparsers/gsth264parse.h               |   15 +-
 gst/videoparsers/gsth265parse.c               |  294 +-
 gst/videoparsers/gsth265parse.h               |    1 +
 gst/videoparsers/gstmpeg4videoparse.c         |    6 +-
 gst/videoparsers/gstmpegvideoparse.c          |    4 +
 gst/videoparsers/gstpngparse.c                |    3 +
 gst/videoparsers/gstvc1parse.c                |    3 +
 gst/videoparsers/gstvideoparserselement.c     |   39 +
 gst/videoparsers/gstvideoparserselements.h    |   46 +
 gst/videoparsers/gstvideoparseutils.c         |   56 +
 gst/videoparsers/gstvideoparseutils.h         |   20 +
 gst/videoparsers/gstvp9parse.c                |  896 ++++
 gst/videoparsers/gstvp9parse.h                |   34 +
 gst/videoparsers/meson.build                  |    4 +-
 gst/videoparsers/plugin.c                     |   53 +-
 123 files changed, 20105 insertions(+), 3126 deletions(-)
 create mode 100644 ext/dtls/gstdtlselement.c
 create mode 100644 ext/dtls/gstdtlselements.h
 create mode 100644 ext/srtp/gstsrtpelement.c
 create mode 100644 ext/srtp/gstsrtpelements.h
 create mode 100644 ext/srtp/gstsrtpplugin.c
 create mode 100644 ext/webrtc/webrtcsctptransport.c
 create mode 100644 ext/webrtc/webrtcsctptransport.h
 create mode 100644 gst-libs/gst/codecparsers/gsth264bitwriter.c
 create mode 100644 gst-libs/gst/codecparsers/gsth264bitwriter.h
 create mode 100644 gst-libs/gst/codecparsers/gsth265bitwriter.c
 create mode 100644 gst-libs/gst/codecparsers/gsth265bitwriter.h
 create mode 100644 gst-libs/gst/webrtc/ice.c
 create mode 100644 gst-libs/gst/webrtc/ice.h
 create mode 100644 gst-libs/gst/webrtc/icestream.c
 create mode 100644 gst-libs/gst/webrtc/icestream.h
 create mode 100644 gst-libs/gst/webrtc/nice/meson.build
 create mode 100644 gst-libs/gst/webrtc/nice/nice.c
 create mode 100644 gst-libs/gst/webrtc/nice/nice.h
 create mode 100644 gst-libs/gst/webrtc/nice/nice_fwd.h
 create mode 100644 gst-libs/gst/webrtc/nice/nicestream.c
 create mode 100644 gst-libs/gst/webrtc/nice/nicestream.h
 create mode 100644 gst-libs/gst/webrtc/nice/nicetransport.c
 create mode 100644 gst-libs/gst/webrtc/nice/nicetransport.h
 create mode 100644 gst-libs/gst/webrtc/sctptransport.c
 create mode 100644 gst-libs/gst/webrtc/sctptransport.h
 create mode 100644 gst-libs/gst/webrtc/webrtc-priv.h
 create mode 100644 gst-libs/gst/webrtc/webrtc.c
 create mode 100644 gst/videoparsers/gstav1parse.c
 create mode 100644 gst/videoparsers/gstav1parse.h
 create mode 100644 gst/videoparsers/gstvideoparserselement.c
 create mode 100644 gst/videoparsers/gstvideoparserselements.h
 create mode 100644 gst/videoparsers/gstvp9parse.c
 create mode 100644 gst/videoparsers/gstvp9parse.h

diff --git a/ext/dtls/gstdtlsagent.c b/ext/dtls/gstdtlsagent.c
index 4070c7957..88cfa167f 100644
--- a/ext/dtls/gstdtlsagent.c
+++ b/ext/dtls/gstdtlsagent.c
@@ -58,7 +58,7 @@ struct _GstDtlsAgentPrivate
   GstDtlsCertificate *certificate;
 };
 
-G_DEFINE_TYPE_WITH_PRIVATE (GstDtlsAgent, gst_dtls_agent, G_TYPE_OBJECT);
+G_DEFINE_TYPE_WITH_PRIVATE (GstDtlsAgent, gst_dtls_agent, GST_TYPE_OBJECT);
 
 static void gst_dtls_agent_finalize (GObject * gobject);
 static void gst_dtls_agent_set_property (GObject *, guint prop_id,
diff --git a/ext/dtls/gstdtlsagent.h b/ext/dtls/gstdtlsagent.h
index fbfa1e860..b4a4e209b 100644
--- a/ext/dtls/gstdtlsagent.h
+++ b/ext/dtls/gstdtlsagent.h
@@ -28,7 +28,7 @@
 
 #include "gstdtlscertificate.h"
 
-#include <glib-object.h>
+#include <gst/gst.h>
 
 G_BEGIN_DECLS
 
@@ -52,13 +52,13 @@ typedef struct _GstDtlsAgentPrivate GstDtlsAgentPrivate;
  * GstDtlsAgent needs to be constructed with the "certificate" property set.
  */
 struct _GstDtlsAgent {
-    GObject parent_instance;
+    GstObject parent_instance;
 
     GstDtlsAgentPrivate *priv;
 };
 
 struct _GstDtlsAgentClass {
-    GObjectClass parent_class;
+    GstObjectClass parent_class;
 };
 
 GType gst_dtls_agent_get_type(void) G_GNUC_CONST;
diff --git a/ext/dtls/gstdtlscertificate.c b/ext/dtls/gstdtlscertificate.c
index d7411c8f4..9b31464b2 100644
--- a/ext/dtls/gstdtlscertificate.c
+++ b/ext/dtls/gstdtlscertificate.c
@@ -221,14 +221,24 @@ init_generated (GstDtlsCertificate * self)
 #if OPENSSL_VERSION_NUMBER < 0x10100001L
   rsa = RSA_generate_key (2048, RSA_F4, NULL, NULL);
 #else
+  /*
+   * OpenSSL 3.0 deprecated all low-level APIs, so we need to rewrite this code
+   * to get rid of the warnings. The porting guide explicitly recommends
+   * disabling the warnings if this is not feasible, so let's do that for now:
+   * https://wiki.openssl.org/index.php/OpenSSL_3.0#Upgrading_to_OpenSSL_3.0_from_OpenSSL_1.1.1
+   */
+  G_GNUC_BEGIN_IGNORE_DEPRECATIONS;
   rsa = RSA_new ();
+  G_GNUC_END_IGNORE_DEPRECATIONS;
   if (rsa != NULL) {
     BIGNUM *e = BN_new ();
+    G_GNUC_BEGIN_IGNORE_DEPRECATIONS;
     if (e == NULL || !BN_set_word (e, RSA_F4)
         || !RSA_generate_key_ex (rsa, 2048, e, NULL)) {
       RSA_free (rsa);
       rsa = NULL;
     }
+    G_GNUC_END_IGNORE_DEPRECATIONS;
     if (e)
       BN_free (e);
   }
@@ -236,16 +246,20 @@ init_generated (GstDtlsCertificate * self)
 
   if (!rsa) {
     GST_WARNING_OBJECT (self, "failed to generate RSA");
+    G_GNUC_BEGIN_IGNORE_DEPRECATIONS;
     EVP_PKEY_free (priv->private_key);
+    G_GNUC_END_IGNORE_DEPRECATIONS;
     priv->private_key = NULL;
     X509_free (priv->x509);
     priv->x509 = NULL;
     return;
   }
 
+  G_GNUC_BEGIN_IGNORE_DEPRECATIONS;
   if (!EVP_PKEY_assign_RSA (priv->private_key, rsa)) {
     GST_WARNING_OBJECT (self, "failed to assign RSA");
     RSA_free (rsa);
+    G_GNUC_END_IGNORE_DEPRECATIONS;
     rsa = NULL;
     EVP_PKEY_free (priv->private_key);
     priv->private_key = NULL;
@@ -259,7 +273,9 @@ init_generated (GstDtlsCertificate * self)
 
   /* Set a random 64 bit integer as serial number */
   serial_number = BN_new ();
+  G_GNUC_BEGIN_IGNORE_DEPRECATIONS;
   BN_pseudo_rand (serial_number, 64, 0, 0);
+  G_GNUC_END_IGNORE_DEPRECATIONS;
   asn1_serial_number = X509_get_serialNumber (priv->x509);
   BN_to_ASN1_INTEGER (serial_number, asn1_serial_number);
   BN_free (serial_number);
diff --git a/ext/dtls/gstdtlsconnection.c b/ext/dtls/gstdtlsconnection.c
index 1c8364a66..4fadde130 100644
--- a/ext/dtls/gstdtlsconnection.c
+++ b/ext/dtls/gstdtlsconnection.c
@@ -101,13 +101,14 @@ struct _GstDtlsConnectionPrivate
   GstDtlsConnectionSendCallback send_callback;
   gpointer send_callback_user_data;
   GDestroyNotify send_callback_destroy_notify;
+  GstFlowReturn syscall_flow_return;
 
   gboolean timeout_pending;
   GThreadPool *thread_pool;
 };
 
-G_DEFINE_TYPE_WITH_CODE (GstDtlsConnection, gst_dtls_connection, G_TYPE_OBJECT,
-    G_ADD_PRIVATE (GstDtlsConnection)
+G_DEFINE_TYPE_WITH_CODE (GstDtlsConnection, gst_dtls_connection,
+    GST_TYPE_OBJECT, G_ADD_PRIVATE (GstDtlsConnection)
     GST_DEBUG_CATEGORY_INIT (gst_dtls_connection_debug, "dtlsconnection", 0,
         "DTLS Connection"));
 
@@ -600,6 +601,14 @@ gst_dtls_connection_set_send_callback (GstDtlsConnection * self,
   g_mutex_unlock (&priv->mutex);
 }
 
+void
+gst_dtls_connection_set_flow_return (GstDtlsConnection * self,
+    GstFlowReturn flow_ret)
+{
+  g_return_if_fail (GST_IS_DTLS_CONNECTION (self));
+  self->priv->syscall_flow_return = flow_ret;
+}
+
 GstFlowReturn
 gst_dtls_connection_process (GstDtlsConnection * self, gpointer data, gsize len,
     gsize * written, GError ** err)
@@ -1002,13 +1011,19 @@ handle_error (GstDtlsConnection * self, int ret, GstResourceError error_type,
     case SSL_ERROR_WANT_WRITE:
       GST_LOG_OBJECT (self, "SSL wants write");
       return GST_FLOW_OK;
-    case SSL_ERROR_SYSCALL:
+    case SSL_ERROR_SYSCALL:{
+      GstFlowReturn rc = GST_FLOW_OK;
       /* OpenSSL shouldn't be making real system calls, so we can safely
        * ignore syscall errors. System interactions should happen through
        * our BIO.
        */
-      GST_DEBUG_OBJECT (self, "OpenSSL reported a syscall error, ignoring.");
-      return GST_FLOW_OK;
+      if (error_type == GST_RESOURCE_ERROR_WRITE) {
+        rc = self->priv->syscall_flow_return;
+      }
+      GST_DEBUG_OBJECT (self,
+          "OpenSSL reported a syscall error. flow_return=%i", rc);
+      return rc;
+    }
     default:
       if (self->priv->connection_state != GST_DTLS_CONNECTION_STATE_FAILED) {
         self->priv->connection_state = GST_DTLS_CONNECTION_STATE_FAILED;
@@ -1182,6 +1197,7 @@ bio_method_write (BIO * bio, const char *data, int size)
   gboolean ret = TRUE;
 
   GST_LOG_OBJECT (self, "BIO: writing %d", size);
+  self->priv->syscall_flow_return = GST_FLOW_OK;
 
   if (self->priv->send_callback)
     ret = self->priv->send_callback (self, data, size,
diff --git a/ext/dtls/gstdtlsconnection.h b/ext/dtls/gstdtlsconnection.h
index b590486b9..82234fafd 100644
--- a/ext/dtls/gstdtlsconnection.h
+++ b/ext/dtls/gstdtlsconnection.h
@@ -85,13 +85,13 @@ GType gst_dtls_connection_state_get_type (void);
  * Once the DTLS handshake is completed, on-encoder-key and on-decoder-key will be signalled.
  */
 struct _GstDtlsConnection {
-    GObject parent_instance;
+    GstObject parent_instance;
 
     GstDtlsConnectionPrivate *priv;
 };
 
 struct _GstDtlsConnectionClass {
-    GObjectClass parent_class;
+    GstObjectClass parent_class;
 };
 
 GType gst_dtls_connection_get_type(void) G_GNUC_CONST;
@@ -118,6 +118,11 @@ typedef gboolean (*GstDtlsConnectionSendCallback) (GstDtlsConnection * connectio
  */
 void gst_dtls_connection_set_send_callback(GstDtlsConnection *, GstDtlsConnectionSendCallback, gpointer, GDestroyNotify);
 
+/*
+ * Sets the GstFlowReturn that be returned from gst_dtls_connection_send() if callback returns FALSE
+ */
+void gst_dtls_connection_set_flow_return(GstDtlsConnection *, GstFlowReturn);
+
 /*
  * Processes data that has been received, the transformation is done in-place.
  *
@@ -142,6 +147,7 @@ GstFlowReturn gst_dtls_connection_process(GstDtlsConnection *, gpointer ptr, gsi
  *     we received an EOS before.
  *   - GST_FLOW_ERROR + err if an error happened
  *   - GST_FLOW_OK + written >= 0 if processing was successful
+ *   - Any GstFlowReturn set with gst_dtls_connection_set_flow_return()
  */
 GstFlowReturn gst_dtls_connection_send(GstDtlsConnection *, gconstpointer ptr, gsize len, gsize *written, GError **err);
 
diff --git a/ext/dtls/gstdtlsdec.c b/ext/dtls/gstdtlsdec.c
index 7b370e26b..ca9f8fd6b 100644
--- a/ext/dtls/gstdtlsdec.c
+++ b/ext/dtls/gstdtlsdec.c
@@ -27,6 +27,7 @@
 #include "config.h"
 #endif
 
+#include "gstdtlselements.h"
 #include "gstdtlsdec.h"
 
 #include "gstdtlscertificate.h"
@@ -48,6 +49,8 @@ GST_DEBUG_CATEGORY_STATIC (gst_dtls_dec_debug);
 #define gst_dtls_dec_parent_class parent_class
 G_DEFINE_TYPE_WITH_CODE (GstDtlsDec, gst_dtls_dec, GST_TYPE_ELEMENT,
     GST_DEBUG_CATEGORY_INIT (gst_dtls_dec_debug, "dtlsdec", 0, "DTLS Decoder"));
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (dtlsdec, "dtlsdec", GST_RANK_NONE,
+    GST_TYPE_DTLS_DEC, dtls_element_init (plugin));
 
 enum
 {
@@ -422,7 +425,7 @@ static void
 on_key_received (GstDtlsConnection * connection, gpointer key, guint cipher,
     guint auth, GstDtlsDec * self)
 {
-  gpointer key_dup;
+  GstBuffer *new_decoder_key;
   gchar *key_str;
 
   g_return_if_fail (GST_IS_DTLS_DEC (self));
@@ -430,15 +433,13 @@ on_key_received (GstDtlsConnection * connection, gpointer key, guint cipher,
   self->srtp_cipher = cipher;
   self->srtp_auth = auth;
 
-  key_dup = g_memdup (key, GST_DTLS_SRTP_MASTER_KEY_LENGTH);
+  new_decoder_key =
+      gst_buffer_new_memdup (key, GST_DTLS_SRTP_MASTER_KEY_LENGTH);
 
-  if (self->decoder_key) {
+  if (self->decoder_key)
     gst_buffer_unref (self->decoder_key);
-    self->decoder_key = NULL;
-  }
 
-  self->decoder_key =
-      gst_buffer_new_wrapped (key_dup, GST_DTLS_SRTP_MASTER_KEY_LENGTH);
+  self->decoder_key = new_decoder_key;
 
   key_str = g_base64_encode (key, GST_DTLS_SRTP_MASTER_KEY_LENGTH);
   GST_INFO_OBJECT (self, "received key: %s", key_str);
diff --git a/ext/dtls/gstdtlselement.c b/ext/dtls/gstdtlselement.c
new file mode 100644
index 000000000..6945339f9
--- /dev/null
+++ b/ext/dtls/gstdtlselement.c
@@ -0,0 +1,44 @@
+/*
+ * Copyright (c) 2014, Ericsson AB. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without modification,
+ * are permitted provided that the following conditions are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright notice, this
+ * list of conditions and the following disclaimer.
+ *
+ * 2. Redistributions in binary form must reproduce the above copyright notice, this
+ * list of conditions and the following disclaimer in the documentation and/or other
+ * materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
+ * IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
+ * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY
+ * OF SUCH DAMAGE.
+ */
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include "gstdtlselements.h"
+#include "gstdtlsconnection.h"
+
+
+#include <gst/gst.h>
+
+void
+dtls_element_init (GstPlugin * plugin)
+{
+  static gsize res = FALSE;
+  if (g_once_init_enter (&res)) {
+    gst_type_mark_as_plugin_api (GST_DTLS_TYPE_CONNECTION_STATE, 0);
+    g_once_init_leave (&res, TRUE);
+  }
+}
diff --git a/ext/dtls/gstdtlselements.h b/ext/dtls/gstdtlselements.h
new file mode 100644
index 000000000..50d03284d
--- /dev/null
+++ b/ext/dtls/gstdtlselements.h
@@ -0,0 +1,38 @@
+/* GStreamer
+ * Copyright (C) <2020> The Gstreamer Contributors.
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+
+#ifndef __GST_DTLS_ELEMENTS_H__
+#define __GST_DTLS_ELEMENTS_H__
+
+#ifdef HAVE_CONFIG_H
+#include <config.h>
+#endif
+
+#include <gst/gst.h>
+
+void dtls_element_init (GstPlugin * plugin);
+
+GST_ELEMENT_REGISTER_DECLARE (dtlsdec);
+GST_ELEMENT_REGISTER_DECLARE (dtlsenc);
+GST_ELEMENT_REGISTER_DECLARE (dtlssrtpdec);
+GST_ELEMENT_REGISTER_DECLARE (dtlssrtpdemux);
+GST_ELEMENT_REGISTER_DECLARE (dtlssrtpenc);
+
+#endif /* __GST_DTLS_ELEMENT_H__ */
diff --git a/ext/dtls/gstdtlsenc.c b/ext/dtls/gstdtlsenc.c
index e64ee4d6c..d344b96ea 100644
--- a/ext/dtls/gstdtlsenc.c
+++ b/ext/dtls/gstdtlsenc.c
@@ -27,6 +27,7 @@
 #include "config.h"
 #endif
 
+#include "gstdtlselements.h"
 #include "gstdtlsenc.h"
 
 #include "gstdtlsdec.h"
@@ -48,6 +49,8 @@ GST_DEBUG_CATEGORY_STATIC (gst_dtls_enc_debug);
 #define gst_dtls_enc_parent_class parent_class
 G_DEFINE_TYPE_WITH_CODE (GstDtlsEnc, gst_dtls_enc, GST_TYPE_ELEMENT,
     GST_DEBUG_CATEGORY_INIT (gst_dtls_enc_debug, "dtlsenc", 0, "DTLS Encoder"));
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (dtlsenc, "dtlsenc", GST_RANK_NONE,
+    GST_TYPE_DTLS_ENC, dtls_element_init (plugin));
 
 enum
 {
@@ -562,6 +565,9 @@ sink_chain (GstPad * pad, GstObject * parent, GstBuffer * buffer)
         GST_ELEMENT_ERROR (self, RESOURCE, WRITE, (NULL), ("%s", err->message));
         g_clear_error (&err);
         break;
+      case GST_FLOW_FLUSHING:
+        GST_INFO_OBJECT (self, "Flushing");
+        break;
       default:
         g_assert_not_reached ();
         break;
@@ -626,7 +632,7 @@ static void
 on_key_received (GstDtlsConnection * connection, gpointer key, guint cipher,
     guint auth, GstDtlsEnc * self)
 {
-  gpointer key_dup;
+  GstBuffer *new_encoder_key;
   gchar *key_str;
 
   g_return_if_fail (GST_IS_DTLS_ENC (self));
@@ -635,15 +641,13 @@ on_key_received (GstDtlsConnection * connection, gpointer key, guint cipher,
   self->srtp_cipher = cipher;
   self->srtp_auth = auth;
 
-  key_dup = g_memdup (key, GST_DTLS_SRTP_MASTER_KEY_LENGTH);
+  new_encoder_key =
+      gst_buffer_new_memdup (key, GST_DTLS_SRTP_MASTER_KEY_LENGTH);
 
-  if (self->encoder_key) {
+  if (self->encoder_key)
     gst_buffer_unref (self->encoder_key);
-    self->encoder_key = NULL;
-  }
 
-  self->encoder_key =
-      gst_buffer_new_wrapped (key_dup, GST_DTLS_SRTP_MASTER_KEY_LENGTH);
+  self->encoder_key = new_encoder_key;
 
   key_str = g_base64_encode (key, GST_DTLS_SRTP_MASTER_KEY_LENGTH);
   GST_INFO_OBJECT (self, "received key: %s", key_str);
@@ -662,8 +666,7 @@ on_send_data (GstDtlsConnection * connection, gconstpointer data, gsize length,
   GST_DEBUG_OBJECT (self, "sending data from %s with length %" G_GSIZE_FORMAT,
       self->connection_id, length);
 
-  buffer =
-      data ? gst_buffer_new_wrapped (g_memdup (data, length), length) : NULL;
+  buffer = data ? gst_buffer_new_memdup (data, length) : NULL;
 
   GST_TRACE_OBJECT (self, "send data: acquiring lock");
   g_mutex_lock (&self->queue_lock);
@@ -677,6 +680,8 @@ on_send_data (GstDtlsConnection * connection, gconstpointer data, gsize length,
   GST_TRACE_OBJECT (self, "send data: releasing lock");
 
   ret = self->src_ret == GST_FLOW_OK;
+  if (self->src_ret == GST_FLOW_FLUSHING)
+    gst_dtls_connection_set_flow_return (connection, self->src_ret);
   g_mutex_unlock (&self->queue_lock);
 
   return ret;
diff --git a/ext/dtls/gstdtlssrtpbin.c b/ext/dtls/gstdtlssrtpbin.c
index acbac30ea..2a786e9c5 100644
--- a/ext/dtls/gstdtlssrtpbin.c
+++ b/ext/dtls/gstdtlssrtpbin.c
@@ -218,7 +218,8 @@ gst_dtls_srtp_bin_get_property (GObject * object,
         g_object_get_property (G_OBJECT (self->dtls_element), "connection-id",
             value);
       } else {
-        g_warning ("tried to get connection-id after disabling DTLS");
+        GST_WARNING_OBJECT (self,
+            "tried to get connection-id after disabling DTLS");
       }
       break;
     case PROP_KEY:
diff --git a/ext/dtls/gstdtlssrtpdec.c b/ext/dtls/gstdtlssrtpdec.c
index 72abfdacb..f441e253f 100644
--- a/ext/dtls/gstdtlssrtpdec.c
+++ b/ext/dtls/gstdtlssrtpdec.c
@@ -27,6 +27,7 @@
 #include "config.h"
 #endif
 
+#include "gstdtlselements.h"
 #include "gstdtlssrtpdec.h"
 #include "gstdtlsconnection.h"
 
@@ -61,7 +62,9 @@ GST_DEBUG_CATEGORY_STATIC (gst_dtls_srtp_dec_debug);
 #define gst_dtls_srtp_dec_parent_class parent_class
 G_DEFINE_TYPE_WITH_CODE (GstDtlsSrtpDec, gst_dtls_srtp_dec,
     GST_TYPE_DTLS_SRTP_BIN, GST_DEBUG_CATEGORY_INIT (gst_dtls_srtp_dec_debug,
-        "dtlssrtpdec", 0, "DTLS Decoder"));
+        "dtlssrtpdec", 0, "DTLS-SRTP Decoder"));
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (dtlssrtpdec, "dtlssrtpdec",
+    GST_RANK_NONE, GST_TYPE_DTLS_SRTP_DEC, dtls_element_init (plugin));
 
 enum
 {
@@ -288,8 +291,13 @@ gst_dtls_srtp_dec_get_property (GObject * object,
       }
       break;
     case PROP_CONNECTION_STATE:
-      g_object_get_property (G_OBJECT (self->bin.dtls_element),
-          "connection-state", value);
+      if (self->bin.dtls_element) {
+        g_object_get_property (G_OBJECT (self->bin.dtls_element),
+            "connection-state", value);
+      } else {
+        GST_WARNING_OBJECT (self,
+            "tried to get connection-state after disabling DTLS");
+      }
       break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (self, prop_id, pspec);
@@ -313,7 +321,7 @@ gst_dtls_srtp_dec_request_new_pad (GstElement * element,
   if (templ == gst_element_class_get_pad_template (klass, "data_src")) {
     GstPad *target_pad;
 
-    target_pad = gst_element_get_request_pad (self->bin.dtls_element, "src");
+    target_pad = gst_element_request_pad_simple (self->bin.dtls_element, "src");
 
     ghost_pad = gst_ghost_pad_new_from_template (name, target_pad, templ);
     gst_object_unref (target_pad);
diff --git a/ext/dtls/gstdtlssrtpdemux.c b/ext/dtls/gstdtlssrtpdemux.c
index ab1ef7082..ca7985be1 100644
--- a/ext/dtls/gstdtlssrtpdemux.c
+++ b/ext/dtls/gstdtlssrtpdemux.c
@@ -27,6 +27,7 @@
 #include "config.h"
 #endif
 
+#include "gstdtlselements.h"
 #include "gstdtlssrtpdemux.h"
 
 #define PACKET_IS_DTLS(b) (b > 0x13 && b < 0x40)
@@ -59,6 +60,9 @@ GST_DEBUG_CATEGORY_STATIC (gst_gst_dtls_srtp_demux_debug);
 G_DEFINE_TYPE_WITH_CODE (GstDtlsSrtpDemux, gst_dtls_srtp_demux,
     GST_TYPE_ELEMENT, GST_DEBUG_CATEGORY_INIT (gst_gst_dtls_srtp_demux_debug,
         "dtlssrtpdemux", 0, "DTLS SRTP Demultiplexer"));
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (dtlssrtpdemux, "dtlssrtpdemux",
+    GST_RANK_NONE, GST_TYPE_DTLS_SRTP_DEMUX, dtls_element_init (plugin));
+
 
 static GstFlowReturn sink_chain (GstPad *, GstObject * self, GstBuffer *);
 
diff --git a/ext/dtls/gstdtlssrtpenc.c b/ext/dtls/gstdtlssrtpenc.c
index 283ad9db6..8653151c3 100644
--- a/ext/dtls/gstdtlssrtpenc.c
+++ b/ext/dtls/gstdtlssrtpenc.c
@@ -27,6 +27,7 @@
 #include "config.h"
 #endif
 
+#include "gstdtlselements.h"
 #include "gstdtlssrtpenc.h"
 #include "gstdtlsconnection.h"
 
@@ -62,8 +63,11 @@ GST_DEBUG_CATEGORY_STATIC (gst_dtls_srtp_enc_debug);
 
 #define gst_dtls_srtp_enc_parent_class parent_class
 G_DEFINE_TYPE_WITH_CODE (GstDtlsSrtpEnc, gst_dtls_srtp_enc,
-    GST_TYPE_DTLS_SRTP_BIN, GST_DEBUG_CATEGORY_INIT (gst_dtls_srtp_enc_debug,
-        "dtlssrtpenc", 0, "DTLS Decoder"));
+    GST_TYPE_DTLS_SRTP_BIN,
+    GST_DEBUG_CATEGORY_INIT (gst_dtls_srtp_enc_debug,
+        "dtlssrtpenc", 0, "DTLS-SRTP Encoder"));
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (dtlssrtpenc, "dtlssrtpenc",
+    GST_RANK_NONE, GST_TYPE_DTLS_SRTP_ENC, dtls_element_init (plugin));
 
 enum
 {
@@ -265,12 +269,21 @@ gst_dtls_srtp_enc_init (GstDtlsSrtpEnc * self)
       NULL, auth_enum_class, NULL);
 }
 
+#if GLIB_CHECK_VERSION(2,68,0)
+#define binding_get_source(b) g_binding_dup_source(b)
+#define unref_source(s) G_STMT_START { if(s) g_object_unref(s); } G_STMT_END
+#else
+#define binding_get_source(b) g_binding_get_source(b)
+#define unref_source(s)         /* no op */
+#endif
+
 static gboolean
 transform_enum (GBinding * binding, const GValue * source_value,
     GValue * target_value, GEnumClass * enum_class)
 {
   GEnumValue *enum_value;
   const gchar *nick;
+  GObject *bind_src;
 
   nick = g_value_get_string (source_value);
   g_return_val_if_fail (nick, FALSE);
@@ -278,9 +291,13 @@ transform_enum (GBinding * binding, const GValue * source_value,
   enum_value = g_enum_get_value_by_nick (enum_class, nick);
   g_return_val_if_fail (enum_value, FALSE);
 
-  GST_DEBUG_OBJECT (g_binding_get_source (binding),
+  bind_src = binding_get_source (binding);
+
+  GST_DEBUG_OBJECT (bind_src,
       "transforming enum from %s to %d", nick, enum_value->value);
 
+  unref_source (bind_src);
+
   g_value_set_enum (target_value, enum_value->value);
 
   return TRUE;
@@ -327,8 +344,13 @@ gst_dtls_srtp_enc_get_property (GObject * object,
       }
       break;
     case PROP_CONNECTION_STATE:
-      g_object_get_property (G_OBJECT (self->bin.dtls_element),
-          "connection-state", value);
+      if (self->bin.dtls_element) {
+        g_object_get_property (G_OBJECT (self->bin.dtls_element),
+            "connection-state", value);
+      } else {
+        GST_WARNING_OBJECT (self,
+            "tried to get connection-state after disabling DTLS");
+      }
       break;
     case PROP_RTP_SYNC:
       g_value_set_boolean (value, self->rtp_sync);
@@ -394,7 +416,7 @@ gst_dtls_srtp_enc_request_new_pad (GstElement * element,
     gst_bin_add (GST_BIN (self), clocksync);
     gst_element_sync_state_with_parent (clocksync);
 
-    target_pad = gst_element_get_request_pad (self->srtp_enc, name);
+    target_pad = gst_element_request_pad_simple (self->srtp_enc, name);
     g_return_val_if_fail (target_pad, NULL);
 
     srtp_src_name = g_strdup_printf ("rtp_src_%d", pad_n);
@@ -409,7 +431,7 @@ gst_dtls_srtp_enc_request_new_pad (GstElement * element,
     GST_LOG_OBJECT (self, "added rtp sink pad");
   } else if (templ == gst_element_class_get_pad_template (klass,
           "rtcp_sink_%d")) {
-    target_pad = gst_element_get_request_pad (self->srtp_enc, name);
+    target_pad = gst_element_request_pad_simple (self->srtp_enc, name);
     g_return_val_if_fail (target_pad, NULL);
 
     sscanf (GST_PAD_NAME (target_pad), "rtcp_sink_%d", &pad_n);
@@ -424,7 +446,8 @@ gst_dtls_srtp_enc_request_new_pad (GstElement * element,
     GST_LOG_OBJECT (self, "added rtcp sink pad");
   } else if (templ == gst_element_class_get_pad_template (klass, "data_sink")) {
     g_return_val_if_fail (self->bin.dtls_element, NULL);
-    target_pad = gst_element_get_request_pad (self->bin.dtls_element, "sink");
+    target_pad =
+        gst_element_request_pad_simple (self->bin.dtls_element, "sink");
 
     ghost_pad = add_ghost_pad (element, name, target_pad, templ);
 
diff --git a/ext/dtls/meson.build b/ext/dtls/meson.build
index 74babae17..afdd8d224 100644
--- a/ext/dtls/meson.build
+++ b/ext/dtls/meson.build
@@ -9,6 +9,7 @@ dtls_sources = [
   'gstdtlssrtpdemux.c',
   'gstdtlssrtpenc.c',
   'plugin.c',
+  'gstdtlselement.c',
 ]
 
 openssl_dep = dependency('openssl', version : '>= 1.0.1', required : get_option('dtls'))
@@ -23,6 +24,5 @@ if openssl_dep.found() and libcrypto_dep.found()
     install : true,
     install_dir : plugins_install_dir,
   )
-  pkgconfig.generate(gstdtls, install_dir : plugins_pkgconfig_install_dir)
   plugins += [gstdtls]
 endif
diff --git a/ext/dtls/plugin.c b/ext/dtls/plugin.c
index 78a998060..679744965 100644
--- a/ext/dtls/plugin.c
+++ b/ext/dtls/plugin.c
@@ -27,29 +27,22 @@
 #include "config.h"
 #endif
 
-#include "gstdtlsdec.h"
-#include "gstdtlsenc.h"
-#include "gstdtlssrtpenc.h"
-#include "gstdtlssrtpdec.h"
-#include "gstdtlssrtpdemux.h"
-
 #include <gst/gst.h>
 
+#include "gstdtlselements.h"
+
 static gboolean
 plugin_init (GstPlugin * plugin)
 {
-  gst_type_mark_as_plugin_api (GST_DTLS_TYPE_CONNECTION_STATE, 0);
+  gboolean ret = FALSE;
+
+  ret |= GST_ELEMENT_REGISTER (dtlsenc, plugin);
+  ret |= GST_ELEMENT_REGISTER (dtlsdec, plugin);
+  ret |= GST_ELEMENT_REGISTER (dtlssrtpdec, plugin);
+  ret |= GST_ELEMENT_REGISTER (dtlssrtpenc, plugin);
+  ret |= GST_ELEMENT_REGISTER (dtlssrtpdemux, plugin);
 
-  return gst_element_register (plugin, "dtlsenc", GST_RANK_NONE,
-      GST_TYPE_DTLS_ENC)
-      && gst_element_register (plugin, "dtlsdec", GST_RANK_NONE,
-      GST_TYPE_DTLS_DEC)
-      && gst_element_register (plugin, "dtlssrtpdec", GST_RANK_NONE,
-      GST_TYPE_DTLS_SRTP_DEC)
-      && gst_element_register (plugin, "dtlssrtpenc", GST_RANK_NONE,
-      GST_TYPE_DTLS_SRTP_ENC)
-      && gst_element_register (plugin, "dtlssrtpdemux", GST_RANK_NONE,
-      GST_TYPE_DTLS_SRTP_DEMUX);
+  return ret;
 }
 
 GST_PLUGIN_DEFINE (GST_VERSION_MAJOR,
diff --git a/ext/sctp/gstsctpdec.c b/ext/sctp/gstsctpdec.c
index c9f6d0827..a90f89428 100644
--- a/ext/sctp/gstsctpdec.c
+++ b/ext/sctp/gstsctpdec.c
@@ -39,6 +39,8 @@ GST_DEBUG_CATEGORY_STATIC (gst_sctp_dec_debug_category);
 
 #define gst_sctp_dec_parent_class parent_class
 G_DEFINE_TYPE (GstSctpDec, gst_sctp_dec, GST_TYPE_ELEMENT);
+GST_ELEMENT_REGISTER_DEFINE (sctpdec, "sctpdec", GST_RANK_NONE,
+    GST_TYPE_SCTP_DEC);
 
 static GstStaticPadTemplate sink_template =
 GST_STATIC_PAD_TEMPLATE ("sink", GST_PAD_SINK,
@@ -604,8 +606,11 @@ static void
 remove_pad (GstSctpDec * self, GstPad * pad)
 {
   stop_srcpad_task (pad);
+  GST_PAD_STREAM_LOCK (pad);
   gst_pad_set_active (pad, FALSE);
-  gst_element_remove_pad (GST_ELEMENT (self), pad);
+  if (gst_object_has_as_parent (GST_OBJECT (pad), GST_OBJECT (self)))
+    gst_element_remove_pad (GST_ELEMENT (self), pad);
+  GST_PAD_STREAM_UNLOCK (pad);
   GST_OBJECT_LOCK (self);
   gst_flow_combiner_remove_pad (self->flow_combiner, pad);
   GST_OBJECT_UNLOCK (self);
@@ -624,8 +629,14 @@ on_gst_sctp_association_stream_reset (GstSctpAssociation * gst_sctp_association,
   srcpad = gst_element_get_static_pad (GST_ELEMENT (self), pad_name);
   g_free (pad_name);
   if (!srcpad) {
-    GST_WARNING_OBJECT (self, "Reset called on stream without a srcpad");
-    return;
+    /* This can happen if a stream is created but the peer never sends any data.
+     * We still need to signal the reset by removing the relevant pad.  To do
+     * that, we need to add the relevant pad first. */
+    srcpad = get_pad_for_stream_id (self, stream_id);
+    if (!srcpad) {
+      GST_WARNING_OBJECT (self, "Reset called on stream without a srcpad");
+      return;
+    }
   }
   remove_pad (self, srcpad);
   gst_object_unref (srcpad);
diff --git a/ext/sctp/gstsctpdec.h b/ext/sctp/gstsctpdec.h
index 6a5591f55..c6c898657 100644
--- a/ext/sctp/gstsctpdec.h
+++ b/ext/sctp/gstsctpdec.h
@@ -63,6 +63,7 @@ struct _GstSctpDecClass
 };
 
 GType gst_sctp_dec_get_type (void);
+GST_ELEMENT_REGISTER_DECLARE (sctpdec);
 
 G_END_DECLS
 
diff --git a/ext/sctp/gstsctpenc.c b/ext/sctp/gstsctpenc.c
index 41590b9fc..3d9406809 100644
--- a/ext/sctp/gstsctpenc.c
+++ b/ext/sctp/gstsctpenc.c
@@ -36,6 +36,8 @@ GST_DEBUG_CATEGORY_STATIC (gst_sctp_enc_debug_category);
 
 #define gst_sctp_enc_parent_class parent_class
 G_DEFINE_TYPE (GstSctpEnc, gst_sctp_enc, GST_TYPE_ELEMENT);
+GST_ELEMENT_REGISTER_DEFINE (sctpenc, "sctpenc", GST_RANK_NONE,
+    GST_TYPE_SCTP_ENC);
 
 static GstStaticPadTemplate sink_template =
 GST_STATIC_PAD_TEMPLATE ("sink_%u", GST_PAD_SINK,
@@ -101,6 +103,7 @@ struct _GstSctpEncPad
   GMutex lock;
   GCond cond;
   gboolean flushing;
+  gboolean clear_to_send;
 };
 
 G_DEFINE_TYPE (GstSctpEncPad, gst_sctp_enc_pad, GST_TYPE_PAD);
@@ -130,6 +133,7 @@ gst_sctp_enc_pad_init (GstSctpEncPad * self)
   g_mutex_init (&self->lock);
   g_cond_init (&self->cond);
   self->flushing = FALSE;
+  self->clear_to_send = FALSE;
 }
 
 static void gst_sctp_enc_finalize (GObject * object);
@@ -481,7 +485,10 @@ gst_sctp_enc_release_pad (GstElement * element, GstPad * pad)
   if (self->sctp_association)
     gst_sctp_association_reset_stream (self->sctp_association, stream_id);
 
-  gst_element_remove_pad (element, pad);
+  GST_PAD_STREAM_LOCK (pad);
+  if (gst_object_has_as_parent (GST_OBJECT (pad), GST_OBJECT (element)))
+    gst_element_remove_pad (element, pad);
+  GST_PAD_STREAM_UNLOCK (pad);
 }
 
 static void
@@ -558,6 +565,7 @@ gst_sctp_enc_sink_chain (GstPad * pad, GstObject * parent, GstBuffer * buffer)
 {
   GstSctpEnc *self = GST_SCTP_ENC (parent);
   GstSctpEncPad *sctpenc_pad = GST_SCTP_ENC_PAD (pad);
+  GstSctpEncPad *sctpenc_pad_next = NULL;
   GstMapInfo map;
   guint32 ppid;
   gboolean ordered;
@@ -569,6 +577,7 @@ gst_sctp_enc_sink_chain (GstPad * pad, GstObject * parent, GstBuffer * buffer)
   GstFlowReturn flow_ret = GST_FLOW_ERROR;
   const guint8 *data;
   guint32 length;
+  gboolean clear_to_send;
 
   GST_OBJECT_LOCK (self);
   if (self->src_ret != GST_FLOW_OK) {
@@ -624,7 +633,21 @@ gst_sctp_enc_sink_chain (GstPad * pad, GstObject * parent, GstBuffer * buffer)
   data = map.data;
   length = map.size;
 
+  GST_OBJECT_LOCK (self);
+  clear_to_send = g_queue_is_empty (&self->pending_pads);
+  g_queue_push_tail (&self->pending_pads, sctpenc_pad);
+  GST_OBJECT_UNLOCK (self);
+
   g_mutex_lock (&sctpenc_pad->lock);
+
+  if (clear_to_send) {
+    sctpenc_pad->clear_to_send = TRUE;
+  }
+
+  while (!sctpenc_pad->flushing && !sctpenc_pad->clear_to_send) {
+    g_cond_wait (&sctpenc_pad->cond, &sctpenc_pad->lock);
+  }
+
   while (!sctpenc_pad->flushing) {
     guint32 bytes_sent;
 
@@ -653,15 +676,8 @@ gst_sctp_enc_sink_chain (GstPad * pad, GstObject * parent, GstBuffer * buffer)
       length -= bytes_sent;
 
       /* The buffer was probably full. Retry in a while */
-      GST_OBJECT_LOCK (self);
-      g_queue_push_tail (&self->pending_pads, sctpenc_pad);
-      GST_OBJECT_UNLOCK (self);
-
       g_cond_wait_until (&sctpenc_pad->cond, &sctpenc_pad->lock, end_time);
 
-      GST_OBJECT_LOCK (self);
-      g_queue_remove (&self->pending_pads, sctpenc_pad);
-      GST_OBJECT_UNLOCK (self);
     } else if (bytes_sent == length) {
       GST_DEBUG_OBJECT (pad, "Successfully sent buffer");
       sctpenc_pad->bytes_sent += bytes_sent;
@@ -671,8 +687,21 @@ gst_sctp_enc_sink_chain (GstPad * pad, GstObject * parent, GstBuffer * buffer)
   flow_ret = sctpenc_pad->flushing ? GST_FLOW_FLUSHING : GST_FLOW_OK;
 
 out:
+  sctpenc_pad->clear_to_send = FALSE;
   g_mutex_unlock (&sctpenc_pad->lock);
 
+  GST_OBJECT_LOCK (self);
+  g_queue_remove (&self->pending_pads, sctpenc_pad);
+  sctpenc_pad_next = g_queue_peek_head (&self->pending_pads);
+  GST_OBJECT_UNLOCK (self);
+
+  if (sctpenc_pad_next) {
+    g_mutex_lock (&sctpenc_pad_next->lock);
+    sctpenc_pad_next->clear_to_send = TRUE;
+    g_cond_signal (&sctpenc_pad_next->cond);
+    g_mutex_unlock (&sctpenc_pad_next->lock);
+  }
+
   gst_buffer_unmap (buffer, &map);
 error:
   gst_buffer_unref (buffer);
@@ -885,13 +914,12 @@ on_sctp_packet_out (GstSctpAssociation * _association, const guint8 * buf,
   GstSctpEnc *self = user_data;
   GstBuffer *gstbuf;
   GstDataQueueItem *item;
-  GList *pending_pads, *l;
   GstSctpEncPad *sctpenc_pad;
 
   GST_DEBUG_OBJECT (self, "Received output packet of size %" G_GSIZE_FORMAT,
       length);
 
-  gstbuf = gst_buffer_new_wrapped (g_memdup (buf, length), length);
+  gstbuf = gst_buffer_new_memdup (buf, length);
 
   item = g_new0 (GstDataQueueItem, 1);
   item->object = GST_MINI_OBJECT (gstbuf);
@@ -904,21 +932,22 @@ on_sctp_packet_out (GstSctpAssociation * _association, const guint8 * buf,
     GST_DEBUG_OBJECT (self, "Failed to push item because we're flushing");
   }
 
-  /* Wake up pads in the order they waited, oldest pad first */
+  /* Wake up the oldest pad which is the one that needs to finish first */
   GST_OBJECT_LOCK (self);
-  pending_pads = NULL;
-  while ((sctpenc_pad = g_queue_pop_tail (&self->pending_pads))) {
-    pending_pads = g_list_prepend (pending_pads, sctpenc_pad);
-  }
-  GST_OBJECT_UNLOCK (self);
+  sctpenc_pad = g_queue_peek_head (&self->pending_pads);
+  if (sctpenc_pad) {
+    gst_object_ref (sctpenc_pad);
+
+    GST_OBJECT_UNLOCK (self);
 
-  for (l = pending_pads; l; l = l->next) {
-    sctpenc_pad = l->data;
     g_mutex_lock (&sctpenc_pad->lock);
     g_cond_signal (&sctpenc_pad->cond);
     g_mutex_unlock (&sctpenc_pad->lock);
+
+    gst_object_unref (sctpenc_pad);
+  } else {
+    GST_OBJECT_UNLOCK (self);
   }
-  g_list_free (pending_pads);
 }
 
 static void
diff --git a/ext/sctp/gstsctpenc.h b/ext/sctp/gstsctpenc.h
index fd4e28e4f..482473d74 100644
--- a/ext/sctp/gstsctpenc.h
+++ b/ext/sctp/gstsctpenc.h
@@ -72,6 +72,7 @@ struct _GstSctpEncClass
 };
 
 GType gst_sctp_enc_get_type (void);
+GST_ELEMENT_REGISTER_DECLARE (sctpenc);
 
 G_END_DECLS
 
diff --git a/ext/sctp/gstsctpplugin.c b/ext/sctp/gstsctpplugin.c
index 888a94c84..9f3400ecf 100644
--- a/ext/sctp/gstsctpplugin.c
+++ b/ext/sctp/gstsctpplugin.c
@@ -35,12 +35,13 @@
 static gboolean
 plugin_init (GstPlugin * plugin)
 {
-  return gst_element_register (plugin, "sctpenc", GST_RANK_NONE,
-      GST_TYPE_SCTP_ENC)
-      && gst_element_register (plugin, "sctpdec", GST_RANK_NONE,
-      GST_TYPE_SCTP_DEC);
-}
+  gboolean ret = FALSE;
+
+  ret |= GST_ELEMENT_REGISTER (sctpenc, plugin);
+  ret |= GST_ELEMENT_REGISTER (sctpdec, plugin);
 
+  return ret;
+}
 
 #ifndef PACKAGE
 #define PACKAGE "sctp"
diff --git a/ext/sctp/meson.build b/ext/sctp/meson.build
index 93f29d7f1..6b3d7f249 100644
--- a/ext/sctp/meson.build
+++ b/ext/sctp/meson.build
@@ -57,6 +57,5 @@ if sctp_dep.found() and sctp_header
     install : true,
     install_dir : plugins_install_dir,
   )
-  pkgconfig.generate(gstsctp, install_dir : plugins_pkgconfig_install_dir)
   plugins += [gstsctp]
 endif
diff --git a/ext/sctp/sctpassociation.c b/ext/sctp/sctpassociation.c
index fbf5b4afe..68c05e62f 100644
--- a/ext/sctp/sctpassociation.c
+++ b/ext/sctp/sctpassociation.c
@@ -234,7 +234,7 @@ gst_sctp_association_init (GstSctpAssociation * self)
 
   self->state = GST_SCTP_ASSOCIATION_STATE_NEW;
 
-  self->use_sock_stream = FALSE;
+  self->use_sock_stream = TRUE;
 
   usrsctp_register_address ((void *) self);
 }
@@ -546,6 +546,7 @@ gst_sctp_association_reset_stream (GstSctpAssociation * self, guint16 stream_id)
 
   length = (socklen_t) (sizeof (struct sctp_reset_streams) + sizeof (guint16));
   srs = (struct sctp_reset_streams *) g_malloc0 (length);
+  srs->srs_assoc_id = SCTP_ALL_ASSOC;
   srs->srs_flags = SCTP_STREAM_RESET_OUTGOING;
   srs->srs_number_streams = 1;
   srs->srs_stream_list[0] = stream_id;
diff --git a/ext/sctp/usrsctp/meson.build b/ext/sctp/usrsctp/meson.build
index 8d474970b..6a1ab845d 100644
--- a/ext/sctp/usrsctp/meson.build
+++ b/ext/sctp/usrsctp/meson.build
@@ -31,7 +31,6 @@ else
         '-Wno-missing-declarations',
         '-Wno-old-style-definition',
         '-Wno-redundant-decls',
-        '-Wno-error',
     ])
 endif
 
@@ -77,7 +76,6 @@ elif system == 'windows'
     if compiler.get_id() == 'gcc'
         compile_args += [compiler.get_supported_arguments([
             '-Wno-format',
-            '-D_WIN32_WINNT=0x601',  # Enables inet_ntop and friends
         ])]
     endif
 else
@@ -170,6 +168,7 @@ usrsctp_static = static_library('usrsctp-static', sources,
     c_args: compile_args,
     dependencies: dependencies,
     include_directories: include_dirs,
+    override_options: ['werror=false'],
     install: false)
 
 # Declare dependency
diff --git a/ext/srtp/gstsrtp.c b/ext/srtp/gstsrtp.c
index b607b2c26..5a3494548 100644
--- a/ext/srtp/gstsrtp.c
+++ b/ext/srtp/gstsrtp.c
@@ -297,26 +297,3 @@ cipher_key_size (GstSrtpCipherType cipher)
 
   return size;
 }
-
-static gboolean
-plugin_init (GstPlugin * plugin)
-{
-  srtp_init ();
-
-  if (!gst_srtp_enc_plugin_init (plugin))
-    return FALSE;
-
-  if (!gst_srtp_dec_plugin_init (plugin))
-    return FALSE;
-
-  gst_type_mark_as_plugin_api (GST_TYPE_SRTP_AUTH_TYPE, 0);
-  gst_type_mark_as_plugin_api (GST_TYPE_SRTP_CIPHER_TYPE, 0);
-
-  return TRUE;
-}
-
-GST_PLUGIN_DEFINE (GST_VERSION_MAJOR,
-    GST_VERSION_MINOR,
-    srtp,
-    "GStreamer SRTP",
-    plugin_init, VERSION, "LGPL", GST_PACKAGE_NAME, GST_PACKAGE_ORIGIN)
diff --git a/ext/srtp/gstsrtpdec.c b/ext/srtp/gstsrtpdec.c
index 6d192995f..2467f1b97 100644
--- a/ext/srtp/gstsrtpdec.c
+++ b/ext/srtp/gstsrtpdec.c
@@ -115,8 +115,8 @@
  *
  */
 
+#include "gstsrtpelements.h"
 #include "gstsrtpdec.h"
-
 #include <gst/rtp/gstrtpbuffer.h>
 #include <string.h>
 
@@ -177,7 +177,11 @@ GST_STATIC_PAD_TEMPLATE ("rtcp_src",
 
 static guint gst_srtp_dec_signals[LAST_SIGNAL] = { 0 };
 
-G_DEFINE_TYPE (GstSrtpDec, gst_srtp_dec, GST_TYPE_ELEMENT);
+G_DEFINE_TYPE_WITH_CODE (GstSrtpDec, gst_srtp_dec, GST_TYPE_ELEMENT,
+    GST_DEBUG_CATEGORY_INIT (gst_srtp_dec_debug, "srtpdec", 0, "SRTP dec");
+    );
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (srtpdec, "srtpdec", GST_RANK_NONE,
+    GST_TYPE_SRTP_DEC, srtp_element_init (plugin));
 
 static void gst_srtp_dec_set_property (GObject * object, guint prop_id,
     const GValue * value, GParamSpec * pspec);
@@ -225,6 +229,8 @@ struct _GstSrtpDecSsrcStream
   GstSrtpCipherType rtcp_cipher;
   GstSrtpAuthType rtcp_auth;
   GArray *keys;
+  guint recv_count;
+  guint recv_drop_count;
 };
 
 #ifdef HAVE_SRTP2
@@ -431,10 +437,11 @@ gst_srtp_dec_create_stats (GstSrtpDec * filter)
 
   if (filter->session) {
     GHashTableIter iter;
-    gpointer key;
+    gpointer key, value;
 
     g_hash_table_iter_init (&iter, filter->streams);
-    while (g_hash_table_iter_next (&iter, &key, NULL)) {
+    while (g_hash_table_iter_next (&iter, &key, &value)) {
+      GstSrtpDecSsrcStream *stream = value;
       GstStructure *ss;
       guint32 ssrc = GPOINTER_TO_UINT (key);
       srtp_err_status_t status;
@@ -446,7 +453,9 @@ gst_srtp_dec_create_stats (GstSrtpDec * filter)
       }
 
       ss = gst_structure_new ("application/x-srtp-stream",
-          "ssrc", G_TYPE_UINT, ssrc, "roc", G_TYPE_UINT, roc, NULL);
+          "ssrc", G_TYPE_UINT, ssrc, "roc", G_TYPE_UINT, roc, "recv-count",
+          G_TYPE_UINT, stream->recv_count, "recv-drop-count", G_TYPE_UINT,
+          stream->recv_drop_count, NULL);
 
       g_value_take_boxed (&v, ss);
       gst_value_array_append_value (&va, &v);
@@ -454,6 +463,11 @@ gst_srtp_dec_create_stats (GstSrtpDec * filter)
   }
 
   gst_structure_take_value (s, "streams", &va);
+  gst_structure_set (s, "recv-count", G_TYPE_UINT, filter->recv_count, NULL);
+  gst_structure_set (s, "recv-drop-count", G_TYPE_UINT,
+      filter->recv_drop_count, NULL);
+  GST_LOG_OBJECT (filter, "stats: recv-count %u recv-drop-count %u",
+      filter->recv_count, filter->recv_drop_count);
   g_value_unset (&v);
 
   return s;
@@ -1321,11 +1335,12 @@ gst_srtp_dec_decode_buffer (GstSrtpDec * filter, GstPad * pad, GstBuffer * buf,
   GstMapInfo map;
   srtp_err_status_t err;
   gint size;
+  GstSrtpDecSsrcStream *stream;
 
   GST_LOG_OBJECT (pad, "Received %s buffer of size %" G_GSIZE_FORMAT
       " with SSRC = %u", is_rtcp ? "RTCP" : "RTP", gst_buffer_get_size (buf),
       ssrc);
-
+  filter->recv_count++;
   /* Change buffer to remove protection */
   buf = gst_buffer_make_writable (buf);
 
@@ -1338,7 +1353,7 @@ unprotect:
 
   if (is_rtcp) {
 #ifdef HAVE_SRTP2
-    GstSrtpDecSsrcStream *stream = find_stream_by_ssrc (filter, ssrc);
+    stream = find_stream_by_ssrc (filter, ssrc);
 
     err = srtp_unprotect_rtcp_mki (filter->session, map.data, &size,
         stream && stream->keys);
@@ -1377,7 +1392,7 @@ unprotect:
 
 #ifdef HAVE_SRTP2
     {
-      GstSrtpDecSsrcStream *stream = find_stream_by_ssrc (filter, ssrc);
+      stream = find_stream_by_ssrc (filter, ssrc);
 
       err = srtp_unprotect_mki (filter->session, map.data, &size,
           stream && stream->keys);
@@ -1386,7 +1401,12 @@ unprotect:
     err = srtp_unprotect (filter->session, map.data, &size);
 #endif
   }
-
+  stream = find_stream_by_ssrc (filter, ssrc);
+  if (stream == NULL) {
+    GST_WARNING_OBJECT (filter, "Could not find matching stream, dropping");
+    goto err;
+  }
+  stream->recv_count++;
   /* Signal user depending on type of error */
   switch (err) {
     case srtp_err_status_ok:
@@ -1395,20 +1415,14 @@ unprotect:
     case srtp_err_status_replay_fail:
       GST_DEBUG_OBJECT (filter,
           "Dropping replayed packet, probably retransmission");
+      stream->recv_drop_count++;
       goto err;
     case srtp_err_status_replay_old:
       GST_DEBUG_OBJECT (filter,
           "Dropping replayed old packet, probably retransmission");
+      stream->recv_drop_count++;
       goto err;
     case srtp_err_status_key_expired:{
-      GstSrtpDecSsrcStream *stream;
-
-      /* Check we have an existing stream to rekey */
-      stream = find_stream_by_ssrc (filter, ssrc);
-      if (stream == NULL) {
-        GST_WARNING_OBJECT (filter, "Could not find matching stream, dropping");
-        goto err;
-      }
 
       GST_OBJECT_UNLOCK (filter);
       stream = request_key_with_signal (filter, ssrc, SIGNAL_HARD_LIMIT);
@@ -1424,21 +1438,24 @@ unprotect:
     }
     case srtp_err_status_auth_fail:
       GST_WARNING_OBJECT (filter, "Error authentication packet, dropping");
+      stream->recv_drop_count++;
       goto err;
     case srtp_err_status_cipher_fail:
       GST_WARNING_OBJECT (filter, "Error while decrypting packet, dropping");
+      stream->recv_drop_count++;
       goto err;
     default:
       GST_WARNING_OBJECT (pad,
           "Unable to unprotect buffer (unprotect failed code %d)", err);
+      stream->recv_drop_count++;
       goto err;
   }
-
   gst_buffer_unmap (buf, &map);
   gst_buffer_set_size (buf, size);
   return TRUE;
 
 err:
+  filter->recv_drop_count++;
   gst_buffer_unmap (buf, &map);
   return FALSE;
 }
@@ -1537,6 +1554,8 @@ gst_srtp_dec_change_state (GstElement * element, GstStateChange transition)
 
       filter->rtp_has_segment = FALSE;
       filter->rtcp_has_segment = FALSE;
+      filter->recv_count = 0;
+      filter->recv_drop_count = 0;
       break;
     case GST_STATE_CHANGE_PAUSED_TO_PLAYING:
       break;
@@ -1556,7 +1575,6 @@ gst_srtp_dec_change_state (GstElement * element, GstStateChange transition)
       gst_srtp_dec_clear_streams (filter);
       g_hash_table_unref (filter->streams);
       filter->streams = NULL;
-
 #ifndef HAVE_SRTP2
       g_hash_table_unref (filter->streams_roc_changed);
       filter->streams_roc_changed = NULL;
@@ -1570,17 +1588,3 @@ gst_srtp_dec_change_state (GstElement * element, GstStateChange transition)
   }
   return res;
 }
-
-
-/* entry point to initialize the plug-in
- * initialize the plug-in itself
- * register the element factories and other features
- */
-gboolean
-gst_srtp_dec_plugin_init (GstPlugin * srtpdec)
-{
-  GST_DEBUG_CATEGORY_INIT (gst_srtp_dec_debug, "srtpdec", 0, "SRTP dec");
-
-  return gst_element_register (srtpdec, "srtpdec", GST_RANK_NONE,
-      GST_TYPE_SRTP_DEC);
-}
diff --git a/ext/srtp/gstsrtpdec.h b/ext/srtp/gstsrtpdec.h
index ba8bcff58..e517cab09 100644
--- a/ext/srtp/gstsrtpdec.h
+++ b/ext/srtp/gstsrtpdec.h
@@ -82,6 +82,8 @@ struct _GstSrtpDec
 
   gboolean rtp_has_segment;
   gboolean rtcp_has_segment;
+  guint recv_count;
+  guint recv_drop_count;
 
 #ifndef HAVE_SRTP2
   GHashTable *streams_roc_changed;
@@ -98,7 +100,6 @@ struct _GstSrtpDecClass
 
 GType gst_srtp_dec_get_type (void);
 
-gboolean gst_srtp_dec_plugin_init (GstPlugin * plugin);
 
 G_END_DECLS
 
diff --git a/ext/srtp/gstsrtpelement.c b/ext/srtp/gstsrtpelement.c
new file mode 100644
index 000000000..231b70db5
--- /dev/null
+++ b/ext/srtp/gstsrtpelement.c
@@ -0,0 +1,41 @@
+/*
+ * GStreamer - GStreamer SRTP encoder and decoder
+ *
+ * Copyright 2009-2013 Collabora Ltd.
+ *  @author: Gabriel Millaire <gabriel.millaire@collabora.co.uk>
+ *  @author: Olivier Crete <olivier.crete@collabora.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 02111-1307, USA.
+ */
+
+
+#define GLIB_DISABLE_DEPRECATION_WARNINGS
+
+#include "gstsrtpelements.h"
+
+
+void
+srtp_element_init (GstPlugin * plugin)
+{
+  static gsize res = FALSE;
+
+  if (g_once_init_enter (&res)) {
+    srtp_init ();
+    gst_type_mark_as_plugin_api (GST_TYPE_SRTP_AUTH_TYPE, 0);
+    gst_type_mark_as_plugin_api (GST_TYPE_SRTP_CIPHER_TYPE, 0);
+    g_once_init_leave (&res, TRUE);
+  }
+}
diff --git a/ext/srtp/gstsrtpelements.h b/ext/srtp/gstsrtpelements.h
new file mode 100644
index 000000000..0a223fbdf
--- /dev/null
+++ b/ext/srtp/gstsrtpelements.h
@@ -0,0 +1,63 @@
+/*
+ * GStreamer - GStreamer SRTP encoder
+ *
+ * Copyright 2011-2013 Collabora Ltd.
+ *  @author: Olivier Crete <olivier.crete@collabora.com>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * Alternatively, the contents of this file may be used under the
+ * GNU Lesser General Public License Version 2.1 (the "LGPL"), in
+ * which case the following provisions apply instead of the ones
+ * mentioned above:
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 02111-1307, USA.
+ */
+#ifndef __GST_SRTP_ELEMENTS_H__
+#define __GST_SRTP_ELEMENTS_H__
+
+#ifdef HAVE_CONFIG_H
+#include <config.h>
+#endif
+
+#include "gstsrtp.h"
+#include "gstsrtpenums.h"
+#include "gstsrtp-enumtypes.h"
+
+#include <gst/gst.h>
+
+void srtp_element_init (GstPlugin * plugin);
+
+GST_ELEMENT_REGISTER_DECLARE (srtpdec);
+GST_ELEMENT_REGISTER_DECLARE (srtpenc);
+
+#endif /* __GST_SRTP_ELEMENTS_H__ */
diff --git a/ext/srtp/gstsrtpenc.c b/ext/srtp/gstsrtpenc.c
index d677afcce..5e17f2ce6 100644
--- a/ext/srtp/gstsrtpenc.c
+++ b/ext/srtp/gstsrtpenc.c
@@ -106,6 +106,7 @@
  * will be added to every buffer.
  */
 
+#include "gstsrtpelements.h"
 #include "gstsrtpenc.h"
 
 #include <gst/rtp/gstrtpbuffer.h>
@@ -201,7 +202,10 @@ GST_STATIC_PAD_TEMPLATE ("rtcp_src_%u",
     GST_STATIC_CAPS ("application/x-srtcp")
     );
 
-G_DEFINE_TYPE (GstSrtpEnc, gst_srtp_enc, GST_TYPE_ELEMENT);
+G_DEFINE_TYPE_WITH_CODE (GstSrtpEnc, gst_srtp_enc, GST_TYPE_ELEMENT,
+    GST_DEBUG_CATEGORY_INIT (gst_srtp_enc_debug, "srtpenc", 0, "SRTP Enc"););
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (srtpenc, "srtpenc", GST_RANK_NONE,
+    GST_TYPE_SRTP_ENC, srtp_element_init (plugin));
 
 static guint gst_srtp_enc_signals[LAST_SIGNAL] = { 0 };
 
@@ -1492,16 +1496,3 @@ gst_srtp_enc_sink_event_rtcp (GstPad * pad, GstObject * parent,
 {
   return gst_srtp_enc_sink_event (pad, parent, event, TRUE);
 }
-
-/* entry point to initialize the plug-in
- * initialize the plug-in itself
- * register the element factories and other features
- */
-gboolean
-gst_srtp_enc_plugin_init (GstPlugin * srtpenc)
-{
-  GST_DEBUG_CATEGORY_INIT (gst_srtp_enc_debug, "srtpenc", 0, "SRTP Enc");
-
-  return gst_element_register (srtpenc, "srtpenc", GST_RANK_NONE,
-      GST_TYPE_SRTP_ENC);
-}
diff --git a/ext/srtp/gstsrtpenc.h b/ext/srtp/gstsrtpenc.h
index df2f8fd30..ed02df416 100644
--- a/ext/srtp/gstsrtpenc.h
+++ b/ext/srtp/gstsrtpenc.h
@@ -95,8 +95,6 @@ struct _GstSrtpEncClass
 
 GType gst_srtp_enc_get_type (void);
 
-gboolean gst_srtp_enc_plugin_init (GstPlugin * plugin);
-
 G_END_DECLS
 
 #endif /* __GST_SRTPENC_H__ */
diff --git a/ext/srtp/gstsrtpplugin.c b/ext/srtp/gstsrtpplugin.c
new file mode 100644
index 000000000..7fb6269f0
--- /dev/null
+++ b/ext/srtp/gstsrtpplugin.c
@@ -0,0 +1,45 @@
+/*
+ * GStreamer - GStreamer SRTP encoder and decoder
+ *
+ * Copyright 2009-2013 Collabora Ltd.
+ *  @author: Gabriel Millaire <gabriel.millaire@collabora.co.uk>
+ *  @author: Olivier Crete <olivier.crete@collabora.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 02111-1307, USA.
+ */
+
+
+#define GLIB_DISABLE_DEPRECATION_WARNINGS
+
+#include "gstsrtpelements.h"
+
+
+static gboolean
+plugin_init (GstPlugin * plugin)
+{
+  gboolean ret = FALSE;
+
+  ret |= GST_ELEMENT_REGISTER (srtpenc, plugin);
+  ret |= GST_ELEMENT_REGISTER (srtpdec, plugin);
+
+  return ret;
+}
+
+GST_PLUGIN_DEFINE (GST_VERSION_MAJOR,
+    GST_VERSION_MINOR,
+    srtp,
+    "GStreamer SRTP",
+    plugin_init, VERSION, "LGPL", GST_PACKAGE_NAME, GST_PACKAGE_ORIGIN)
diff --git a/ext/srtp/meson.build b/ext/srtp/meson.build
index affdac367..49eed5b0e 100644
--- a/ext/srtp/meson.build
+++ b/ext/srtp/meson.build
@@ -1,11 +1,14 @@
 srtp_sources = [
   'gstsrtp.c',
+  'gstsrtpelement.c',
+  'gstsrtpplugin.c',
   'gstsrtpdec.c',
   'gstsrtpenc.c',
 ]
 
 srtp_cargs = []
 if get_option('srtp').disabled()
+  srtp_dep = dependency('', required : false)
   subdir_done()
 endif
 
@@ -37,6 +40,5 @@ if srtp_dep.found()
     install : true,
     install_dir : plugins_install_dir,
   )
-  pkgconfig.generate(gstsrtp, install_dir : plugins_pkgconfig_install_dir)
   plugins += [gstsrtp]
 endif
diff --git a/ext/webrtc/fwd.h b/ext/webrtc/fwd.h
index aa26ec6de..dc7273b60 100644
--- a/ext/webrtc/fwd.h
+++ b/ext/webrtc/fwd.h
@@ -29,18 +29,6 @@ typedef struct _GstWebRTCBin GstWebRTCBin;
 typedef struct _GstWebRTCBinClass GstWebRTCBinClass;
 typedef struct _GstWebRTCBinPrivate GstWebRTCBinPrivate;
 
-typedef struct _GstWebRTCICE GstWebRTCICE;
-typedef struct _GstWebRTCICEClass GstWebRTCICEClass;
-typedef struct _GstWebRTCICEPrivate GstWebRTCICEPrivate;
-
-typedef struct _GstWebRTCICEStream GstWebRTCICEStream;
-typedef struct _GstWebRTCICEStreamClass GstWebRTCICEStreamClass;
-typedef struct _GstWebRTCICEStreamPrivate GstWebRTCICEStreamPrivate;
-
-typedef struct _GstWebRTCNiceTransport GstWebRTCNiceTransport;
-typedef struct _GstWebRTCNiceTransportClass GstWebRTCNiceTransportClass;
-typedef struct _GstWebRTCNiceTransportPrivate GstWebRTCNiceTransportPrivate;
-
 typedef struct _GstWebRTCSCTPTransport GstWebRTCSCTPTransport;
 typedef struct _GstWebRTCSCTPTransportClass GstWebRTCSCTPTransportClass;
 typedef struct _GstWebRTCSCTPTransportPrivate GstWebRTCSCTPTransportPrivate;
diff --git a/ext/webrtc/gstwebrtcbin.c b/ext/webrtc/gstwebrtcbin.c
index 85435303b..6a8f72236 100644
--- a/ext/webrtc/gstwebrtcbin.c
+++ b/ext/webrtc/gstwebrtcbin.c
@@ -29,7 +29,11 @@
 #include "webrtcsdp.h"
 #include "webrtctransceiver.h"
 #include "webrtcdatachannel.h"
-#include "sctptransport.h"
+#include "webrtcsctptransport.h"
+
+#include "gst/webrtc/webrtc-priv.h"
+#include <gst/webrtc/nice/nice.h>
+#include <gst/rtp/rtp.h>
 
 #include <stdio.h>
 #include <stdlib.h>
@@ -53,11 +57,23 @@
 #define ICE_LOCK(w) (g_mutex_lock (ICE_GET_LOCK(w)))
 #define ICE_UNLOCK(w) (g_mutex_unlock (ICE_GET_LOCK(w)))
 
+#define DC_GET_LOCK(w) (&w->priv->dc_lock)
+#define DC_LOCK(w) (g_mutex_lock (DC_GET_LOCK(w)))
+#define DC_UNLOCK(w) (g_mutex_unlock (DC_GET_LOCK(w)))
 
 /* The extra time for the rtpstorage compared to the RTP jitterbuffer (in ms) */
 #define RTPSTORAGE_EXTRA_TIME (50)
 
-/*
+#define DEFAULT_JB_LATENCY 200
+
+#define RTPHDREXT_MID GST_RTP_HDREXT_BASE "sdes:mid"
+#define RTPHDREXT_STREAM_ID GST_RTP_HDREXT_BASE "sdes:rtp-stream-id"
+#define RTPHDREXT_REPAIRED_STREAM_ID GST_RTP_HDREXT_BASE "sdes:repaired-rtp-stream-id"
+
+/**
+ * SECTION: element-webrtcbin
+ * title: webrtcbin
+ *
  * This webrtcbin implements the majority of the W3's peerconnection API and
  * implementation guide where possible. Generating offers, answers and setting
  * local and remote SDP's are all supported.  Both media descriptions and
@@ -78,10 +94,10 @@
  * configuration.  Some cases are outlined below for a simple single
  * audio/video/data session:
  *
- * - max-bundle (requires rtcp-muxing) uses a single transport for all
+ * - max-bundle uses a single transport for all
  *   media/data transported.  Renegotiation involves adding/removing the
  *   necessary streams to the existing transports.
- * - max-compat without rtcp-mux involves two TransportStream per media stream
+ * - max-compat involves two TransportStream per media stream
  *   to transport the rtp and the rtcp packets and a single TransportStream for
  *   all data channels.  Each stream change involves modifying the associated
  *   TransportStream/s as necessary.
@@ -100,6 +116,9 @@
  */
 
 static void _update_need_negotiation (GstWebRTCBin * webrtc);
+static GstPad *_connect_input_stream (GstWebRTCBin * webrtc,
+    GstWebRTCBinPad * pad);
+
 
 #define GST_CAT_DEFAULT gst_webrtc_bin_debug
 GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
@@ -197,19 +216,23 @@ _have_dtls_elements (GstWebRTCBin * webrtc)
   return TRUE;
 }
 
-G_DEFINE_TYPE (GstWebRTCBinPad, gst_webrtc_bin_pad, GST_TYPE_GHOST_PAD);
-
-static void
-gst_webrtc_bin_pad_set_property (GObject * object, guint prop_id,
-    const GValue * value, GParamSpec * pspec)
+static gboolean
+_gst_element_accumulator (GSignalInvocationHint * ihint,
+    GValue * return_accu, const GValue * handler_return, gpointer dummy)
 {
-  switch (prop_id) {
-    default:
-      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
-      break;
-  }
+  GstElement *element;
+
+  element = g_value_get_object (handler_return);
+  GST_DEBUG ("got element %" GST_PTR_FORMAT, element);
+
+  g_value_set_object (return_accu, element);
+
+  /* stop emission if we have an element */
+  return (element == NULL);
 }
 
+G_DEFINE_TYPE (GstWebRTCBinPad, gst_webrtc_bin_pad, GST_TYPE_GHOST_PAD);
+
 static void
 gst_webrtc_bin_pad_get_property (GObject * object, guint prop_id,
     GValue * value, GParamSpec * pspec)
@@ -231,13 +254,9 @@ gst_webrtc_bin_pad_finalize (GObject * object)
 {
   GstWebRTCBinPad *pad = GST_WEBRTC_BIN_PAD (object);
 
-  if (pad->trans)
-    gst_object_unref (pad->trans);
-  pad->trans = NULL;
-
-  if (pad->received_caps)
-    gst_caps_unref (pad->received_caps);
-  pad->received_caps = NULL;
+  gst_clear_object (&pad->trans);
+  gst_clear_caps (&pad->received_caps);
+  g_clear_pointer (&pad->msid, g_free);
 
   G_OBJECT_CLASS (gst_webrtc_bin_pad_parent_class)->finalize (object);
 }
@@ -248,7 +267,6 @@ gst_webrtc_bin_pad_class_init (GstWebRTCBinPadClass * klass)
   GObjectClass *gobject_class = (GObjectClass *) klass;
 
   gobject_class->get_property = gst_webrtc_bin_pad_get_property;
-  gobject_class->set_property = gst_webrtc_bin_pad_set_property;
   gobject_class->finalize = gst_webrtc_bin_pad_finalize;
 
   g_object_class_install_property (gobject_class,
@@ -259,6 +277,38 @@ gst_webrtc_bin_pad_class_init (GstWebRTCBinPadClass * klass)
           G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
 }
 
+static void
+gst_webrtc_bin_pad_update_tos_event (GstWebRTCBinPad * wpad)
+{
+  WebRTCTransceiver *trans = (WebRTCTransceiver *) wpad->trans;
+
+  if (wpad->received_caps && trans->parent.mid) {
+    GstPad *pad = GST_PAD (wpad);
+
+    gst_event_take (&trans->tos_event,
+        gst_event_new_custom (GST_EVENT_CUSTOM_DOWNSTREAM_STICKY,
+            gst_structure_new ("GstWebRtcBinUpdateTos", "mid", G_TYPE_STRING,
+                trans->parent.mid, NULL)));
+
+    GST_DEBUG_OBJECT (pad, "sending new tos event %" GST_PTR_FORMAT,
+        trans->tos_event);
+    gst_pad_send_event (pad, gst_event_ref (trans->tos_event));
+  }
+}
+
+static GList *
+_get_pending_sink_transceiver (GstWebRTCBin * webrtc, GstWebRTCBinPad * pad)
+{
+  GList *ret;
+
+  for (ret = webrtc->priv->pending_sink_transceivers; ret; ret = ret->next) {
+    if (ret->data == pad)
+      break;
+  }
+
+  return ret;
+}
+
 static gboolean
 gst_webrtcbin_sink_event (GstPad * pad, GstObject * parent, GstEvent * event)
 {
@@ -271,12 +321,45 @@ gst_webrtcbin_sink_event (GstPad * pad, GstObject * parent, GstEvent * event)
 
     gst_event_parse_caps (event, &caps);
     check_negotiation = (!wpad->received_caps
-        || gst_caps_is_equal (wpad->received_caps, caps));
+        || !gst_caps_is_equal (wpad->received_caps, caps));
     gst_caps_replace (&wpad->received_caps, caps);
 
     GST_DEBUG_OBJECT (parent,
         "On %" GST_PTR_FORMAT " checking negotiation? %u, caps %"
         GST_PTR_FORMAT, pad, check_negotiation, caps);
+
+    if (check_negotiation) {
+      gst_webrtc_bin_pad_update_tos_event (wpad);
+    }
+
+    /* A remote description might have been set while the pad hadn't
+     * yet received caps, delaying the connection of the input stream
+     */
+    PC_LOCK (webrtc);
+    if (wpad->trans) {
+      GST_OBJECT_LOCK (wpad->trans);
+      if (wpad->trans->current_direction ==
+          GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDONLY
+          || wpad->trans->current_direction ==
+          GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDRECV) {
+        GList *pending = _get_pending_sink_transceiver (webrtc, wpad);
+
+        if (pending) {
+          GST_LOG_OBJECT (pad, "Connecting input stream to rtpbin with "
+              "transceiver %" GST_PTR_FORMAT " and caps %" GST_PTR_FORMAT,
+              wpad->trans, wpad->received_caps);
+          _connect_input_stream (webrtc, wpad);
+          gst_pad_remove_probe (GST_PAD (pad), wpad->block_id);
+          wpad->block_id = 0;
+          gst_object_unref (pending->data);
+          webrtc->priv->pending_sink_transceivers =
+              g_list_delete_link (webrtc->priv->pending_sink_transceivers,
+              pending);
+        }
+      }
+      GST_OBJECT_UNLOCK (wpad->trans);
+    }
+    PC_UNLOCK (webrtc);
   } else if (GST_EVENT_TYPE (event) == GST_EVENT_EOS) {
     check_negotiation = TRUE;
   }
@@ -290,45 +373,263 @@ gst_webrtcbin_sink_event (GstPad * pad, GstObject * parent, GstEvent * event)
   return gst_pad_event_default (pad, parent, event);
 }
 
+static gboolean
+gst_webrtcbin_sink_query (GstPad * pad, GstObject * parent, GstQuery * query)
+{
+  GstWebRTCBinPad *wpad = GST_WEBRTC_BIN_PAD (pad);
+  gboolean ret = FALSE;
+
+  switch (GST_QUERY_TYPE (query)) {
+    case GST_QUERY_ACCEPT_CAPS:
+      GST_OBJECT_LOCK (wpad->trans);
+      if (wpad->trans->codec_preferences) {
+        GstCaps *caps;
+
+        gst_query_parse_accept_caps (query, &caps);
+
+        gst_query_set_accept_caps_result (query,
+            gst_caps_can_intersect (caps, wpad->trans->codec_preferences));
+        ret = TRUE;
+      }
+      GST_OBJECT_UNLOCK (wpad->trans);
+      break;
+
+    case GST_QUERY_CAPS:
+    {
+      GstCaps *codec_preferences = NULL;
+
+      GST_OBJECT_LOCK (wpad->trans);
+      if (wpad->trans->codec_preferences)
+        codec_preferences = gst_caps_ref (wpad->trans->codec_preferences);
+      GST_OBJECT_UNLOCK (wpad->trans);
+
+      if (codec_preferences) {
+        GstCaps *filter = NULL;
+        GstCaps *filter_prefs = NULL;
+        GstPad *target;
+
+        gst_query_parse_caps (query, &filter);
+
+        if (filter) {
+          filter_prefs = gst_caps_intersect_full (filter, codec_preferences,
+              GST_CAPS_INTERSECT_FIRST);
+          gst_caps_unref (codec_preferences);
+        } else {
+          filter_prefs = codec_preferences;
+        }
+
+        target = gst_ghost_pad_get_target (GST_GHOST_PAD (pad));
+        if (target) {
+          GstCaps *result;
+
+          result = gst_pad_query_caps (target, filter_prefs);
+          gst_query_set_caps_result (query, result);
+          gst_caps_unref (result);
+
+          gst_object_unref (target);
+        } else {
+          gst_query_set_caps_result (query, filter_prefs);
+        }
+
+        gst_caps_unref (filter_prefs);
+        ret = TRUE;
+      }
+      break;
+    }
+    default:
+      break;
+  }
+
+  if (ret)
+    return TRUE;
+
+  return gst_pad_query_default (pad, parent, query);
+}
+
+
 static void
 gst_webrtc_bin_pad_init (GstWebRTCBinPad * pad)
 {
 }
 
 static GstWebRTCBinPad *
-gst_webrtc_bin_pad_new (const gchar * name, GstPadDirection direction)
+gst_webrtc_bin_pad_new (const gchar * name, GstPadDirection direction,
+    char *msid)
 {
   GstWebRTCBinPad *pad;
   GstPadTemplate *template;
+  GType pad_type;
 
-  if (direction == GST_PAD_SINK)
+  if (direction == GST_PAD_SINK) {
     template = gst_static_pad_template_get (&sink_template);
-  else if (direction == GST_PAD_SRC)
+    pad_type = GST_TYPE_WEBRTC_BIN_SINK_PAD;
+  } else if (direction == GST_PAD_SRC) {
     template = gst_static_pad_template_get (&src_template);
-  else
+    pad_type = GST_TYPE_WEBRTC_BIN_SRC_PAD;
+  } else {
     g_assert_not_reached ();
+  }
 
   pad =
-      g_object_new (gst_webrtc_bin_pad_get_type (), "name", name, "direction",
+      g_object_new (pad_type, "name", name, "direction",
       direction, "template", template, NULL);
   gst_object_unref (template);
 
-  gst_pad_set_event_function (GST_PAD (pad), gst_webrtcbin_sink_event);
+  pad->msid = msid;
 
   GST_DEBUG_OBJECT (pad, "new visible pad with direction %s",
       direction == GST_PAD_SRC ? "src" : "sink");
   return pad;
 }
 
+enum
+{
+  PROP_SINK_PAD_MSID = 1,
+};
+
+/**
+ * GstWebRTCBinSinkPad:
+ *
+ * Since: 1.22
+ */
+struct _GstWebRTCBinSinkPad
+{
+  GstWebRTCBinPad pad;
+};
+
+G_DEFINE_TYPE (GstWebRTCBinSinkPad, gst_webrtc_bin_sink_pad,
+    GST_TYPE_WEBRTC_BIN_PAD);
+
+static void
+gst_webrtc_bin_sink_pad_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  GstWebRTCBinPad *pad = GST_WEBRTC_BIN_PAD (object);
+
+  switch (prop_id) {
+    case PROP_SINK_PAD_MSID:
+      g_value_set_string (value, pad->msid);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_webrtc_bin_sink_pad_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  GstWebRTCBinPad *pad = GST_WEBRTC_BIN_PAD (object);
+
+  switch (prop_id) {
+    case PROP_SINK_PAD_MSID:
+      g_free (pad->msid);
+      pad->msid = g_value_dup_string (value);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_webrtc_bin_sink_pad_class_init (GstWebRTCBinSinkPadClass * klass)
+{
+  GObjectClass *gobject_class = (GObjectClass *) klass;
+
+  gobject_class->get_property = gst_webrtc_bin_sink_pad_get_property;
+  gobject_class->set_property = gst_webrtc_bin_sink_pad_set_property;
+
+  /**
+   * GstWebRTCBinSinkPad:msid:
+   *
+   * The MediaStream Identifier to use for this pad (MediaStreamTrack).
+   * Fallback is the RTP SDES cname value if not provided.
+   *
+   * Since: 1.22
+   */
+  g_object_class_install_property (gobject_class,
+      PROP_SINK_PAD_MSID,
+      g_param_spec_string ("msid", "MSID",
+          "Local MediaStream ID to use for this pad (NULL = unset)", NULL,
+          G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+}
+
+static void
+gst_webrtc_bin_sink_pad_init (GstWebRTCBinSinkPad * pad)
+{
+  gst_pad_set_event_function (GST_PAD (pad), gst_webrtcbin_sink_event);
+  gst_pad_set_query_function (GST_PAD (pad), gst_webrtcbin_sink_query);
+}
+
+enum
+{
+  PROP_SRC_PAD_MSID = 1,
+};
+
+/**
+ * GstWebRTCBinSrcPad:
+ *
+ * Since: 1.22
+ */
+struct _GstWebRTCBinSrcPad
+{
+  GstWebRTCBinPad pad;
+};
+
+G_DEFINE_TYPE (GstWebRTCBinSrcPad, gst_webrtc_bin_src_pad,
+    GST_TYPE_WEBRTC_BIN_PAD);
+
+static void
+gst_webrtc_bin_src_pad_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  GstWebRTCBinPad *pad = GST_WEBRTC_BIN_PAD (object);
+
+  switch (prop_id) {
+    case PROP_SRC_PAD_MSID:
+      g_value_set_string (value, pad->msid);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_webrtc_bin_src_pad_class_init (GstWebRTCBinSrcPadClass * klass)
+{
+  GObjectClass *gobject_class = (GObjectClass *) klass;
+
+  gobject_class->get_property = gst_webrtc_bin_src_pad_get_property;
+
+  /**
+   * GstWebRTCBinSrcPad:msid:
+   *
+   * The MediaStream Identifier the remote peer used for this pad (MediaStreamTrack).
+   * Will be NULL if not advertised in the remote SDP.
+   *
+   * Since: 1.22
+   */
+  g_object_class_install_property (gobject_class,
+      PROP_SRC_PAD_MSID,
+      g_param_spec_string ("msid", "MSID",
+          "Remote MediaStream ID in use for this pad (NULL = not advertised)",
+          NULL, G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
+}
+
+static void
+gst_webrtc_bin_src_pad_init (GstWebRTCBinSrcPad * pad)
+{
+}
+
 #define gst_webrtc_bin_parent_class parent_class
 G_DEFINE_TYPE_WITH_CODE (GstWebRTCBin, gst_webrtc_bin, GST_TYPE_BIN,
     G_ADD_PRIVATE (GstWebRTCBin)
     GST_DEBUG_CATEGORY_INIT (gst_webrtc_bin_debug, "webrtcbin", 0,
         "webrtcbin element"););
 
-static GstPad *_connect_input_stream (GstWebRTCBin * webrtc,
-    GstWebRTCBinPad * pad);
-
 enum
 {
   SIGNAL_0,
@@ -347,6 +648,8 @@ enum
   ADD_TURN_SERVER_SIGNAL,
   CREATE_DATA_CHANNEL_SIGNAL,
   ON_DATA_CHANNEL_SIGNAL,
+  PREPARE_DATA_CHANNEL_SIGNAL,
+  REQUEST_AUX_SENDER,
   LAST_SIGNAL,
 };
 
@@ -368,7 +671,9 @@ enum
   PROP_BUNDLE_POLICY,
   PROP_ICE_TRANSPORT_POLICY,
   PROP_ICE_AGENT,
-  PROP_LATENCY
+  PROP_LATENCY,
+  PROP_SCTP_TRANSPORT,
+  PROP_HTTP_PROXY
 };
 
 static guint gst_webrtc_bin_signals[LAST_SIGNAL] = { 0 };
@@ -412,18 +717,6 @@ _add_ice_stream_item (GstWebRTCBin * webrtc, guint session_id,
   g_array_append_val (webrtc->priv->ice_stream_map, item);
 }
 
-typedef struct
-{
-  guint session_id;
-  gchar *mid;
-} SessionMidItem;
-
-static void
-clear_session_mid_item (SessionMidItem * item)
-{
-  g_free (item->mid);
-}
-
 typedef gboolean (*FindTransceiverFunc) (GstWebRTCRTPTransceiver * p1,
     gconstpointer data);
 
@@ -445,7 +738,7 @@ _find_transceiver (GstWebRTCBin * webrtc, gconstpointer data,
 }
 
 static gboolean
-match_for_mid (GstWebRTCRTPTransceiver * trans, const gchar * mid)
+transceiver_match_for_mid (GstWebRTCRTPTransceiver * trans, const gchar * mid)
 {
   return g_strcmp0 (trans->mid, mid) == 0;
 }
@@ -453,6 +746,9 @@ match_for_mid (GstWebRTCRTPTransceiver * trans, const gchar * mid)
 static gboolean
 transceiver_match_for_mline (GstWebRTCRTPTransceiver * trans, guint * mline)
 {
+  if (trans->stopped)
+    return FALSE;
+
   return trans->mline == *mline;
 }
 
@@ -471,6 +767,20 @@ _find_transceiver_for_mline (GstWebRTCBin * webrtc, guint mlineindex)
   return trans;
 }
 
+static GstWebRTCRTPTransceiver *
+_find_transceiver_for_mid (GstWebRTCBin * webrtc, const char *mid)
+{
+  GstWebRTCRTPTransceiver *trans;
+
+  trans = _find_transceiver (webrtc, mid,
+      (FindTransceiverFunc) transceiver_match_for_mid);
+
+  GST_TRACE_OBJECT (webrtc, "Found transceiver %" GST_PTR_FORMAT " for "
+      "mid %s", trans, mid);
+
+  return trans;
+}
+
 typedef gboolean (*FindTransportFunc) (TransportStream * p1,
     gconstpointer data);
 
@@ -571,6 +881,7 @@ data_channel_match_for_id (WebRTCDataChannel * channel, gint * id)
   return channel->parent.id == *id;
 }
 
+/* always called with dc_lock held */
 static WebRTCDataChannel *
 _find_data_channel_for_id (GstWebRTCBin * webrtc, gint id)
 {
@@ -593,12 +904,23 @@ _add_pad_to_list (GstWebRTCBin * webrtc, GstWebRTCBinPad * pad)
   GST_OBJECT_UNLOCK (webrtc);
 }
 
-static void
+static gboolean
 _remove_pending_pad (GstWebRTCBin * webrtc, GstWebRTCBinPad * pad)
 {
+  gboolean ret = FALSE;
+  GList *l;
+
   GST_OBJECT_LOCK (webrtc);
-  webrtc->priv->pending_pads = g_list_remove (webrtc->priv->pending_pads, pad);
+  l = g_list_find (webrtc->priv->pending_pads, pad);
+  if (l) {
+    webrtc->priv->pending_pads =
+        g_list_remove_link (webrtc->priv->pending_pads, l);
+    g_list_free (l);
+    ret = TRUE;
+  }
   GST_OBJECT_UNLOCK (webrtc);
+
+  return ret;
 }
 
 static void
@@ -622,21 +944,21 @@ _remove_pad (GstWebRTCBin * webrtc, GstWebRTCBinPad * pad)
 typedef struct
 {
   GstPadDirection direction;
-  guint mlineindex;
+  guint mline;
 } MLineMatch;
 
 static gboolean
 pad_match_for_mline (GstWebRTCBinPad * pad, const MLineMatch * match)
 {
   return GST_PAD_DIRECTION (pad) == match->direction
-      && pad->mlineindex == match->mlineindex;
+      && pad->trans->mline == match->mline;
 }
 
 static GstWebRTCBinPad *
 _find_pad_for_mline (GstWebRTCBin * webrtc, GstPadDirection direction,
-    guint mlineindex)
+    guint mline)
 {
-  MLineMatch m = { direction, mlineindex };
+  MLineMatch m = { direction, mline };
 
   return _find_pad (webrtc, &m, (FindPadFunc) pad_match_for_mline);
 }
@@ -664,17 +986,82 @@ _find_pad_for_transceiver (GstWebRTCBin * webrtc, GstPadDirection direction,
 
 #if 0
 static gboolean
-match_for_ssrc (GstWebRTCBinPad * pad, guint * ssrc)
+match_for_pad (GstWebRTCBinPad * pad, GstWebRTCBinPad * other)
 {
-  return pad->ssrc == *ssrc;
+  return pad == other;
 }
+#endif
+
+struct SsrcMatch
+{
+  GstWebRTCRTPTransceiverDirection direction;
+  guint32 ssrc;
+};
 
 static gboolean
-match_for_pad (GstWebRTCBinPad * pad, GstWebRTCBinPad * other)
+mid_ssrc_match_for_ssrc (SsrcMapItem * entry, const struct SsrcMatch *match)
 {
-  return pad == other;
+  return entry->direction == match->direction && entry->ssrc == match->ssrc;
+}
+
+static gboolean
+mid_ssrc_remove_ssrc (SsrcMapItem * item, const struct SsrcMatch *match)
+{
+  return !mid_ssrc_match_for_ssrc (item, match);
+}
+
+static SsrcMapItem *
+find_mid_ssrc_for_ssrc (GstWebRTCBin * webrtc,
+    GstWebRTCRTPTransceiverDirection direction, guint rtp_session, guint ssrc)
+{
+  TransportStream *stream = _find_transport_for_session (webrtc, rtp_session);
+  struct SsrcMatch m = { direction, ssrc };
+
+  if (!stream)
+    return NULL;
+
+  return transport_stream_find_ssrc_map_item (stream, &m,
+      (FindSsrcMapFunc) mid_ssrc_match_for_ssrc);
+}
+
+static SsrcMapItem *
+find_or_add_ssrc_map_item (GstWebRTCBin * webrtc,
+    GstWebRTCRTPTransceiverDirection direction, guint rtp_session, guint ssrc,
+    guint media_idx)
+{
+  TransportStream *stream = _find_transport_for_session (webrtc, rtp_session);
+  struct SsrcMatch m = { direction, ssrc };
+  SsrcMapItem *item;
+
+  if (!stream)
+    return NULL;
+
+  if ((item = transport_stream_find_ssrc_map_item (stream, &m,
+              (FindSsrcMapFunc) mid_ssrc_match_for_ssrc)))
+    return item;
+
+  return transport_stream_add_ssrc_map_item (stream, direction, ssrc,
+      media_idx);
+}
+
+static void
+remove_ssrc_entry_by_ssrc (GstWebRTCBin * webrtc, guint rtp_session, guint ssrc)
+{
+  TransportStream *stream;
+
+  stream = _find_transport_for_session (webrtc, rtp_session);
+  if (stream) {
+    struct SsrcMatch m =
+        { GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_RECVONLY, ssrc };
+
+    transport_stream_filter_ssrc_map_item (stream, &m,
+        (FindSsrcMapFunc) mid_ssrc_remove_ssrc);
+
+    m.direction = GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDONLY;
+    transport_stream_filter_ssrc_map_item (stream, &m,
+        (FindSsrcMapFunc) mid_ssrc_remove_ssrc);
+  }
 }
-#endif
 
 static gboolean
 _unlock_pc_thread (GMutex * lock)
@@ -749,14 +1136,17 @@ _stop_thread (GstWebRTCBin * webrtc)
 static gboolean
 _execute_op (GstWebRTCBinTask * op)
 {
+  GstStructure *s;
+
   PC_LOCK (op->webrtc);
   if (op->webrtc->priv->is_closed) {
+    PC_UNLOCK (op->webrtc);
+
     if (op->promise) {
       GError *error =
-          g_error_new (GST_WEBRTC_BIN_ERROR, GST_WEBRTC_BIN_ERROR_CLOSED,
+          g_error_new (GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_INVALID_STATE,
           "webrtcbin is closed. aborting execution.");
-      GstStructure *s =
-          gst_structure_new ("application/x-gstwebrtcbin-promise-error",
+      GstStructure *s = gst_structure_new ("application/x-gst-promise",
           "error", G_TYPE_ERROR, error, NULL);
 
       gst_promise_reply (op->promise, s);
@@ -768,10 +1158,16 @@ _execute_op (GstWebRTCBinTask * op)
     goto out;
   }
 
-  op->op (op->webrtc, op->data);
+  s = op->op (op->webrtc, op->data);
 
-out:
   PC_UNLOCK (op->webrtc);
+
+  if (op->promise)
+    gst_promise_reply (op->promise, s);
+  else if (s)
+    gst_structure_free (s);
+
+out:
   return G_SOURCE_REMOVE;
 }
 
@@ -845,11 +1241,8 @@ _collate_ice_connection_states (GstWebRTCBin * webrtc)
   for (i = 0; i < webrtc->priv->transceivers->len; i++) {
     GstWebRTCRTPTransceiver *rtp_trans =
         g_ptr_array_index (webrtc->priv->transceivers, i);
-    WebRTCTransceiver *trans = WEBRTC_TRANSCEIVER (rtp_trans);
-    TransportStream *stream = trans->stream;
-    GstWebRTCICETransport *transport, *rtcp_transport;
+    GstWebRTCICETransport *transport;
     GstWebRTCICEConnectionState ice_state;
-    gboolean rtcp_mux = FALSE;
 
     if (rtp_trans->stopped) {
       GST_TRACE_OBJECT (webrtc, "transceiver %p stopped", rtp_trans);
@@ -861,8 +1254,6 @@ _collate_ice_connection_states (GstWebRTCBin * webrtc)
       continue;
     }
 
-    g_object_get (stream, "rtcp-mux", &rtcp_mux, NULL);
-
     transport = webrtc_transceiver_get_dtls_transport (rtp_trans)->transport;
 
     /* get transport state */
@@ -878,24 +1269,6 @@ _collate_ice_connection_states (GstWebRTCBin * webrtc)
     if (ice_state != STATE (CONNECTED) && ice_state != STATE (COMPLETED)
         && ice_state != STATE (CLOSED))
       all_connected_completed_or_closed = FALSE;
-
-    rtcp_transport =
-        webrtc_transceiver_get_rtcp_dtls_transport (rtp_trans)->transport;
-
-    if (!rtcp_mux && rtcp_transport && transport != rtcp_transport) {
-      g_object_get (rtcp_transport, "state", &ice_state, NULL);
-      GST_TRACE_OBJECT (webrtc, "transceiver %p RTCP state 0x%x", rtp_trans,
-          ice_state);
-      any_state |= (1 << ice_state);
-
-      if (ice_state != STATE (NEW) && ice_state != STATE (CLOSED))
-        all_new_or_closed = FALSE;
-      if (ice_state != STATE (COMPLETED) && ice_state != STATE (CLOSED))
-        all_completed_or_closed = FALSE;
-      if (ice_state != STATE (CONNECTED) && ice_state != STATE (COMPLETED)
-          && ice_state != STATE (CLOSED))
-        all_connected_completed_or_closed = FALSE;
-    }
   }
 
   GST_TRACE_OBJECT (webrtc, "ICE connection state: 0x%x", any_state);
@@ -947,7 +1320,11 @@ _collate_ice_gathering_states (GstWebRTCBin * webrtc)
 {
 #define STATE(val) GST_WEBRTC_ICE_GATHERING_STATE_ ## val
   GstWebRTCICEGatheringState any_state = 0;
-  gboolean all_completed = webrtc->priv->transceivers->len > 0;
+  GstWebRTCICEGatheringState ice_state;
+  GstWebRTCDTLSTransport *dtls_transport;
+  GstWebRTCICETransport *transport;
+  gboolean all_completed = webrtc->priv->transceivers->len > 0 ||
+      webrtc->priv->data_channel_transport;
   int i;
 
   for (i = 0; i < webrtc->priv->transceivers->len; i++) {
@@ -955,10 +1332,6 @@ _collate_ice_gathering_states (GstWebRTCBin * webrtc)
         g_ptr_array_index (webrtc->priv->transceivers, i);
     WebRTCTransceiver *trans = WEBRTC_TRANSCEIVER (rtp_trans);
     TransportStream *stream = trans->stream;
-    GstWebRTCDTLSTransport *dtls_transport;
-    GstWebRTCICETransport *transport, *rtcp_transport;
-    GstWebRTCICEGatheringState ice_state;
-    gboolean rtcp_mux = FALSE;
 
     if (rtp_trans->stopped || stream == NULL) {
       GST_TRACE_OBJECT (webrtc, "transceiver %p stopped or unassociated",
@@ -972,8 +1345,6 @@ _collate_ice_gathering_states (GstWebRTCBin * webrtc)
       GST_TRACE_OBJECT (webrtc, "transceiver %p has no mid", rtp_trans);
     }
 
-    g_object_get (stream, "rtcp-mux", &rtcp_mux, NULL);
-
     dtls_transport = webrtc_transceiver_get_dtls_transport (rtp_trans);
     if (dtls_transport == NULL) {
       GST_WARNING ("Transceiver %p has no DTLS transport", rtp_trans);
@@ -989,18 +1360,16 @@ _collate_ice_gathering_states (GstWebRTCBin * webrtc)
     any_state |= (1 << ice_state);
     if (ice_state != STATE (COMPLETE))
       all_completed = FALSE;
+  }
 
-    dtls_transport = webrtc_transceiver_get_rtcp_dtls_transport (rtp_trans);
-    if (dtls_transport == NULL) {
-      GST_WARNING ("Transceiver %p has no DTLS RTCP transport", rtp_trans);
-      continue;
-    }
-    rtcp_transport = dtls_transport->transport;
-
-    if (!rtcp_mux && rtcp_transport && rtcp_transport != transport) {
-      g_object_get (rtcp_transport, "gathering-state", &ice_state, NULL);
-      GST_TRACE_OBJECT (webrtc, "transceiver %p RTCP gathering state: 0x%x",
-          rtp_trans, ice_state);
+  /* check data channel transport gathering state */
+  if (all_completed && webrtc->priv->data_channel_transport) {
+    if ((dtls_transport = webrtc->priv->data_channel_transport->transport)) {
+      transport = dtls_transport->transport;
+      g_object_get (transport, "gathering-state", &ice_state, NULL);
+      GST_TRACE_OBJECT (webrtc,
+          "data channel transport %p gathering state: 0x%x", dtls_transport,
+          ice_state);
       any_state |= (1 << ice_state);
       if (ice_state != STATE (COMPLETE))
         all_completed = FALSE;
@@ -1048,12 +1417,9 @@ _collate_peer_connection_states (GstWebRTCBin * webrtc)
   for (i = 0; i < webrtc->priv->transceivers->len; i++) {
     GstWebRTCRTPTransceiver *rtp_trans =
         g_ptr_array_index (webrtc->priv->transceivers, i);
-    WebRTCTransceiver *trans = WEBRTC_TRANSCEIVER (rtp_trans);
-    TransportStream *stream = trans->stream;
-    GstWebRTCDTLSTransport *transport, *rtcp_transport;
+    GstWebRTCDTLSTransport *transport;
     GstWebRTCICEConnectionState ice_state;
     GstWebRTCDTLSTransportState dtls_state;
-    gboolean rtcp_mux = FALSE;
 
     if (rtp_trans->stopped) {
       GST_TRACE_OBJECT (webrtc, "transceiver %p stopped", rtp_trans);
@@ -1064,7 +1430,6 @@ _collate_peer_connection_states (GstWebRTCBin * webrtc)
       continue;
     }
 
-    g_object_get (stream, "rtcp-mux", &rtcp_mux, NULL);
     transport = webrtc_transceiver_get_dtls_transport (rtp_trans);
 
     /* get transport state */
@@ -1093,38 +1458,40 @@ _collate_peer_connection_states (GstWebRTCBin * webrtc)
     if (ice_state != ICE_STATE (CONNECTED) && ice_state != ICE_STATE (COMPLETED)
         && ice_state != ICE_STATE (CLOSED))
       ice_all_connected_completed_or_closed = FALSE;
+  }
 
-    rtcp_transport = webrtc_transceiver_get_rtcp_dtls_transport (rtp_trans);
+  // also check data channel transport state
+  if (webrtc->priv->data_channel_transport) {
+    GstWebRTCDTLSTransport *transport =
+        webrtc->priv->data_channel_transport->transport;
+    GstWebRTCICEConnectionState ice_state;
+    GstWebRTCDTLSTransportState dtls_state;
 
-    if (!rtcp_mux && rtcp_transport && rtcp_transport != transport) {
-      g_object_get (rtcp_transport, "state", &dtls_state, NULL);
-      GST_TRACE_OBJECT (webrtc, "transceiver %p RTCP DTLS state: 0x%x",
-          rtp_trans, dtls_state);
-      any_dtls_state |= (1 << dtls_state);
+    g_object_get (transport, "state", &dtls_state, NULL);
+    GST_TRACE_OBJECT (webrtc, "data channel transport DTLS state: 0x%x",
+        dtls_state);
+    any_dtls_state |= (1 << dtls_state);
 
-      if (dtls_state != DTLS_STATE (NEW) && dtls_state != DTLS_STATE (CLOSED))
-        dtls_all_new_or_closed = FALSE;
-      if (dtls_state != DTLS_STATE (NEW)
-          && dtls_state != DTLS_STATE (CONNECTING))
-        dtls_all_new_connecting_or_checking = FALSE;
-      if (dtls_state != DTLS_STATE (CONNECTED)
-          && dtls_state != DTLS_STATE (CLOSED))
-        dtls_all_connected_completed_or_closed = FALSE;
+    if (dtls_state != DTLS_STATE (NEW) && dtls_state != DTLS_STATE (CLOSED))
+      dtls_all_new_or_closed = FALSE;
+    if (dtls_state != DTLS_STATE (NEW) && dtls_state != DTLS_STATE (CONNECTING))
+      dtls_all_new_connecting_or_checking = FALSE;
+    if (dtls_state != DTLS_STATE (CONNECTED)
+        && dtls_state != DTLS_STATE (CLOSED))
+      dtls_all_connected_completed_or_closed = FALSE;
 
-      g_object_get (rtcp_transport->transport, "state", &ice_state, NULL);
-      GST_TRACE_OBJECT (webrtc, "transceiver %p RTCP ICE state: 0x%x",
-          rtp_trans, ice_state);
-      any_ice_state |= (1 << ice_state);
+    g_object_get (transport->transport, "state", &ice_state, NULL);
+    GST_TRACE_OBJECT (webrtc, "data channel transport ICE state: 0x%x",
+        ice_state);
+    any_ice_state |= (1 << ice_state);
 
-      if (ice_state != ICE_STATE (NEW) && ice_state != ICE_STATE (CLOSED))
-        ice_all_new_or_closed = FALSE;
-      if (ice_state != ICE_STATE (NEW) && ice_state != ICE_STATE (CHECKING))
-        ice_all_new_connecting_or_checking = FALSE;
-      if (ice_state != ICE_STATE (CONNECTED)
-          && ice_state != ICE_STATE (COMPLETED)
-          && ice_state != ICE_STATE (CLOSED))
-        ice_all_connected_completed_or_closed = FALSE;
-    }
+    if (ice_state != ICE_STATE (NEW) && ice_state != ICE_STATE (CLOSED))
+      ice_all_new_or_closed = FALSE;
+    if (ice_state != ICE_STATE (NEW) && ice_state != ICE_STATE (CHECKING))
+      ice_all_new_connecting_or_checking = FALSE;
+    if (ice_state != ICE_STATE (CONNECTED) && ice_state != ICE_STATE (COMPLETED)
+        && ice_state != ICE_STATE (CLOSED))
+      ice_all_connected_completed_or_closed = FALSE;
   }
 
   GST_TRACE_OBJECT (webrtc, "ICE connection state: 0x%x. DTLS connection "
@@ -1156,7 +1523,7 @@ _collate_peer_connection_states (GstWebRTCBin * webrtc)
   /* All RTCIceTransports and RTCDtlsTransports are in the new or closed
    * state, or there are no transports. */
   if ((dtls_all_new_or_closed && ice_all_new_or_closed)
-      || webrtc->priv->transceivers->len == 0) {
+      || webrtc->priv->transports->len == 0) {
     GST_TRACE_OBJECT (webrtc, "returning new");
     return STATE (NEW);
   }
@@ -1193,7 +1560,7 @@ _collate_peer_connection_states (GstWebRTCBin * webrtc)
 #undef STATE
 }
 
-static void
+static GstStructure *
 _update_ice_gathering_state_task (GstWebRTCBin * webrtc, gpointer data)
 {
   GstWebRTCICEGatheringState old_state = webrtc->ice_gathering_state;
@@ -1215,7 +1582,7 @@ _update_ice_gathering_state_task (GstWebRTCBin * webrtc, gpointer data)
   }
 
   if (new_state != webrtc->ice_gathering_state) {
-    gchar *old_s, *new_s;
+    const gchar *old_s, *new_s;
 
     old_s = _enum_value_to_string (GST_TYPE_WEBRTC_ICE_GATHERING_STATE,
         old_state);
@@ -1223,14 +1590,14 @@ _update_ice_gathering_state_task (GstWebRTCBin * webrtc, gpointer data)
         new_state);
     GST_INFO_OBJECT (webrtc, "ICE gathering state change from %s(%u) to %s(%u)",
         old_s, old_state, new_s, new_state);
-    g_free (old_s);
-    g_free (new_s);
 
     webrtc->ice_gathering_state = new_state;
     PC_UNLOCK (webrtc);
     g_object_notify (G_OBJECT (webrtc), "ice-gathering-state");
     PC_LOCK (webrtc);
   }
+
+  return NULL;
 }
 
 static void
@@ -1240,7 +1607,7 @@ _update_ice_gathering_state (GstWebRTCBin * webrtc)
       NULL, NULL);
 }
 
-static void
+static GstStructure *
 _update_ice_connection_state_task (GstWebRTCBin * webrtc, gpointer data)
 {
   GstWebRTCICEConnectionState old_state = webrtc->ice_connection_state;
@@ -1249,7 +1616,7 @@ _update_ice_connection_state_task (GstWebRTCBin * webrtc, gpointer data)
   new_state = _collate_ice_connection_states (webrtc);
 
   if (new_state != old_state) {
-    gchar *old_s, *new_s;
+    const gchar *old_s, *new_s;
 
     old_s = _enum_value_to_string (GST_TYPE_WEBRTC_ICE_CONNECTION_STATE,
         old_state);
@@ -1258,14 +1625,14 @@ _update_ice_connection_state_task (GstWebRTCBin * webrtc, gpointer data)
     GST_INFO_OBJECT (webrtc,
         "ICE connection state change from %s(%u) to %s(%u)", old_s, old_state,
         new_s, new_state);
-    g_free (old_s);
-    g_free (new_s);
 
     webrtc->ice_connection_state = new_state;
     PC_UNLOCK (webrtc);
     g_object_notify (G_OBJECT (webrtc), "ice-connection-state");
     PC_LOCK (webrtc);
   }
+
+  return NULL;
 }
 
 static void
@@ -1275,7 +1642,7 @@ _update_ice_connection_state (GstWebRTCBin * webrtc)
       NULL, NULL);
 }
 
-static void
+static GstStructure *
 _update_peer_connection_state_task (GstWebRTCBin * webrtc, gpointer data)
 {
   GstWebRTCPeerConnectionState old_state = webrtc->peer_connection_state;
@@ -1284,7 +1651,7 @@ _update_peer_connection_state_task (GstWebRTCBin * webrtc, gpointer data)
   new_state = _collate_peer_connection_states (webrtc);
 
   if (new_state != old_state) {
-    gchar *old_s, *new_s;
+    const gchar *old_s, *new_s;
 
     old_s = _enum_value_to_string (GST_TYPE_WEBRTC_PEER_CONNECTION_STATE,
         old_state);
@@ -1293,14 +1660,14 @@ _update_peer_connection_state_task (GstWebRTCBin * webrtc, gpointer data)
     GST_INFO_OBJECT (webrtc,
         "Peer connection state change from %s(%u) to %s(%u)", old_s, old_state,
         new_s, new_state);
-    g_free (old_s);
-    g_free (new_s);
 
     webrtc->peer_connection_state = new_state;
     PC_UNLOCK (webrtc);
     g_object_notify (G_OBJECT (webrtc), "connection-state");
     PC_LOCK (webrtc);
   }
+
+  return NULL;
 }
 
 static void
@@ -1327,7 +1694,11 @@ _all_sinks_have_caps (GstWebRTCBin * webrtc)
     wpad = GST_WEBRTC_BIN_PAD (l->data);
     if (GST_PAD_DIRECTION (l->data) == GST_PAD_SINK && !wpad->received_caps
         && (!wpad->trans || !wpad->trans->stopped)) {
-      goto done;
+      if (wpad->trans && wpad->trans->codec_preferences) {
+        continue;
+      } else {
+        goto done;
+      }
     }
   }
 
@@ -1354,7 +1725,7 @@ _check_if_negotiation_is_needed (GstWebRTCBin * webrtc)
   GST_LOG_OBJECT (webrtc, "checking if negotiation is needed");
 
   /* We can't negotiate until we have received caps on all our sink pads,
-   * as we will need the ssrcs in our offer / answer */
+   * as we will need the formats in our offer / answer */
   if (!_all_sinks_have_caps (webrtc)) {
     GST_LOG_OBJECT (webrtc,
         "no negotiation possible until caps have been received on all sink pads");
@@ -1436,26 +1807,11 @@ _check_if_negotiation_is_needed (GstWebRTCBin * webrtc)
          * nor answer matches t's direction, return "true". */
 
         if (local_dir != trans->direction && remote_dir != trans->direction) {
-          gchar *local_str, *remote_str, *dir_str;
-
-          local_str =
-              _enum_value_to_string (GST_TYPE_WEBRTC_RTP_TRANSCEIVER_DIRECTION,
-              local_dir);
-          remote_str =
-              _enum_value_to_string (GST_TYPE_WEBRTC_RTP_TRANSCEIVER_DIRECTION,
-              remote_dir);
-          dir_str =
-              _enum_value_to_string (GST_TYPE_WEBRTC_RTP_TRANSCEIVER_DIRECTION,
-              trans->direction);
-
           GST_LOG_OBJECT (webrtc, "transceiver direction (%s) doesn't match "
-              "description (local %s remote %s)", dir_str, local_str,
-              remote_str);
-
-          g_free (dir_str);
-          g_free (local_str);
-          g_free (remote_str);
-
+              "description (local %s remote %s)",
+              gst_webrtc_rtp_transceiver_direction_to_string (trans->direction),
+              gst_webrtc_rtp_transceiver_direction_to_string (local_dir),
+              gst_webrtc_rtp_transceiver_direction_to_string (remote_dir));
           return TRUE;
         }
       } else if (webrtc->current_local_description->type ==
@@ -1471,30 +1827,12 @@ _check_if_negotiation_is_needed (GstWebRTCBin * webrtc)
         intersect_dir = _intersect_answer_directions (remote_dir, local_dir);
 
         if (intersect_dir != trans->direction) {
-          gchar *local_str, *remote_str, *inter_str, *dir_str;
-
-          local_str =
-              _enum_value_to_string (GST_TYPE_WEBRTC_RTP_TRANSCEIVER_DIRECTION,
-              local_dir);
-          remote_str =
-              _enum_value_to_string (GST_TYPE_WEBRTC_RTP_TRANSCEIVER_DIRECTION,
-              remote_dir);
-          dir_str =
-              _enum_value_to_string (GST_TYPE_WEBRTC_RTP_TRANSCEIVER_DIRECTION,
-              trans->direction);
-          inter_str =
-              _enum_value_to_string (GST_TYPE_WEBRTC_RTP_TRANSCEIVER_DIRECTION,
-              intersect_dir);
-
           GST_LOG_OBJECT (webrtc, "transceiver direction (%s) doesn't match "
               "description intersected direction %s (local %s remote %s)",
-              dir_str, local_str, inter_str, remote_str);
-
-          g_free (dir_str);
-          g_free (local_str);
-          g_free (remote_str);
-          g_free (inter_str);
-
+              gst_webrtc_rtp_transceiver_direction_to_string (trans->direction),
+              gst_webrtc_rtp_transceiver_direction_to_string (local_dir),
+              gst_webrtc_rtp_transceiver_direction_to_string (intersect_dir),
+              gst_webrtc_rtp_transceiver_direction_to_string (remote_dir));
           return TRUE;
         }
       }
@@ -1505,7 +1843,7 @@ _check_if_negotiation_is_needed (GstWebRTCBin * webrtc)
   return FALSE;
 }
 
-static void
+static GstStructure *
 _check_need_negotiation_task (GstWebRTCBin * webrtc, gpointer unused)
 {
   if (webrtc->priv->need_negotiation) {
@@ -1515,6 +1853,8 @@ _check_need_negotiation_task (GstWebRTCBin * webrtc, gpointer unused)
         0);
     PC_LOCK (webrtc);
   }
+
+  return NULL;
 }
 
 /* http://w3c.github.io/webrtc-pc/#dfn-update-the-negotiation-needed-flag */
@@ -1546,56 +1886,185 @@ _update_need_negotiation (GstWebRTCBin * webrtc)
       NULL, NULL);
 }
 
+static GstCaps *
+_query_pad_caps (GstWebRTCBin * webrtc, GstWebRTCRTPTransceiver * rtp_trans,
+    GstWebRTCBinPad * pad, GstCaps * filter, GError ** error)
+{
+  GstCaps *caps;
+  guint i, n;
+
+  caps = gst_pad_peer_query_caps (GST_PAD (pad), filter);
+  GST_LOG_OBJECT (webrtc, "Using peer query caps: %" GST_PTR_FORMAT, caps);
+
+  /* Only return an error if actual empty caps were returned from the query. */
+  if (gst_caps_is_empty (caps)) {
+    g_set_error (error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+        "Caps negotiation on pad %s failed", GST_PAD_NAME (pad));
+    gst_clear_caps (&caps);
+    gst_caps_unref (filter);
+    return NULL;
+  }
+
+  n = gst_caps_get_size (caps);
+  if (n > 0) {
+    /* Make sure the caps are complete enough to figure out the media type and
+     * encoding-name, otherwise they would match with basically any media. */
+    caps = gst_caps_make_writable (caps);
+    for (i = n; i > 0; i--) {
+      const GstStructure *s = gst_caps_get_structure (caps, i - 1);
+
+      if (!gst_structure_has_name (s, "application/x-rtp") ||
+          !gst_structure_has_field (s, "media") ||
+          !gst_structure_has_field (s, "encoding-name")) {
+        gst_caps_remove_structure (caps, i - 1);
+      }
+    }
+  }
+
+  /* If the filtering above resulted in empty caps, or the caps were ANY to
+   * begin with, then don't report and error but just NULL.
+   *
+   * This would be the case if negotiation would not fail but the peer does
+   * not have any specific enough preferred caps that would allow us to
+   * use them further.
+   */
+  if (gst_caps_is_any (caps) || gst_caps_is_empty (caps)) {
+    GST_DEBUG_OBJECT (webrtc, "Peer caps not specific enough");
+    gst_clear_caps (&caps);
+  }
+
+  gst_caps_unref (filter);
+
+  return caps;
+}
+
 static GstCaps *
 _find_codec_preferences (GstWebRTCBin * webrtc,
-    GstWebRTCRTPTransceiver * rtp_trans, GstPadDirection direction,
-    guint media_idx)
+    GstWebRTCRTPTransceiver * rtp_trans, guint media_idx, GError ** error)
 {
   WebRTCTransceiver *trans = (WebRTCTransceiver *) rtp_trans;
   GstCaps *ret = NULL;
+  GstCaps *codec_preferences = NULL;
+  GstWebRTCBinPad *pad = NULL;
+  GstPadDirection direction;
+
+  g_assert (rtp_trans);
+  g_assert (error && *error == NULL);
 
   GST_LOG_OBJECT (webrtc, "retrieving codec preferences from %" GST_PTR_FORMAT,
       trans);
 
-  if (rtp_trans && rtp_trans->codec_preferences) {
+  GST_OBJECT_LOCK (rtp_trans);
+  if (rtp_trans->codec_preferences) {
     GST_LOG_OBJECT (webrtc, "Using codec preferences: %" GST_PTR_FORMAT,
         rtp_trans->codec_preferences);
-    ret = gst_caps_ref (rtp_trans->codec_preferences);
-  } else {
-    GstWebRTCBinPad *pad = NULL;
+    codec_preferences = gst_caps_ref (rtp_trans->codec_preferences);
+  }
+  GST_OBJECT_UNLOCK (rtp_trans);
+
+  if (rtp_trans->direction == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_RECVONLY)
+    direction = GST_PAD_SRC;
+  else
+    direction = GST_PAD_SINK;
+
+  pad = _find_pad_for_transceiver (webrtc, direction, rtp_trans);
+
+  /* try to find a pad */
+  if (!pad)
+    pad = _find_pad_for_mline (webrtc, direction, media_idx);
+
+  /* For the case where we have set our transceiver to sendrecv, but the
+   * sink pad has not been requested yet.
+   */
+  if (!pad &&
+      rtp_trans->direction == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDRECV) {
+
+    pad = _find_pad_for_transceiver (webrtc, GST_PAD_SRC, rtp_trans);
 
     /* try to find a pad */
-    if (!trans
-        || !(pad = _find_pad_for_transceiver (webrtc, direction, rtp_trans)))
-      pad = _find_pad_for_mline (webrtc, direction, media_idx);
+    if (!pad)
+      pad = _find_pad_for_mline (webrtc, GST_PAD_SRC, media_idx);
+  }
+
+  if (pad) {
+    GstCaps *caps = NULL;
 
-    if (!pad) {
-      if (trans && trans->last_configured_caps)
-        ret = gst_caps_ref (trans->last_configured_caps);
+    if (pad->received_caps) {
+      caps = gst_caps_ref (pad->received_caps);
     } else {
-      GstCaps *caps = NULL;
+      static GstStaticCaps static_filter =
+          GST_STATIC_CAPS ("application/x-rtp, "
+          "media = (string) { audio, video }, payload = (int) [ 0, 127 ]");
+      GstCaps *filter = gst_static_caps_get (&static_filter);
 
-      if (pad->received_caps) {
-        caps = gst_caps_ref (pad->received_caps);
-      } else if ((caps = gst_pad_get_current_caps (GST_PAD (pad)))) {
-        GST_LOG_OBJECT (webrtc, "Using current pad caps: %" GST_PTR_FORMAT,
-            caps);
-      } else {
-        if ((caps = gst_pad_peer_query_caps (GST_PAD (pad), NULL)))
-          GST_LOG_OBJECT (webrtc, "Using peer query caps: %" GST_PTR_FORMAT,
-              caps);
+      filter = gst_caps_make_writable (filter);
+
+      if (rtp_trans->kind == GST_WEBRTC_KIND_AUDIO)
+        gst_caps_set_simple (filter, "media", G_TYPE_STRING, "audio", NULL);
+      else if (rtp_trans->kind == GST_WEBRTC_KIND_VIDEO)
+        gst_caps_set_simple (filter, "media", G_TYPE_STRING, "video", NULL);
+
+      caps = _query_pad_caps (webrtc, rtp_trans, pad, filter, error);
+    }
+
+    if (*error)
+      goto out;
+
+    if (caps &&
+        rtp_trans->direction == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDRECV) {
+      GstWebRTCBinPad *srcpad =
+          _find_pad_for_transceiver (webrtc, GST_PAD_SRC, rtp_trans);
+
+      if (srcpad) {
+        caps = _query_pad_caps (webrtc, rtp_trans, srcpad, caps, error);
+        gst_object_unref (srcpad);
+
+        if (*error)
+          goto out;
       }
-      if (caps) {
-        if (trans)
-          gst_caps_replace (&trans->last_configured_caps, caps);
+    }
 
-        ret = caps;
+    if (caps && codec_preferences) {
+      GstCaps *intersection;
+
+      intersection = gst_caps_intersect_full (codec_preferences, caps,
+          GST_CAPS_INTERSECT_FIRST);
+      gst_clear_caps (&caps);
+
+      if (gst_caps_is_empty (intersection)) {
+        g_set_error (error, GST_WEBRTC_ERROR,
+            GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+            "Caps negotiation on pad %s failed against codec preferences",
+            GST_PAD_NAME (pad));
+        gst_clear_caps (&intersection);
+      } else {
+        caps = intersection;
       }
+    }
 
-      gst_object_unref (pad);
+    if (caps) {
+      if (trans)
+        gst_caps_replace (&trans->last_retrieved_caps, caps);
+
+      ret = caps;
     }
   }
 
+  if (!ret) {
+    if (codec_preferences)
+      ret = gst_caps_ref (codec_preferences);
+    else if (trans->last_retrieved_caps)
+      ret = gst_caps_ref (trans->last_retrieved_caps);
+  }
+
+out:
+
+  if (pad)
+    gst_object_unref (pad);
+  if (codec_preferences)
+    gst_caps_unref (codec_preferences);
+
   if (!ret)
     GST_DEBUG_OBJECT (trans, "Could not find caps for mline %u", media_idx);
 
@@ -1606,11 +2075,16 @@ static GstCaps *
 _add_supported_attributes_to_caps (GstWebRTCBin * webrtc,
     WebRTCTransceiver * trans, const GstCaps * caps)
 {
+  GstWebRTCKind kind;
   GstCaps *ret;
   guint i;
 
+  if (caps == NULL)
+    return NULL;
+
   ret = gst_caps_make_writable (caps);
 
+  kind = webrtc_kind_from_caps (ret);
   for (i = 0; i < gst_caps_get_size (ret); i++) {
     GstStructure *s = gst_caps_get_structure (ret, i);
 
@@ -1618,11 +2092,14 @@ _add_supported_attributes_to_caps (GstWebRTCBin * webrtc,
       if (!gst_structure_has_field (s, "rtcp-fb-nack"))
         gst_structure_set (s, "rtcp-fb-nack", G_TYPE_BOOLEAN, TRUE, NULL);
 
-    if (!gst_structure_has_field (s, "rtcp-fb-nack-pli"))
-      gst_structure_set (s, "rtcp-fb-nack-pli", G_TYPE_BOOLEAN, TRUE, NULL);
-    /* FIXME: is this needed? */
-    /*if (!gst_structure_has_field (s, "rtcp-fb-transport-cc"))
-       gst_structure_set (s, "rtcp-fb-nack-pli", G_TYPE_BOOLEAN, TRUE, NULL); */
+    if (kind == GST_WEBRTC_KIND_VIDEO) {
+      if (!gst_structure_has_field (s, "rtcp-fb-nack-pli"))
+        gst_structure_set (s, "rtcp-fb-nack-pli", G_TYPE_BOOLEAN, TRUE, NULL);
+      if (!gst_structure_has_field (s, "rtcp-fb-ccm-fir"))
+        gst_structure_set (s, "rtcp-fb-ccm-fir", G_TYPE_BOOLEAN, TRUE, NULL);
+    }
+    if (!gst_structure_has_field (s, "rtcp-fb-transport-cc"))
+      gst_structure_set (s, "rtcp-fb-transport-cc", G_TYPE_BOOLEAN, TRUE, NULL);
 
     /* FIXME: codec-specific parameters? */
   }
@@ -1652,9 +2129,267 @@ _on_dtls_transport_notify_state (GstWebRTCDTLSTransport * transport,
   _update_peer_connection_state (webrtc);
 }
 
+static gboolean
+_on_sending_rtcp (GObject * internal_session, GstBuffer * buffer,
+    gboolean early, gpointer user_data)
+{
+  GstWebRTCBin *webrtc = user_data;
+  GstRTCPBuffer rtcp = GST_RTCP_BUFFER_INIT;
+  GstRTCPPacket packet;
+
+  if (!gst_rtcp_buffer_map (buffer, GST_MAP_READ, &rtcp))
+    goto done;
+
+  if (gst_rtcp_buffer_get_first_packet (&rtcp, &packet)) {
+    if (gst_rtcp_packet_get_type (&packet) == GST_RTCP_TYPE_SR) {
+      guint32 ssrc;
+      GstWebRTCRTPTransceiver *rtp_trans = NULL;
+      WebRTCTransceiver *trans;
+      guint rtp_session;
+      SsrcMapItem *mid;
+
+      gst_rtcp_packet_sr_get_sender_info (&packet, &ssrc, NULL, NULL, NULL,
+          NULL);
+      rtp_session =
+          GPOINTER_TO_UINT (g_object_get_data (internal_session,
+              "GstWebRTCBinRTPSessionID"));
+
+      mid = find_mid_ssrc_for_ssrc (webrtc,
+          GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDONLY, rtp_session, ssrc);
+      if (mid && mid->mid) {
+        rtp_trans = _find_transceiver_for_mid (webrtc, mid->mid);
+        GST_LOG_OBJECT (webrtc, "found %" GST_PTR_FORMAT " from mid entry "
+            "using rtp session %u ssrc %u -> mid \'%s\'", rtp_trans,
+            rtp_session, ssrc, mid->mid);
+      }
+      trans = (WebRTCTransceiver *) rtp_trans;
+
+      if (rtp_trans && rtp_trans->sender && trans->tos_event) {
+        GstPad *pad;
+        gchar *pad_name = NULL;
+
+        pad_name =
+            g_strdup_printf ("send_rtcp_src_%u",
+            rtp_trans->sender->transport->session_id);
+        pad = gst_element_get_static_pad (webrtc->rtpbin, pad_name);
+        g_free (pad_name);
+        if (pad) {
+          gst_pad_push_event (pad, gst_event_ref (trans->tos_event));
+          gst_object_unref (pad);
+        }
+      }
+    }
+  }
+
+  gst_rtcp_buffer_unmap (&rtcp);
+
+done:
+  /* False means we don't care about suppression */
+  return FALSE;
+}
+
+static void
+gst_webrtc_bin_attach_tos_to_session (GstWebRTCBin * webrtc, guint session_id)
+{
+  GObject *internal_session = NULL;
+
+  g_signal_emit_by_name (webrtc->rtpbin, "get-internal-session",
+      session_id, &internal_session);
+
+  if (internal_session) {
+    g_object_set_data (internal_session, "GstWebRTCBinRTPSessionID",
+        GUINT_TO_POINTER (session_id));
+    g_signal_connect (internal_session, "on-sending-rtcp",
+        G_CALLBACK (_on_sending_rtcp), webrtc);
+    g_object_unref (internal_session);
+  }
+}
+
+static void
+weak_free (GWeakRef * weak)
+{
+  g_weak_ref_clear (weak);
+  g_free (weak);
+}
+
+static GstPadProbeReturn
+_nicesink_pad_probe (GstPad * pad, GstPadProbeInfo * info, gpointer user_data)
+{
+  GstWebRTCBin *webrtc = g_weak_ref_get ((GWeakRef *) user_data);
+
+  if (!webrtc)
+    return GST_PAD_PROBE_REMOVE;
+
+  if (GST_EVENT_TYPE (GST_PAD_PROBE_INFO_EVENT (info))
+      == GST_EVENT_CUSTOM_DOWNSTREAM_STICKY) {
+    const GstStructure *s =
+        gst_event_get_structure (GST_PAD_PROBE_INFO_EVENT (info));
+
+    if (gst_structure_has_name (s, "GstWebRtcBinUpdateTos")) {
+      const char *mid;
+      gint priority;
+
+      if ((mid = gst_structure_get_string (s, "mid"))) {
+        GstWebRTCRTPTransceiver *rtp_trans;
+
+        rtp_trans = _find_transceiver_for_mid (webrtc, mid);
+        if (rtp_trans) {
+          WebRTCTransceiver *trans = WEBRTC_TRANSCEIVER (rtp_trans);
+          GstWebRTCICEStream *stream = _find_ice_stream_for_session (webrtc,
+              trans->stream->session_id);
+          guint8 dscp = 0;
+
+          /* Set DSCP field based on
+           * https://tools.ietf.org/html/draft-ietf-tsvwg-rtcweb-qos-18#section-5
+           */
+          switch (rtp_trans->sender->priority) {
+            case GST_WEBRTC_PRIORITY_TYPE_VERY_LOW:
+              dscp = 8;         /* CS1 */
+              break;
+            case GST_WEBRTC_PRIORITY_TYPE_LOW:
+              dscp = 0;         /* DF */
+              break;
+            case GST_WEBRTC_PRIORITY_TYPE_MEDIUM:
+              switch (rtp_trans->kind) {
+                case GST_WEBRTC_KIND_AUDIO:
+                  dscp = 46;    /* EF */
+                  break;
+                case GST_WEBRTC_KIND_VIDEO:
+                  dscp = 38;    /* AF43 *//* TODO: differentiate non-interactive */
+                  break;
+                case GST_WEBRTC_KIND_UNKNOWN:
+                  dscp = 0;
+                  break;
+              }
+              break;
+            case GST_WEBRTC_PRIORITY_TYPE_HIGH:
+              switch (rtp_trans->kind) {
+                case GST_WEBRTC_KIND_AUDIO:
+                  dscp = 46;    /* EF */
+                  break;
+                case GST_WEBRTC_KIND_VIDEO:
+                  dscp = 36;    /* AF42 *//* TODO: differentiate non-interactive */
+                  break;
+                case GST_WEBRTC_KIND_UNKNOWN:
+                  dscp = 0;
+                  break;
+              }
+              break;
+          }
+
+          gst_webrtc_ice_set_tos (webrtc->priv->ice, stream, dscp << 2);
+        }
+      } else if (gst_structure_get_enum (s, "sctp-priority",
+              GST_TYPE_WEBRTC_PRIORITY_TYPE, &priority)) {
+        guint8 dscp = 0;
+
+        /* Set DSCP field based on
+         * https://tools.ietf.org/html/draft-ietf-tsvwg-rtcweb-qos-18#section-5
+         */
+        switch (priority) {
+          case GST_WEBRTC_PRIORITY_TYPE_VERY_LOW:
+            dscp = 8;           /* CS1 */
+            break;
+          case GST_WEBRTC_PRIORITY_TYPE_LOW:
+            dscp = 0;           /* DF */
+            break;
+          case GST_WEBRTC_PRIORITY_TYPE_MEDIUM:
+            dscp = 10;          /* AF11 */
+            break;
+          case GST_WEBRTC_PRIORITY_TYPE_HIGH:
+            dscp = 18;          /* AF21 */
+            break;
+        }
+        if (webrtc->priv->data_channel_transport)
+          gst_webrtc_ice_set_tos (webrtc->priv->ice,
+              webrtc->priv->data_channel_transport->stream, dscp << 2);
+      }
+    }
+  }
+
+  gst_object_unref (webrtc);
+
+  return GST_PAD_PROBE_OK;
+}
+
+static void gst_webrtc_bin_attach_tos (GstWebRTCBin * webrtc);
+
+static void
+gst_webrtc_bin_update_sctp_priority (GstWebRTCBin * webrtc)
+{
+  GstWebRTCPriorityType sctp_priority = 0;
+  guint i;
+
+  if (!webrtc->priv->sctp_transport)
+    return;
+
+  DC_LOCK (webrtc);
+  for (i = 0; i < webrtc->priv->data_channels->len; i++) {
+    GstWebRTCDataChannel *channel
+        = g_ptr_array_index (webrtc->priv->data_channels, i);
+
+    sctp_priority = MAX (sctp_priority, channel->priority);
+  }
+  DC_UNLOCK (webrtc);
+
+  /* Default priority is low means DSCP field is left as 0 */
+  if (sctp_priority == 0)
+    sctp_priority = GST_WEBRTC_PRIORITY_TYPE_LOW;
+
+  /* Nobody asks for DSCP, leave it as-is */
+  if (sctp_priority == GST_WEBRTC_PRIORITY_TYPE_LOW &&
+      !webrtc->priv->tos_attached)
+    return;
+
+  /* If one stream has a non-default priority, then everyone else does too */
+  gst_webrtc_bin_attach_tos (webrtc);
+
+  webrtc_sctp_transport_set_priority (webrtc->priv->sctp_transport,
+      sctp_priority);
+}
+
+static void
+gst_webrtc_bin_attach_probe_to_ice_sink (GstWebRTCBin * webrtc,
+    GstWebRTCICETransport * transport)
+{
+  GstPad *pad;
+  GWeakRef *weak;
+
+  pad = gst_element_get_static_pad (transport->sink, "sink");
+
+  weak = g_new0 (GWeakRef, 1);
+  g_weak_ref_init (weak, webrtc);
+
+  gst_pad_add_probe (pad, GST_PAD_PROBE_TYPE_EVENT_DOWNSTREAM,
+      _nicesink_pad_probe, weak, (GDestroyNotify) weak_free);
+  gst_object_unref (pad);
+}
+
+static void
+gst_webrtc_bin_attach_tos (GstWebRTCBin * webrtc)
+{
+  guint i;
+
+  if (webrtc->priv->tos_attached)
+    return;
+  webrtc->priv->tos_attached = TRUE;
+
+  for (i = 0; i < webrtc->priv->transports->len; i++) {
+    TransportStream *stream = g_ptr_array_index (webrtc->priv->transports, i);
+
+    gst_webrtc_bin_attach_tos_to_session (webrtc, stream->session_id);
+
+    gst_webrtc_bin_attach_probe_to_ice_sink (webrtc,
+        stream->transport->transport);
+  }
+
+  gst_webrtc_bin_update_sctp_priority (webrtc);
+}
+
 static WebRTCTransceiver *
 _create_webrtc_transceiver (GstWebRTCBin * webrtc,
-    GstWebRTCRTPTransceiverDirection direction, guint mline)
+    GstWebRTCRTPTransceiverDirection direction, guint mline, GstWebRTCKind kind,
+    GstCaps * codec_preferences)
 {
   WebRTCTransceiver *trans;
   GstWebRTCRTPTransceiver *rtp_trans;
@@ -1667,9 +2402,20 @@ _create_webrtc_transceiver (GstWebRTCBin * webrtc,
   rtp_trans = GST_WEBRTC_RTP_TRANSCEIVER (trans);
   rtp_trans->direction = direction;
   rtp_trans->mline = mline;
+  rtp_trans->kind = kind;
+  rtp_trans->codec_preferences =
+      codec_preferences ? gst_caps_ref (codec_preferences) : NULL;
   /* FIXME: We don't support stopping transceiver yet so they're always not stopped */
   rtp_trans->stopped = FALSE;
 
+  GST_LOG_OBJECT (webrtc, "created new transceiver %" GST_PTR_FORMAT " with "
+      "direction %s (%d), mline %u, kind %s (%d)", rtp_trans,
+      gst_webrtc_rtp_transceiver_direction_to_string (direction), direction,
+      mline, gst_webrtc_kind_to_string (kind), kind);
+
+  g_signal_connect_object (sender, "notify::priority",
+      G_CALLBACK (gst_webrtc_bin_attach_tos), webrtc, G_CONNECT_SWAPPED);
+
   g_ptr_array_add (webrtc->priv->transceivers, trans);
 
   gst_object_unref (sender);
@@ -1686,6 +2432,7 @@ _create_transport_channel (GstWebRTCBin * webrtc, guint session_id)
 {
   GstWebRTCDTLSTransport *transport;
   TransportStream *ret;
+  gchar *pad_name;
 
   /* FIXME: how to parametrize the sender and the receiver */
   ret = transport_stream_new (webrtc, session_id);
@@ -1698,16 +2445,24 @@ _create_transport_channel (GstWebRTCBin * webrtc, guint session_id)
       G_CALLBACK (_on_ice_transport_notify_gathering_state), webrtc);
   g_signal_connect (G_OBJECT (transport), "notify::state",
       G_CALLBACK (_on_dtls_transport_notify_state), webrtc);
+  if (webrtc->priv->tos_attached)
+    gst_webrtc_bin_attach_probe_to_ice_sink (webrtc, transport->transport);
 
-  if ((transport = ret->rtcp_transport)) {
-    g_signal_connect (G_OBJECT (transport->transport),
-        "notify::state", G_CALLBACK (_on_ice_transport_notify_state), webrtc);
-    g_signal_connect (G_OBJECT (transport->transport),
-        "notify::gathering-state",
-        G_CALLBACK (_on_ice_transport_notify_gathering_state), webrtc);
-    g_signal_connect (G_OBJECT (transport), "notify::state",
-        G_CALLBACK (_on_dtls_transport_notify_state), webrtc);
-  }
+  gst_bin_add (GST_BIN (webrtc), GST_ELEMENT (ret->send_bin));
+  gst_bin_add (GST_BIN (webrtc), GST_ELEMENT (ret->receive_bin));
+  g_ptr_array_add (webrtc->priv->transports, ret);
+
+  pad_name = g_strdup_printf ("recv_rtcp_sink_%u", ret->session_id);
+  if (!gst_element_link_pads (GST_ELEMENT (ret->receive_bin), "rtcp_src",
+          GST_ELEMENT (webrtc->rtpbin), pad_name))
+    g_warn_if_reached ();
+  g_free (pad_name);
+
+  pad_name = g_strdup_printf ("send_rtcp_src_%u", ret->session_id);
+  if (!gst_element_link_pads (GST_ELEMENT (webrtc->rtpbin), pad_name,
+          GST_ELEMENT (ret->send_bin), "rtcp_sink"))
+    g_warn_if_reached ();
+  g_free (pad_name);
 
   GST_TRACE_OBJECT (webrtc,
       "Create transport %" GST_PTR_FORMAT " for session %u", ret, session_id);
@@ -1719,28 +2474,11 @@ static TransportStream *
 _get_or_create_rtp_transport_channel (GstWebRTCBin * webrtc, guint session_id)
 {
   TransportStream *ret;
-  gchar *pad_name;
 
   ret = _find_transport_for_session (webrtc, session_id);
 
-  if (!ret) {
+  if (!ret)
     ret = _create_transport_channel (webrtc, session_id);
-    gst_bin_add (GST_BIN (webrtc), GST_ELEMENT (ret->send_bin));
-    gst_bin_add (GST_BIN (webrtc), GST_ELEMENT (ret->receive_bin));
-    g_ptr_array_add (webrtc->priv->transports, ret);
-
-    pad_name = g_strdup_printf ("recv_rtcp_sink_%u", ret->session_id);
-    if (!gst_element_link_pads (GST_ELEMENT (ret->receive_bin), "rtcp_src",
-            GST_ELEMENT (webrtc->rtpbin), pad_name))
-      g_warn_if_reached ();
-    g_free (pad_name);
-
-    pad_name = g_strdup_printf ("send_rtcp_src_%u", ret->session_id);
-    if (!gst_element_link_pads (GST_ELEMENT (webrtc->rtpbin), pad_name,
-            GST_ELEMENT (ret->send_bin), "rtcp_sink"))
-      g_warn_if_reached ();
-    g_free (pad_name);
-  }
 
   gst_element_sync_state_with_parent (GST_ELEMENT (ret->send_bin));
   gst_element_sync_state_with_parent (GST_ELEMENT (ret->receive_bin));
@@ -1754,32 +2492,38 @@ _on_data_channel_ready_state (WebRTCDataChannel * channel,
     GParamSpec * pspec, GstWebRTCBin * webrtc)
 {
   GstWebRTCDataChannelState ready_state;
-  guint i;
 
   g_object_get (channel, "ready-state", &ready_state, NULL);
 
   if (ready_state == GST_WEBRTC_DATA_CHANNEL_STATE_OPEN) {
-    gboolean found = FALSE;
+    gboolean found;
 
-    for (i = 0; i < webrtc->priv->pending_data_channels->len; i++) {
-      WebRTCDataChannel *c;
-
-      c = g_ptr_array_index (webrtc->priv->pending_data_channels, i);
-      if (c == channel) {
-        found = TRUE;
-        g_ptr_array_remove_index (webrtc->priv->pending_data_channels, i);
-        break;
-      }
-    }
+    DC_LOCK (webrtc);
+    found = g_ptr_array_remove (webrtc->priv->pending_data_channels, channel);
     if (found == FALSE) {
       GST_FIXME_OBJECT (webrtc, "Received open for unknown data channel");
+      DC_UNLOCK (webrtc);
       return;
     }
 
-    g_ptr_array_add (webrtc->priv->data_channels, channel);
+    g_ptr_array_add (webrtc->priv->data_channels, gst_object_ref (channel));
+    DC_UNLOCK (webrtc);
+
+    gst_webrtc_bin_update_sctp_priority (webrtc);
 
     g_signal_emit (webrtc, gst_webrtc_bin_signals[ON_DATA_CHANNEL_SIGNAL], 0,
-        gst_object_ref (channel));
+        channel);
+  } else if (ready_state == GST_WEBRTC_DATA_CHANNEL_STATE_CLOSED) {
+    gboolean found;
+
+    DC_LOCK (webrtc);
+    found = g_ptr_array_remove (webrtc->priv->pending_data_channels, channel)
+        || g_ptr_array_remove (webrtc->priv->data_channels, channel);
+
+    if (found == FALSE) {
+      GST_FIXME_OBJECT (webrtc, "Received close for unknown data channel");
+    }
+    DC_UNLOCK (webrtc);
   }
 }
 
@@ -1794,37 +2538,40 @@ _on_sctpdec_pad_added (GstElement * sctpdec, GstPad * pad,
   if (sscanf (GST_PAD_NAME (pad), "src_%u", &stream_id) != 1)
     return;
 
-  PC_LOCK (webrtc);
+  DC_LOCK (webrtc);
   channel = _find_data_channel_for_id (webrtc, stream_id);
   if (!channel) {
     channel = g_object_new (WEBRTC_TYPE_DATA_CHANNEL, NULL);
     channel->parent.id = stream_id;
     channel->webrtcbin = webrtc;
 
-    gst_bin_add (GST_BIN (webrtc), channel->appsrc);
-    gst_bin_add (GST_BIN (webrtc), channel->appsink);
+    g_signal_emit (webrtc, gst_webrtc_bin_signals[PREPARE_DATA_CHANNEL_SIGNAL],
+        0, channel, FALSE);
+
+    gst_bin_add (GST_BIN (webrtc), channel->src_bin);
+    gst_bin_add (GST_BIN (webrtc), channel->sink_bin);
 
-    gst_element_sync_state_with_parent (channel->appsrc);
-    gst_element_sync_state_with_parent (channel->appsink);
+    gst_element_sync_state_with_parent (channel->src_bin);
+    gst_element_sync_state_with_parent (channel->sink_bin);
 
     webrtc_data_channel_link_to_sctp (channel, webrtc->priv->sctp_transport);
 
     g_ptr_array_add (webrtc->priv->pending_data_channels, channel);
   }
+  DC_UNLOCK (webrtc);
 
   g_signal_connect (channel, "notify::ready-state",
       G_CALLBACK (_on_data_channel_ready_state), webrtc);
 
-  sink_pad = gst_element_get_static_pad (channel->appsink, "sink");
+  sink_pad = gst_element_get_static_pad (channel->sink_bin, "sink");
   if (gst_pad_link (pad, sink_pad) != GST_PAD_LINK_OK)
     GST_WARNING_OBJECT (channel, "Failed to link sctp pad %s with channel %"
         GST_PTR_FORMAT, GST_PAD_NAME (pad), channel);
   gst_object_unref (sink_pad);
-  PC_UNLOCK (webrtc);
 }
 
 static void
-_on_sctp_state_notify (GstWebRTCSCTPTransport * sctp, GParamSpec * pspec,
+_on_sctp_state_notify (WebRTCSCTPTransport * sctp, GParamSpec * pspec,
     GstWebRTCBin * webrtc)
 {
   GstWebRTCSCTPTransportState state;
@@ -1834,9 +2581,9 @@ _on_sctp_state_notify (GstWebRTCSCTPTransport * sctp, GParamSpec * pspec,
   if (state == GST_WEBRTC_SCTP_TRANSPORT_STATE_CONNECTED) {
     int i;
 
-    PC_LOCK (webrtc);
     GST_DEBUG_OBJECT (webrtc, "SCTP association established");
 
+    DC_LOCK (webrtc);
     for (i = 0; i < webrtc->priv->data_channels->len; i++) {
       WebRTCDataChannel *channel;
 
@@ -1847,7 +2594,7 @@ _on_sctp_state_notify (GstWebRTCSCTPTransport * sctp, GParamSpec * pspec,
       if (!channel->parent.negotiated && !channel->opened)
         webrtc_data_channel_start_negotiation (channel);
     }
-    PC_UNLOCK (webrtc);
+    DC_UNLOCK (webrtc);
   }
 }
 
@@ -1855,13 +2602,13 @@ _on_sctp_state_notify (GstWebRTCSCTPTransport * sctp, GParamSpec * pspec,
 static void _on_sctp_notify_dtls_state (GstWebRTCDTLSTransport * transport,
     GParamSpec * pspec, GstWebRTCBin * webrtc);
 
-static void
+static GstStructure *
 _sctp_check_dtls_state_task (GstWebRTCBin * webrtc, gpointer unused)
 {
   TransportStream *stream;
   GstWebRTCDTLSTransport *transport;
   GstWebRTCDTLSTransportState dtls_state;
-  GstWebRTCSCTPTransport *sctp_transport;
+  WebRTCSCTPTransport *sctp_transport;
 
   stream = webrtc->priv->data_channel_transport;
   transport = stream->transport;
@@ -1871,7 +2618,7 @@ _sctp_check_dtls_state_task (GstWebRTCBin * webrtc, gpointer unused)
   if (dtls_state != GST_WEBRTC_DTLS_TRANSPORT_STATE_CONNECTED) {
     GST_DEBUG_OBJECT (webrtc,
         "Data channel DTLS connection is not ready yet: %d", dtls_state);
-    return;
+    return NULL;
   }
 
   GST_DEBUG_OBJECT (webrtc, "Data channel DTLS connection is now ready");
@@ -1879,7 +2626,7 @@ _sctp_check_dtls_state_task (GstWebRTCBin * webrtc, gpointer unused)
 
   /* Not locked state anymore so this was already taken care of before */
   if (!gst_element_is_locked_state (sctp_transport->sctpdec))
-    return;
+    return NULL;
 
   /* Start up the SCTP elements now that the DTLS connection is established */
   gst_element_set_locked_state (sctp_transport->sctpdec, FALSE);
@@ -1902,6 +2649,8 @@ _sctp_check_dtls_state_task (GstWebRTCBin * webrtc, gpointer unused)
 
   g_signal_handlers_disconnect_by_func (transport, _on_sctp_notify_dtls_state,
       webrtc);
+
+  return NULL;
 }
 
 static void
@@ -1947,24 +2696,17 @@ _get_or_create_data_channel_transports (GstWebRTCBin * webrtc, guint session_id)
 {
   if (!webrtc->priv->data_channel_transport) {
     TransportStream *stream;
-    GstWebRTCSCTPTransport *sctp_transport;
-    int i;
+    WebRTCSCTPTransport *sctp_transport;
 
     stream = _find_transport_for_session (webrtc, session_id);
 
-    if (!stream) {
+    if (!stream)
       stream = _create_transport_channel (webrtc, session_id);
-      gst_bin_add (GST_BIN (webrtc), GST_ELEMENT (stream->send_bin));
-      gst_bin_add (GST_BIN (webrtc), GST_ELEMENT (stream->receive_bin));
-      g_ptr_array_add (webrtc->priv->transports, stream);
-    }
 
     webrtc->priv->data_channel_transport = stream;
 
-    g_object_set (stream, "rtcp-mux", TRUE, NULL);
-
     if (!(sctp_transport = webrtc->priv->sctp_transport)) {
-      sctp_transport = gst_webrtc_sctp_transport_new ();
+      sctp_transport = webrtc_sctp_transport_new ();
       sctp_transport->transport =
           g_object_ref (webrtc->priv->data_channel_transport->transport);
       sctp_transport->webrtcbin = webrtc;
@@ -2003,14 +2745,6 @@ _get_or_create_data_channel_transports (GstWebRTCBin * webrtc, guint session_id)
             GST_ELEMENT (stream->send_bin), "data_sink"))
       g_warn_if_reached ();
 
-    for (i = 0; i < webrtc->priv->data_channels->len; i++) {
-      WebRTCDataChannel *channel;
-
-      channel = g_ptr_array_index (webrtc->priv->data_channels, i);
-
-      webrtc_data_channel_link_to_sctp (channel, webrtc->priv->sctp_transport);
-    }
-
     gst_element_sync_state_with_parent (GST_ELEMENT (stream->send_bin));
     gst_element_sync_state_with_parent (GST_ELEMENT (stream->receive_bin));
 
@@ -2028,6 +2762,8 @@ _get_or_create_data_channel_transports (GstWebRTCBin * webrtc, guint session_id)
     }
 
     webrtc->priv->sctp_transport = sctp_transport;
+
+    gst_webrtc_bin_update_sctp_priority (webrtc);
   }
 
   return webrtc->priv->data_channel_transport;
@@ -2043,38 +2779,92 @@ _get_or_create_transport_stream (GstWebRTCBin * webrtc, guint session_id,
     return _get_or_create_rtp_transport_channel (webrtc, session_id);
 }
 
-static guint
-g_array_find_uint (GArray * array, guint val)
+struct media_payload_map_item
+{
+  guint media_pt;
+  guint red_pt;
+  guint ulpfec_pt;
+  guint rtx_pt;
+  guint red_rtx_pt;
+};
+
+static void
+media_payload_map_item_init (struct media_payload_map_item *item,
+    guint media_pt)
+{
+  item->media_pt = media_pt;
+  item->red_pt = G_MAXUINT;
+  item->rtx_pt = G_MAXUINT;
+  item->ulpfec_pt = G_MAXUINT;
+  item->red_rtx_pt = G_MAXUINT;
+}
+
+static struct media_payload_map_item *
+find_payload_map_for_media_pt (GArray * media_mapping, guint media_pt)
 {
   guint i;
 
-  for (i = 0; i < array->len; i++) {
-    if (g_array_index (array, guint, i) == val)
-      return i;
+  for (i = 0; i < media_mapping->len; i++) {
+    struct media_payload_map_item *item;
+
+    item = &g_array_index (media_mapping, struct media_payload_map_item, i);
+
+    if (item->media_pt == media_pt)
+      return item;
   }
 
-  return G_MAXUINT;
+  return NULL;
+}
+
+static struct media_payload_map_item *
+find_or_create_payload_map_for_media_pt (GArray * media_mapping, guint media_pt)
+{
+  struct media_payload_map_item new_item;
+  struct media_payload_map_item *item;
+
+  if ((item = find_payload_map_for_media_pt (media_mapping, media_pt)))
+    return item;
+
+  media_payload_map_item_init (&new_item, media_pt);
+  g_array_append_val (media_mapping, new_item);
+  return &g_array_index (media_mapping, struct media_payload_map_item,
+      media_mapping->len - 1);
 }
 
 static gboolean
-_pick_available_pt (GArray * reserved_pts, guint * i)
+_pick_available_pt (GArray * media_mapping, guint * ret)
 {
-  gboolean ret = FALSE;
+  int i;
 
-  for (*i = 96; *i <= 127; (*i)++) {
-    if (g_array_find_uint (reserved_pts, *i) == G_MAXUINT) {
-      g_array_append_val (reserved_pts, *i);
-      ret = TRUE;
-      break;
+  for (i = 96; i <= 127; i++) {
+    gboolean available = TRUE;
+    int j;
+
+    for (j = 0; j < media_mapping->len; j++) {
+      struct media_payload_map_item *item;
+
+      item = &g_array_index (media_mapping, struct media_payload_map_item, j);
+
+      if (item->media_pt == i || item->red_pt == i || item->rtx_pt == i
+          || item->ulpfec_pt == i || item->red_rtx_pt == i) {
+        available = FALSE;
+        break;
+      }
+    }
+
+    if (available) {
+      *ret = i;
+      return TRUE;
     }
   }
 
-  return ret;
+  *ret = G_MAXUINT;
+  return FALSE;
 }
 
 static gboolean
 _pick_fec_payload_types (GstWebRTCBin * webrtc, WebRTCTransceiver * trans,
-    GArray * reserved_pts, gint clockrate, gint * rtx_target_pt,
+    GArray * media_mapping, gint clockrate, gint media_pt, gint * rtx_target_pt,
     GstSDPMedia * media)
 {
   gboolean ret = TRUE;
@@ -2083,30 +2873,35 @@ _pick_fec_payload_types (GstWebRTCBin * webrtc, WebRTCTransceiver * trans,
     goto done;
 
   if (trans->fec_type == GST_WEBRTC_FEC_TYPE_ULP_RED && clockrate != -1) {
-    guint pt;
+    struct media_payload_map_item *item;
     gchar *str;
 
-    if (!(ret = _pick_available_pt (reserved_pts, &pt)))
-      goto done;
+    item = find_or_create_payload_map_for_media_pt (media_mapping, media_pt);
+    if (item->red_pt == G_MAXUINT) {
+      if (!(ret = _pick_available_pt (media_mapping, &item->red_pt)))
+        goto done;
+    }
 
     /* https://tools.ietf.org/html/rfc5109#section-14.1 */
 
-    str = g_strdup_printf ("%u", pt);
+    str = g_strdup_printf ("%u", item->red_pt);
     gst_sdp_media_add_format (media, str);
     g_free (str);
-    str = g_strdup_printf ("%u red/%d", pt, clockrate);
+    str = g_strdup_printf ("%u red/%d", item->red_pt, clockrate);
     gst_sdp_media_add_attribute (media, "rtpmap", str);
     g_free (str);
 
-    *rtx_target_pt = pt;
+    *rtx_target_pt = item->red_pt;
 
-    if (!(ret = _pick_available_pt (reserved_pts, &pt)))
-      goto done;
+    if (item->ulpfec_pt == G_MAXUINT) {
+      if (!(ret = _pick_available_pt (media_mapping, &item->ulpfec_pt)))
+        goto done;
+    }
 
-    str = g_strdup_printf ("%u", pt);
+    str = g_strdup_printf ("%u", item->ulpfec_pt);
     gst_sdp_media_add_format (media, str);
     g_free (str);
-    str = g_strdup_printf ("%u ulpfec/%d", pt, clockrate);
+    str = g_strdup_printf ("%u ulpfec/%d", item->ulpfec_pt, clockrate);
     gst_sdp_media_add_attribute (media, "rtpmap", str);
     g_free (str);
   }
@@ -2115,10 +2910,37 @@ done:
   return ret;
 }
 
+static void
+add_rtx_to_media (WebRTCTransceiver * trans, gint clockrate, gint rtx_pt,
+    gint rtx_target_pt, guint target_ssrc, GstSDPMedia * media)
+{
+  char *str;
+
+  /* https://tools.ietf.org/html/rfc4588#section-8.6 */
+  if (target_ssrc != -1) {
+    str = g_strdup_printf ("%u", target_ssrc);
+    gst_structure_set (trans->local_rtx_ssrc_map, str, G_TYPE_UINT,
+        g_random_int (), NULL);
+    g_free (str);
+  }
+
+  str = g_strdup_printf ("%u", rtx_pt);
+  gst_sdp_media_add_format (media, str);
+  g_free (str);
+
+  str = g_strdup_printf ("%u rtx/%d", rtx_pt, clockrate);
+  gst_sdp_media_add_attribute (media, "rtpmap", str);
+  g_free (str);
+
+  str = g_strdup_printf ("%u apt=%d", rtx_pt, rtx_target_pt);
+  gst_sdp_media_add_attribute (media, "fmtp", str);
+  g_free (str);
+}
+
 static gboolean
 _pick_rtx_payload_types (GstWebRTCBin * webrtc, WebRTCTransceiver * trans,
-    GArray * reserved_pts, gint clockrate, gint target_pt, guint target_ssrc,
-    GstSDPMedia * media)
+    GArray * media_mapping, gint clockrate, gint media_pt, gint target_pt,
+    guint target_ssrc, GstSDPMedia * media)
 {
   gboolean ret = TRUE;
 
@@ -2129,30 +2951,26 @@ _pick_rtx_payload_types (GstWebRTCBin * webrtc, WebRTCTransceiver * trans,
       gst_structure_new_empty ("application/x-rtp-ssrc-map");
 
   if (trans->do_nack) {
-    guint pt;
-    gchar *str;
-
-    if (!(ret = _pick_available_pt (reserved_pts, &pt)))
-      goto done;
+    struct media_payload_map_item *item;
 
-    /* https://tools.ietf.org/html/rfc4588#section-8.6 */
-
-    str = g_strdup_printf ("%u", target_ssrc);
-    gst_structure_set (trans->local_rtx_ssrc_map, str, G_TYPE_UINT,
-        g_random_int (), NULL);
-    g_free (str);
-
-    str = g_strdup_printf ("%u", pt);
-    gst_sdp_media_add_format (media, str);
-    g_free (str);
+    item = find_or_create_payload_map_for_media_pt (media_mapping, media_pt);
+    if (item->rtx_pt == G_MAXUINT) {
+      if (!(ret = _pick_available_pt (media_mapping, &item->rtx_pt)))
+        goto done;
+    }
 
-    str = g_strdup_printf ("%u rtx/%d", pt, clockrate);
-    gst_sdp_media_add_attribute (media, "rtpmap", str);
-    g_free (str);
+    add_rtx_to_media (trans, clockrate, item->rtx_pt, media_pt, target_ssrc,
+        media);
 
-    str = g_strdup_printf ("%u apt=%d", pt, target_pt);
-    gst_sdp_media_add_attribute (media, "fmtp", str);
-    g_free (str);
+    if (item->red_pt != G_MAXUINT) {
+      /* Workaround chrome bug: https://bugs.chromium.org/p/webrtc/issues/detail?id=6196 */
+      if (item->red_rtx_pt == G_MAXUINT) {
+        if (!(ret = _pick_available_pt (media_mapping, &item->red_rtx_pt)))
+          goto done;
+      }
+      add_rtx_to_media (trans, clockrate, item->red_rtx_pt, item->red_pt,
+          target_ssrc, media);
+    }
   }
 
 done:
@@ -2189,15 +3007,27 @@ _media_add_rtx_ssrc (GQuark field_id, const GValue * value, RtxSsrcData * data)
   gchar *str;
   GstStructure *sdes;
   const gchar *cname;
+  GstWebRTCBinPad *sink_pad;
+  const char *msid = NULL;
 
   g_object_get (data->webrtc->rtpbin, "sdes", &sdes, NULL);
   /* http://www.freesoft.org/CIE/RFC/1889/24.htm */
   cname = gst_structure_get_string (sdes, "cname");
 
+  sink_pad =
+      _find_pad_for_transceiver (data->webrtc, GST_PAD_SINK,
+      GST_WEBRTC_RTP_TRANSCEIVER (data->trans));
+  if (sink_pad)
+    msid = sink_pad->msid;
+  /* fallback to cname if no msid provided */
+  if (!msid)
+    msid = cname;
+
   /* https://tools.ietf.org/html/draft-ietf-mmusic-msid-16 */
+  /* FIXME: the ssrc is not present in RFC8830, do we still need that? */
   str =
       g_strdup_printf ("%u msid:%s %s", g_value_get_uint (value),
-      cname, GST_OBJECT_NAME (data->trans));
+      msid, GST_OBJECT_NAME (data->trans));
   gst_sdp_media_add_attribute (data->media, "ssrc", str);
   g_free (str);
 
@@ -2205,6 +3035,7 @@ _media_add_rtx_ssrc (GQuark field_id, const GValue * value, RtxSsrcData * data)
   gst_sdp_media_add_attribute (data->media, "ssrc", str);
   g_free (str);
 
+  gst_clear_object (&sink_pad);
   gst_structure_free (sdes);
 
   return TRUE;
@@ -2233,10 +3064,22 @@ _media_add_ssrcs (GstSDPMedia * media, GstCaps * caps, GstWebRTCBin * webrtc,
 
     if (gst_structure_get_uint (s, "ssrc", &ssrc)) {
       gchar *str;
+      GstWebRTCBinPad *sink_pad;
+      const char *msid = NULL;
+
+      sink_pad =
+          _find_pad_for_transceiver (webrtc, GST_PAD_SINK,
+          GST_WEBRTC_RTP_TRANSCEIVER (trans));
+      if (sink_pad)
+        msid = sink_pad->msid;
+      /* fallback to cname if no msid provided */
+      if (!msid)
+        msid = cname;
 
       /* https://tools.ietf.org/html/draft-ietf-mmusic-msid-16 */
+      /* FIXME: the ssrc is not present in RFC8830, do we still need that? */
       str =
-          g_strdup_printf ("%u msid:%s %s", ssrc, cname,
+          g_strdup_printf ("%u msid:%s %s", ssrc, msid,
           GST_OBJECT_NAME (trans));
       gst_sdp_media_add_attribute (media, "ssrc", str);
       g_free (str);
@@ -2244,6 +3087,8 @@ _media_add_ssrcs (GstSDPMedia * media, GstCaps * caps, GstWebRTCBin * webrtc,
       str = g_strdup_printf ("%u cname:%s", ssrc, cname);
       gst_sdp_media_add_attribute (media, "ssrc", str);
       g_free (str);
+
+      gst_clear_object (&sink_pad);
     }
   }
 
@@ -2274,12 +3119,217 @@ _add_fingerprint_to_media (GstWebRTCDTLSTransport * transport,
   g_free (val);
 }
 
+static gchar *
+_parse_extmap (GQuark field_id, const GValue * value, GError ** error)
+{
+  gchar *ret = NULL;
+
+  if (G_VALUE_HOLDS_STRING (value)) {
+    ret = g_value_dup_string (value);
+  } else if (G_VALUE_HOLDS (value, GST_TYPE_ARRAY)
+      && gst_value_array_get_size (value) == 3) {
+    const GValue *val;
+    const gchar *direction, *extensionname, *extensionattributes;
+
+    val = gst_value_array_get_value (value, 0);
+    direction = g_value_get_string (val);
+
+    val = gst_value_array_get_value (value, 1);
+    extensionname = g_value_get_string (val);
+
+    val = gst_value_array_get_value (value, 2);
+    extensionattributes = g_value_get_string (val);
+
+    if (!extensionname || *extensionname == '\0')
+      goto done;
+
+    if (direction && *direction != '\0' && extensionattributes
+        && *extensionattributes != '\0') {
+      ret =
+          g_strdup_printf ("/%s %s %s", direction, extensionname,
+          extensionattributes);
+    } else if (direction && *direction != '\0') {
+      ret = g_strdup_printf ("/%s %s", direction, extensionname);
+    } else if (extensionattributes && *extensionattributes != '\0') {
+      ret = g_strdup_printf ("%s %s", extensionname, extensionattributes);
+    } else {
+      ret = g_strdup (extensionname);
+    }
+  }
+
+  if (!ret && error) {
+    gchar *val_str = gst_value_serialize (value);
+
+    g_set_error (error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+        "Invalid value for %s: %s", g_quark_to_string (field_id), val_str);
+    g_free (val_str);
+  }
+
+done:
+  return ret;
+}
+
+typedef struct
+{
+  gboolean ret;
+  GstStructure *extmap;
+  GError **error;
+} ExtmapData;
+
+static gboolean
+_dedup_extmap_field (GQuark field_id, const GValue * value, ExtmapData * data)
+{
+  gboolean is_extmap =
+      g_str_has_prefix (g_quark_to_string (field_id), "extmap-");
+
+  if (!data->ret)
+    goto done;
+
+  if (is_extmap) {
+    gchar *new_value = _parse_extmap (field_id, value, data->error);
+
+    if (!new_value) {
+      data->ret = FALSE;
+      goto done;
+    }
+
+    if (gst_structure_id_has_field (data->extmap, field_id)) {
+      gchar *old_value =
+          _parse_extmap (field_id, gst_structure_id_get_value (data->extmap,
+              field_id), NULL);
+
+      g_assert (old_value);
+
+      if (g_strcmp0 (new_value, old_value)) {
+        GST_ERROR
+            ("extmap contains different values for id %s (%s != %s)",
+            g_quark_to_string (field_id), old_value, new_value);
+        g_set_error (data->error, GST_WEBRTC_ERROR,
+            GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+            "extmap contains different values for id %s (%s != %s)",
+            g_quark_to_string (field_id), old_value, new_value);
+        data->ret = FALSE;
+      }
+
+      g_free (old_value);
+
+    }
+
+    if (data->ret) {
+      gst_structure_id_set_value (data->extmap, field_id, value);
+    }
+
+    g_free (new_value);
+  }
+
+done:
+  return !is_extmap;
+}
+
+static GstStructure *
+_gather_extmap (GstCaps * caps, GError ** error)
+{
+  ExtmapData edata =
+      { TRUE, gst_structure_new_empty ("application/x-extmap"), error };
+  guint i, n;
+
+  n = gst_caps_get_size (caps);
+
+  for (i = 0; i < n; i++) {
+    GstStructure *s = gst_caps_get_structure (caps, i);
+
+    gst_structure_filter_and_map_in_place (s,
+        (GstStructureFilterMapFunc) _dedup_extmap_field, &edata);
+
+    if (!edata.ret) {
+      gst_clear_structure (&edata.extmap);
+      break;
+    }
+  }
+
+  return edata.extmap;
+}
+
+struct hdrext_id
+{
+  const char *rtphdrext_uri;
+  guint ext_id;
+};
+
+static gboolean
+structure_value_get_rtphdrext_id (GQuark field_id, const GValue * value,
+    gpointer user_data)
+{
+  struct hdrext_id *rtphdrext = user_data;
+  const char *field_name = g_quark_to_string (field_id);
+
+  if (g_str_has_prefix (field_name, "extmap-")) {
+    const char *val = NULL;
+
+    if (GST_VALUE_HOLDS_ARRAY (value) && gst_value_array_get_size (value) >= 2) {
+      value = gst_value_array_get_value (value, 1);
+    }
+    if (G_VALUE_HOLDS_STRING (value)) {
+      val = g_value_get_string (value);
+    }
+
+    if (g_strcmp0 (val, rtphdrext->rtphdrext_uri) == 0) {
+      gint64 id = g_ascii_strtoll (&field_name[strlen ("extmap-")], NULL, 10);
+
+      if (id > 0 && id < 256)
+        rtphdrext->ext_id = id;
+
+      return FALSE;
+    }
+  }
+
+  return TRUE;
+}
+
+// Returns -1 when not found
+static guint
+caps_get_rtp_header_extension_id (const GstCaps * caps,
+    const char *rtphdrext_uri)
+{
+  guint i, n;
+
+  n = gst_caps_get_size (caps);
+  for (i = 0; i < n; i++) {
+    const GstStructure *s = gst_caps_get_structure (caps, i);
+    struct hdrext_id data = { rtphdrext_uri, -1 };
+
+    gst_structure_foreach (s, structure_value_get_rtphdrext_id, &data);
+
+    if (data.ext_id != -1)
+      return data.ext_id;
+  }
+
+  return -1;
+}
+
+static gboolean
+caps_contain_rtp_header_extension (const GstCaps * caps,
+    const char *rtphdrext_uri)
+{
+  return caps_get_rtp_header_extension_id (caps, rtphdrext_uri) != -1;
+}
+
+static gboolean
+_copy_field (GQuark field_id, const GValue * value, GstStructure * s)
+{
+  gst_structure_id_set_value (s, field_id, value);
+
+  return TRUE;
+}
+
 /* based off https://tools.ietf.org/html/draft-ietf-rtcweb-jsep-18#section-5.2.1 */
 static gboolean
 sdp_media_from_transceiver (GstWebRTCBin * webrtc, GstSDPMedia * media,
-    GstWebRTCRTPTransceiver * trans, GstWebRTCSDPType type, guint media_idx,
-    GString * bundled_mids, guint bundle_idx, gchar * bundle_ufrag,
-    gchar * bundle_pwd, GArray * reserved_pts)
+    const GstSDPMedia * last_media, GstWebRTCRTPTransceiver * trans,
+    guint media_idx, GString * bundled_mids, guint bundle_idx,
+    gchar * bundle_ufrag, gchar * bundle_pwd, GArray * media_mapping,
+    GHashTable * all_mids, gboolean * no_more_mlines, GError ** error)
 {
   /* TODO:
    * rtp header extensions
@@ -2292,22 +3342,79 @@ sdp_media_from_transceiver (GstWebRTCBin * webrtc, GstSDPMedia * media,
    * multiple dtls fingerprints https://tools.ietf.org/html/draft-ietf-mmusic-4572-update-05
    */
   GstSDPMessage *last_offer = _get_latest_self_generated_sdp (webrtc);
-  gchar *direction, *sdp_mid, *ufrag, *pwd;
+  gchar *ufrag, *pwd, *mid = NULL;
   gboolean bundle_only;
+  guint rtp_session_idx;
   GstCaps *caps;
+  GstStructure *extmap;
   int i;
 
-  if (trans->direction == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_NONE
-      || trans->direction == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_INACTIVE)
+  if (trans->direction == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_NONE)
     return FALSE;
 
   g_assert (trans->mline == -1 || trans->mline == media_idx);
 
+  rtp_session_idx = bundled_mids ? bundle_idx : media_idx;
+
   bundle_only = bundled_mids && bundle_idx != media_idx
       && webrtc->bundle_policy == GST_WEBRTC_BUNDLE_POLICY_MAX_BUNDLE;
 
-  /* mandated by JSEP */
-  gst_sdp_media_add_attribute (media, "setup", "actpass");
+  caps = _find_codec_preferences (webrtc, trans, media_idx, error);
+  caps = _add_supported_attributes_to_caps (webrtc, WEBRTC_TRANSCEIVER (trans),
+      caps);
+
+  if (!caps || gst_caps_is_empty (caps) || gst_caps_is_any (caps)) {
+    gst_clear_caps (&caps);
+
+    if (last_media) {
+      guint i, n;
+
+      n = gst_sdp_media_formats_len (last_media);
+      if (n > 0) {
+        caps = gst_caps_new_empty ();
+        for (i = 0; i < n; i++) {
+          guint fmt = atoi (gst_sdp_media_get_format (last_media, i));
+          GstCaps *tmp = gst_sdp_media_get_caps_from_media (last_media, fmt);
+          GstStructure *s = gst_caps_get_structure (tmp, 0);
+          gst_structure_set_name (s, "application/x-rtp");
+          gst_caps_append_structure (caps, gst_structure_copy (s));
+          gst_clear_caps (&tmp);
+        }
+        GST_DEBUG_OBJECT (webrtc, "using previously negotiated caps for "
+            "transceiver %" GST_PTR_FORMAT " %" GST_PTR_FORMAT, trans, caps);
+      }
+    }
+
+    if (!caps) {
+      if (WEBRTC_TRANSCEIVER (trans)->mline_locked) {
+        GST_WARNING_OBJECT (webrtc,
+            "Transceiver <%s> with mid %s has locked mline %u, but no caps. "
+            "Can't add more lines after this one.", GST_OBJECT_NAME (trans),
+            trans->mid, trans->mline);
+        *no_more_mlines = TRUE;
+      } else {
+        GST_WARNING_OBJECT (webrtc, "no caps available for transceiver %"
+            GST_PTR_FORMAT ", skipping", trans);
+      }
+      return FALSE;
+    }
+  }
+
+  if (last_media) {
+    const char *setup = gst_sdp_media_get_attribute_val (last_media, "setup");
+    if (setup) {
+      gst_sdp_media_add_attribute (media, "setup", setup);
+    } else {
+      g_set_error (error, GST_WEBRTC_ERROR,
+          GST_WEBRTC_ERROR_INVALID_MODIFICATION,
+          "media %u cannot renegotiate without an existing a=setup line",
+          media_idx);
+      return FALSE;
+    }
+  } else {
+    /* mandated by JSEP */
+    gst_sdp_media_add_attribute (media, "setup", "actpass");
+  }
 
   /* FIXME: deal with ICE restarts */
   if (last_offer && trans->mline != -1 && trans->mid) {
@@ -2348,83 +3455,158 @@ sdp_media_from_transceiver (GstWebRTCBin * webrtc, GstSDPMedia * media,
   gst_sdp_media_add_attribute (media, "rtcp-mux", "");
   gst_sdp_media_add_attribute (media, "rtcp-rsize", NULL);
 
-  direction =
-      _enum_value_to_string (GST_TYPE_WEBRTC_RTP_TRANSCEIVER_DIRECTION,
-      trans->direction);
-  gst_sdp_media_add_attribute (media, direction, "");
-  g_free (direction);
-
-  if (type == GST_WEBRTC_SDP_TYPE_OFFER) {
-    caps = _find_codec_preferences (webrtc, trans, GST_PAD_SINK, media_idx);
-    caps =
-        _add_supported_attributes_to_caps (webrtc, WEBRTC_TRANSCEIVER (trans),
-        caps);
-  } else {
-    g_assert_not_reached ();
-  }
+  gst_sdp_media_add_attribute (media,
+      gst_webrtc_rtp_transceiver_direction_to_string (trans->direction), "");
 
-  if (!caps || gst_caps_is_empty (caps) || gst_caps_is_any (caps)) {
-    GST_WARNING_OBJECT (webrtc, "no caps available for transceiver, skipping");
-    if (caps)
-      gst_caps_unref (caps);
+  caps = gst_caps_make_writable (caps);
+
+  /* When an extmap is defined twice for the same ID, firefox complains and
+   * errors out (chrome is smart enough to accept strict duplicates).
+   *
+   * To work around this, we deduplicate extmap attributes, and also error
+   * out when a different extmap is defined for the same ID.
+   *
+   * _gather_extmap will strip out all extmap- fields, which will then be
+   * added upon adding the first format for the media.
+   */
+  extmap = _gather_extmap (caps, error);
+
+  if (!extmap) {
+    GST_ERROR_OBJECT (webrtc,
+        "Failed to build extmap for transceiver %" GST_PTR_FORMAT, trans);
+    gst_caps_unref (caps);
     return FALSE;
   }
 
+  caps = _add_supported_attributes_to_caps (webrtc, WEBRTC_TRANSCEIVER (trans),
+      caps);
+
   for (i = 0; i < gst_caps_get_size (caps); i++) {
     GstCaps *format = gst_caps_new_empty ();
-    const GstStructure *s = gst_caps_get_structure (caps, i);
+    GstStructure *s = gst_structure_copy (gst_caps_get_structure (caps, i));
 
-    gst_caps_append_structure (format, gst_structure_copy (s));
+    if (i == 0) {
+      gst_structure_foreach (extmap, (GstStructureForeachFunc) _copy_field, s);
+    }
+
+    gst_caps_append_structure (format, s);
 
     GST_DEBUG_OBJECT (webrtc, "Adding %u-th caps %" GST_PTR_FORMAT
         " to %u-th media", i, format, media_idx);
 
     /* this only looks at the first structure so we loop over the given caps
      * and add each structure inside it piecemeal */
-    gst_sdp_media_set_media_from_caps (format, media);
+    if (gst_sdp_media_set_media_from_caps (format, media) != GST_SDP_OK) {
+      GST_ERROR_OBJECT (webrtc,
+          "Failed to build media from caps %" GST_PTR_FORMAT
+          " for transceiver %" GST_PTR_FORMAT, format, trans);
+      gst_caps_unref (caps);
+      gst_caps_unref (format);
+      gst_structure_free (extmap);
+      return FALSE;
+    }
 
     gst_caps_unref (format);
   }
 
-  if (type == GST_WEBRTC_SDP_TYPE_OFFER) {
+  gst_clear_structure (&extmap);
+
+  {
     const GstStructure *s = gst_caps_get_structure (caps, 0);
     gint clockrate = -1;
     gint rtx_target_pt;
-    gint original_rtx_target_pt;        /* Workaround chrome bug: https://bugs.chromium.org/p/webrtc/issues/detail?id=6196 */
     guint rtx_target_ssrc = -1;
+    gint media_pt;
 
-    if (gst_structure_get_int (s, "payload", &rtx_target_pt) &&
+    if (gst_structure_get_int (s, "payload", &media_pt) &&
         webrtc->bundle_policy == GST_WEBRTC_BUNDLE_POLICY_NONE)
-      g_array_append_val (reserved_pts, rtx_target_pt);
+      find_or_create_payload_map_for_media_pt (media_mapping, media_pt);
 
-    original_rtx_target_pt = rtx_target_pt;
+    rtx_target_pt = media_pt;
 
     if (!gst_structure_get_int (s, "clock-rate", &clockrate))
       GST_WARNING_OBJECT (webrtc,
           "Caps %" GST_PTR_FORMAT " are missing clock-rate", caps);
-    if (!gst_structure_get_uint (s, "ssrc", &rtx_target_ssrc))
-      GST_WARNING_OBJECT (webrtc, "Caps %" GST_PTR_FORMAT " are missing ssrc",
-          caps);
+    if (!gst_structure_get_uint (s, "ssrc", &rtx_target_ssrc)) {
+      if (!caps_contain_rtp_header_extension (caps, RTPHDREXT_MID)) {
+        GST_WARNING_OBJECT (webrtc, "Caps %" GST_PTR_FORMAT " are missing ssrc",
+            caps);
+      }
+    }
 
-    _pick_fec_payload_types (webrtc, WEBRTC_TRANSCEIVER (trans), reserved_pts,
-        clockrate, &rtx_target_pt, media);
-    _pick_rtx_payload_types (webrtc, WEBRTC_TRANSCEIVER (trans), reserved_pts,
-        clockrate, rtx_target_pt, rtx_target_ssrc, media);
-    if (original_rtx_target_pt != rtx_target_pt)
-      _pick_rtx_payload_types (webrtc, WEBRTC_TRANSCEIVER (trans), reserved_pts,
-          clockrate, original_rtx_target_pt, rtx_target_ssrc, media);
+    _pick_fec_payload_types (webrtc, WEBRTC_TRANSCEIVER (trans), media_mapping,
+        clockrate, media_pt, &rtx_target_pt, media);
+    _pick_rtx_payload_types (webrtc, WEBRTC_TRANSCEIVER (trans), media_mapping,
+        clockrate, media_pt, rtx_target_pt, rtx_target_ssrc, media);
   }
 
   _media_add_ssrcs (media, caps, webrtc, WEBRTC_TRANSCEIVER (trans));
 
   /* Some identifier; we also add the media name to it so it's identifiable */
   if (trans->mid) {
-    gst_sdp_media_add_attribute (media, "mid", trans->mid);
-  } else {
-    sdp_mid = g_strdup_printf ("%s%u", gst_sdp_media_get_media (media),
-        webrtc->priv->media_counter++);
-    gst_sdp_media_add_attribute (media, "mid", sdp_mid);
-    g_free (sdp_mid);
+    const char *media_mid = gst_sdp_media_get_attribute_val (media, "mid");
+
+    if (!media_mid) {
+      gst_sdp_media_add_attribute (media, "mid", trans->mid);
+    } else if (g_strcmp0 (media_mid, trans->mid) != 0) {
+      g_set_error (error, GST_WEBRTC_ERROR,
+          GST_WEBRTC_ERROR_INVALID_MODIFICATION,
+          "Cannot change media %u mid value from \'%s\' to \'%s\'",
+          media_idx, media_mid, trans->mid);
+      return FALSE;
+    }
+    mid = g_strdup (trans->mid);
+    g_hash_table_insert (all_mids, g_strdup (mid), NULL);
+  }
+
+  if (mid == NULL) {
+    const GstStructure *s = gst_caps_get_structure (caps, 0);
+
+    mid = g_strdup (gst_structure_get_string (s, "a-mid"));
+    if (mid) {
+      if (g_hash_table_contains (all_mids, (gpointer) mid)) {
+        g_set_error (error, GST_WEBRTC_ERROR,
+            GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+            "Cannot re-use mid \'%s\' from the caps in m= line %u that has "
+            "already been used for a previous m= line in the SDP", mid,
+            media_idx);
+        return FALSE;
+      }
+      g_free (WEBRTC_TRANSCEIVER (trans)->pending_mid);
+      WEBRTC_TRANSCEIVER (trans)->pending_mid = g_strdup (mid);
+      g_hash_table_insert (all_mids, g_strdup (mid), NULL);
+    }
+  }
+
+  if (mid == NULL) {
+    mid = g_strdup (WEBRTC_TRANSCEIVER (trans)->pending_mid);
+    if (mid) {
+      /* If it's already used, just ignore the pending one and generate
+       * a new one */
+      if (g_hash_table_contains (all_mids, (gpointer) mid)) {
+        g_clear_pointer (&mid, free);
+        g_clear_pointer (&WEBRTC_TRANSCEIVER (trans)->pending_mid, free);
+      } else {
+        gst_sdp_media_add_attribute (media, "mid", mid);
+        g_hash_table_insert (all_mids, g_strdup (mid), NULL);
+      }
+    }
+  }
+
+  if (mid == NULL) {
+    /* Make sure to avoid mid collisions */
+    while (TRUE) {
+      mid = g_strdup_printf ("%s%u", gst_sdp_media_get_media (media),
+          webrtc->priv->media_counter++);
+      if (g_hash_table_contains (all_mids, (gpointer) mid)) {
+        g_free (mid);
+      } else {
+        gst_sdp_media_add_attribute (media, "mid", mid);
+        g_hash_table_insert (all_mids, g_strdup (mid), NULL);
+        WEBRTC_TRANSCEIVER (trans)->pending_mid = g_strdup (mid);
+        break;
+      }
+    }
   }
 
   /* TODO:
@@ -2435,9 +3617,7 @@ sdp_media_from_transceiver (GstWebRTCBin * webrtc, GstSDPMedia * media,
     if (!trans->sender->transport) {
       TransportStream *item;
 
-      item =
-          _get_or_create_transport_stream (webrtc,
-          bundled_mids ? bundle_idx : media_idx, FALSE);
+      item = _get_or_create_transport_stream (webrtc, rtp_session_idx, FALSE);
 
       webrtc_transceiver_set_transport (WEBRTC_TRANSCEIVER (trans), item);
     }
@@ -2446,49 +3626,74 @@ sdp_media_from_transceiver (GstWebRTCBin * webrtc, GstSDPMedia * media,
   }
 
   if (bundled_mids) {
-    const gchar *mid = gst_sdp_media_get_attribute_val (media, "mid");
-
     g_assert (mid);
     g_string_append_printf (bundled_mids, " %s", mid);
   }
 
+  g_clear_pointer (&mid, g_free);
+
   gst_caps_unref (caps);
 
   return TRUE;
 }
 
 static void
-gather_pad_pt (GstWebRTCBinPad * pad, GArray * reserved_pts)
+gather_pad_pt (GstWebRTCBinPad * pad, GArray * media_mapping)
 {
   if (pad->received_caps) {
     GstStructure *s = gst_caps_get_structure (pad->received_caps, 0);
     gint pt;
 
     if (gst_structure_get_int (s, "payload", &pt)) {
-      g_array_append_val (reserved_pts, pt);
+      GST_TRACE_OBJECT (pad, "have media pt %u from received caps", pt);
+      find_or_create_payload_map_for_media_pt (media_mapping, pt);
     }
   }
 }
 
 static GArray *
-gather_reserved_pts (GstWebRTCBin * webrtc)
+gather_media_mapping (GstWebRTCBin * webrtc)
 {
   GstElement *element = GST_ELEMENT (webrtc);
-  GArray *reserved_pts = g_array_new (FALSE, FALSE, sizeof (guint));
+  GArray *media_mapping =
+      g_array_new (FALSE, FALSE, sizeof (struct media_payload_map_item));
+  guint i;
 
   GST_OBJECT_LOCK (webrtc);
-  g_list_foreach (element->sinkpads, (GFunc) gather_pad_pt, reserved_pts);
+  g_list_foreach (element->sinkpads, (GFunc) gather_pad_pt, media_mapping);
   g_list_foreach (webrtc->priv->pending_pads, (GFunc) gather_pad_pt,
-      reserved_pts);
+      media_mapping);
+
+  for (i = 0; i < webrtc->priv->transceivers->len; i++) {
+    GstWebRTCRTPTransceiver *trans;
+
+    trans = g_ptr_array_index (webrtc->priv->transceivers, i);
+    GST_OBJECT_LOCK (trans);
+    if (trans->codec_preferences) {
+      guint j, n;
+      gint pt;
+
+      n = gst_caps_get_size (trans->codec_preferences);
+      for (j = 0; j < n; j++) {
+        GstStructure *s = gst_caps_get_structure (trans->codec_preferences, j);
+        if (gst_structure_get_int (s, "payload", &pt)) {
+          GST_TRACE_OBJECT (trans, "have media pt %u from codec preferences",
+              pt);
+          find_or_create_payload_map_for_media_pt (media_mapping, pt);
+        }
+      }
+    }
+    GST_OBJECT_UNLOCK (trans);
+  }
   GST_OBJECT_UNLOCK (webrtc);
 
-  return reserved_pts;
+  return media_mapping;
 }
 
 static gboolean
 _add_data_channel_offer (GstWebRTCBin * webrtc, GstSDPMessage * msg,
     GstSDPMedia * media, GString * bundled_mids, guint bundle_idx,
-    gchar * bundle_ufrag, gchar * bundle_pwd)
+    gchar * bundle_ufrag, gchar * bundle_pwd, GHashTable * all_mids)
 {
   GstSDPMessage *last_offer = _get_latest_self_generated_sdp (webrtc);
   gchar *ufrag, *pwd, *sdp_mid;
@@ -2549,10 +3754,18 @@ _add_data_channel_offer (GstWebRTCBin * webrtc, GstSDPMessage * msg,
 
     gst_sdp_media_add_attribute (media, "mid", mid);
   } else {
-    sdp_mid = g_strdup_printf ("%s%u", gst_sdp_media_get_media (media),
-        webrtc->priv->media_counter++);
-    gst_sdp_media_add_attribute (media, "mid", sdp_mid);
-    g_free (sdp_mid);
+    /* Make sure to avoid mid collisions */
+    while (TRUE) {
+      sdp_mid = g_strdup_printf ("%s%u", gst_sdp_media_get_media (media),
+          webrtc->priv->media_counter++);
+      if (g_hash_table_contains (all_mids, (gpointer) sdp_mid)) {
+        g_free (sdp_mid);
+      } else {
+        gst_sdp_media_add_attribute (media, "mid", sdp_mid);
+        g_hash_table_insert (all_mids, sdp_mid, NULL);
+        break;
+      }
+    }
   }
 
   if (bundled_mids) {
@@ -2574,17 +3787,22 @@ _add_data_channel_offer (GstWebRTCBin * webrtc, GstSDPMessage * msg,
 
 /* TODO: use the options argument */
 static GstSDPMessage *
-_create_offer_task (GstWebRTCBin * webrtc, const GstStructure * options)
+_create_offer_task (GstWebRTCBin * webrtc, const GstStructure * options,
+    GError ** error)
 {
-  GstSDPMessage *ret;
+  GstSDPMessage *ret = NULL;
   GString *bundled_mids = NULL;
   gchar *bundle_ufrag = NULL;
   gchar *bundle_pwd = NULL;
-  GArray *reserved_pts = NULL;
+  GArray *media_mapping = NULL;
+  GHashTable *all_mids =
+      g_hash_table_new_full (g_str_hash, g_str_equal, g_free, NULL);
+
   GstSDPMessage *last_offer = _get_latest_self_generated_sdp (webrtc);
   GList *seen_transceivers = NULL;
   guint media_idx = 0;
   int i;
+  gboolean no_more_mlines = FALSE;
 
   gst_sdp_message_new (&ret);
 
@@ -2616,8 +3834,8 @@ _create_offer_task (GstWebRTCBin * webrtc, const GstStructure * options)
     GStrv last_bundle = NULL;
     guint bundle_media_index;
 
-    reserved_pts = gather_reserved_pts (webrtc);
-    if (last_offer && _parse_bundle (last_offer, &last_bundle) && last_bundle
+    media_mapping = gather_media_mapping (webrtc);
+    if (last_offer && _parse_bundle (last_offer, &last_bundle, NULL)
         && last_bundle && last_bundle[0]
         && _get_bundle_index (last_offer, last_bundle, &bundle_media_index)) {
       bundle_ufrag =
@@ -2645,35 +3863,72 @@ _create_offer_task (GstWebRTCBin * webrtc, const GstStructure * options)
           || g_strcmp0 (gst_sdp_media_get_media (last_media), "video") == 0) {
         const gchar *last_mid;
         int j;
+
         last_mid = gst_sdp_media_get_attribute_val (last_media, "mid");
 
         for (j = 0; j < webrtc->priv->transceivers->len; j++) {
+          WebRTCTransceiver *wtrans;
+          const gchar *mid;
+
           trans = g_ptr_array_index (webrtc->priv->transceivers, j);
+          wtrans = WEBRTC_TRANSCEIVER (trans);
 
-          if (trans->mid && g_strcmp0 (trans->mid, last_mid) == 0) {
-            GstSDPMedia *media;
+          if (trans->mid)
+            mid = trans->mid;
+          else
+            mid = wtrans->pending_mid;
+
+          if (mid && g_strcmp0 (mid, last_mid) == 0) {
+            GstSDPMedia media;
+
+            memset (&media, 0, sizeof (media));
 
             g_assert (!g_list_find (seen_transceivers, trans));
 
+            if (wtrans->mline_locked && trans->mline != media_idx) {
+              g_set_error (error, GST_WEBRTC_ERROR,
+                  GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+                  "Previous negotiatied transceiver <%s> with mid %s was in "
+                  "mline %d but transceiver has locked mline %u",
+                  GST_OBJECT_NAME (trans), trans->mid, media_idx, trans->mline);
+              goto cancel_offer;
+            }
+
             GST_LOG_OBJECT (webrtc, "using previous negotiatied transceiver %"
                 GST_PTR_FORMAT " with mid %s into media index %u", trans,
                 trans->mid, media_idx);
 
-            /* FIXME: deal with format changes */
-            gst_sdp_media_copy (last_media, &media);
-            _media_replace_direction (media, trans->direction);
+            if (webrtc->bundle_policy == GST_WEBRTC_BUNDLE_POLICY_NONE) {
+              media_mapping =
+                  g_array_new (FALSE, FALSE,
+                  sizeof (struct media_payload_map_item));
+            }
 
-            if (bundled_mids) {
-              const gchar *mid = gst_sdp_media_get_attribute_val (media, "mid");
+            gst_sdp_media_init (&media);
+            if (!sdp_media_from_transceiver (webrtc, &media, last_media, trans,
+                    media_idx, bundled_mids, 0, bundle_ufrag, bundle_pwd,
+                    media_mapping, all_mids, &no_more_mlines, error)) {
+              gst_sdp_media_uninit (&media);
+              if (!*error)
+                g_set_error_literal (error, GST_WEBRTC_ERROR,
+                    GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+                    "Could not reuse transceiver");
+            }
 
-              g_assert (mid);
-              g_string_append_printf (bundled_mids, " %s", mid);
+            if (webrtc->bundle_policy == GST_WEBRTC_BUNDLE_POLICY_NONE) {
+              g_array_free (media_mapping, TRUE);
+              media_mapping = NULL;
             }
+            if (*error)
+              goto cancel_offer;
+
+            mid = gst_sdp_media_get_attribute_val (&media, "mid");
+            g_assert (mid && g_strcmp0 (last_mid, mid) == 0);
 
-            gst_sdp_message_add_media (ret, media);
+            gst_sdp_message_add_media (ret, &media);
             media_idx++;
 
-            gst_sdp_media_free (media);
+            gst_sdp_media_uninit (&media);
             seen_transceivers = g_list_prepend (seen_transceivers, trans);
             break;
           }
@@ -2683,7 +3938,7 @@ _create_offer_task (GstWebRTCBin * webrtc, const GstStructure * options)
         GstSDPMedia media = { 0, };
         gst_sdp_media_init (&media);
         if (_add_data_channel_offer (webrtc, ret, &media, bundled_mids, 0,
-                bundle_ufrag, bundle_pwd)) {
+                bundle_ufrag, bundle_pwd, all_mids)) {
           gst_sdp_message_add_media (ret, &media);
           media_idx++;
         } else {
@@ -2691,35 +3946,150 @@ _create_offer_task (GstWebRTCBin * webrtc, const GstStructure * options)
         }
       }
     }
-  }
-
-  /* add any extra streams */
-  for (i = 0; i < webrtc->priv->transceivers->len; i++) {
-    GstWebRTCRTPTransceiver *trans;
-    GstSDPMedia media = { 0, };
-
-    trans = g_ptr_array_index (webrtc->priv->transceivers, i);
-
-    /* don't add transceivers twice */
-    if (g_list_find (seen_transceivers, trans))
-      continue;
+  }
+
+  /* First, go over all transceivers and gather existing mids */
+  for (i = 0; i < webrtc->priv->transceivers->len; i++) {
+    GstWebRTCRTPTransceiver *trans;
+
+    trans = g_ptr_array_index (webrtc->priv->transceivers, i);
+
+    if (g_list_find (seen_transceivers, trans))
+      continue;
+
+    if (trans->mid) {
+      if (g_hash_table_contains (all_mids, trans->mid)) {
+        g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+            "Duplicate mid %s when creating offer", trans->mid);
+        goto cancel_offer;
+      }
+
+      g_hash_table_insert (all_mids, g_strdup (trans->mid), NULL);
+    } else if (WEBRTC_TRANSCEIVER (trans)->pending_mid &&
+        !g_hash_table_contains (all_mids,
+            WEBRTC_TRANSCEIVER (trans)->pending_mid)) {
+      g_hash_table_insert (all_mids,
+          g_strdup (WEBRTC_TRANSCEIVER (trans)->pending_mid), NULL);
+    }
+  }
+
+
+  /* add any extra streams */
+  for (;;) {
+    GstWebRTCRTPTransceiver *trans = NULL;
+    GstSDPMedia media = { 0, };
+
+    /* First find a transceiver requesting this m-line */
+    trans = _find_transceiver_for_mline (webrtc, media_idx);
+
+    if (trans) {
+      /* We can't have seen it already, because it is locked to this line,
+       * unless it's a no-more-mlines case
+       */
+      if (!g_list_find (seen_transceivers, trans))
+        seen_transceivers = g_list_prepend (seen_transceivers, trans);
+    } else {
+      /* Otherwise find a free transceiver */
+      for (i = 0; i < webrtc->priv->transceivers->len; i++) {
+        WebRTCTransceiver *wtrans;
+
+        trans = g_ptr_array_index (webrtc->priv->transceivers, i);
+        wtrans = WEBRTC_TRANSCEIVER (trans);
+
+        /* don't add transceivers twice */
+        if (g_list_find (seen_transceivers, trans))
+          continue;
+
+        /* Ignore transceivers with a locked mline, as they would have been
+         * found above or will be used later */
+        if (wtrans->mline_locked)
+          continue;
+
+        seen_transceivers = g_list_prepend (seen_transceivers, trans);
+        /* don't add stopped transceivers */
+        if (trans->stopped) {
+          continue;
+        }
+
+        /* Otherwise take it */
+        break;
+      }
+
+      /* Stop if we got all transceivers */
+      if (i == webrtc->priv->transceivers->len) {
+
+        /* But try to add a data channel first, we do it here, because
+         * it can allow a locked m-line to be put after, so we need to
+         * do another iteration after.
+         */
+        if (_message_get_datachannel_index (ret) == G_MAXUINT) {
+          GstSDPMedia media = { 0, };
+          gst_sdp_media_init (&media);
+          if (_add_data_channel_offer (webrtc, ret, &media, bundled_mids, 0,
+                  bundle_ufrag, bundle_pwd, all_mids)) {
+            if (no_more_mlines) {
+              g_set_error (error, GST_WEBRTC_ERROR,
+                  GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+                  "Trying to add data channel but there is a"
+                  " transceiver locked to line %d which doesn't have caps",
+                  media_idx);
+              gst_sdp_media_uninit (&media);
+              goto cancel_offer;
+            }
+            gst_sdp_message_add_media (ret, &media);
+            media_idx++;
+            continue;
+          } else {
+            gst_sdp_media_uninit (&media);
+          }
+        }
+
+        /* Verify that we didn't ignore any locked m-line transceivers */
+        for (i = 0; i < webrtc->priv->transceivers->len; i++) {
+          WebRTCTransceiver *wtrans;
+
+          trans = g_ptr_array_index (webrtc->priv->transceivers, i);
+          wtrans = WEBRTC_TRANSCEIVER (trans);
+          /* don't add transceivers twice */
+          if (g_list_find (seen_transceivers, trans))
+            continue;
+          g_assert (wtrans->mline_locked);
+
+          g_set_error (error, GST_WEBRTC_ERROR,
+              GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+              "Tranceiver <%s> with mid %s has locked mline %d but the offer "
+              "only has %u sections", GST_OBJECT_NAME (trans), trans->mid,
+              trans->mline, media_idx);
+          goto cancel_offer;
+        }
+        break;
+      }
+    }
 
-    /* don't add stopped transceivers */
-    if (trans->stopped)
-      continue;
+    if (no_more_mlines) {
+      g_set_error (error, GST_WEBRTC_ERROR,
+          GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+          "Trying to add transceiver at line %u but there is a transceiver "
+          "with a locked mline for this line which doesn't have caps",
+          media_idx);
+      goto cancel_offer;
+    }
 
     gst_sdp_media_init (&media);
 
     if (webrtc->bundle_policy == GST_WEBRTC_BUNDLE_POLICY_NONE) {
-      reserved_pts = g_array_new (FALSE, FALSE, sizeof (guint));
+      media_mapping =
+          g_array_new (FALSE, FALSE, sizeof (struct media_payload_map_item));
     }
 
     GST_LOG_OBJECT (webrtc, "adding transceiver %" GST_PTR_FORMAT " at media "
         "index %u", trans, media_idx);
 
-    if (sdp_media_from_transceiver (webrtc, &media, trans,
-            GST_WEBRTC_SDP_TYPE_OFFER, media_idx, bundled_mids, 0, bundle_ufrag,
-            bundle_pwd, reserved_pts)) {
+    if (sdp_media_from_transceiver (webrtc, &media, NULL, trans, media_idx,
+            bundled_mids, 0, bundle_ufrag, bundle_pwd, media_mapping, all_mids,
+            &no_more_mlines, error)) {
+      /* as per JSEP, a=rtcp-mux-only is only added for new streams */
+      gst_sdp_media_add_attribute (&media, "rtcp-mux-only", "");
       gst_sdp_message_add_media (ret, &media);
       media_idx++;
     } else {
@@ -2727,27 +4097,20 @@ _create_offer_task (GstWebRTCBin * webrtc, const GstStructure * options)
     }
 
     if (webrtc->bundle_policy == GST_WEBRTC_BUNDLE_POLICY_NONE) {
-      g_array_free (reserved_pts, TRUE);
+      g_array_free (media_mapping, TRUE);
+      media_mapping = NULL;
     }
-    seen_transceivers = g_list_prepend (seen_transceivers, trans);
+    if (*error)
+      goto cancel_offer;
   }
 
   if (webrtc->bundle_policy != GST_WEBRTC_BUNDLE_POLICY_NONE) {
-    g_array_free (reserved_pts, TRUE);
+    g_array_free (media_mapping, TRUE);
+    media_mapping = NULL;
   }
 
-  /* add a data channel if exists and not renegotiated */
-  if (_message_get_datachannel_index (ret) == G_MAXUINT) {
-    GstSDPMedia media = { 0, };
-    gst_sdp_media_init (&media);
-    if (_add_data_channel_offer (webrtc, ret, &media, bundled_mids, 0,
-            bundle_ufrag, bundle_pwd)) {
-      gst_sdp_message_add_media (ret, &media);
-      media_idx++;
-    } else {
-      gst_sdp_media_uninit (&media);
-    }
-  }
+  webrtc->priv->max_sink_pad_serial = MAX (webrtc->priv->max_sink_pad_serial,
+      media_idx);
 
   g_assert (media_idx == gst_sdp_message_medias_len (ret));
 
@@ -2756,18 +4119,11 @@ _create_offer_task (GstWebRTCBin * webrtc, const GstStructure * options)
 
     gst_sdp_message_add_attribute (ret, "group", mids);
     g_free (mids);
+    bundled_mids = NULL;
   }
 
-  if (bundle_ufrag)
-    g_free (bundle_ufrag);
-
-  if (bundle_pwd)
-    g_free (bundle_pwd);
-
   /* FIXME: pre-emptively setup receiving elements when needed */
 
-  g_list_free (seen_transceivers);
-
   if (webrtc->priv->last_generated_answer)
     gst_webrtc_session_description_free (webrtc->priv->last_generated_answer);
   webrtc->priv->last_generated_answer = NULL;
@@ -2780,7 +4136,29 @@ _create_offer_task (GstWebRTCBin * webrtc, const GstStructure * options)
         gst_webrtc_session_description_new (GST_WEBRTC_SDP_TYPE_OFFER, copy);
   }
 
+out:
+  if (media_mapping)
+    g_array_free (media_mapping, TRUE);
+
+  g_hash_table_unref (all_mids);
+
+  g_list_free (seen_transceivers);
+
+  if (bundle_ufrag)
+    g_free (bundle_ufrag);
+
+  if (bundle_pwd)
+    g_free (bundle_pwd);
+
+  if (bundled_mids)
+    g_string_free (bundled_mids, TRUE);
+
   return ret;
+
+cancel_offer:
+  gst_sdp_message_free (ret);
+  ret = NULL;
+  goto out;
 }
 
 static void
@@ -2876,12 +4254,30 @@ _media_add_rtx (GstSDPMedia * media, WebRTCTransceiver * trans,
           str = g_strdup_printf ("%u", target_ssrc);
           gst_structure_set (trans->local_rtx_ssrc_map, str, G_TYPE_UINT,
               g_random_int (), NULL);
+          g_free (str);
         }
       }
     }
   }
 }
 
+static gboolean
+_update_transceiver_kind_from_caps (GstWebRTCRTPTransceiver * trans,
+    const GstCaps * caps)
+{
+  GstWebRTCKind kind = webrtc_kind_from_caps (caps);
+
+  if (trans->kind == kind)
+    return TRUE;
+
+  if (trans->kind == GST_WEBRTC_KIND_UNKNOWN) {
+    trans->kind = kind;
+    return TRUE;
+  } else {
+    return FALSE;
+  }
+}
+
 static void
 _get_rtx_target_pt_and_ssrc_from_caps (GstCaps * answer_caps, gint * target_pt,
     guint * target_ssrc)
@@ -2894,7 +4290,8 @@ _get_rtx_target_pt_and_ssrc_from_caps (GstCaps * answer_caps, gint * target_pt,
 
 /* TODO: use the options argument */
 static GstSDPMessage *
-_create_answer_task (GstWebRTCBin * webrtc, const GstStructure * options)
+_create_answer_task (GstWebRTCBin * webrtc, const GstStructure * options,
+    GError ** error)
 {
   GstSDPMessage *ret = NULL;
   const GstWebRTCSessionDescription *pending_remote =
@@ -2909,12 +4306,13 @@ _create_answer_task (GstWebRTCBin * webrtc, const GstStructure * options)
   GstSDPMessage *last_answer = _get_latest_self_generated_sdp (webrtc);
 
   if (!webrtc->pending_remote_description) {
-    GST_ERROR_OBJECT (webrtc,
+    g_set_error_literal (error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_INVALID_STATE,
         "Asked to create an answer without a remote description");
     return NULL;
   }
 
-  if (!_parse_bundle (pending_remote->sdp, &bundled))
+  if (!_parse_bundle (pending_remote->sdp, &bundled, error))
     goto out;
 
   if (bundled) {
@@ -2922,8 +4320,8 @@ _create_answer_task (GstWebRTCBin * webrtc, const GstStructure * options)
     guint bundle_media_index;
 
     if (!_get_bundle_index (pending_remote->sdp, bundled, &bundle_idx)) {
-      GST_ERROR_OBJECT (webrtc, "Bundle tag is %s but no media found matching",
-          bundled[0]);
+      g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
+          "Bundle tag is %s but no media found matching", bundled[0]);
       goto out;
     }
 
@@ -2931,7 +4329,7 @@ _create_answer_task (GstWebRTCBin * webrtc, const GstStructure * options)
       bundled_mids = g_string_new ("BUNDLE");
     }
 
-    if (last_answer && _parse_bundle (last_answer, &last_bundle)
+    if (last_answer && _parse_bundle (last_answer, &last_bundle, NULL)
         && last_bundle && last_bundle[0]
         && _get_bundle_index (last_answer, last_bundle, &bundle_media_index)) {
       bundle_ufrag =
@@ -3079,33 +4477,38 @@ _create_answer_task (GstWebRTCBin * webrtc, const GstStructure * options)
       offer_caps = _rtp_caps_from_media (offer_media);
 
       if (last_answer && i < gst_sdp_message_medias_len (last_answer)
-          && (rtp_trans =
-              _find_transceiver (webrtc, mid,
-                  (FindTransceiverFunc) match_for_mid))) {
+          && (rtp_trans = _find_transceiver_for_mid (webrtc, mid))) {
         const GstSDPMedia *last_media =
             gst_sdp_message_get_media (last_answer, i);
         const gchar *last_mid =
             gst_sdp_media_get_attribute_val (last_media, "mid");
+        GstCaps *current_caps;
 
         /* FIXME: assumes no shenanigans with recycling transceivers */
         g_assert (g_strcmp0 (mid, last_mid) == 0);
 
-        if (!answer_caps
-            && (rtp_trans->direction ==
-                GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDRECV
-                || rtp_trans->direction ==
-                GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_RECVONLY))
-          answer_caps =
-              _find_codec_preferences (webrtc, rtp_trans, GST_PAD_SINK, i);
-        if (!answer_caps
-            && (rtp_trans->direction ==
-                GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDRECV
-                || rtp_trans->direction ==
-                GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDONLY))
-          answer_caps =
-              _find_codec_preferences (webrtc, rtp_trans, GST_PAD_SRC, i);
-        if (!answer_caps)
-          answer_caps = _rtp_caps_from_media (last_media);
+        current_caps = _find_codec_preferences (webrtc, rtp_trans, i, error);
+        if (*error) {
+          gst_caps_unref (offer_caps);
+          goto rejected;
+        }
+        if (!current_caps)
+          current_caps = _rtp_caps_from_media (last_media);
+
+        if (current_caps) {
+          answer_caps = gst_caps_intersect (offer_caps, current_caps);
+          if (gst_caps_is_empty (answer_caps)) {
+            GST_WARNING_OBJECT (webrtc, "Caps from offer for m-line %d (%"
+                GST_PTR_FORMAT ") don't intersect with caps from codec"
+                " preferences and transceiver %" GST_PTR_FORMAT, i, offer_caps,
+                current_caps);
+            gst_caps_unref (current_caps);
+            gst_caps_unref (answer_caps);
+            gst_caps_unref (offer_caps);
+            goto rejected;
+          }
+          gst_caps_unref (current_caps);
+        }
 
         /* XXX: In theory we're meant to use the sendrecv formats for the
          * inactive direction however we don't know what that may be and would
@@ -3126,10 +4529,13 @@ _create_answer_task (GstWebRTCBin * webrtc, const GstStructure * options)
             continue;
           }
 
-          trans_caps =
-              _find_codec_preferences (webrtc, rtp_trans, GST_PAD_SINK, j);
+          trans_caps = _find_codec_preferences (webrtc, rtp_trans, j, error);
+          if (*error) {
+            gst_caps_unref (offer_caps);
+            goto rejected;
+          }
 
-          GST_TRACE_OBJECT (webrtc, "trying to compare %" GST_PTR_FORMAT
+          GST_LOG_OBJECT (webrtc, "trying to compare %" GST_PTR_FORMAT
               " and %" GST_PTR_FORMAT, offer_caps, trans_caps);
 
           /* FIXME: technically this is a little overreaching as some fields we
@@ -3137,25 +4543,19 @@ _create_answer_task (GstWebRTCBin * webrtc, const GstStructure * options)
            * that we cannot actually support */
           if (trans_caps) {
             answer_caps = gst_caps_intersect (offer_caps, trans_caps);
-            if (answer_caps && !gst_caps_is_empty (answer_caps)) {
-              GST_LOG_OBJECT (webrtc,
-                  "found compatible transceiver %" GST_PTR_FORMAT
-                  " for offer media %u", rtp_trans, i);
-              if (trans_caps)
-                gst_caps_unref (trans_caps);
-              break;
-            } else {
-              if (answer_caps) {
-                gst_caps_unref (answer_caps);
-                answer_caps = NULL;
+            gst_caps_unref (trans_caps);
+            if (answer_caps) {
+              if (!gst_caps_is_empty (answer_caps)) {
+                GST_LOG_OBJECT (webrtc,
+                    "found compatible transceiver %" GST_PTR_FORMAT
+                    " for offer media %u", rtp_trans, i);
+                break;
               }
-              if (trans_caps)
-                gst_caps_unref (trans_caps);
-              rtp_trans = NULL;
+              gst_caps_unref (answer_caps);
+              answer_caps = NULL;
             }
-          } else {
-            rtp_trans = NULL;
           }
+          rtp_trans = NULL;
         }
       }
 
@@ -3164,42 +4564,88 @@ _create_answer_task (GstWebRTCBin * webrtc, const GstStructure * options)
         g_assert (answer_caps != NULL);
       } else {
         /* if no transceiver, then we only receive that stream and respond with
-         * the exact same caps */
-        /* FIXME: how to validate that subsequent elements can actually receive
-         * this payload/format */
+         * the intersection with the transceivers codec preferences caps */
         answer_dir = GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_RECVONLY;
-        answer_caps = gst_caps_ref (offer_caps);
-      }
-
-      if (gst_caps_is_empty (answer_caps)) {
-        GST_WARNING_OBJECT (webrtc, "Could not create caps for media");
-        if (rtp_trans)
-          gst_object_unref (rtp_trans);
-        gst_caps_unref (answer_caps);
-        goto rejected;
+        GST_WARNING_OBJECT (webrtc, "did not find compatible transceiver for "
+            "offer caps %" GST_PTR_FORMAT ", will only receive", offer_caps);
       }
 
-      seen_transceivers = g_list_prepend (seen_transceivers, rtp_trans);
-
       if (!rtp_trans) {
-        trans = _create_webrtc_transceiver (webrtc, answer_dir, i);
+        GstCaps *trans_caps;
+        GstWebRTCKind kind = GST_WEBRTC_KIND_UNKNOWN;
+
+        if (g_strcmp0 (gst_sdp_media_get_media (offer_media), "audio") == 0)
+          kind = GST_WEBRTC_KIND_AUDIO;
+        else if (g_strcmp0 (gst_sdp_media_get_media (offer_media),
+                "video") == 0)
+          kind = GST_WEBRTC_KIND_VIDEO;
+        else
+          GST_LOG_OBJECT (webrtc, "Unknown media kind %s",
+              GST_STR_NULL (gst_sdp_media_get_media (offer_media)));
+
+        trans = _create_webrtc_transceiver (webrtc, answer_dir, i, kind, NULL);
         rtp_trans = GST_WEBRTC_RTP_TRANSCEIVER (trans);
 
         GST_LOG_OBJECT (webrtc, "Created new transceiver %" GST_PTR_FORMAT
-            " for mline %u", trans, i);
+            " for mline %u with media kind %d", trans, i, kind);
+
+        trans_caps = _find_codec_preferences (webrtc, rtp_trans, i, error);
+        if (*error) {
+          gst_caps_unref (offer_caps);
+          goto rejected;
+        }
+
+        GST_TRACE_OBJECT (webrtc, "trying to compare %" GST_PTR_FORMAT
+            " and %" GST_PTR_FORMAT, offer_caps, trans_caps);
+
+        /* FIXME: technically this is a little overreaching as some fields we
+         * we can deal with not having and/or we may have unrecognized fields
+         * that we cannot actually support */
+        if (trans_caps) {
+          answer_caps = gst_caps_intersect (offer_caps, trans_caps);
+          gst_clear_caps (&trans_caps);
+        } else {
+          answer_caps = gst_caps_ref (offer_caps);
+        }
       } else {
         trans = WEBRTC_TRANSCEIVER (rtp_trans);
       }
 
-      if (!trans->do_nack) {
-        answer_caps = gst_caps_make_writable (answer_caps);
-        for (k = 0; k < gst_caps_get_size (answer_caps); k++) {
-          GstStructure *s = gst_caps_get_structure (answer_caps, k);
+      seen_transceivers = g_list_prepend (seen_transceivers, rtp_trans);
+
+      if (gst_caps_is_empty (answer_caps)) {
+        GST_WARNING_OBJECT (webrtc, "Could not create caps for media");
+        gst_clear_caps (&answer_caps);
+        gst_clear_caps (&offer_caps);
+        goto rejected;
+      }
+
+      if (!_update_transceiver_kind_from_caps (rtp_trans, answer_caps)) {
+        GstWebRTCKind caps_kind = webrtc_kind_from_caps (answer_caps);
+
+        GST_WARNING_OBJECT (webrtc,
+            "Trying to change kind of transceiver %" GST_PTR_FORMAT
+            " at m-line %d from %s (%d) to %s (%d)", trans, rtp_trans->mline,
+            gst_webrtc_kind_to_string (rtp_trans->kind), rtp_trans->kind,
+            gst_webrtc_kind_to_string (caps_kind), caps_kind);
+      }
+
+      answer_caps = gst_caps_make_writable (answer_caps);
+      for (k = 0; k < gst_caps_get_size (answer_caps); k++) {
+        GstStructure *s = gst_caps_get_structure (answer_caps, k);
+        /* taken from the offer sdp already and already intersected above */
+        gst_structure_remove_field (s, "a-mid");
+        if (!trans->do_nack)
           gst_structure_remove_fields (s, "rtcp-fb-nack", NULL);
-        }
       }
 
-      gst_sdp_media_set_media_from_caps (answer_caps, media);
+      if (gst_sdp_media_set_media_from_caps (answer_caps, media) != GST_SDP_OK) {
+        GST_WARNING_OBJECT (webrtc,
+            "Could not build media from caps %" GST_PTR_FORMAT, answer_caps);
+        gst_clear_caps (&answer_caps);
+        gst_clear_caps (&offer_caps);
+        goto rejected;
+      }
 
       _get_rtx_target_pt_and_ssrc_from_caps (answer_caps, &target_pt,
           &target_ssrc);
@@ -3227,6 +4673,7 @@ _create_answer_task (GstWebRTCBin * webrtc, const GstStructure * options)
       if (answer_dir == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_NONE) {
         GST_WARNING_OBJECT (webrtc, "Could not intersect offer direction with "
             "transceiver direction");
+        gst_caps_unref (offer_caps);
         goto rejected;
       }
       _media_replace_direction (media, answer_dir);
@@ -3258,10 +4705,16 @@ _create_answer_task (GstWebRTCBin * webrtc, const GstStructure * options)
 
     if (0) {
     rejected:
-      GST_INFO_OBJECT (webrtc, "media %u rejected", i);
+      if (error && *error)
+        GST_INFO_OBJECT (webrtc, "media %u rejected: %s", i, (*error)->message);
+      else
+        GST_INFO_OBJECT (webrtc, "media %u rejected", i);
       gst_sdp_media_free (media);
       gst_sdp_media_copy (offer_media, &media);
       gst_sdp_media_set_port_info (media, 0, 0);
+      /* Clear error here as it is not propagated to the caller and the media
+       * is just skipped, i.e. more iterations are going to happen. */
+      g_clear_error (error);
     }
     gst_sdp_message_add_media (ret, media);
     gst_sdp_media_free (media);
@@ -3308,24 +4761,24 @@ out:
 struct create_sdp
 {
   GstStructure *options;
-  GstPromise *promise;
   GstWebRTCSDPType type;
 };
 
-static void
+static GstStructure *
 _create_sdp_task (GstWebRTCBin * webrtc, struct create_sdp *data)
 {
   GstWebRTCSessionDescription *desc = NULL;
   GstSDPMessage *sdp = NULL;
   GstStructure *s = NULL;
+  GError *error = NULL;
 
   GST_INFO_OBJECT (webrtc, "creating %s sdp with options %" GST_PTR_FORMAT,
       gst_webrtc_sdp_type_to_string (data->type), data->options);
 
   if (data->type == GST_WEBRTC_SDP_TYPE_OFFER)
-    sdp = _create_offer_task (webrtc, data->options);
+    sdp = _create_offer_task (webrtc, data->options, &error);
   else if (data->type == GST_WEBRTC_SDP_TYPE_ANSWER)
-    sdp = _create_answer_task (webrtc, data->options);
+    sdp = _create_answer_task (webrtc, data->options, &error);
   else {
     g_assert_not_reached ();
     goto out;
@@ -3336,15 +4789,21 @@ _create_sdp_task (GstWebRTCBin * webrtc, struct create_sdp *data)
     s = gst_structure_new ("application/x-gst-promise",
         gst_webrtc_sdp_type_to_string (data->type),
         GST_TYPE_WEBRTC_SESSION_DESCRIPTION, desc, NULL);
+  } else {
+    g_warn_if_fail (error != NULL);
+    GST_WARNING_OBJECT (webrtc, "returning error: %s",
+        error ? error->message : "Unknown");
+    s = gst_structure_new ("application/x-gst-promise",
+        "error", G_TYPE_ERROR, error, NULL);
+    g_clear_error (&error);
   }
 
 out:
-  PC_UNLOCK (webrtc);
-  gst_promise_reply (data->promise, s);
-  PC_LOCK (webrtc);
 
   if (desc)
     gst_webrtc_session_description_free (desc);
+
+  return s;
 }
 
 static void
@@ -3352,7 +4811,6 @@ _free_create_sdp_data (struct create_sdp *data)
 {
   if (data->options)
     gst_structure_free (data->options);
-  gst_promise_unref (data->promise);
   g_free (data);
 }
 
@@ -3364,16 +4822,14 @@ gst_webrtc_bin_create_offer (GstWebRTCBin * webrtc,
 
   if (options)
     data->options = gst_structure_copy (options);
-  data->promise = gst_promise_ref (promise);
   data->type = GST_WEBRTC_SDP_TYPE_OFFER;
 
   if (!gst_webrtc_bin_enqueue_task (webrtc, (GstWebRTCBinFunc) _create_sdp_task,
           data, (GDestroyNotify) _free_create_sdp_data, promise)) {
     GError *error =
-        g_error_new (GST_WEBRTC_BIN_ERROR, GST_WEBRTC_BIN_ERROR_CLOSED,
+        g_error_new (GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_INVALID_STATE,
         "Could not create offer. webrtcbin is closed");
-    GstStructure *s =
-        gst_structure_new ("application/x-gstwebrtcbin-promise-error",
+    GstStructure *s = gst_structure_new ("application/x-gst-promise",
         "error", G_TYPE_ERROR, error, NULL);
 
     gst_promise_reply (promise, s);
@@ -3390,16 +4846,14 @@ gst_webrtc_bin_create_answer (GstWebRTCBin * webrtc,
 
   if (options)
     data->options = gst_structure_copy (options);
-  data->promise = gst_promise_ref (promise);
   data->type = GST_WEBRTC_SDP_TYPE_ANSWER;
 
   if (!gst_webrtc_bin_enqueue_task (webrtc, (GstWebRTCBinFunc) _create_sdp_task,
           data, (GDestroyNotify) _free_create_sdp_data, promise)) {
     GError *error =
-        g_error_new (GST_WEBRTC_BIN_ERROR, GST_WEBRTC_BIN_ERROR_CLOSED,
+        g_error_new (GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_INVALID_STATE,
         "Could not create answer. webrtcbin is closed.");
-    GstStructure *s =
-        gst_structure_new ("application/x-gstwebrtcbin-promise-error",
+    GstStructure *s = gst_structure_new ("application/x-gst-promise",
         "error", G_TYPE_ERROR, error, NULL);
 
     gst_promise_reply (promise, s);
@@ -3410,17 +4864,25 @@ gst_webrtc_bin_create_answer (GstWebRTCBin * webrtc,
 
 static GstWebRTCBinPad *
 _create_pad_for_sdp_media (GstWebRTCBin * webrtc, GstPadDirection direction,
-    guint media_idx)
+    GstWebRTCRTPTransceiver * trans, guint serial, char *msid)
 {
   GstWebRTCBinPad *pad;
   gchar *pad_name;
 
+  if (direction == GST_PAD_SINK) {
+    if (serial == G_MAXUINT)
+      serial = webrtc->priv->max_sink_pad_serial++;
+  } else {
+    serial = webrtc->priv->src_pad_counter++;
+  }
+
   pad_name =
       g_strdup_printf ("%s_%u", direction == GST_PAD_SRC ? "src" : "sink",
-      media_idx);
-  pad = gst_webrtc_bin_pad_new (pad_name, direction);
+      serial);
+  pad = gst_webrtc_bin_pad_new (pad_name, direction, msid);
   g_free (pad_name);
-  pad->mlineindex = media_idx;
+
+  pad->trans = gst_object_ref (trans);
 
   return pad;
 }
@@ -3437,9 +4899,7 @@ _find_transceiver_for_sdp_media (GstWebRTCBin * webrtc,
     const GstSDPAttribute *attr = gst_sdp_media_get_attribute (media, i);
 
     if (g_strcmp0 (attr->key, "mid") == 0) {
-      if ((ret =
-              _find_transceiver (webrtc, attr->value,
-                  (FindTransceiverFunc) match_for_mid)))
+      if ((ret = _find_transceiver_for_mid (webrtc, attr->value)))
         goto out;
     }
   }
@@ -3452,81 +4912,345 @@ out:
   return ret;
 }
 
+static GstElement *
+_build_fec_encoder (GstWebRTCBin * webrtc, WebRTCTransceiver * trans)
+{
+  GstWebRTCRTPTransceiver *rtp_trans = GST_WEBRTC_RTP_TRANSCEIVER (trans);
+  guint ulpfec_pt = 0, red_pt = 0;
+  GstPad *sinkpad, *srcpad, *ghost;
+  GstElement *ret;
+
+  if (trans->stream) {
+    ulpfec_pt =
+        transport_stream_get_pt (trans->stream, "ULPFEC", rtp_trans->mline);
+    red_pt = transport_stream_get_pt (trans->stream, "RED", rtp_trans->mline);
+  }
+
+  if (trans->ulpfecenc || trans->redenc) {
+    g_critical ("webrtcbin: duplicate call to create a fec encoder or "
+        "red encoder!");
+    return NULL;
+  }
+
+  GST_DEBUG_OBJECT (webrtc,
+      "Creating ULPFEC encoder for mline %u with pt %d", rtp_trans->mline,
+      ulpfec_pt);
+
+  ret = gst_bin_new (NULL);
+
+  trans->ulpfecenc = gst_element_factory_make ("rtpulpfecenc", NULL);
+  gst_object_ref_sink (trans->ulpfecenc);
+  if (!gst_bin_add (GST_BIN (ret), trans->ulpfecenc))
+    g_warn_if_reached ();
+  sinkpad = gst_element_get_static_pad (trans->ulpfecenc, "sink");
+
+  g_object_bind_property (rtp_trans, "fec-percentage", trans->ulpfecenc,
+      "percentage", G_BINDING_DEFAULT);
+
+  trans->redenc = gst_element_factory_make ("rtpredenc", NULL);
+  gst_object_ref_sink (trans->redenc);
+
+  GST_DEBUG_OBJECT (webrtc, "Creating RED encoder for mline %u with pt %d",
+      rtp_trans->mline, red_pt);
+
+  gst_bin_add (GST_BIN (ret), trans->redenc);
+  gst_element_link (trans->ulpfecenc, trans->redenc);
+
+  ghost = gst_ghost_pad_new ("sink", sinkpad);
+  gst_clear_object (&sinkpad);
+  gst_element_add_pad (ret, ghost);
+  ghost = NULL;
+
+  srcpad = gst_element_get_static_pad (trans->redenc, "src");
+  ghost = gst_ghost_pad_new ("src", srcpad);
+  gst_clear_object (&srcpad);
+  gst_element_add_pad (ret, ghost);
+  ghost = NULL;
+
+  return ret;
+}
+
+static gboolean
+_merge_structure (GQuark field_id, const GValue * value, gpointer user_data)
+{
+  GstStructure *s = user_data;
+
+  gst_structure_id_set_value (s, field_id, value);
+
+  return TRUE;
+}
+
+#define GST_WEBRTC_PAYLOAD_TYPE "gst.webrtcbin.payload.type"
+
+static void
+try_match_transceiver_with_fec_decoder (GstWebRTCBin * webrtc,
+    WebRTCTransceiver * trans)
+{
+  GList *l;
+
+  for (l = trans->stream->fecdecs; l; l = l->next) {
+    GstElement *fecdec = GST_ELEMENT (l->data);
+    gboolean found_transceiver = FALSE;
+    int original_pt;
+    guint i;
+
+    original_pt =
+        GPOINTER_TO_INT (g_object_get_data (G_OBJECT (fecdec),
+            GST_WEBRTC_PAYLOAD_TYPE));
+    if (original_pt <= 0) {
+      GST_WARNING_OBJECT (trans, "failed to match fec decoder with "
+          "transceiver, fec decoder %" GST_PTR_FORMAT " does not contain a "
+          "valid payload type", fecdec);
+      continue;
+    }
+
+    for (i = 0; i < trans->stream->ptmap->len; i++) {
+      PtMapItem *item = &g_array_index (trans->stream->ptmap, PtMapItem, i);
+
+      /* FIXME: this only works for a 1-1 original_pt->fec_pt mapping */
+      if (original_pt == item->pt && item->media_idx != -1
+          && item->media_idx == trans->parent.mline) {
+        if (trans->ulpfecdec) {
+          GST_FIXME_OBJECT (trans, "cannot");
+          gst_clear_object (&trans->ulpfecdec);
+        }
+        trans->ulpfecdec = gst_object_ref (fecdec);
+        found_transceiver = TRUE;
+        break;
+      }
+    }
+
+    if (!found_transceiver) {
+      GST_WARNING_OBJECT (trans, "failed to match fec decoder with "
+          "transceiver");
+    }
+  }
+}
+
+static void
+_set_internal_rtpbin_element_props_from_stream (GstWebRTCBin * webrtc,
+    TransportStream * stream)
+{
+  GstStructure *merged_local_rtx_ssrc_map;
+  GstStructure *pt_map = gst_structure_new_empty ("application/x-rtp-pt-map");
+  GValue red_pt_array = { 0, };
+  gint *rtx_pt;
+  gsize rtx_count;
+  gsize i;
+
+  gst_value_array_init (&red_pt_array, 0);
+
+  rtx_pt = transport_stream_get_all_pt (stream, "RTX", &rtx_count);
+  GST_DEBUG_OBJECT (stream, "have %" G_GSIZE_FORMAT " rtx payloads", rtx_count);
+
+  for (i = 0; i < rtx_count; i++) {
+    GstCaps *rtx_caps = transport_stream_get_caps_for_pt (stream, rtx_pt[i]);
+    const GstStructure *s = gst_caps_get_structure (rtx_caps, 0);
+    const gchar *apt = gst_structure_get_string (s, "apt");
+
+    GST_LOG_OBJECT (stream, "setting rtx mapping: %s -> %u", apt, rtx_pt[i]);
+    gst_structure_set (pt_map, apt, G_TYPE_UINT, rtx_pt[i], NULL);
+  }
+
+  GST_DEBUG_OBJECT (stream, "setting payload map on %" GST_PTR_FORMAT " : %"
+      GST_PTR_FORMAT " and %" GST_PTR_FORMAT, stream->rtxreceive,
+      stream->rtxsend, pt_map);
+
+  if (stream->rtxreceive)
+    g_object_set (stream->rtxreceive, "payload-type-map", pt_map, NULL);
+  if (stream->rtxsend)
+    g_object_set (stream->rtxsend, "payload-type-map", pt_map, NULL);
+
+  gst_structure_free (pt_map);
+  g_clear_pointer (&rtx_pt, g_free);
+
+  merged_local_rtx_ssrc_map =
+      gst_structure_new_empty ("application/x-rtp-ssrc-map");
+
+  for (i = 0; i < webrtc->priv->transceivers->len; i++) {
+    GstWebRTCRTPTransceiver *rtp_trans =
+        g_ptr_array_index (webrtc->priv->transceivers, i);
+    WebRTCTransceiver *trans = WEBRTC_TRANSCEIVER (rtp_trans);
+
+    if (trans->stream == stream) {
+      gint ulpfec_pt, red_pt = 0;
+
+      ulpfec_pt = transport_stream_get_pt (stream, "ULPFEC", rtp_trans->mline);
+      if (ulpfec_pt <= 0)
+        ulpfec_pt = 0;
+
+      red_pt = transport_stream_get_pt (stream, "RED", rtp_trans->mline);
+      if (red_pt <= 0) {
+        red_pt = -1;
+      } else {
+        GValue ptval = { 0, };
+
+        g_value_init (&ptval, G_TYPE_INT);
+        g_value_set_int (&ptval, red_pt);
+        gst_value_array_append_value (&red_pt_array, &ptval);
+        g_value_unset (&ptval);
+      }
+
+      GST_DEBUG_OBJECT (webrtc, "stream %" GST_PTR_FORMAT " transceiver %"
+          GST_PTR_FORMAT " has FEC payload %d and RED payload %d", stream,
+          trans, ulpfec_pt, red_pt);
+
+      if (trans->ulpfecenc) {
+        guint ulpfecenc_pt = ulpfec_pt;
+
+        if (ulpfecenc_pt == 0)
+          ulpfecenc_pt = 255;
+
+        g_object_set (trans->ulpfecenc, "pt", ulpfecenc_pt, "multipacket",
+            rtp_trans->kind == GST_WEBRTC_KIND_VIDEO, "percentage",
+            trans->fec_percentage, NULL);
+      }
+
+      try_match_transceiver_with_fec_decoder (webrtc, trans);
+      if (trans->ulpfecdec) {
+        g_object_set (trans->ulpfecdec, "passthrough", ulpfec_pt == 0, "pt",
+            ulpfec_pt, NULL);
+      }
+
+      if (trans->redenc) {
+        gboolean always_produce = TRUE;
+        if (red_pt == -1) {
+          /* passthrough settings */
+          red_pt = 0;
+          always_produce = FALSE;
+        }
+        g_object_set (trans->redenc, "pt", red_pt, "allow-no-red-blocks",
+            always_produce, NULL);
+      }
+
+      if (trans->local_rtx_ssrc_map) {
+        gst_structure_foreach (trans->local_rtx_ssrc_map,
+            _merge_structure, merged_local_rtx_ssrc_map);
+      }
+    }
+  }
+
+  if (stream->rtxsend)
+    g_object_set (stream->rtxsend, "ssrc-map", merged_local_rtx_ssrc_map, NULL);
+  gst_clear_structure (&merged_local_rtx_ssrc_map);
+
+  if (stream->reddec) {
+    g_object_set_property (G_OBJECT (stream->reddec), "payloads",
+        &red_pt_array);
+  }
+
+  g_value_unset (&red_pt_array);
+}
+
 static GstPad *
 _connect_input_stream (GstWebRTCBin * webrtc, GstWebRTCBinPad * pad)
 {
 /*
  * Not-bundle case:
  *
- * ,-------------------------webrtcbin-------------------------,
- * ;                                                           ;
- * ;          ,-------rtpbin-------,   ,--transport_send_%u--, ;
- * ;          ;    send_rtp_src_%u o---o rtp_sink            ; ;
- * ;          ;                    ;   ;                     ; ;
- * ;          ;   send_rtcp_src_%u o---o rtcp_sink           ; ;
- * ; sink_%u  ;                    ;   '---------------------' ;
- * o----------o send_rtp_sink_%u   ;                           ;
- * ;          '--------------------'                           ;
- * '--------------------- -------------------------------------'
+ * ,--------------------------------------------webrtcbin--------------------------------------------,
+ * ;                                                                                                 ;
+ * ;                                                ,-------rtpbin-------,   ,--transport_send_%u--, ;
+ * ;                                                ;    send_rtp_src_%u o---o rtp_sink            ; ;
+ * ;         ,---clocksync---,                      ;                    ;   ;                     ; ;
+ * ;         ;               ;                      ;   send_rtcp_src_%u o---o rtcp_sink           ; ;
+ * ; sink_%u ;               ; ,---fec encoder---,  ;                    ;   '---------------------' ;
+ * o---------o sink      src o-o sink        src o--o send_rtp_sink_%u   ;                           ;
+ * ;         '---------------' ,-----------------,  '--------------------'                           ;
+ * '-------------------------------------------------------------------------------------------------'
  */
 
 /*
  * Bundle case:
- * ,--------------------------------webrtcbin--------------------------------,
- * ;                                                                         ;
- * ;                        ,-------rtpbin-------,   ,--transport_send_%u--, ;
- * ;                        ;    send_rtp_src_%u o---o rtp_sink            ; ;
- * ;                        ;                    ;   ;                     ; ;
- * ;                        ;   send_rtcp_src_%u o---o rtcp_sink           ; ;
- * ; sink_%u ,---funnel---, ;                    ;   '---------------------' ;
- * o---------o sink_%u    ; ;                    ;                           ;
- * ; sink_%u ;        src o-o send_rtp_sink_%u   ;                           ;
- * o---------o sink_%u    ; ;                    ;                           ;
- * ;         '------------' '--------------------'                           ;
- * '-------------------------------------------------------------------------'
+ * ,-----------------------------------------------------webrtcbin---------------------------------------------------,
+ * ;                                                                                                                 ;
+ * ;                                                                ,-------rtpbin-------,   ,--transport_send_%u--, ;
+ * ;                                                                ;    send_rtp_src_%u o---o rtp_sink            ; ;
+ * ;                                                                ;                    ;   ;                     ; ;
+ * ; sink_%u  ,---clocksync---, ,---fec encoder---,  ,---funnel---, ;   send_rtcp_src_%u o---o rtcp_sink           ; ;
+ * o----------o sink      src o-o sink        src o--o sink_%u    ; ;                    ;   '---------------------' ;
+ * ;          '---------------' ,-----------------,  ;            ; ;                    ;                           ;
+ * ;                                                 ;        src o-o send_rtp_sink_%u   ;                           ;
+ * ; sink_%u  ,---clocksync---, ,---fec encoder---,  ;            ; ;                    ;                           ;
+ * o----------o sink      src o-o sink        src o--o sink%u     ; '--------------------'                           ;
+ * ;          '---------------' ,-----------------,  '------------'                                                  ;
+ * '-----------------------------------------------------------------------------------------------------------------'
  */
   GstPadTemplate *rtp_templ;
-  GstPad *rtp_sink;
+  GstPad *rtp_sink, *sinkpad, *srcpad;
   gchar *pad_name;
   WebRTCTransceiver *trans;
+  GstElement *clocksync;
+  GstElement *fec_encoder;
 
   g_return_val_if_fail (pad->trans != NULL, NULL);
 
-  GST_INFO_OBJECT (pad, "linking input stream %u", pad->mlineindex);
-
   trans = WEBRTC_TRANSCEIVER (pad->trans);
 
+  GST_INFO_OBJECT (pad, "linking input stream %u", pad->trans->mline);
+
   g_assert (trans->stream);
 
+  clocksync = gst_element_factory_make ("clocksync", NULL);
+  g_object_set (clocksync, "sync", TRUE, NULL);
+  gst_bin_add (GST_BIN (webrtc), clocksync);
+  gst_element_sync_state_with_parent (clocksync);
+
+  srcpad = gst_element_get_static_pad (clocksync, "src");
+
+  fec_encoder = _build_fec_encoder (webrtc, trans);
+  if (!fec_encoder) {
+    g_warn_if_reached ();
+    return NULL;
+  }
+
+  _set_internal_rtpbin_element_props_from_stream (webrtc, trans->stream);
+
+  gst_bin_add (GST_BIN (webrtc), fec_encoder);
+  gst_element_sync_state_with_parent (fec_encoder);
+
+  sinkpad = gst_element_get_static_pad (fec_encoder, "sink");
+  if (gst_pad_link (srcpad, sinkpad) != GST_PAD_LINK_OK)
+    g_warn_if_reached ();
+  gst_clear_object (&srcpad);
+  gst_clear_object (&sinkpad);
+  sinkpad = gst_element_get_static_pad (clocksync, "sink");
+  srcpad = gst_element_get_static_pad (fec_encoder, "src");
+
   if (!webrtc->rtpfunnel) {
     rtp_templ =
         _find_pad_template (webrtc->rtpbin, GST_PAD_SINK, GST_PAD_REQUEST,
         "send_rtp_sink_%u");
     g_assert (rtp_templ);
 
-    pad_name = g_strdup_printf ("send_rtp_sink_%u", pad->mlineindex);
+    pad_name = g_strdup_printf ("send_rtp_sink_%u", pad->trans->mline);
     rtp_sink =
         gst_element_request_pad (webrtc->rtpbin, rtp_templ, pad_name, NULL);
     g_free (pad_name);
-    gst_ghost_pad_set_target (GST_GHOST_PAD (pad), rtp_sink);
+    gst_pad_link (srcpad, rtp_sink);
     gst_object_unref (rtp_sink);
 
-    pad_name = g_strdup_printf ("send_rtp_src_%u", pad->mlineindex);
+    pad_name = g_strdup_printf ("send_rtp_src_%u", pad->trans->mline);
     if (!gst_element_link_pads (GST_ELEMENT (webrtc->rtpbin), pad_name,
             GST_ELEMENT (trans->stream->send_bin), "rtp_sink"))
       g_warn_if_reached ();
     g_free (pad_name);
   } else {
-    gchar *pad_name = g_strdup_printf ("sink_%u", pad->mlineindex);
+    gchar *pad_name = g_strdup_printf ("sink_%u", pad->trans->mline);
     GstPad *funnel_sinkpad =
-        gst_element_get_request_pad (webrtc->rtpfunnel, pad_name);
+        gst_element_request_pad_simple (webrtc->rtpfunnel, pad_name);
 
-    gst_ghost_pad_set_target (GST_GHOST_PAD (pad), funnel_sinkpad);
+    gst_pad_link (srcpad, funnel_sinkpad);
 
     g_free (pad_name);
     gst_object_unref (funnel_sinkpad);
   }
 
+  gst_ghost_pad_set_target (GST_GHOST_PAD (pad), sinkpad);
+
+  gst_clear_object (&srcpad);
+  gst_clear_object (&sinkpad);
+
   gst_element_sync_state_with_parent (GST_ELEMENT (trans->stream->send_bin));
 
   return GST_PAD (pad);
@@ -3631,7 +5355,7 @@ _add_ice_candidates_from_sdp (GstWebRTCBin * webrtc, gint mlineindex,
       if (stream == NULL)
         stream = _find_ice_stream_for_session (webrtc, mlineindex);
       if (stream == NULL) {
-        GST_WARNING_OBJECT (webrtc,
+        GST_DEBUG_OBJECT (webrtc,
             "Unknown mline %u, dropping ICE candidates from SDP", mlineindex);
         return;
       }
@@ -3681,37 +5405,106 @@ _filter_sdp_fields (GQuark field_id, const GValue * value,
   return TRUE;
 }
 
-static void
-_set_rtx_ptmap_from_stream (GstWebRTCBin * webrtc, TransportStream * stream)
+static guint
+transport_stream_ptmap_get_rtp_header_extension_id (TransportStream * stream,
+    const char *rtphdrext_uri)
 {
-  gint *rtx_pt;
-  gsize rtx_count;
+  guint i;
 
-  rtx_pt = transport_stream_get_all_pt (stream, "RTX", &rtx_count);
-  GST_LOG_OBJECT (stream, "have %" G_GSIZE_FORMAT " rtx payloads", rtx_count);
-  if (rtx_pt) {
-    GstStructure *pt_map = gst_structure_new_empty ("application/x-rtp-pt-map");
-    gsize i;
+  for (i = 0; i < stream->ptmap->len; i++) {
+    PtMapItem *item = &g_array_index (stream->ptmap, PtMapItem, i);
+    guint id;
+
+    id = caps_get_rtp_header_extension_id (item->caps, rtphdrext_uri);
+    if (id != -1)
+      return id;
+  }
+
+  return -1;
+}
 
-    for (i = 0; i < rtx_count; i++) {
-      GstCaps *rtx_caps = transport_stream_get_caps_for_pt (stream, rtx_pt[i]);
-      const GstStructure *s = gst_caps_get_structure (rtx_caps, 0);
-      const gchar *apt = gst_structure_get_string (s, "apt");
+static void
+ensure_rtx_hdr_ext (TransportStream * stream)
+{
+  stream->rtphdrext_id_stream_id =
+      transport_stream_ptmap_get_rtp_header_extension_id (stream,
+      RTPHDREXT_STREAM_ID);
+  stream->rtphdrext_id_repaired_stream_id =
+      transport_stream_ptmap_get_rtp_header_extension_id (stream,
+      RTPHDREXT_REPAIRED_STREAM_ID);
+
+  /* TODO: removing header extensions usage from rtx on renegotiation */
+
+  if (stream->rtxsend) {
+    if (stream->rtphdrext_id_stream_id != -1 && !stream->rtxsend_stream_id) {
+      stream->rtxsend_stream_id =
+          gst_rtp_header_extension_create_from_uri (RTPHDREXT_STREAM_ID);
+      if (!stream->rtxsend_stream_id)
+        g_warn_if_reached ();
+      gst_rtp_header_extension_set_id (stream->rtxsend_stream_id,
+          stream->rtphdrext_id_stream_id);
+
+      GST_DEBUG_OBJECT (stream, "adding rtp header extension %" GST_PTR_FORMAT
+          " with id %u to %" GST_PTR_FORMAT, stream->rtxsend_stream_id,
+          stream->rtphdrext_id_stream_id, stream->rtxsend);
+
+      g_signal_emit_by_name (stream->rtxsend, "add-extension",
+          stream->rtxsend_stream_id);
+    }
 
-      GST_LOG_OBJECT (stream, "setting rtx mapping: %s -> %u", apt, rtx_pt[i]);
-      gst_structure_set (pt_map, apt, G_TYPE_UINT, rtx_pt[i], NULL);
+    if (stream->rtphdrext_id_repaired_stream_id != -1
+        && !stream->rtxsend_repaired_stream_id) {
+      stream->rtxsend_repaired_stream_id =
+          gst_rtp_header_extension_create_from_uri
+          (RTPHDREXT_REPAIRED_STREAM_ID);
+      if (!stream->rtxsend_repaired_stream_id)
+        g_warn_if_reached ();
+      gst_rtp_header_extension_set_id (stream->rtxsend_repaired_stream_id,
+          stream->rtphdrext_id_repaired_stream_id);
+
+      GST_DEBUG_OBJECT (stream, "adding rtp header extension %" GST_PTR_FORMAT
+          " with id %u to %" GST_PTR_FORMAT, stream->rtxsend_repaired_stream_id,
+          stream->rtphdrext_id_repaired_stream_id, stream->rtxsend);
+
+      g_signal_emit_by_name (stream->rtxsend, "add-extension",
+          stream->rtxsend_repaired_stream_id);
     }
+  }
 
-    GST_DEBUG_OBJECT (stream, "setting payload map on %" GST_PTR_FORMAT " : %"
-        GST_PTR_FORMAT " and %" GST_PTR_FORMAT, stream->rtxreceive,
-        stream->rtxsend, pt_map);
+  if (stream->rtxreceive) {
+    if (stream->rtphdrext_id_stream_id != -1 && !stream->rtxreceive_stream_id) {
+      stream->rtxreceive_stream_id =
+          gst_rtp_header_extension_create_from_uri (RTPHDREXT_STREAM_ID);
+      if (!stream->rtxreceive_stream_id)
+        g_warn_if_reached ();
+      gst_rtp_header_extension_set_id (stream->rtxreceive_stream_id,
+          stream->rtphdrext_id_stream_id);
 
-    if (stream->rtxreceive)
-      g_object_set (stream->rtxreceive, "payload-type-map", pt_map, NULL);
-    if (stream->rtxsend)
-      g_object_set (stream->rtxsend, "payload-type-map", pt_map, NULL);
+      GST_DEBUG_OBJECT (stream, "adding rtp header extension %" GST_PTR_FORMAT
+          " with id %u to %" GST_PTR_FORMAT, stream->rtxsend_stream_id,
+          stream->rtphdrext_id_stream_id, stream->rtxreceive);
+
+      g_signal_emit_by_name (stream->rtxreceive, "add-extension",
+          stream->rtxreceive_stream_id);
+    }
 
-    gst_structure_free (pt_map);
+    if (stream->rtphdrext_id_repaired_stream_id != -1
+        && !stream->rtxreceive_repaired_stream_id) {
+      stream->rtxreceive_repaired_stream_id =
+          gst_rtp_header_extension_create_from_uri
+          (RTPHDREXT_REPAIRED_STREAM_ID);
+      if (!stream->rtxreceive_repaired_stream_id)
+        g_warn_if_reached ();
+      gst_rtp_header_extension_set_id (stream->rtxreceive_repaired_stream_id,
+          stream->rtphdrext_id_repaired_stream_id);
+
+      GST_DEBUG_OBJECT (stream, "adding rtp header extension %" GST_PTR_FORMAT
+          " with id %u to %" GST_PTR_FORMAT, stream->rtxsend_repaired_stream_id,
+          stream->rtphdrext_id_repaired_stream_id, stream->rtxreceive);
+
+      g_signal_emit_by_name (stream->rtxreceive, "add-extension",
+          stream->rtxreceive_repaired_stream_id);
+    }
   }
 }
 
@@ -3775,6 +5568,7 @@ _update_transport_ptmap_from_media (GstWebRTCBin * webrtc,
       }
 
       item.pt = pt;
+      item.media_idx = media_idx;
       gst_caps_unref (outcaps);
 
       g_array_append_val (stream->ptmap, item);
@@ -3788,19 +5582,42 @@ static void
 _update_transceiver_from_sdp_media (GstWebRTCBin * webrtc,
     const GstSDPMessage * sdp, guint media_idx,
     TransportStream * stream, GstWebRTCRTPTransceiver * rtp_trans,
-    GStrv bundled, guint bundle_idx)
+    GStrv bundled, guint bundle_idx, GError ** error)
 {
   WebRTCTransceiver *trans = WEBRTC_TRANSCEIVER (rtp_trans);
   GstWebRTCRTPTransceiverDirection prev_dir = rtp_trans->current_direction;
   GstWebRTCRTPTransceiverDirection new_dir;
+  const GstSDPMedia *local_media, *remote_media;
   const GstSDPMedia *media = gst_sdp_message_get_media (sdp, media_idx);
   GstWebRTCDTLSSetup new_setup;
-  gboolean new_rtcp_mux, new_rtcp_rsize;
+  char *local_msid = NULL;
+  gboolean new_rtcp_rsize;
   ReceiveState receive_state = RECEIVE_STATE_UNSET;
   int i;
 
+  local_media =
+      gst_sdp_message_get_media (webrtc->current_local_description->sdp,
+      media_idx);
+  remote_media =
+      gst_sdp_message_get_media (webrtc->current_remote_description->sdp,
+      media_idx);
+
   rtp_trans->mline = media_idx;
 
+  if (!g_strcmp0 (gst_sdp_media_get_media (media), "audio")) {
+    if (rtp_trans->kind == GST_WEBRTC_KIND_VIDEO)
+      GST_FIXME_OBJECT (webrtc, "Updating video transceiver %" GST_PTR_FORMAT
+          " to audio, which isn't fully supported.", rtp_trans);
+    rtp_trans->kind = GST_WEBRTC_KIND_AUDIO;
+  }
+
+  if (!g_strcmp0 (gst_sdp_media_get_media (media), "video")) {
+    if (rtp_trans->kind == GST_WEBRTC_KIND_AUDIO)
+      GST_FIXME_OBJECT (webrtc, "Updating audio transceiver %" GST_PTR_FORMAT
+          " to video, which isn't fully supported.", rtp_trans);
+    rtp_trans->kind = GST_WEBRTC_KIND_VIDEO;
+  }
+
   for (i = 0; i < gst_sdp_media_attributes_len (media); i++) {
     const GstSDPAttribute *attr = gst_sdp_media_get_attribute (media, i);
 
@@ -3811,40 +5628,38 @@ _update_transceiver_from_sdp_media (GstWebRTCBin * webrtc,
   }
 
   {
-    const GstSDPMedia *local_media, *remote_media;
     GstWebRTCRTPTransceiverDirection local_dir, remote_dir;
     GstWebRTCDTLSSetup local_setup, remote_setup;
 
-    local_media =
-        gst_sdp_message_get_media (webrtc->current_local_description->sdp,
-        media_idx);
-    remote_media =
-        gst_sdp_message_get_media (webrtc->current_remote_description->sdp,
-        media_idx);
-
     local_setup = _get_dtls_setup_from_media (local_media);
     remote_setup = _get_dtls_setup_from_media (remote_media);
     new_setup = _get_final_setup (local_setup, remote_setup);
-    if (new_setup == GST_WEBRTC_DTLS_SETUP_NONE)
+    if (new_setup == GST_WEBRTC_DTLS_SETUP_NONE) {
+      g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
+          "Cannot intersect direction attributes for media %u", media_idx);
       return;
+    }
 
     local_dir = _get_direction_from_media (local_media);
     remote_dir = _get_direction_from_media (remote_media);
     new_dir = _get_final_direction (local_dir, remote_dir);
-
-    if (new_dir == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_NONE)
+    if (new_dir == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_NONE) {
+      g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
+          "Cannot intersect dtls setup attributes for media %u", media_idx);
       return;
+    }
 
     if (prev_dir != GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_NONE
         && new_dir != GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_INACTIVE
         && prev_dir != new_dir) {
-      GST_FIXME_OBJECT (webrtc, "implement transceiver direction changes");
+      g_set_error (error, GST_WEBRTC_ERROR,
+          GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+          "transceiver direction changes are not implemented. Media %u",
+          media_idx);
       return;
     }
 
     if (!bundled || bundle_idx == media_idx) {
-      new_rtcp_mux = _media_has_attribute_key (local_media, "rtcp-mux")
-          && _media_has_attribute_key (remote_media, "rtcp-mux");
       new_rtcp_rsize = _media_has_attribute_key (local_media, "rtcp-rsize")
           && _media_has_attribute_key (remote_media, "rtcp-rsize");
 
@@ -3857,8 +5672,6 @@ _update_transceiver_from_sdp_media (GstWebRTCBin * webrtc,
           g_object_unref (session);
         }
       }
-
-      g_object_set (stream, "rtcp-mux", new_rtcp_mux, NULL);
     }
   }
 
@@ -3879,22 +5692,12 @@ _update_transceiver_from_sdp_media (GstWebRTCBin * webrtc,
   }
 
   if (new_dir != prev_dir) {
-    gchar *prev_dir_s, *new_dir_s;
-
-    prev_dir_s =
-        _enum_value_to_string (GST_TYPE_WEBRTC_RTP_TRANSCEIVER_DIRECTION,
-        prev_dir);
-    new_dir_s =
-        _enum_value_to_string (GST_TYPE_WEBRTC_RTP_TRANSCEIVER_DIRECTION,
-        new_dir);
+    guint rtp_session_id = bundled ? bundle_idx : media_idx;
 
     GST_DEBUG_OBJECT (webrtc, "transceiver %" GST_PTR_FORMAT
-        " direction change from %s to %s", rtp_trans, prev_dir_s, new_dir_s);
-
-    g_free (prev_dir_s);
-    prev_dir_s = NULL;
-    g_free (new_dir_s);
-    new_dir_s = NULL;
+        " direction change from %s to %s", rtp_trans,
+        gst_webrtc_rtp_transceiver_direction_to_string (prev_dir),
+        gst_webrtc_rtp_transceiver_direction_to_string (new_dir));
 
     if (new_dir == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_INACTIVE) {
       GstWebRTCBinPad *pad;
@@ -3919,18 +5722,31 @@ _update_transceiver_from_sdp_media (GstWebRTCBin * webrtc,
     if (new_dir == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDONLY ||
         new_dir == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDRECV) {
       GstWebRTCBinPad *pad =
-          _find_pad_for_mline (webrtc, GST_PAD_SINK, media_idx);
+          _find_pad_for_transceiver (webrtc, GST_PAD_SINK, rtp_trans);
+      local_msid = _get_msid_from_media (local_media);
+
       if (pad) {
         GST_DEBUG_OBJECT (webrtc, "found existing send pad %" GST_PTR_FORMAT
-            " for transceiver %" GST_PTR_FORMAT, pad, trans);
-        g_assert (pad->trans == rtp_trans);
-        g_assert (pad->mlineindex == media_idx);
+            " for transceiver %" GST_PTR_FORMAT " with msid \'%s\'", pad, trans,
+            pad->msid);
+        if (g_strcmp0 (pad->msid, local_msid) != 0) {
+          GST_DEBUG_OBJECT (webrtc, "send pad %" GST_PTR_FORMAT
+              " transceiver %" GST_PTR_FORMAT " changing msid from \'%s\'"
+              " to \'%s\'", pad, trans, pad->msid, local_msid);
+          g_clear_pointer (&pad->msid, g_free);
+          pad->msid = local_msid;
+          g_object_notify (G_OBJECT (pad), "msid");
+          local_msid = NULL;
+        } else {
+          g_clear_pointer (&local_msid, g_free);
+        }
         gst_object_unref (pad);
       } else {
         GST_DEBUG_OBJECT (webrtc,
             "creating new send pad for transceiver %" GST_PTR_FORMAT, trans);
-        pad = _create_pad_for_sdp_media (webrtc, GST_PAD_SINK, media_idx);
-        pad->trans = gst_object_ref (rtp_trans);
+        pad = _create_pad_for_sdp_media (webrtc, GST_PAD_SINK, rtp_trans,
+            G_MAXUINT, local_msid);
+        local_msid = NULL;
         _connect_input_stream (webrtc, pad);
         _add_pad (webrtc, pad);
       }
@@ -3938,36 +5754,46 @@ _update_transceiver_from_sdp_media (GstWebRTCBin * webrtc,
     if (new_dir == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_RECVONLY ||
         new_dir == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDRECV) {
       GstWebRTCBinPad *pad =
-          _find_pad_for_mline (webrtc, GST_PAD_SRC, media_idx);
+          _find_pad_for_transceiver (webrtc, GST_PAD_SRC, rtp_trans);
+      char *remote_msid = _get_msid_from_media (remote_media);
+
       if (pad) {
         GST_DEBUG_OBJECT (webrtc, "found existing receive pad %" GST_PTR_FORMAT
-            " for transceiver %" GST_PTR_FORMAT, pad, trans);
-        g_assert (pad->trans == rtp_trans);
-        g_assert (pad->mlineindex == media_idx);
+            " for transceiver %" GST_PTR_FORMAT " with msid \'%s\'", pad, trans,
+            pad->msid);
+        if (g_strcmp0 (pad->msid, remote_msid) != 0) {
+          GST_DEBUG_OBJECT (webrtc, "receive pad %" GST_PTR_FORMAT
+              " transceiver %" GST_PTR_FORMAT " changing msid from \'%s\'"
+              " to \'%s\'", pad, trans, pad->msid, remote_msid);
+          g_clear_pointer (&pad->msid, g_free);
+          pad->msid = remote_msid;
+          remote_msid = NULL;
+          g_object_notify (G_OBJECT (pad), "msid");
+        } else {
+          g_clear_pointer (&remote_msid, g_free);
+        }
         gst_object_unref (pad);
       } else {
         GST_DEBUG_OBJECT (webrtc,
             "creating new receive pad for transceiver %" GST_PTR_FORMAT, trans);
-        pad = _create_pad_for_sdp_media (webrtc, GST_PAD_SRC, media_idx);
-        pad->trans = gst_object_ref (rtp_trans);
+        pad = _create_pad_for_sdp_media (webrtc, GST_PAD_SRC, rtp_trans,
+            G_MAXUINT, remote_msid);
+        remote_msid = NULL;
 
         if (!trans->stream) {
           TransportStream *item;
 
           item =
-              _get_or_create_transport_stream (webrtc,
-              bundled ? bundle_idx : media_idx, FALSE);
+              _get_or_create_transport_stream (webrtc, rtp_session_id, FALSE);
           webrtc_transceiver_set_transport (trans, item);
         }
 
-        _connect_output_stream (webrtc, trans->stream,
-            bundled ? bundle_idx : media_idx);
+        _connect_output_stream (webrtc, trans->stream, rtp_session_id);
         /* delay adding the pad until rtpbin creates the recv output pad
          * to ghost to so queries/events travel through the pipeline correctly
          * as soon as the pad is added */
         _add_pad_to_list (webrtc, pad);
       }
-
     }
 
     rtp_trans->mline = media_idx;
@@ -3976,7 +5802,7 @@ _update_transceiver_from_sdp_media (GstWebRTCBin * webrtc,
 
   if (!bundled || bundle_idx == media_idx) {
     if (stream->rtxsend || stream->rtxreceive) {
-      _set_rtx_ptmap_from_stream (webrtc, stream);
+      _set_internal_rtpbin_element_props_from_stream (webrtc, stream);
     }
 
     g_object_set (stream, "dtls-client",
@@ -4023,7 +5849,7 @@ _generate_data_channel_id (GstWebRTCBin * webrtc)
     }
 
     /* client must generate even ids, server must generate odd ids */
-    if (new_id % 2 == ! !is_client)
+    if (new_id % 2 == !(!is_client))
       continue;
 
     channel = _find_data_channel_for_id (webrtc, new_id);
@@ -4036,7 +5862,8 @@ _generate_data_channel_id (GstWebRTCBin * webrtc)
 
 static void
 _update_data_channel_from_sdp_media (GstWebRTCBin * webrtc,
-    const GstSDPMessage * sdp, guint media_idx, TransportStream * stream)
+    const GstSDPMessage * sdp, guint media_idx, TransportStream * stream,
+    GError ** error)
 {
   const GstSDPMedia *local_media, *remote_media;
   GstWebRTCDTLSSetup local_setup, remote_setup, new_setup;
@@ -4055,18 +5882,25 @@ _update_data_channel_from_sdp_media (GstWebRTCBin * webrtc,
   local_setup = _get_dtls_setup_from_media (local_media);
   remote_setup = _get_dtls_setup_from_media (remote_media);
   new_setup = _get_final_setup (local_setup, remote_setup);
-  if (new_setup == GST_WEBRTC_DTLS_SETUP_NONE)
+  if (new_setup == GST_WEBRTC_DTLS_SETUP_NONE) {
+    g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
+        "Cannot intersect dtls setup for media %u", media_idx);
     return;
+  }
 
   /* data channel is always rtcp-muxed to avoid generating ICE candidates
    * for RTCP */
-  g_object_set (stream, "rtcp-mux", TRUE, "dtls-client",
+  g_object_set (stream, "dtls-client",
       new_setup == GST_WEBRTC_DTLS_SETUP_ACTIVE, NULL);
 
   local_port = _get_sctp_port_from_media (local_media);
   remote_port = _get_sctp_port_from_media (local_media);
-  if (local_port == -1 || remote_port == -1)
+  if (local_port == -1 || remote_port == -1) {
+    g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
+        "Could not find sctp port for media %u (local %i, remote %i)",
+        media_idx, local_port, remote_port);
     return;
+  }
 
   if (0 == (local_max_size =
           _get_sctp_max_message_size_from_media (local_media)))
@@ -4096,6 +5930,7 @@ _update_data_channel_from_sdp_media (GstWebRTCBin * webrtc,
           remote_port, NULL);
   }
 
+  DC_LOCK (webrtc);
   for (i = 0; i < webrtc->priv->data_channels->len; i++) {
     WebRTCDataChannel *channel;
 
@@ -4113,6 +5948,7 @@ _update_data_channel_from_sdp_media (GstWebRTCBin * webrtc,
       webrtc_data_channel_start_negotiation (channel);
     }
   }
+  DC_UNLOCK (webrtc);
 
   stream->active = TRUE;
 
@@ -4124,12 +5960,16 @@ static gboolean
 _find_compatible_unassociated_transceiver (GstWebRTCRTPTransceiver * p1,
     gconstpointer data)
 {
+  GstWebRTCKind kind = GPOINTER_TO_INT (data);
+
   if (p1->mid)
     return FALSE;
   if (p1->mline != -1)
     return FALSE;
   if (p1->stopped)
     return FALSE;
+  if (p1->kind != GST_WEBRTC_KIND_UNKNOWN && p1->kind != kind)
+    return FALSE;
 
   return TRUE;
 }
@@ -4138,10 +5978,9 @@ static void
 _connect_rtpfunnel (GstWebRTCBin * webrtc, guint session_id)
 {
   gchar *pad_name;
-  GstPad *queue_srcpad;
+  GstPad *srcpad;
   GstPad *rtp_sink;
   TransportStream *stream = _find_transport_for_session (webrtc, session_id);
-  GstElement *queue;
 
   g_assert (stream);
 
@@ -4152,19 +5991,14 @@ _connect_rtpfunnel (GstWebRTCBin * webrtc, guint session_id)
   gst_bin_add (GST_BIN (webrtc), webrtc->rtpfunnel);
   gst_element_sync_state_with_parent (webrtc->rtpfunnel);
 
-  queue = gst_element_factory_make ("queue", NULL);
-  gst_bin_add (GST_BIN (webrtc), queue);
-  gst_element_sync_state_with_parent (queue);
-
-  gst_element_link (webrtc->rtpfunnel, queue);
-
-  queue_srcpad = gst_element_get_static_pad (queue, "src");
+  srcpad = gst_element_get_static_pad (webrtc->rtpfunnel, "src");
 
   pad_name = g_strdup_printf ("send_rtp_sink_%d", session_id);
-  rtp_sink = gst_element_get_request_pad (webrtc->rtpbin, pad_name);
+  rtp_sink = gst_element_request_pad_simple (webrtc->rtpbin, pad_name);
   g_free (pad_name);
-  gst_pad_link (queue_srcpad, rtp_sink);
-  gst_object_unref (queue_srcpad);
+
+  gst_pad_link (srcpad, rtp_sink);
+  gst_object_unref (srcpad);
   gst_object_unref (rtp_sink);
 
   pad_name = g_strdup_printf ("send_rtp_src_%d", session_id);
@@ -4179,7 +6013,7 @@ done:
 
 static gboolean
 _update_transceivers_from_sdp (GstWebRTCBin * webrtc, SDPSource source,
-    GstWebRTCSessionDescription * sdp)
+    GstWebRTCSessionDescription * sdp, GError ** error)
 {
   int i;
   gboolean ret = FALSE;
@@ -4190,14 +6024,14 @@ _update_transceivers_from_sdp (GstWebRTCBin * webrtc, SDPSource source,
   /* FIXME: With some peers, it's possible we could have
    * multiple bundles to deal with, although I've never seen one yet */
   if (webrtc->bundle_policy != GST_WEBRTC_BUNDLE_POLICY_NONE)
-    if (!_parse_bundle (sdp->sdp, &bundled))
+    if (!_parse_bundle (sdp->sdp, &bundled, error))
       goto done;
 
   if (bundled) {
 
     if (!_get_bundle_index (sdp->sdp, bundled, &bundle_idx)) {
-      GST_ERROR_OBJECT (webrtc, "Bundle tag is %s but no media found matching",
-          bundled[0]);
+      g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
+          "Bundle tag is %s but no media found matching", bundled[0]);
       goto done;
     }
 
@@ -4214,6 +6048,7 @@ _update_transceivers_from_sdp (GstWebRTCBin * webrtc, SDPSource source,
        * parameters aren't set up properly for the bundled streams */
       _update_transport_ptmap_from_media (webrtc, bundle_stream, sdp->sdp, i);
     }
+    ensure_rtx_hdr_ext (bundle_stream);
 
     _connect_rtpfunnel (webrtc, bundle_idx);
   }
@@ -4242,20 +6077,32 @@ _update_transceivers_from_sdp (GstWebRTCBin * webrtc, SDPSource source,
        * bundling we need to do it now */
       g_array_set_size (stream->ptmap, 0);
       _update_transport_ptmap_from_media (webrtc, stream, sdp->sdp, i);
+      ensure_rtx_hdr_ext (stream);
     }
 
     if (trans)
       webrtc_transceiver_set_transport ((WebRTCTransceiver *) trans, stream);
 
     if (source == SDP_LOCAL && sdp->type == GST_WEBRTC_SDP_TYPE_OFFER && !trans) {
-      GST_ERROR ("State mismatch.  Could not find local transceiver by mline.");
+      g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
+          "State mismatch.  Could not find local transceiver by mline %u", i);
       goto done;
     } else {
       if (g_strcmp0 (gst_sdp_media_get_media (media), "audio") == 0 ||
           g_strcmp0 (gst_sdp_media_get_media (media), "video") == 0) {
+        GstWebRTCKind kind = GST_WEBRTC_KIND_UNKNOWN;
+
         /* No existing transceiver, find an unused one */
         if (!trans) {
-          trans = _find_transceiver (webrtc, NULL,
+          if (g_strcmp0 (gst_sdp_media_get_media (media), "audio") == 0)
+            kind = GST_WEBRTC_KIND_AUDIO;
+          else if (g_strcmp0 (gst_sdp_media_get_media (media), "video") == 0)
+            kind = GST_WEBRTC_KIND_VIDEO;
+          else
+            GST_LOG_OBJECT (webrtc, "Unknown media kind %s",
+                GST_STR_NULL (gst_sdp_media_get_media (media)));
+
+          trans = _find_transceiver (webrtc, GINT_TO_POINTER (kind),
               (FindTransceiverFunc) _find_compatible_unassociated_transceiver);
         }
 
@@ -4265,15 +6112,21 @@ _update_transceivers_from_sdp (GstWebRTCBin * webrtc, SDPSource source,
          * that calls to setDirection will change the value.  Nothing about
          * a default value when the transceiver is created internally */
         if (!trans) {
-          trans =
-              GST_WEBRTC_RTP_TRANSCEIVER (_create_webrtc_transceiver (webrtc,
-                  _get_direction_from_media (media), i));
+          WebRTCTransceiver *t = _create_webrtc_transceiver (webrtc,
+              _get_direction_from_media (media), i, kind, NULL);
+          webrtc_transceiver_set_transport (t, stream);
+          trans = GST_WEBRTC_RTP_TRANSCEIVER (t);
         }
 
         _update_transceiver_from_sdp_media (webrtc, sdp->sdp, i, stream,
-            trans, bundled, bundle_idx);
+            trans, bundled, bundle_idx, error);
+        if (error && *error)
+          goto done;
       } else if (_message_media_is_datachannel (sdp->sdp, i)) {
-        _update_data_channel_from_sdp_media (webrtc, sdp->sdp, i, stream);
+        _update_data_channel_from_sdp_media (webrtc, sdp->sdp, i, stream,
+            error);
+        if (error && *error)
+          goto done;
       } else {
         GST_ERROR_OBJECT (webrtc, "Unknown media type in SDP at index %u", i);
       }
@@ -4297,15 +6150,138 @@ done:
   return ret;
 }
 
+static gint
+transceivers_media_num_cmp (GstWebRTCBin * webrtc,
+    GstWebRTCSessionDescription * previous, GstWebRTCSessionDescription * new)
+{
+  if (!previous)
+    return 0;
+
+  return gst_sdp_message_medias_len (new->sdp) -
+      gst_sdp_message_medias_len (previous->sdp);
+
+}
+
+static gboolean
+check_locked_mlines (GstWebRTCBin * webrtc, GstWebRTCSessionDescription * sdp,
+    GError ** error)
+{
+  guint i;
+
+  for (i = 0; i < gst_sdp_message_medias_len (sdp->sdp); i++) {
+    const GstSDPMedia *media = gst_sdp_message_get_media (sdp->sdp, i);
+    GstWebRTCRTPTransceiver *rtp_trans;
+    WebRTCTransceiver *trans;
+
+    rtp_trans = _find_transceiver_for_sdp_media (webrtc, sdp->sdp, i);
+    /* only look for matching mid */
+    if (rtp_trans == NULL)
+      continue;
+
+    trans = WEBRTC_TRANSCEIVER (rtp_trans);
+
+    /* We only validate the locked mlines for now */
+    if (!trans->mline_locked)
+      continue;
+
+    if (rtp_trans->mline != i) {
+      g_set_error (error, GST_WEBRTC_ERROR,
+          GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+          "m-line with mid %s is at position %d, but was locked to %d, "
+          "rejecting", rtp_trans->mid, i, rtp_trans->mline);
+      return FALSE;
+    }
+
+    if (rtp_trans->kind != GST_WEBRTC_KIND_UNKNOWN) {
+      if (!g_strcmp0 (gst_sdp_media_get_media (media), "audio") &&
+          rtp_trans->kind != GST_WEBRTC_KIND_AUDIO) {
+        g_set_error (error, GST_WEBRTC_ERROR,
+            GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+            "m-line %d with transceiver <%s> was locked to %s, but SDP has "
+            "%s media", i, GST_OBJECT_NAME (rtp_trans),
+            gst_webrtc_kind_to_string (rtp_trans->kind),
+            gst_sdp_media_get_media (media));
+        return FALSE;
+      }
+
+      if (!g_strcmp0 (gst_sdp_media_get_media (media), "video") &&
+          rtp_trans->kind != GST_WEBRTC_KIND_VIDEO) {
+        g_set_error (error, GST_WEBRTC_ERROR,
+            GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+            "m-line %d with transceiver <%s> was locked to %s, but SDP has "
+            "%s media", i, GST_OBJECT_NAME (rtp_trans),
+            gst_webrtc_kind_to_string (rtp_trans->kind),
+            gst_sdp_media_get_media (media));
+        return FALSE;
+      }
+    }
+  }
+
+  return TRUE;
+}
+
+
 struct set_description
 {
-  GstPromise *promise;
   SDPSource source;
   GstWebRTCSessionDescription *sdp;
 };
 
+static GstWebRTCSessionDescription *
+get_previous_description (GstWebRTCBin * webrtc, SDPSource source,
+    GstWebRTCSDPType type)
+{
+  switch (type) {
+    case GST_WEBRTC_SDP_TYPE_OFFER:
+    case GST_WEBRTC_SDP_TYPE_PRANSWER:
+    case GST_WEBRTC_SDP_TYPE_ANSWER:
+      if (source == SDP_LOCAL) {
+        return webrtc->current_local_description;
+      } else {
+        return webrtc->current_remote_description;
+      }
+    case GST_WEBRTC_SDP_TYPE_ROLLBACK:
+      return NULL;
+    default:
+      /* other values mean memory corruption/uninitialized! */
+      g_assert_not_reached ();
+      break;
+  }
+
+  return NULL;
+}
+
+static GstWebRTCSessionDescription *
+get_last_generated_description (GstWebRTCBin * webrtc, SDPSource source,
+    GstWebRTCSDPType type)
+{
+  switch (type) {
+    case GST_WEBRTC_SDP_TYPE_OFFER:
+      if (source == SDP_REMOTE)
+        return webrtc->priv->last_generated_answer;
+      else
+        return webrtc->priv->last_generated_offer;
+      break;
+    case GST_WEBRTC_SDP_TYPE_PRANSWER:
+    case GST_WEBRTC_SDP_TYPE_ANSWER:
+      if (source == SDP_LOCAL)
+        return webrtc->priv->last_generated_answer;
+      else
+        return webrtc->priv->last_generated_offer;
+    case GST_WEBRTC_SDP_TYPE_ROLLBACK:
+      return NULL;
+    default:
+      /* other values mean memory corruption/uninitialized! */
+      g_assert_not_reached ();
+      break;
+  }
+
+  return NULL;
+}
+
+
 /* http://w3c.github.io/webrtc-pc/#set-description */
-static void
+static GstStructure *
 _set_description_task (GstWebRTCBin * webrtc, struct set_description *sd)
 {
   GstWebRTCSignalingState new_signaling_state = webrtc->signaling_state;
@@ -4316,42 +6292,56 @@ _set_description_task (GstWebRTCBin * webrtc, struct set_description *sd)
   guint i;
 
   {
-    gchar *state = _enum_value_to_string (GST_TYPE_WEBRTC_SIGNALING_STATE,
+    const gchar *state = _enum_value_to_string (GST_TYPE_WEBRTC_SIGNALING_STATE,
         webrtc->signaling_state);
-    gchar *type_str =
+    const gchar *type_str =
         _enum_value_to_string (GST_TYPE_WEBRTC_SDP_TYPE, sd->sdp->type);
     gchar *sdp_text = gst_sdp_message_as_text (sd->sdp->sdp);
     GST_INFO_OBJECT (webrtc, "Attempting to set %s %s in the %s state",
         _sdp_source_to_string (sd->source), type_str, state);
     GST_TRACE_OBJECT (webrtc, "SDP contents\n%s", sdp_text);
     g_free (sdp_text);
-    g_free (state);
-    g_free (type_str);
-  }
-
-  if (!validate_sdp (webrtc->signaling_state, sd->source, sd->sdp, &error)) {
-    GST_ERROR_OBJECT (webrtc, "%s", error->message);
-    g_clear_error (&error);
-    goto out;
   }
 
-  if (webrtc->priv->is_closed) {
-    GST_WARNING_OBJECT (webrtc, "we are closed");
+  if (!validate_sdp (webrtc->signaling_state, sd->source, sd->sdp, &error))
     goto out;
-  }
 
   if (webrtc->bundle_policy != GST_WEBRTC_BUNDLE_POLICY_NONE)
-    if (!_parse_bundle (sd->sdp->sdp, &bundled))
+    if (!_parse_bundle (sd->sdp->sdp, &bundled, &error))
       goto out;
 
   if (bundled) {
     if (!_get_bundle_index (sd->sdp->sdp, bundled, &bundle_idx)) {
-      GST_ERROR_OBJECT (webrtc, "Bundle tag is %s but no media found matching",
-          bundled[0]);
+      g_set_error (&error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
+          "Bundle tag is %s but no matching media found", bundled[0]);
       goto out;
     }
   }
 
+  if (transceivers_media_num_cmp (webrtc,
+          get_previous_description (webrtc, sd->source, sd->sdp->type),
+          sd->sdp) < 0) {
+    g_set_error_literal (&error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
+        "m=lines removed from the SDP. Processing a completely new connection "
+        "is not currently supported.");
+    goto out;
+  }
+
+  if ((sd->sdp->type == GST_WEBRTC_SDP_TYPE_PRANSWER ||
+          sd->sdp->type == GST_WEBRTC_SDP_TYPE_ANSWER) &&
+      transceivers_media_num_cmp (webrtc,
+          get_last_generated_description (webrtc, sd->source, sd->sdp->type),
+          sd->sdp) != 0) {
+    g_set_error_literal (&error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
+        "Answer doesn't have the same number of m-lines as the offer.");
+    goto out;
+  }
+
+  if (!check_locked_mlines (webrtc, sd->sdp, &error))
+    goto out;
+
   switch (sd->sdp->type) {
     case GST_WEBRTC_SDP_TYPE_OFFER:{
       if (sd->source == SDP_LOCAL) {
@@ -4497,7 +6487,8 @@ _set_description_task (GstWebRTCBin * webrtc, struct set_description *sd)
     GList *tmp;
 
     /* media modifications */
-    _update_transceivers_from_sdp (webrtc, sd->source, sd->sdp);
+    if (!_update_transceivers_from_sdp (webrtc, sd->source, sd->sdp, &error))
+      goto out;
 
     for (tmp = webrtc->priv->pending_sink_transceivers; tmp;) {
       GstWebRTCBinPad *pad = GST_WEBRTC_BIN_PAD (tmp->data);
@@ -4511,13 +6502,19 @@ _set_description_task (GstWebRTCBin * webrtc, struct set_description *sd)
         continue;
       }
 
-      if (pad->mlineindex >= gst_sdp_message_medias_len (sd->sdp->sdp)) {
+      if (!pad->trans) {
+        GST_LOG_OBJECT (pad, "doesn't have a transceiver");
+        tmp = tmp->next;
+        continue;
+      }
+
+      if (pad->trans->mline >= gst_sdp_message_medias_len (sd->sdp->sdp)) {
         GST_DEBUG_OBJECT (pad, "not mentioned in this description. Skipping");
         tmp = tmp->next;
         continue;
       }
 
-      media = gst_sdp_message_get_media (sd->sdp->sdp, pad->mlineindex);
+      media = gst_sdp_message_get_media (sd->sdp->sdp, pad->trans->mline);
       /* skip rejected media */
       if (gst_sdp_media_get_port (media) == 0) {
         /* FIXME: arrange for an appropriate flow return */
@@ -4527,12 +6524,6 @@ _set_description_task (GstWebRTCBin * webrtc, struct set_description *sd)
         continue;
       }
 
-      if (!pad->trans) {
-        GST_LOG_OBJECT (pad, "doesn't have a transceiver");
-        tmp = tmp->next;
-        continue;
-      }
-
       new_dir = pad->trans->direction;
       if (new_dir != GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDONLY &&
           new_dir != GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDRECV) {
@@ -4560,10 +6551,11 @@ _set_description_task (GstWebRTCBin * webrtc, struct set_description *sd)
     const GstSDPMedia *media = gst_sdp_message_get_media (sd->sdp->sdp, i);
     gchar *ufrag, *pwd;
     TransportStream *item;
+    guint rtp_session_id = bundled ? bundle_idx : i;
 
     item =
-        _get_or_create_transport_stream (webrtc, bundled ? bundle_idx : i,
-        _message_media_is_datachannel (sd->sdp->sdp, bundled ? bundle_idx : i));
+        _get_or_create_transport_stream (webrtc, rtp_session_id,
+        _message_media_is_datachannel (sd->sdp->sdp, rtp_session_id));
 
     if (sd->source == SDP_REMOTE) {
       guint j;
@@ -4577,11 +6569,11 @@ _set_description_task (GstWebRTCBin * webrtc, struct set_description *sd)
 
           if (split[0] && sscanf (split[0], "%u", &ssrc) && split[1]
               && g_str_has_prefix (split[1], "cname:")) {
-            SsrcMapItem ssrc_item;
-
-            ssrc_item.media_idx = i;
-            ssrc_item.ssrc = ssrc;
-            g_array_append_val (item->remote_ssrcmap, ssrc_item);
+            if (!find_mid_ssrc_for_ssrc (webrtc,
+                    GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_RECVONLY,
+                    rtp_session_id, ssrc))
+              transport_stream_add_ssrc_map_item (item,
+                  GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_RECVONLY, ssrc, i);
           }
           g_strfreev (split);
         }
@@ -4645,18 +6637,15 @@ _set_description_task (GstWebRTCBin * webrtc, struct set_description *sd)
    * signalingstatechange at connection.
    */
   if (signalling_state_changed) {
-    gchar *from = _enum_value_to_string (GST_TYPE_WEBRTC_SIGNALING_STATE,
+    const gchar *from = _enum_value_to_string (GST_TYPE_WEBRTC_SIGNALING_STATE,
         webrtc->signaling_state);
-    gchar *to = _enum_value_to_string (GST_TYPE_WEBRTC_SIGNALING_STATE,
+    const gchar *to = _enum_value_to_string (GST_TYPE_WEBRTC_SIGNALING_STATE,
         new_signaling_state);
     GST_TRACE_OBJECT (webrtc, "notify signaling-state from %s "
         "to %s", from, to);
     PC_UNLOCK (webrtc);
     g_object_notify (G_OBJECT (webrtc), "signaling-state");
     PC_LOCK (webrtc);
-
-    g_free (from);
-    g_free (to);
   }
 
   if (webrtc->signaling_state == GST_WEBRTC_SIGNALING_STATE_STABLE) {
@@ -4676,16 +6665,20 @@ _set_description_task (GstWebRTCBin * webrtc, struct set_description *sd)
 out:
   g_strfreev (bundled);
 
-  PC_UNLOCK (webrtc);
-  gst_promise_reply (sd->promise, NULL);
-  PC_LOCK (webrtc);
+  if (error) {
+    GstStructure *s = gst_structure_new ("application/x-gst-promise",
+        "error", G_TYPE_ERROR, error, NULL);
+    GST_WARNING_OBJECT (webrtc, "returning error: %s", error->message);
+    g_clear_error (&error);
+    return s;
+  } else {
+    return NULL;
+  }
 }
 
 static void
 _free_set_description_data (struct set_description *sd)
 {
-  if (sd->promise)
-    gst_promise_unref (sd->promise);
   if (sd->sdp)
     gst_webrtc_session_description_free (sd->sdp);
   g_free (sd);
@@ -4703,8 +6696,6 @@ gst_webrtc_bin_set_remote_description (GstWebRTCBin * webrtc,
     goto bad_input;
 
   sd = g_new0 (struct set_description, 1);
-  if (promise != NULL)
-    sd->promise = gst_promise_ref (promise);
   sd->source = SDP_REMOTE;
   sd->sdp = gst_webrtc_session_description_copy (remote_sdp);
 
@@ -4712,10 +6703,9 @@ gst_webrtc_bin_set_remote_description (GstWebRTCBin * webrtc,
           (GstWebRTCBinFunc) _set_description_task, sd,
           (GDestroyNotify) _free_set_description_data, promise)) {
     GError *error =
-        g_error_new (GST_WEBRTC_BIN_ERROR, GST_WEBRTC_BIN_ERROR_CLOSED,
+        g_error_new (GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_INVALID_STATE,
         "Could not set remote description. webrtcbin is closed.");
-    GstStructure *s =
-        gst_structure_new ("application/x-gstwebrtcbin-promise-error",
+    GstStructure *s = gst_structure_new ("application/x-gst-promise",
         "error", G_TYPE_ERROR, error, NULL);
 
     gst_promise_reply (promise, s);
@@ -4744,8 +6734,6 @@ gst_webrtc_bin_set_local_description (GstWebRTCBin * webrtc,
     goto bad_input;
 
   sd = g_new0 (struct set_description, 1);
-  if (promise != NULL)
-    sd->promise = gst_promise_ref (promise);
   sd->source = SDP_LOCAL;
   sd->sdp = gst_webrtc_session_description_copy (local_sdp);
 
@@ -4753,10 +6741,9 @@ gst_webrtc_bin_set_local_description (GstWebRTCBin * webrtc,
           (GstWebRTCBinFunc) _set_description_task, sd,
           (GDestroyNotify) _free_set_description_data, promise)) {
     GError *error =
-        g_error_new (GST_WEBRTC_BIN_ERROR, GST_WEBRTC_BIN_ERROR_CLOSED,
+        g_error_new (GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_INVALID_STATE,
         "Could not set local description. webrtcbin is closed");
-    GstStructure *s =
-        gst_structure_new ("application/x-gstwebrtcbin-promise-error",
+    GstStructure *s = gst_structure_new ("application/x-gst-promise",
         "error", G_TYPE_ERROR, error, NULL);
 
     gst_promise_reply (promise, s);
@@ -4773,7 +6760,7 @@ bad_input:
   }
 }
 
-static void
+static GstStructure *
 _add_ice_candidate_task (GstWebRTCBin * webrtc, IceCandidateItem * item)
 {
   if (!webrtc->current_local_description || !webrtc->current_remote_description) {
@@ -4787,6 +6774,8 @@ _add_ice_candidate_task (GstWebRTCBin * webrtc, IceCandidateItem * item)
   } else {
     _add_ice_candidate (webrtc, item, FALSE);
   }
+
+  return NULL;
 }
 
 static void
@@ -4804,16 +6793,18 @@ gst_webrtc_bin_add_ice_candidate (GstWebRTCBin * webrtc, guint mline,
 
   item = g_new0 (IceCandidateItem, 1);
   item->mlineindex = mline;
-  if (!g_ascii_strncasecmp (attr, "a=candidate:", 12))
-    item->candidate = g_strdup (attr);
-  else if (!g_ascii_strncasecmp (attr, "candidate:", 10))
-    item->candidate = g_strdup_printf ("a=%s", attr);
+  if (attr && attr[0] != 0) {
+    if (!g_ascii_strncasecmp (attr, "a=candidate:", 12))
+      item->candidate = g_strdup (attr);
+    else if (!g_ascii_strncasecmp (attr, "candidate:", 10))
+      item->candidate = g_strdup_printf ("a=%s", attr);
+  }
   gst_webrtc_bin_enqueue_task (webrtc,
       (GstWebRTCBinFunc) _add_ice_candidate_task, item,
       (GDestroyNotify) _free_ice_candidate_item, NULL);
 }
 
-static void
+static GstStructure *
 _on_local_ice_candidate_task (GstWebRTCBin * webrtc)
 {
   gsize i;
@@ -4823,7 +6814,7 @@ _on_local_ice_candidate_task (GstWebRTCBin * webrtc)
   if (webrtc->priv->pending_local_ice_candidates->len == 0) {
     ICE_UNLOCK (webrtc);
     GST_LOG_OBJECT (webrtc, "No ICE candidates to process right now");
-    return;                     /* Nothing to process */
+    return NULL;                /* Nothing to process */
   }
   /* Take the array so we can process it all and free it later
    * without holding the lock
@@ -4870,6 +6861,8 @@ _on_local_ice_candidate_task (GstWebRTCBin * webrtc)
 
   }
   g_array_free (items, TRUE);
+
+  return NULL;
 }
 
 static void
@@ -4898,16 +6891,6 @@ _on_local_ice_candidate_cb (GstWebRTCICE * ice, guint session_id,
   }
 }
 
-/* https://www.w3.org/TR/webrtc/#dfn-stats-selection-algorithm */
-static GstStructure *
-_get_stats_from_selector (GstWebRTCBin * webrtc, gpointer selector)
-{
-  if (selector)
-    GST_FIXME_OBJECT (webrtc, "Implement stats selection");
-
-  return gst_structure_copy (webrtc->priv->stats);
-}
-
 struct get_stats
 {
   GstPad *pad;
@@ -4925,28 +6908,14 @@ _free_get_stats (struct get_stats *stats)
 }
 
 /* https://www.w3.org/TR/webrtc/#dom-rtcpeerconnection-getstats() */
-static void
+static GstStructure *
 _get_stats_task (GstWebRTCBin * webrtc, struct get_stats *stats)
 {
-  GstStructure *s;
-  gpointer selector = NULL;
-
-  gst_webrtc_bin_update_stats (webrtc);
-
-  if (stats->pad) {
-    GstWebRTCBinPad *wpad = GST_WEBRTC_BIN_PAD (stats->pad);
-
-    if (wpad->trans) {
-      if (GST_PAD_DIRECTION (wpad) == GST_PAD_SRC) {
-        selector = wpad->trans->receiver;
-      } else {
-        selector = wpad->trans->sender;
-      }
-    }
-  }
+  /* Our selector is the pad,
+   * https://www.w3.org/TR/webrtc/#dfn-stats-selection-algorithm
+   */
 
-  s = _get_stats_from_selector (webrtc, selector);
-  gst_promise_reply (stats->promise, s);
+  return gst_webrtc_bin_create_stats (webrtc, stats->pad);
 }
 
 static void
@@ -4967,9 +6936,9 @@ gst_webrtc_bin_get_stats (GstWebRTCBin * webrtc, GstPad * pad,
   if (!gst_webrtc_bin_enqueue_task (webrtc, (GstWebRTCBinFunc) _get_stats_task,
           stats, (GDestroyNotify) _free_get_stats, promise)) {
     GError *error =
-        g_error_new (GST_WEBRTC_BIN_ERROR, GST_WEBRTC_BIN_ERROR_CLOSED,
+        g_error_new (GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_INVALID_STATE,
         "Could not retrieve statistics. webrtcbin is closed.");
-    GstStructure *s = gst_structure_new ("application/x-gst-promise-error",
+    GstStructure *s = gst_structure_new ("application/x-gst-promise",
         "error", G_TYPE_ERROR, error, NULL);
 
     gst_promise_reply (promise, s);
@@ -4983,18 +6952,19 @@ gst_webrtc_bin_add_transceiver (GstWebRTCBin * webrtc,
     GstWebRTCRTPTransceiverDirection direction, GstCaps * caps)
 {
   WebRTCTransceiver *trans;
-  GstWebRTCRTPTransceiver *rtp_trans;
 
   g_return_val_if_fail (direction != GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_NONE,
       NULL);
 
-  trans = _create_webrtc_transceiver (webrtc, direction, -1);
+  PC_LOCK (webrtc);
+
+  trans =
+      _create_webrtc_transceiver (webrtc, direction, -1,
+      webrtc_kind_from_caps (caps), caps);
   GST_LOG_OBJECT (webrtc,
       "Created new unassociated transceiver %" GST_PTR_FORMAT, trans);
 
-  rtp_trans = GST_WEBRTC_RTP_TRANSCEIVER (trans);
-  if (caps)
-    rtp_trans->codec_preferences = gst_caps_ref (caps);
+  PC_UNLOCK (webrtc);
 
   return gst_object_ref (trans);
 }
@@ -5011,6 +6981,8 @@ gst_webrtc_bin_get_transceivers (GstWebRTCBin * webrtc)
   GArray *arr = g_array_new (FALSE, TRUE, sizeof (GstWebRTCRTPTransceiver *));
   int i;
 
+  PC_LOCK (webrtc);
+
   g_array_set_clear_func (arr, (GDestroyNotify) _deref_and_unref);
 
   for (i = 0; i < webrtc->priv->transceivers->len; i++) {
@@ -5019,6 +6991,7 @@ gst_webrtc_bin_get_transceivers (GstWebRTCBin * webrtc)
     gst_object_ref (trans);
     g_array_append_val (arr, trans);
   }
+  PC_UNLOCK (webrtc);
 
   return arr;
 }
@@ -5028,6 +7001,8 @@ gst_webrtc_bin_get_transceiver (GstWebRTCBin * webrtc, guint idx)
 {
   GstWebRTCRTPTransceiver *trans = NULL;
 
+  PC_LOCK (webrtc);
+
   if (idx >= webrtc->priv->transceivers->len) {
     GST_ERROR_OBJECT (webrtc, "No transceiver for idx %d", idx);
     goto done;
@@ -5037,18 +7012,25 @@ gst_webrtc_bin_get_transceiver (GstWebRTCBin * webrtc, guint idx)
   gst_object_ref (trans);
 
 done:
+  PC_UNLOCK (webrtc);
   return trans;
 }
 
 static gboolean
 gst_webrtc_bin_add_turn_server (GstWebRTCBin * webrtc, const gchar * uri)
 {
+  gboolean ret;
+
   g_return_val_if_fail (GST_IS_WEBRTC_BIN (webrtc), FALSE);
   g_return_val_if_fail (uri != NULL, FALSE);
 
   GST_DEBUG_OBJECT (webrtc, "Adding turn server: %s", uri);
 
-  return gst_webrtc_ice_add_turn_server (webrtc->priv->ice, uri);
+  PC_LOCK (webrtc);
+  ret = gst_webrtc_ice_add_turn_server (webrtc->priv->ice, uri);
+  PC_UNLOCK (webrtc);
+
+  return ret;
 }
 
 static gboolean
@@ -5121,7 +7103,7 @@ gst_webrtc_bin_create_data_channel (GstWebRTCBin * webrtc, const gchar * label,
   if (webrtc->priv->sctp_transport) {
     /* Let transport be the connection's [[SctpTransport]] slot.
      *
-     * If the [[DataChannelId]] slot is not null, transport is in 
+     * If the [[DataChannelId]] slot is not null, transport is in
      * connected state and [[DataChannelId]] is greater or equal to the
      * transport's [[MaxChannels]] slot, throw an OperationError.
      */
@@ -5136,6 +7118,7 @@ gst_webrtc_bin_create_data_channel (GstWebRTCBin * webrtc, const gchar * label,
     return NULL;
 
   PC_LOCK (webrtc);
+  DC_LOCK (webrtc);
   /* check if the id has been used already */
   if (id != -1) {
     WebRTCDataChannel *channel = _find_data_channel_for_id (webrtc, id);
@@ -5143,6 +7126,7 @@ gst_webrtc_bin_create_data_channel (GstWebRTCBin * webrtc, const gchar * label,
       GST_ELEMENT_WARNING (webrtc, LIBRARY, SETTINGS,
           ("Attempting to add a data channel with a duplicate ID: %i", id),
           NULL);
+      DC_UNLOCK (webrtc);
       PC_UNLOCK (webrtc);
       return NULL;
     }
@@ -5155,6 +7139,7 @@ gst_webrtc_bin_create_data_channel (GstWebRTCBin * webrtc, const gchar * label,
     if (id == -1) {
       GST_ELEMENT_WARNING (webrtc, RESOURCE, NOT_FOUND,
           ("%s", "Failed to generate an identifier for a data channel"), NULL);
+      DC_UNLOCK (webrtc);
       PC_UNLOCK (webrtc);
       return NULL;
     }
@@ -5165,24 +7150,34 @@ gst_webrtc_bin_create_data_channel (GstWebRTCBin * webrtc, const gchar * label,
       "max-retransmits", max_retransmits, "protocol", protocol,
       "negotiated", negotiated, "id", id, "priority", priority, NULL);
 
-  if (ret) {
-    gst_bin_add (GST_BIN (webrtc), ret->appsrc);
-    gst_bin_add (GST_BIN (webrtc), ret->appsink);
-
-    gst_element_sync_state_with_parent (ret->appsrc);
-    gst_element_sync_state_with_parent (ret->appsink);
-
-    ret = gst_object_ref (ret);
-    ret->webrtcbin = webrtc;
-    g_ptr_array_add (webrtc->priv->data_channels, ret);
-    webrtc_data_channel_link_to_sctp (ret, webrtc->priv->sctp_transport);
-    if (webrtc->priv->sctp_transport &&
-        webrtc->priv->sctp_transport->association_established
-        && !ret->parent.negotiated) {
-      webrtc_data_channel_start_negotiation (ret);
-    } else {
-      _update_need_negotiation (webrtc);
-    }
+  if (!ret) {
+    DC_UNLOCK (webrtc);
+    PC_UNLOCK (webrtc);
+    return ret;
+  }
+
+  g_signal_emit (webrtc, gst_webrtc_bin_signals[PREPARE_DATA_CHANNEL_SIGNAL], 0,
+      ret, TRUE);
+
+  gst_bin_add (GST_BIN (webrtc), ret->src_bin);
+  gst_bin_add (GST_BIN (webrtc), ret->sink_bin);
+
+  gst_element_sync_state_with_parent (ret->src_bin);
+  gst_element_sync_state_with_parent (ret->sink_bin);
+
+  ret = gst_object_ref (ret);
+  ret->webrtcbin = webrtc;
+  g_ptr_array_add (webrtc->priv->data_channels, ret);
+  DC_UNLOCK (webrtc);
+
+  gst_webrtc_bin_update_sctp_priority (webrtc);
+  webrtc_data_channel_link_to_sctp (ret, webrtc->priv->sctp_transport);
+  if (webrtc->priv->sctp_transport &&
+      webrtc->priv->sctp_transport->association_established
+      && !ret->parent.negotiated) {
+    webrtc_data_channel_start_negotiation (ret);
+  } else {
+    _update_need_negotiation (webrtc);
   }
 
   PC_UNLOCK (webrtc);
@@ -5201,13 +7196,12 @@ on_rtpbin_pad_added (GstElement * rtpbin, GstPad * new_pad,
   GST_TRACE_OBJECT (webrtc, "new rtpbin pad %s", new_pad_name);
   if (g_str_has_prefix (new_pad_name, "recv_rtp_src_")) {
     guint32 session_id = 0, ssrc = 0, pt = 0;
-    GstWebRTCRTPTransceiver *rtp_trans;
+    SsrcMapItem *mid_entry;
+    GstWebRTCRTPTransceiver *rtp_trans = NULL;
     WebRTCTransceiver *trans;
     TransportStream *stream;
     GstWebRTCBinPad *pad;
-    guint media_idx = 0;
-    gboolean found_ssrc = FALSE;
-    guint i;
+    guint media_idx;
 
     if (sscanf (new_pad_name, "recv_rtp_src_%u_%u_%u", &session_id, &ssrc,
             &pt) != 3) {
@@ -5215,45 +7209,70 @@ on_rtpbin_pad_added (GstElement * rtpbin, GstPad * new_pad,
       return;
     }
 
+    media_idx = session_id;
+
+    PC_LOCK (webrtc);
     stream = _find_transport_for_session (webrtc, session_id);
     if (!stream)
       g_warn_if_reached ();
 
-    media_idx = session_id;
+    mid_entry =
+        find_mid_ssrc_for_ssrc (webrtc,
+        GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_RECVONLY, session_id, ssrc);
 
-    for (i = 0; i < stream->remote_ssrcmap->len; i++) {
-      SsrcMapItem *item =
-          &g_array_index (stream->remote_ssrcmap, SsrcMapItem, i);
-      if (item->ssrc == ssrc) {
-        media_idx = item->media_idx;
-        found_ssrc = TRUE;
-        break;
+    if (mid_entry) {
+      if (mid_entry->mid) {
+        /* Can't use the mid_entry if the mid doesn't exist */
+        rtp_trans = _find_transceiver_for_mid (webrtc, mid_entry->mid);
+        if (rtp_trans) {
+          g_assert_cmpint (rtp_trans->mline, ==, mid_entry->media_idx);
+        }
       }
-    }
 
-    if (!found_ssrc) {
+      if (mid_entry->media_idx != -1)
+        media_idx = mid_entry->media_idx;
+    } else {
       GST_WARNING_OBJECT (webrtc, "Could not find ssrc %u", ssrc);
+      /* TODO: connect up to fakesink and reconnect later when this information
+       * is known from RTCP SDES or RTP Header extension
+       */
     }
 
-    rtp_trans = _find_transceiver_for_mline (webrtc, media_idx);
+    if (!rtp_trans)
+      rtp_trans = _find_transceiver_for_mline (webrtc, media_idx);
     if (!rtp_trans)
       g_warn_if_reached ();
     trans = WEBRTC_TRANSCEIVER (rtp_trans);
     g_assert (trans->stream == stream);
 
     pad = _find_pad_for_transceiver (webrtc, GST_PAD_SRC, rtp_trans);
-
     GST_TRACE_OBJECT (webrtc, "found pad %" GST_PTR_FORMAT
         " for rtpbin pad name %s", pad, new_pad_name);
+    if (!_remove_pending_pad (webrtc, pad)) {
+      /* assumption here is that rtpbin doesn't duplicate pads and that if
+       * there is no pending pad, this is a duplicate stream for e.g. simulcast
+       * or somesuch */
+      gst_clear_object (&pad);
+      pad =
+          _create_pad_for_sdp_media (webrtc, GST_PAD_SRC, rtp_trans, G_MAXUINT,
+          NULL);
+      GST_TRACE_OBJECT (webrtc,
+          "duplicate output ssrc? created new pad %" GST_PTR_FORMAT " for %"
+          GST_PTR_FORMAT " for rtp pad %s", pad, rtp_trans, new_pad_name);
+      gst_object_ref_sink (pad);
+    }
+
     if (!pad)
       g_warn_if_reached ();
     gst_ghost_pad_set_target (GST_GHOST_PAD (pad), GST_PAD (new_pad));
 
     if (webrtc->priv->running)
       gst_pad_set_active (GST_PAD (pad), TRUE);
+
+    PC_UNLOCK (webrtc);
+
     gst_pad_sticky_events_foreach (new_pad, copy_sticky_events, pad);
     gst_element_add_pad (GST_ELEMENT (webrtc), GST_PAD (pad));
-    _remove_pending_pad (webrtc, pad);
 
     gst_object_unref (pad);
   }
@@ -5271,6 +7290,7 @@ on_rtpbin_request_pt_map (GstElement * rtpbin, guint session_id, guint pt,
   GST_DEBUG_OBJECT (webrtc, "getting pt map for pt %d in session %d", pt,
       session_id);
 
+  PC_LOCK (webrtc);
   stream = _find_transport_for_session (webrtc, session_id);
   if (!stream)
     goto unknown_session;
@@ -5278,13 +7298,15 @@ on_rtpbin_request_pt_map (GstElement * rtpbin, guint session_id, guint pt,
   if ((ret = transport_stream_get_caps_for_pt (stream, pt)))
     gst_caps_ref (ret);
 
-  GST_TRACE_OBJECT (webrtc, "Found caps %" GST_PTR_FORMAT " for pt %d in "
+  GST_DEBUG_OBJECT (webrtc, "Found caps %" GST_PTR_FORMAT " for pt %d in "
       "session %d", ret, pt, session_id);
 
+  PC_UNLOCK (webrtc);
   return ret;
 
 unknown_session:
   {
+    PC_UNLOCK (webrtc);
     GST_DEBUG_OBJECT (webrtc, "unknown session %d", session_id);
     return NULL;
   }
@@ -5295,62 +7317,99 @@ on_rtpbin_request_aux_sender (GstElement * rtpbin, guint session_id,
     GstWebRTCBin * webrtc)
 {
   TransportStream *stream;
-  gboolean have_rtx = FALSE;
-  GstStructure *pt_map = NULL;
-  GstElement *ret = NULL;
-  GstWebRTCRTPTransceiver *trans;
+  GstElement *ret, *rtx;
+  GstPad *pad;
+  char *name;
+  GstElement *aux_sender = NULL;
 
   stream = _find_transport_for_session (webrtc, session_id);
-  trans = _find_transceiver (webrtc, &session_id,
-      (FindTransceiverFunc) transceiver_match_for_mline);
+  if (!stream) {
+    /* a rtp session without a stream is a webrtcbin bug */
+    g_warn_if_reached ();
+    return NULL;
+  }
 
-  if (stream)
-    have_rtx = transport_stream_get_pt (stream, "RTX") != 0;
+  if (stream->rtxsend) {
+    GST_WARNING_OBJECT (webrtc, "rtprtxsend already created! rtpbin bug?!");
+    g_warn_if_reached ();
+    return NULL;
+  }
 
-  GST_LOG_OBJECT (webrtc, "requesting aux sender for stream %" GST_PTR_FORMAT
-      " with transport %" GST_PTR_FORMAT " and pt map %" GST_PTR_FORMAT, stream,
-      trans, pt_map);
+  GST_DEBUG_OBJECT (webrtc, "requesting aux sender for session %u "
+      "stream %" GST_PTR_FORMAT, session_id, stream);
 
-  if (have_rtx) {
-    GstElement *rtx;
-    GstPad *pad;
-    gchar *name;
+  ret = gst_bin_new (NULL);
+  rtx = gst_element_factory_make ("rtprtxsend", NULL);
+  /* XXX: allow control from outside? */
+  g_object_set (rtx, "max-size-packets", 500, NULL);
 
-    if (stream->rtxsend) {
-      GST_WARNING_OBJECT (webrtc, "rtprtxsend already created! rtpbin bug?!");
-      goto out;
-    }
+  if (!gst_bin_add (GST_BIN (ret), rtx))
+    g_warn_if_reached ();
+  ensure_rtx_hdr_ext (stream);
 
-    GST_INFO ("creating AUX sender");
-    ret = gst_bin_new (NULL);
-    rtx = gst_element_factory_make ("rtprtxsend", NULL);
-    g_object_set (rtx, "max-size-packets", 500, NULL);
-    _set_rtx_ptmap_from_stream (webrtc, stream);
+  stream->rtxsend = gst_object_ref (rtx);
+  _set_internal_rtpbin_element_props_from_stream (webrtc, stream);
 
-    if (WEBRTC_TRANSCEIVER (trans)->local_rtx_ssrc_map)
-      g_object_set (rtx, "ssrc-map",
-          WEBRTC_TRANSCEIVER (trans)->local_rtx_ssrc_map, NULL);
+  name = g_strdup_printf ("src_%u", session_id);
+  pad = gst_element_get_static_pad (rtx, "src");
 
-    gst_bin_add (GST_BIN (ret), rtx);
 
-    pad = gst_element_get_static_pad (rtx, "src");
-    name = g_strdup_printf ("src_%u", session_id);
-    gst_element_add_pad (ret, gst_ghost_pad_new (name, pad));
-    g_free (name);
-    gst_object_unref (pad);
+  g_signal_emit (webrtc, gst_webrtc_bin_signals[REQUEST_AUX_SENDER], 0,
+      stream->transport, &aux_sender);
+  if (aux_sender) {
+    GstPadLinkReturn link_res;
+    GstPad *sinkpad = gst_element_get_static_pad (aux_sender, "sink");
+    GstPad *srcpad = gst_element_get_static_pad (aux_sender, "src");
 
-    pad = gst_element_get_static_pad (rtx, "sink");
-    name = g_strdup_printf ("sink_%u", session_id);
-    gst_element_add_pad (ret, gst_ghost_pad_new (name, pad));
-    g_free (name);
-    gst_object_unref (pad);
+    gst_object_ref_sink (aux_sender);
+
+    if (!sinkpad || !srcpad) {
+      GST_ERROR_OBJECT (webrtc,
+          "Invalid pads for the aux sender %" GST_PTR_FORMAT
+          ". Skipping it.", aux_sender);
+      goto bwe_done;
+    }
+
+    if (!gst_bin_add (GST_BIN (ret), aux_sender)) {
+      GST_ERROR_OBJECT (webrtc,
+          "Could not add aux sender %" GST_PTR_FORMAT, aux_sender);
+      goto bwe_done;
+    }
+
+    link_res = gst_pad_link (pad, sinkpad);
+    if (link_res != GST_PAD_LINK_OK) {
+      GST_ERROR_OBJECT (webrtc,
+          "Could not link aux sender %" GST_PTR_FORMAT " %s", aux_sender,
+          gst_pad_link_get_name (link_res));
+      goto bwe_done;
+    }
+
+    gst_clear_object (&pad);
+    pad = gst_object_ref (srcpad);
 
-    stream->rtxsend = gst_object_ref (rtx);
+  bwe_done:
+    if (pad != srcpad) {
+      /* Failed using the provided aux sender */
+      if (gst_object_has_as_parent (GST_OBJECT (aux_sender), GST_OBJECT (ret))) {
+        gst_bin_remove (GST_BIN (ret), aux_sender);
+      }
+    }
+    gst_clear_object (&aux_sender);
+    gst_clear_object (&srcpad);
+    gst_clear_object (&sinkpad);
   }
 
-out:
-  if (pt_map)
-    gst_structure_free (pt_map);
+  if (!gst_element_add_pad (ret, gst_ghost_pad_new (name, pad)))
+    g_warn_if_reached ();
+  gst_clear_object (&pad);
+  g_clear_pointer (&name, g_free);
+
+  name = g_strdup_printf ("sink_%u", session_id);
+  pad = gst_element_get_static_pad (rtx, "sink");
+  if (!gst_element_add_pad (ret, gst_ghost_pad_new (name, pad)))
+    g_warn_if_reached ();
+  gst_clear_object (&pad);
+  g_clear_pointer (&name, g_free);
 
   return ret;
 }
@@ -5359,97 +7418,86 @@ static GstElement *
 on_rtpbin_request_aux_receiver (GstElement * rtpbin, guint session_id,
     GstWebRTCBin * webrtc)
 {
-  GstElement *ret = NULL;
-  GstElement *prev = NULL;
-  GstPad *sinkpad = NULL;
   TransportStream *stream;
-  gint red_pt = 0;
-  gint rtx_pt = 0;
+  GstPad *pad, *ghost;
+  GstElement *ret;
+  char *name;
 
   stream = _find_transport_for_session (webrtc, session_id);
-
-  if (stream) {
-    red_pt = transport_stream_get_pt (stream, "RED");
-    rtx_pt = transport_stream_get_pt (stream, "RTX");
+  if (!stream) {
+    /* no transport stream before the session has been created is a webrtcbin
+     * programming error! */
+    g_warn_if_reached ();
+    return NULL;
   }
 
-  GST_LOG_OBJECT (webrtc, "requesting aux receiver for stream %" GST_PTR_FORMAT,
-      stream);
-
-  if (red_pt || rtx_pt)
-    ret = gst_bin_new (NULL);
-
-  if (rtx_pt) {
-    if (stream->rtxreceive) {
-      GST_WARNING_OBJECT (webrtc,
-          "rtprtxreceive already created! rtpbin bug?!");
-      goto error;
-    }
-
-    stream->rtxreceive = gst_element_factory_make ("rtprtxreceive", NULL);
-    _set_rtx_ptmap_from_stream (webrtc, stream);
-
-    gst_bin_add (GST_BIN (ret), stream->rtxreceive);
-
-    sinkpad = gst_element_get_static_pad (stream->rtxreceive, "sink");
+  if (stream->rtxreceive) {
+    GST_WARNING_OBJECT (webrtc, "rtprtxreceive already created! rtpbin bug?!");
+    g_warn_if_reached ();
+    return NULL;
+  }
 
-    prev = gst_object_ref (stream->rtxreceive);
+  if (stream->reddec) {
+    GST_WARNING_OBJECT (webrtc, "rtpreddec already created! rtpbin bug?!");
+    g_warn_if_reached ();
+    return NULL;
   }
 
-  if (red_pt) {
-    GstElement *rtpreddec = gst_element_factory_make ("rtpreddec", NULL);
+  GST_DEBUG_OBJECT (webrtc, "requesting aux receiver for session %u "
+      "stream %" GST_PTR_FORMAT, session_id, stream);
 
-    GST_DEBUG_OBJECT (webrtc, "Creating RED decoder for pt %d in session %u",
-        red_pt, session_id);
+  ret = gst_bin_new (NULL);
 
-    gst_bin_add (GST_BIN (ret), rtpreddec);
+  stream->rtxreceive = gst_element_factory_make ("rtprtxreceive", NULL);
+  gst_object_ref (stream->rtxreceive);
+  if (!gst_bin_add (GST_BIN (ret), stream->rtxreceive))
+    g_warn_if_reached ();
 
-    g_object_set (rtpreddec, "pt", red_pt, NULL);
+  ensure_rtx_hdr_ext (stream);
 
-    if (prev)
-      gst_element_link (prev, rtpreddec);
-    else
-      sinkpad = gst_element_get_static_pad (rtpreddec, "sink");
+  stream->reddec = gst_element_factory_make ("rtpreddec", NULL);
+  gst_object_ref (stream->reddec);
+  if (!gst_bin_add (GST_BIN (ret), stream->reddec))
+    g_warn_if_reached ();
 
-    prev = rtpreddec;
-  }
+  _set_internal_rtpbin_element_props_from_stream (webrtc, stream);
 
-  if (sinkpad) {
-    gchar *name = g_strdup_printf ("sink_%u", session_id);
-    GstPad *ghost = gst_ghost_pad_new (name, sinkpad);
-    g_free (name);
-    gst_object_unref (sinkpad);
-    gst_element_add_pad (ret, ghost);
-  }
+  if (!gst_element_link (stream->rtxreceive, stream->reddec))
+    g_warn_if_reached ();
 
-  if (prev) {
-    gchar *name = g_strdup_printf ("src_%u", session_id);
-    GstPad *srcpad = gst_element_get_static_pad (prev, "src");
-    GstPad *ghost = gst_ghost_pad_new (name, srcpad);
-    g_free (name);
-    gst_object_unref (srcpad);
-    gst_element_add_pad (ret, ghost);
-  }
+  name = g_strdup_printf ("sink_%u", session_id);
+  pad = gst_element_get_static_pad (stream->rtxreceive, "sink");
+  ghost = gst_ghost_pad_new (name, pad);
+  g_clear_pointer (&name, g_free);
+  gst_clear_object (&pad);
+  if (!gst_element_add_pad (ret, ghost))
+    g_warn_if_reached ();
 
-out:
-  return ret;
+  name = g_strdup_printf ("src_%u", session_id);
+  pad = gst_element_get_static_pad (stream->reddec, "src");
+  ghost = gst_ghost_pad_new (name, pad);
+  g_clear_pointer (&name, g_free);
+  gst_clear_object (&pad);
+  if (!gst_element_add_pad (ret, ghost))
+    g_warn_if_reached ();
 
-error:
-  if (ret)
-    gst_object_unref (ret);
-  goto out;
+  return ret;
 }
 
 static GstElement *
-on_rtpbin_request_fec_decoder (GstElement * rtpbin, guint session_id,
-    GstWebRTCBin * webrtc)
+on_rtpbin_request_fec_decoder_full (GstElement * rtpbin, guint session_id,
+    guint ssrc, guint pt, GstWebRTCBin * webrtc)
 {
   TransportStream *stream;
   GstElement *ret = NULL;
-  gint pt = 0;
   GObject *internal_storage;
 
   stream = _find_transport_for_session (webrtc, session_id);
+  if (!stream) {
+    /* a rtp session without a stream is a webrtcbin bug */
+    g_warn_if_reached ();
+    return NULL;
+  }
 
   /* TODO: for now, we only support ulpfec, but once we support
    * more algorithms, if the remote may use more than one algorithm,
@@ -5457,105 +7505,25 @@ on_rtpbin_request_fec_decoder (GstElement * rtpbin, guint session_id,
    *
    * + Return a bin here, with the relevant FEC decoders plugged in
    *   and their payload type set to 0
-   * + Enable the decoders by setting the payload type only when
-   *   we detect it (by connecting to ptdemux:new-payload-type for
-   *   example)
    */
-  if (stream)
-    pt = transport_stream_get_pt (stream, "ULPFEC");
-
-  if (pt) {
-    GST_DEBUG_OBJECT (webrtc, "Creating ULPFEC decoder for pt %d in session %u",
-        pt, session_id);
-    ret = gst_element_factory_make ("rtpulpfecdec", NULL);
-    g_signal_emit_by_name (webrtc->rtpbin, "get-internal-storage", session_id,
-        &internal_storage);
-
-    g_object_set (ret, "pt", pt, "storage", internal_storage, NULL);
-    g_object_unref (internal_storage);
-  }
-
-  return ret;
-}
-
-static GstElement *
-on_rtpbin_request_fec_encoder (GstElement * rtpbin, guint session_id,
-    GstWebRTCBin * webrtc)
-{
-  GstElement *ret = NULL;
-  GstElement *prev = NULL;
-  TransportStream *stream;
-  guint ulpfec_pt = 0;
-  guint red_pt = 0;
-  GstPad *sinkpad = NULL;
-  GstWebRTCRTPTransceiver *trans;
-
-  stream = _find_transport_for_session (webrtc, session_id);
-  trans = _find_transceiver (webrtc, &session_id,
-      (FindTransceiverFunc) transceiver_match_for_mline);
-
-  if (stream) {
-    ulpfec_pt = transport_stream_get_pt (stream, "ULPFEC");
-    red_pt = transport_stream_get_pt (stream, "RED");
-  }
-
-  if (ulpfec_pt || red_pt)
-    ret = gst_bin_new (NULL);
-
-  if (ulpfec_pt) {
-    GstElement *fecenc = gst_element_factory_make ("rtpulpfecenc", NULL);
-    GstCaps *caps = transport_stream_get_caps_for_pt (stream, ulpfec_pt);
-
-    GST_DEBUG_OBJECT (webrtc,
-        "Creating ULPFEC encoder for session %d with pt %d", session_id,
-        ulpfec_pt);
-
-    gst_bin_add (GST_BIN (ret), fecenc);
-    sinkpad = gst_element_get_static_pad (fecenc, "sink");
-    g_object_set (fecenc, "pt", ulpfec_pt, "percentage",
-        WEBRTC_TRANSCEIVER (trans)->fec_percentage, NULL);
-
-
-    if (caps && !gst_caps_is_empty (caps)) {
-      const GstStructure *s = gst_caps_get_structure (caps, 0);
-      const gchar *media = gst_structure_get_string (s, "media");
-
-      if (!g_strcmp0 (media, "video"))
-        g_object_set (fecenc, "multipacket", TRUE, NULL);
-    }
-
-    prev = fecenc;
-  }
-
-  if (red_pt) {
-    GstElement *redenc = gst_element_factory_make ("rtpredenc", NULL);
+  GST_DEBUG_OBJECT (webrtc, "Creating ULPFEC decoder for pt %d in session %u "
+      "stream %" GST_PTR_FORMAT, pt, session_id, stream);
 
-    GST_DEBUG_OBJECT (webrtc, "Creating RED encoder for session %d with pt %d",
-        session_id, red_pt);
+  ret = gst_element_factory_make ("rtpulpfecdec", NULL);
 
-    gst_bin_add (GST_BIN (ret), redenc);
-    if (prev)
-      gst_element_link (prev, redenc);
-    else
-      sinkpad = gst_element_get_static_pad (redenc, "sink");
-
-    g_object_set (redenc, "pt", red_pt, "allow-no-red-blocks", TRUE, NULL);
+  g_signal_emit_by_name (webrtc->rtpbin, "get-internal-storage", session_id,
+      &internal_storage);
 
-    prev = redenc;
-  }
+  g_object_set (ret, "storage", internal_storage, NULL);
+  g_clear_object (&internal_storage);
 
-  if (sinkpad) {
-    GstPad *ghost = gst_ghost_pad_new ("sink", sinkpad);
-    gst_object_unref (sinkpad);
-    gst_element_add_pad (ret, ghost);
-  }
+  g_object_set_data (G_OBJECT (ret), GST_WEBRTC_PAYLOAD_TYPE,
+      GINT_TO_POINTER (pt));
 
-  if (prev) {
-    GstPad *srcpad = gst_element_get_static_pad (prev, "src");
-    GstPad *ghost = gst_ghost_pad_new ("src", srcpad);
-    gst_object_unref (srcpad);
-    gst_element_add_pad (ret, ghost);
-  }
+  PC_LOCK (webrtc);
+  stream->fecdecs = g_list_prepend (stream->fecdecs, gst_object_ref (ret));
+  _set_internal_rtpbin_element_props_from_stream (webrtc, stream);
+  PC_UNLOCK (webrtc);
 
   return ret;
 }
@@ -5565,6 +7533,10 @@ on_rtpbin_bye_ssrc (GstElement * rtpbin, guint session_id, guint ssrc,
     GstWebRTCBin * webrtc)
 {
   GST_INFO_OBJECT (webrtc, "session %u ssrc %u received bye", session_id, ssrc);
+
+  PC_LOCK (webrtc);
+  remove_ssrc_entry_by_ssrc (webrtc, session_id, ssrc);
+  PC_UNLOCK (webrtc);
 }
 
 static void
@@ -5572,6 +7544,10 @@ on_rtpbin_bye_timeout (GstElement * rtpbin, guint session_id, guint ssrc,
     GstWebRTCBin * webrtc)
 {
   GST_INFO_OBJECT (webrtc, "session %u ssrc %u bye timeout", session_id, ssrc);
+
+  PC_LOCK (webrtc);
+  remove_ssrc_entry_by_ssrc (webrtc, session_id, ssrc);
+  PC_UNLOCK (webrtc);
 }
 
 static void
@@ -5580,6 +7556,10 @@ on_rtpbin_sender_timeout (GstElement * rtpbin, guint session_id, guint ssrc,
 {
   GST_INFO_OBJECT (webrtc, "session %u ssrc %u sender timeout", session_id,
       ssrc);
+
+  PC_LOCK (webrtc);
+  remove_ssrc_entry_by_ssrc (webrtc, session_id, ssrc);
+  PC_UNLOCK (webrtc);
 }
 
 static void
@@ -5587,13 +7567,21 @@ on_rtpbin_new_ssrc (GstElement * rtpbin, guint session_id, guint ssrc,
     GstWebRTCBin * webrtc)
 {
   GST_INFO_OBJECT (webrtc, "session %u ssrc %u new ssrc", session_id, ssrc);
+
+  if (ssrc == 0)
+    return;
+
+  PC_LOCK (webrtc);
+  find_or_add_ssrc_map_item (webrtc,
+      GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_RECVONLY, session_id, ssrc, -1);
+  PC_UNLOCK (webrtc);
 }
 
 static void
 on_rtpbin_ssrc_active (GstElement * rtpbin, guint session_id, guint ssrc,
     GstWebRTCBin * webrtc)
 {
-  GST_INFO_OBJECT (webrtc, "session %u ssrc %u active", session_id, ssrc);
+  GST_TRACE_OBJECT (webrtc, "session %u ssrc %u active", session_id, ssrc);
 }
 
 static void
@@ -5607,7 +7595,30 @@ static void
 on_rtpbin_ssrc_sdes (GstElement * rtpbin, guint session_id, guint ssrc,
     GstWebRTCBin * webrtc)
 {
+  GObject *session;
+
   GST_INFO_OBJECT (webrtc, "session %u ssrc %u sdes", session_id, ssrc);
+
+  g_signal_emit_by_name (rtpbin, "get-internal-session", session_id, &session);
+  if (session) {
+    GObject *source;
+
+    g_signal_emit_by_name (session, "get-source-by-ssrc", ssrc, &source);
+    if (source) {
+      GstStructure *sdes;
+
+      g_object_get (source, "sdes", &sdes, NULL);
+
+      /* TODO: when the sdes contains the mid, use that to correlate streams
+       * as necessary */
+      GST_DEBUG_OBJECT (webrtc, "session %u ssrc %u sdes %" GST_PTR_FORMAT,
+          session_id, ssrc, sdes);
+
+      gst_clear_structure (&sdes);
+      gst_clear_object (&source);
+    }
+    g_clear_object (&session);
+  }
 }
 
 static void
@@ -5622,40 +7633,144 @@ on_rtpbin_timeout (GstElement * rtpbin, guint session_id, guint ssrc,
     GstWebRTCBin * webrtc)
 {
   GST_INFO_OBJECT (webrtc, "session %u ssrc %u timeout", session_id, ssrc);
+
+  PC_LOCK (webrtc);
+  remove_ssrc_entry_by_ssrc (webrtc, session_id, ssrc);
+  PC_UNLOCK (webrtc);
 }
 
 static void
 on_rtpbin_new_sender_ssrc (GstElement * rtpbin, guint session_id, guint ssrc,
     GstWebRTCBin * webrtc)
 {
+  SsrcMapItem *mid;
+
   GST_INFO_OBJECT (webrtc, "session %u ssrc %u new sender ssrc", session_id,
       ssrc);
+
+  PC_LOCK (webrtc);
+  mid = find_mid_ssrc_for_ssrc (webrtc,
+      GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDONLY, session_id, ssrc);
+  if (!mid) {
+    TransportStream *stream = _find_transport_for_session (webrtc, session_id);
+    transport_stream_add_ssrc_map_item (stream,
+        GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDONLY, ssrc, -1);
+  } else if (mid->mid) {
+    /* XXX: when peers support the sdes rtcp item, use this to send the mid rtcp
+     * sdes item.  Requires being able to set the sdes on the rtpsource. */
+#if 0
+    GObject *session;
+
+    g_signal_emit_by_name (rtpbin, "get-internal-session", session_id,
+        &session, NULL);
+    if (session) {
+      GObject *source;
+
+      g_signal_emit_by_name (session, "get-source-by-ssrc", ssrc, &source);
+      if (source) {
+        GstStructure *sdes;
+        const char *sdes_field_name;
+
+        g_object_get (source, "sdes", &sdes, NULL);
+        GST_WARNING_OBJECT (webrtc, "session %u ssrc %u retrieve sdes %"
+            GST_PTR_FORMAT, session_id, ssrc, sdes);
+        sdes_field_name = gst_rtcp_sdes_type_to_name (GST_RTCP_SDES_MID);
+        g_assert (sdes_field_name);
+        gst_structure_set (sdes, sdes_field_name, G_TYPE_STRING, mid->mid,
+            NULL);
+        if (mid->rid) {
+          sdes_field_name =
+              gst_rtcp_sdes_type_to_name (GST_RTCP_SDES_RTP_STREAM_ID);
+          g_assert (sdes_field_name);
+          gst_structure_set (sdes, sdes_field_name, mid->rid, NULL);
+          // TODO: repaired-rtp-stream-id
+        }
+        // TODO: writable sdes?
+        g_object_set (source, "sdes", sdes, NULL);
+        GST_INFO_OBJECT (webrtc,
+            "session %u ssrc %u set sdes %" GST_PTR_FORMAT, session_id, ssrc,
+            sdes);
+
+        gst_clear_structure (&sdes);
+        gst_clear_object (&source);
+      }
+      g_clear_object (&session);
+    }
+#endif
+  }
+  PC_UNLOCK (webrtc);
 }
 
 static void
 on_rtpbin_sender_ssrc_active (GstElement * rtpbin, guint session_id, guint ssrc,
     GstWebRTCBin * webrtc)
 {
-  GST_INFO_OBJECT (webrtc, "session %u ssrc %u sender ssrc active", session_id,
+  GST_TRACE_OBJECT (webrtc, "session %u ssrc %u sender ssrc active", session_id,
       ssrc);
 }
 
+struct new_jb_args
+{
+  GstWebRTCBin *webrtc;
+  GstElement *jitterbuffer;
+  TransportStream *stream;
+  guint ssrc;
+};
+
+static gboolean
+jitter_buffer_set_retransmission (SsrcMapItem * item,
+    const struct new_jb_args *data)
+{
+  GstWebRTCRTPTransceiver *trans;
+  gboolean do_nack;
+
+  if (item->media_idx == -1)
+    return TRUE;
+
+  trans = _find_transceiver_for_mline (data->webrtc, item->media_idx);
+  if (!trans) {
+    g_warn_if_reached ();
+    return TRUE;
+  }
+
+  do_nack = WEBRTC_TRANSCEIVER (trans)->do_nack;
+  /* We don't set do-retransmission on rtpbin as we want per-session control */
+  GST_LOG_OBJECT (data->webrtc, "setting do-nack=%s for transceiver %"
+      GST_PTR_FORMAT " with transport %" GST_PTR_FORMAT
+      " rtp session %u ssrc %u", do_nack ? "true" : "false", trans,
+      data->stream, data->stream->session_id, data->ssrc);
+  g_object_set (data->jitterbuffer, "do-retransmission", do_nack, NULL);
+
+  g_weak_ref_set (&item->rtpjitterbuffer, data->jitterbuffer);
+
+  return TRUE;
+}
+
 static void
 on_rtpbin_new_jitterbuffer (GstElement * rtpbin, GstElement * jitterbuffer,
     guint session_id, guint ssrc, GstWebRTCBin * webrtc)
 {
-  GstWebRTCRTPTransceiver *trans;
+  TransportStream *stream;
+  struct new_jb_args d = { 0, };
 
-  trans = _find_transceiver (webrtc, &session_id,
-      (FindTransceiverFunc) transceiver_match_for_mline);
+  PC_LOCK (webrtc);
+  GST_INFO_OBJECT (webrtc, "new jitterbuffer %" GST_PTR_FORMAT " for "
+      "session %u ssrc %u", jitterbuffer, session_id, ssrc);
 
-  if (trans) {
-    /* We don't set do-retransmission on rtpbin as we want per-session control */
-    g_object_set (jitterbuffer, "do-retransmission",
-        WEBRTC_TRANSCEIVER (trans)->do_nack, NULL);
-  } else {
-    g_assert_not_reached ();
+  if (!(stream = _find_transport_for_session (webrtc, session_id))) {
+    g_warn_if_reached ();
+    goto out;
   }
+
+  d.webrtc = webrtc;
+  d.jitterbuffer = jitterbuffer;
+  d.stream = stream;
+  d.ssrc = ssrc;
+  transport_stream_filter_ssrc_map_item (stream, &d,
+      (FindSsrcMapFunc) jitter_buffer_set_retransmission);
+
+out:
+  PC_UNLOCK (webrtc);
 }
 
 static void
@@ -5694,10 +7809,8 @@ _create_rtpbin (GstWebRTCBin * webrtc)
       G_CALLBACK (on_rtpbin_request_aux_receiver), webrtc);
   g_signal_connect (rtpbin, "new-storage",
       G_CALLBACK (on_rtpbin_new_storage), webrtc);
-  g_signal_connect (rtpbin, "request-fec-decoder",
-      G_CALLBACK (on_rtpbin_request_fec_decoder), webrtc);
-  g_signal_connect (rtpbin, "request-fec-encoder",
-      G_CALLBACK (on_rtpbin_request_fec_encoder), webrtc);
+  g_signal_connect (rtpbin, "request-fec-decoder-full",
+      G_CALLBACK (on_rtpbin_request_fec_decoder_full), webrtc);
   g_signal_connect (rtpbin, "on-bye-ssrc",
       G_CALLBACK (on_rtpbin_bye_ssrc), webrtc);
   g_signal_connect (rtpbin, "on-bye-timeout",
@@ -5786,57 +7899,272 @@ sink_pad_block (GstPad * pad, GstPadProbeInfo * info, gpointer unused)
   return GST_PAD_PROBE_OK;
 }
 
+static void
+peek_sink_buffer (GstWebRTCBin * webrtc, guint rtp_session_id,
+    guint media_idx, WebRTCTransceiver * trans, GstBuffer * buffer)
+{
+  GstRTPBuffer rtp = GST_RTP_BUFFER_INIT;
+  SsrcMapItem *item;
+  guint ssrc;
+
+  if (!gst_rtp_buffer_map (buffer, GST_MAP_READ, &rtp))
+    return;
+  ssrc = gst_rtp_buffer_get_ssrc (&rtp);
+  gst_rtp_buffer_unmap (&rtp);
+
+  if (!ssrc) {
+    GST_WARNING_OBJECT (webrtc,
+        "incoming buffer does not contain a valid ssrc");
+    return;
+  }
+
+  PC_LOCK (webrtc);
+  item =
+      find_or_add_ssrc_map_item (webrtc,
+      GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDONLY, rtp_session_id, ssrc,
+      media_idx);
+  if (item->media_idx == -1) {
+    char *str;
+
+    GST_DEBUG_OBJECT (webrtc, "updating media idx of ssrc item %p to %u", item,
+        media_idx);
+    item->media_idx = media_idx;
+
+    /* ensure that the rtx mapping contains a valid ssrc to use for rtx when
+     * used even when there are no ssrc's in the input/codec preferences caps */
+    str = g_strdup_printf ("%u", ssrc);
+    if (!gst_structure_has_field_typed (trans->local_rtx_ssrc_map, str,
+            G_TYPE_UINT)) {
+      /* TODO: ssrc-collision? */
+      gst_structure_set (trans->local_rtx_ssrc_map, str, G_TYPE_UINT,
+          g_random_int (), NULL);
+      _set_internal_rtpbin_element_props_from_stream (webrtc, trans->stream);
+    }
+    g_free (str);
+  }
+  PC_UNLOCK (webrtc);
+}
+
+static GstPadProbeReturn
+sink_pad_buffer_peek (GstPad * pad, GstPadProbeInfo * info,
+    GstWebRTCBin * webrtc)
+{
+  GstWebRTCBinPad *webrtc_pad = GST_WEBRTC_BIN_PAD (pad);
+  WebRTCTransceiver *trans;
+  guint rtp_session_id, media_idx;
+
+  if (!webrtc_pad->trans)
+    return GST_PAD_PROBE_OK;
+
+  trans = (WebRTCTransceiver *) webrtc_pad->trans;
+  if (!trans->stream)
+    return GST_PAD_PROBE_OK;
+
+  rtp_session_id = trans->stream->session_id;
+  media_idx = webrtc_pad->trans->mline;
+
+  if (media_idx != G_MAXUINT)
+    return GST_PAD_PROBE_OK;
+
+  if (info->type & GST_PAD_PROBE_TYPE_BUFFER) {
+    GstBuffer *buffer = GST_PAD_PROBE_INFO_BUFFER (info);
+    peek_sink_buffer (webrtc, rtp_session_id, media_idx, trans, buffer);
+  } else if (info->type & GST_PAD_PROBE_TYPE_BUFFER_LIST) {
+    GstBufferList *list = GST_PAD_PROBE_INFO_BUFFER_LIST (info);
+    guint i, n;
+
+    n = gst_buffer_list_length (list);
+    for (i = 0; i < n; i++) {
+      GstBuffer *buffer = gst_buffer_list_get (list, i);
+      peek_sink_buffer (webrtc, rtp_session_id, media_idx, trans, buffer);
+    }
+  } else {
+    g_assert_not_reached ();
+  }
+
+  return GST_PAD_PROBE_OK;
+}
+
 static GstPad *
 gst_webrtc_bin_request_new_pad (GstElement * element, GstPadTemplate * templ,
     const gchar * name, const GstCaps * caps)
 {
   GstWebRTCBin *webrtc = GST_WEBRTC_BIN (element);
+  GstWebRTCRTPTransceiver *trans = NULL;
   GstWebRTCBinPad *pad = NULL;
   guint serial;
+  gboolean lock_mline = FALSE;
 
   if (!_have_nice_elements (webrtc) || !_have_dtls_elements (webrtc))
     return NULL;
 
-  if (templ->direction == GST_PAD_SINK ||
-      g_strcmp0 (templ->name_template, "sink_%u") == 0) {
-    GstWebRTCRTPTransceiver *trans;
+  if (templ->direction != GST_PAD_SINK ||
+      g_strcmp0 (templ->name_template, "sink_%u") != 0) {
+    GST_ERROR_OBJECT (element, "Requested pad that shouldn't be requestable");
+    return NULL;
+  }
 
-    GST_OBJECT_LOCK (webrtc);
-    if (name == NULL || strlen (name) < 6 || !g_str_has_prefix (name, "sink_")) {
-      /* no name given when requesting the pad, use next available int */
-      serial = webrtc->priv->max_sink_pad_serial++;
-    } else {
-      /* parse serial number from requested padname */
-      serial = g_ascii_strtoull (&name[5], NULL, 10);
-      if (serial > webrtc->priv->max_sink_pad_serial)
-        webrtc->priv->max_sink_pad_serial = serial;
-    }
-    GST_OBJECT_UNLOCK (webrtc);
+  PC_LOCK (webrtc);
+
+  if (name == NULL || strlen (name) < 6 || !g_str_has_prefix (name, "sink_")) {
+    /* no name given when requesting the pad, use next available int */
+    serial = webrtc->priv->max_sink_pad_serial++;
+  } else {
+    /* parse serial number from requested padname */
+    serial = g_ascii_strtoull (&name[5], NULL, 10);
+    lock_mline = TRUE;
+  }
+
+  if (lock_mline) {
+    GstWebRTCBinPad *pad2;
 
-    pad = _create_pad_for_sdp_media (webrtc, GST_PAD_SINK, serial);
     trans = _find_transceiver_for_mline (webrtc, serial);
-    if (!trans) {
-      trans =
-          GST_WEBRTC_RTP_TRANSCEIVER (_create_webrtc_transceiver (webrtc,
-              GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDRECV, serial));
-      GST_LOG_OBJECT (webrtc, "Created new transceiver %" GST_PTR_FORMAT
-          " for mline %u", trans, serial);
-    } else {
-      GST_LOG_OBJECT (webrtc, "Using existing transceiver %" GST_PTR_FORMAT
-          " for mline %u", trans, serial);
+
+    if (trans) {
+      /* Reject transceivers that are only for receiving ... */
+      if (trans->direction == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_RECVONLY ||
+          trans->direction == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_INACTIVE) {
+        GST_ERROR_OBJECT (element, "Tried to request a new sink pad %s for"
+            " existing m-line %d, but the transceiver's direction is %s",
+            name, serial,
+            gst_webrtc_rtp_transceiver_direction_to_string (trans->direction));
+        goto error_out;
+      }
+
+      /* Reject transceivers that already have a pad allocated */
+      pad2 = _find_pad_for_transceiver (webrtc, GST_PAD_SINK, trans);
+      if (pad2) {
+        GST_ERROR_OBJECT (element, "Trying to request pad %s for m-line %d, "
+            " but the transceiver associated with this m-line already has pad"
+            " %s", name, serial, GST_PAD_NAME (pad2));
+        gst_object_unref (pad2);
+        goto error_out;
+      }
+
+      if (caps) {
+        GST_OBJECT_LOCK (trans);
+        if (trans->codec_preferences &&
+            !gst_caps_can_intersect (caps, trans->codec_preferences)) {
+          GST_ERROR_OBJECT (element, "Tried to request a new sink pad %s for"
+              " existing m-line %d, but requested caps %" GST_PTR_FORMAT
+              " don't match existing codec preferences %" GST_PTR_FORMAT,
+              name, serial, caps, trans->codec_preferences);
+          GST_OBJECT_UNLOCK (trans);
+          goto error_out;
+        }
+        GST_OBJECT_UNLOCK (trans);
+
+        if (trans->kind != GST_WEBRTC_KIND_UNKNOWN) {
+          GstWebRTCKind kind = webrtc_kind_from_caps (caps);
+
+          if (trans->kind != kind) {
+            GST_ERROR_OBJECT (element, "Tried to request a new sink pad %s for"
+                " existing m-line %d, but requested caps %" GST_PTR_FORMAT
+                " don't match transceiver kind %d",
+                name, serial, caps, trans->kind);
+            goto error_out;
+          }
+        }
+      }
+    }
+  }
+
+  /* Let's try to find a free transceiver that matches */
+  if (!trans) {
+    GstWebRTCKind kind = GST_WEBRTC_KIND_UNKNOWN;
+    guint i;
+
+    kind = webrtc_kind_from_caps (caps);
+
+    for (i = 0; i < webrtc->priv->transceivers->len; i++) {
+      GstWebRTCRTPTransceiver *tmptrans =
+          g_ptr_array_index (webrtc->priv->transceivers, i);
+      GstWebRTCBinPad *pad2;
+      gboolean has_matching_caps;
+
+      /* Ignore transceivers with a non-matching kind */
+      if (tmptrans->kind != GST_WEBRTC_KIND_UNKNOWN &&
+          kind != GST_WEBRTC_KIND_UNKNOWN && tmptrans->kind != kind)
+        continue;
+
+      /* Ignore stopped transmitters */
+      if (tmptrans->stopped)
+        continue;
+
+      /* Ignore transceivers that are only for receiving ... */
+      if (tmptrans->direction == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_RECVONLY
+          || tmptrans->direction ==
+          GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_INACTIVE)
+        continue;
+
+      /* Ignore transceivers that already have a pad allocated */
+      pad2 = _find_pad_for_transceiver (webrtc, GST_PAD_SINK, tmptrans);
+      if (pad2) {
+        gst_object_unref (pad2);
+        continue;
+      }
+
+      GST_OBJECT_LOCK (tmptrans);
+      has_matching_caps = (caps && tmptrans->codec_preferences &&
+          !gst_caps_can_intersect (caps, tmptrans->codec_preferences));
+      GST_OBJECT_UNLOCK (tmptrans);
+      /* Ignore transceivers with non-matching caps */
+      if (!has_matching_caps)
+        continue;
+
+      trans = tmptrans;
+      break;
+    }
+  }
+
+  if (!trans) {
+    trans = GST_WEBRTC_RTP_TRANSCEIVER (_create_webrtc_transceiver (webrtc,
+            GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDRECV, -1,
+            webrtc_kind_from_caps (caps), NULL));
+    GST_LOG_OBJECT (webrtc, "Created new transceiver %" GST_PTR_FORMAT, trans);
+  } else {
+    GST_LOG_OBJECT (webrtc, "Using existing transceiver %" GST_PTR_FORMAT
+        " for mline %u", trans, serial);
+    if (caps) {
+      if (!_update_transceiver_kind_from_caps (trans, caps)) {
+        GstWebRTCKind caps_kind = webrtc_kind_from_caps (caps);
+
+        GST_WARNING_OBJECT (webrtc,
+            "Trying to change kind of transceiver %" GST_PTR_FORMAT
+            " at m-line %d from %s (%d) to %s (%d)", trans, serial,
+            gst_webrtc_kind_to_string (trans->kind), trans->kind,
+            gst_webrtc_kind_to_string (caps_kind), caps_kind);
+      }
     }
-    pad->trans = gst_object_ref (trans);
+  }
+  pad = _create_pad_for_sdp_media (webrtc, GST_PAD_SINK, trans, serial, NULL);
+
+  pad->block_id = gst_pad_add_probe (GST_PAD (pad), GST_PAD_PROBE_TYPE_BLOCK |
+      GST_PAD_PROBE_TYPE_BUFFER | GST_PAD_PROBE_TYPE_BUFFER_LIST,
+      (GstPadProbeCallback) sink_pad_block, NULL, NULL);
+  webrtc->priv->pending_sink_transceivers =
+      g_list_append (webrtc->priv->pending_sink_transceivers,
+      gst_object_ref (pad));
 
-    pad->block_id = gst_pad_add_probe (GST_PAD (pad), GST_PAD_PROBE_TYPE_BLOCK |
-        GST_PAD_PROBE_TYPE_BUFFER | GST_PAD_PROBE_TYPE_BUFFER_LIST,
-        (GstPadProbeCallback) sink_pad_block, NULL, NULL);
-    webrtc->priv->pending_sink_transceivers =
-        g_list_append (webrtc->priv->pending_sink_transceivers,
-        gst_object_ref (pad));
-    _add_pad (webrtc, pad);
+  gst_pad_add_probe (GST_PAD (pad),
+      GST_PAD_PROBE_TYPE_BUFFER | GST_PAD_PROBE_TYPE_BUFFER_LIST,
+      (GstPadProbeCallback) sink_pad_buffer_peek, webrtc, NULL);
+
+  if (lock_mline) {
+    WebRTCTransceiver *wtrans = WEBRTC_TRANSCEIVER (trans);
+    wtrans->mline_locked = TRUE;
+    trans->mline = serial;
   }
 
+  PC_UNLOCK (webrtc);
+
+  _add_pad (webrtc, pad);
+
   return GST_PAD (pad);
+
+error_out:
+  PC_UNLOCK (webrtc);
+  return NULL;
 }
 
 static void
@@ -5853,6 +8181,7 @@ gst_webrtc_bin_release_pad (GstElement * element, GstPad * pad)
   if (webrtc_pad->trans)
     gst_object_unref (webrtc_pad->trans);
   webrtc_pad->trans = NULL;
+  gst_caps_replace (&webrtc_pad->received_caps, NULL);
   PC_UNLOCK (webrtc);
 
   _remove_pad (webrtc, webrtc_pad);
@@ -5918,6 +8247,13 @@ gst_webrtc_bin_set_property (GObject * object, guint prop_id,
       webrtc->priv->jb_latency = g_value_get_uint (value);
       _update_rtpstorage_latency (webrtc);
       break;
+    case PROP_ICE_AGENT:
+      webrtc->priv->ice = g_value_get_object (value);
+      break;
+    case PROP_HTTP_PROXY:
+      gst_webrtc_ice_set_http_proxy (webrtc->priv->ice,
+          g_value_get_string (value));
+      break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
       break;
@@ -5992,6 +8328,13 @@ gst_webrtc_bin_get_property (GObject * object, guint prop_id,
     case PROP_LATENCY:
       g_value_set_uint (value, webrtc->priv->jb_latency);
       break;
+    case PROP_SCTP_TRANSPORT:
+      g_value_set_object (value, webrtc->priv->sctp_transport);
+      break;
+    case PROP_HTTP_PROXY:
+      g_value_take_string (value,
+          gst_webrtc_ice_get_http_proxy (webrtc->priv->ice));
+      break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
       break;
@@ -6005,13 +8348,13 @@ gst_webrtc_bin_constructed (GObject * object)
   GstWebRTCBin *webrtc = GST_WEBRTC_BIN (object);
   gchar *name;
 
-  name = g_strdup_printf ("%s:ice", GST_OBJECT_NAME (webrtc));
-  webrtc->priv->ice = gst_webrtc_ice_new (name);
-
+  if (!webrtc->priv->ice) {
+    name = g_strdup_printf ("%s:ice", GST_OBJECT_NAME (webrtc));
+    webrtc->priv->ice = GST_WEBRTC_ICE (gst_webrtc_nice_new (name));
+    g_free (name);
+  }
   gst_webrtc_ice_set_on_ice_candidate (webrtc->priv->ice,
-      (GstWebRTCIceOnCandidateFunc) _on_local_ice_candidate_cb, webrtc, NULL);
-
-  g_free (name);
+      (GstWebRTCICEOnCandidateFunc) _on_local_ice_candidate_cb, webrtc, NULL);
 
   G_OBJECT_CLASS (parent_class)->constructed (object);
 }
@@ -6069,10 +8412,6 @@ gst_webrtc_bin_finalize (GObject * object)
     g_array_free (webrtc->priv->pending_local_ice_candidates, TRUE);
   webrtc->priv->pending_local_ice_candidates = NULL;
 
-  if (webrtc->priv->session_mid_map)
-    g_array_free (webrtc->priv->session_mid_map, TRUE);
-  webrtc->priv->session_mid_map = NULL;
-
   if (webrtc->priv->pending_pads)
     g_list_free_full (webrtc->priv->pending_pads,
         (GDestroyNotify) _free_pending_pad);
@@ -6104,10 +8443,7 @@ gst_webrtc_bin_finalize (GObject * object)
     gst_webrtc_session_description_free (webrtc->priv->last_generated_offer);
   webrtc->priv->last_generated_offer = NULL;
 
-  if (webrtc->priv->stats)
-    gst_structure_free (webrtc->priv->stats);
-  webrtc->priv->stats = NULL;
-
+  g_mutex_clear (DC_GET_LOCK (webrtc));
   g_mutex_clear (ICE_GET_LOCK (webrtc));
   g_mutex_clear (PC_GET_LOCK (webrtc));
   g_cond_clear (PC_GET_COND (webrtc));
@@ -6126,8 +8462,9 @@ gst_webrtc_bin_class_init (GstWebRTCBinClass * klass)
   element_class->change_state = gst_webrtc_bin_change_state;
 
   gst_element_class_add_static_pad_template_with_gtype (element_class,
-      &sink_template, GST_TYPE_WEBRTC_BIN_PAD);
-  gst_element_class_add_static_pad_template (element_class, &src_template);
+      &sink_template, GST_TYPE_WEBRTC_BIN_SINK_PAD);
+  gst_element_class_add_static_pad_template_with_gtype (element_class,
+      &src_template, GST_TYPE_WEBRTC_BIN_SRC_PAD);
 
   gst_element_class_set_metadata (element_class, "WebRTC Bin",
       "Filter/Network/WebRTC", "A bin for webrtc connections",
@@ -6205,6 +8542,10 @@ gst_webrtc_bin_class_init (GstWebRTCBinClass * klass)
       PROP_TURN_SERVER,
       g_param_spec_string ("turn-server", "TURN Server",
           "The TURN server of the form turn(s)://username:password@host:port. "
+          "To use time-limited credentials, the form must be turn(s)://timestamp:"
+          "username:password@host:port. Please note that the ':' character of "
+          "the 'timestamp:username' and the 'password' encoded by base64 should "
+          "be escaped to be parsed properly. "
           "This is a convenience property, use #GstWebRTCBin::add-turn-server "
           "if you wish to use multiple TURN servers",
           NULL, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
@@ -6261,7 +8602,8 @@ gst_webrtc_bin_class_init (GstWebRTCBinClass * klass)
       PROP_ICE_AGENT,
       g_param_spec_object ("ice-agent", "WebRTC ICE agent",
           "The WebRTC ICE agent",
-          GST_TYPE_WEBRTC_ICE, G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
+          GST_TYPE_WEBRTC_ICE,
+          G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS | G_PARAM_CONSTRUCT_ONLY));
 
   /**
    * GstWebRTCBin:latency:
@@ -6275,7 +8617,37 @@ gst_webrtc_bin_class_init (GstWebRTCBinClass * klass)
       PROP_LATENCY,
       g_param_spec_uint ("latency", "Latency",
           "Default duration to buffer in the jitterbuffers (in ms)",
-          0, G_MAXUINT, 200, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+          0, G_MAXUINT, DEFAULT_JB_LATENCY,
+          G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+  /**
+   * GstWebRTCBin:http-proxy:
+   *
+   * A HTTP proxy for use with TURN/TCP of the form
+   * http://[username:password@]hostname[:port]
+   *
+   * Since: 1.22
+   */
+  g_object_class_install_property (gobject_class,
+      PROP_HTTP_PROXY,
+      g_param_spec_string ("http-proxy", "HTTP Proxy",
+          "A HTTP proxy for use with TURN/TCP of the form "
+          "http://[username:password@]hostname[:port]",
+          NULL, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+  /**
+   * GstWebRTCBin:sctp-transport:
+   *
+   * The WebRTC SCTP Transport
+   *
+   * Since: 1.20
+   */
+  g_object_class_install_property (gobject_class,
+      PROP_SCTP_TRANSPORT,
+      g_param_spec_object ("sctp-transport", "WebRTC SCTP Transport",
+          "The WebRTC SCTP Transport",
+          GST_TYPE_WEBRTC_SCTP_TRANSPORT,
+          G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
 
   /**
    * GstWebRTCBin::create-offer:
@@ -6329,7 +8701,8 @@ gst_webrtc_bin_class_init (GstWebRTCBinClass * klass)
    * GstWebRTCBin::add-ice-candidate:
    * @object: the #webrtcbin
    * @mline_index: the index of the media description in the SDP
-   * @ice-candidate: an ice candidate
+   * @ice-candidate: an ice candidate or NULL/"" to mark that no more candidates
+   * will arrive
    */
   gst_webrtc_bin_signals[ADD_ICE_CANDIDATE_SIGNAL] =
       g_signal_new_class_handler ("add-ice-candidate",
@@ -6373,25 +8746,30 @@ gst_webrtc_bin_class_init (GstWebRTCBinClass * klass)
    *  "ssrc"                G_TYPE_STRING               the rtp sequence src in use
    *  "transport-id"        G_TYPE_STRING               identifier for the associated RTCTransportStats for this stream
    *  "codec-id"            G_TYPE_STRING               identifier for the associated RTCCodecStats for this stream
-   *  "fir-count"           G_TYPE_UINT                 FIR requests received by the sender (only for local statistics)
-   *  "pli-count"           G_TYPE_UINT                 PLI requests received by the sender (only for local statistics)
-   *  "nack-count"          G_TYPE_UINT                 NACK requests received by the sender (only for local statistics)
+   *  "kind"                G_TYPE_STRING               either "audio" or "video", depending on the associated transceiver (Since: 1.22)
    *
    * RTCReceivedStreamStats supported fields (https://w3c.github.io/webrtc-stats/#receivedrtpstats-dict*)
    *
-   *  "packets-received"     G_TYPE_UINT64              number of packets received (only for local inbound)
-   *  "bytes-received"       G_TYPE_UINT64              number of bytes received (only for local inbound)
-   *  "packets-lost"         G_TYPE_UINT                number of packets lost
-   *  "jitter"               G_TYPE_DOUBLE              packet jitter measured in secondss
+   *  "packets-received"    G_TYPE_UINT64               number of packets received (only for local inbound)
+   *  "packets-lost"        G_TYPE_INT64                number of packets lost
+   *  "packets-discarded"   G_TYPE_UINT64               number of packets discarded
+   *  "packets-repaired"    G_TYPE_UINT64               number of packets repaired
+   *  "jitter"              G_TYPE_DOUBLE               packet jitter measured in seconds
    *
    * RTCInboundRTPStreamStats supported fields (https://w3c.github.io/webrtc-stats/#inboundrtpstats-dict*)
    *
    *  "remote-id"           G_TYPE_STRING               identifier for the associated RTCRemoteOutboundRTPStreamStats
+   *  "bytes-received"      G_TYPE_UINT64               number of bytes received (only for local inbound)
+   *  "packets-duplicated"  G_TYPE_UINT64               number of packets duplicated
+   *  "fir-count"           G_TYPE_UINT                 FIR packets sent by the receiver
+   *  "pli-count"           G_TYPE_UINT                 PLI packets sent by the receiver
+   *  "nack-count"          G_TYPE_UINT                 NACK packets sent by the receiver
    *
    * RTCRemoteInboundRTPStreamStats supported fields (https://w3c.github.io/webrtc-stats/#remoteinboundrtpstats-dict*)
    *
    *  "local-id"            G_TYPE_STRING               identifier for the associated RTCOutboundRTPSTreamStats
    *  "round-trip-time"     G_TYPE_DOUBLE               round trip time of packets measured in seconds
+   *  "fraction-lost"       G_TYPE_DOUBLE               fraction packet loss
    *
    * RTCSentRTPStreamStats supported fields (https://w3c.github.io/webrtc-stats/#sentrtpstats-dict*)
    *
@@ -6400,12 +8778,31 @@ gst_webrtc_bin_class_init (GstWebRTCBinClass * klass)
    *
    * RTCOutboundRTPStreamStats supported fields (https://w3c.github.io/webrtc-stats/#outboundrtpstats-dict*)
    *
-   *  "remote-id"           G_TYPE_STRING               identifier for the associated RTCRemoteInboundRTPSTreamStats
+   *  "remote-id"           G_TYPE_STRING               identifier for the associated RTCRemoteInboundRTPSTreamStats (optional since 1.22)
+   *  "fir-count"           G_TYPE_UINT                 FIR packets received by the sender
+   *  "pli-count"           G_TYPE_UINT                 PLI packets received by the sender
+   *  "nack-count"          G_TYPE_UINT                 NACK packets received by the sender
    *
    * RTCRemoteOutboundRTPStreamStats supported fields (https://w3c.github.io/webrtc-stats/#remoteoutboundrtpstats-dict*)
    *
    *  "local-id"            G_TYPE_STRING               identifier for the associated RTCInboundRTPSTreamStats
+   *  "remote-timestamp"    G_TYPE_DOUBLE               remote timestamp the statistics were sent by the remote
+   *
+   * RTCIceCandidateStats supported fields (https://www.w3.org/TR/webrtc-stats/#icecandidate-dict*) (Since: 1.22)
    *
+   *  "transport-id"         G_TYPE_STRING              identifier for the associated RTCTransportStats for this stream
+   *  "address"              G_TYPE_STRING              address of the candidate, allowing for IPv4, IPv6 and FQDNs
+   *  "port"                 G_TYPE_UINT                port number of the candidate
+   *  "candidate-type"       G_TYPE_STRING              RTCIceCandidateType
+   *  "priority"             G_TYPE_UINT64              calculated as defined in RFC 5245
+   *  "protocol"             G_TYPE_STRING              Either "udp" or "tcp". Based on the "transport" defined in RFC 5245
+   *  "relay-protocol"       G_TYPE_STRING              protocol used by the endpoint to communicate with the TURN server. Only present for local candidates. Either "udp", "tcp" or "tls"
+   *  "url"                  G_TYPE_STRING              URL of the ICE server from which the candidate was obtained. Only present for local candidates
+   *
+   * RTCIceCandidatePairStats supported fields (https://www.w3.org/TR/webrtc-stats/#candidatepair-dict*) (Since: 1.22)
+   *
+   *  "local-candidate-id"  G_TYPE_STRING               unique identifier that is associated to the object that was inspected to produce the RTCIceCandidateStats for the local candidate associated with this candidate pair.
+   *  "remote-candidate-id" G_TYPE_STRING               unique identifier that is associated to the object that was inspected to produce the RTCIceCandidateStats for the remote candidate associated with this candidate pair.
    */
   gst_webrtc_bin_signals[GET_STATS_SIGNAL] =
       g_signal_new_class_handler ("get-stats",
@@ -6445,13 +8842,46 @@ gst_webrtc_bin_class_init (GstWebRTCBinClass * klass)
   /**
    * GstWebRTCBin::on-data-channel:
    * @object: the #GstWebRTCBin
-   * @candidate: the new `GstWebRTCDataChannel`
+   * @channel: the new `GstWebRTCDataChannel`
    */
   gst_webrtc_bin_signals[ON_DATA_CHANNEL_SIGNAL] =
       g_signal_new ("on-data-channel", G_TYPE_FROM_CLASS (klass),
       G_SIGNAL_RUN_LAST, 0, NULL, NULL, NULL,
       G_TYPE_NONE, 1, GST_TYPE_WEBRTC_DATA_CHANNEL);
 
+  /**
+   * GstWebRTCBin::prepare-data-channel:
+   * @object: the #GstWebRTCBin
+   * @channel: the new `GstWebRTCDataChannel`
+   * @is_local: Whether this channel is local or remote
+   *
+   * Allows data-channel consumers to configure signal handlers on a newly
+   * created data-channel, before any data or state change has been notified.
+   *
+   * Since: 1.22
+   */
+  gst_webrtc_bin_signals[PREPARE_DATA_CHANNEL_SIGNAL] =
+      g_signal_new ("prepare-data-channel", G_TYPE_FROM_CLASS (klass),
+      G_SIGNAL_RUN_LAST, 0, NULL, NULL, NULL, G_TYPE_NONE, 2,
+      GST_TYPE_WEBRTC_DATA_CHANNEL, G_TYPE_BOOLEAN);
+
+   /**
+   * GstWebRTCBin::request-aux-sender:
+   * @object: the #GstWebRTCBin
+   * @dtls-transport: The #GstWebRTCDTLSTransport object for which the aux
+   * sender will be used.
+   *
+   * Request an AUX sender element for the given @dtls-transport.
+   *
+   * Returns: (transfer full): A new GStreamer element
+   *
+   * Since: 1.22
+   */
+  gst_webrtc_bin_signals[REQUEST_AUX_SENDER] =
+      g_signal_new ("request-aux-sender", G_TYPE_FROM_CLASS (klass),
+      G_SIGNAL_RUN_LAST, 0, _gst_element_accumulator, NULL, NULL,
+      GST_TYPE_ELEMENT, 1, GST_TYPE_WEBRTC_DTLS_TRANSPORT);
+
   /**
    * GstWebRTCBin::add-transceiver:
    * @object: the #webrtcbin
@@ -6533,7 +8963,8 @@ gst_webrtc_bin_class_init (GstWebRTCBinClass * klass)
       NULL, GST_TYPE_WEBRTC_DATA_CHANNEL, 2, G_TYPE_STRING, GST_TYPE_STRUCTURE);
 
   gst_type_mark_as_plugin_api (GST_TYPE_WEBRTC_BIN_PAD, 0);
-  gst_type_mark_as_plugin_api (GST_TYPE_WEBRTC_ICE, 0);
+  gst_type_mark_as_plugin_api (GST_TYPE_WEBRTC_BIN_SINK_PAD, 0);
+  gst_type_mark_as_plugin_api (GST_TYPE_WEBRTC_BIN_SRC_PAD, 0);
 }
 
 static void
@@ -6558,11 +8989,6 @@ _transport_free (GObject * object)
     g_signal_handlers_disconnect_by_data (stream->transport->transport, webrtc);
     g_signal_handlers_disconnect_by_data (stream->transport, webrtc);
   }
-  if (stream->rtcp_transport) {
-    g_signal_handlers_disconnect_by_data (stream->rtcp_transport->transport,
-        webrtc);
-    g_signal_handlers_disconnect_by_data (stream->rtcp_transport, webrtc);
-  }
 
   gst_object_unref (object);
 }
@@ -6585,6 +9011,7 @@ gst_webrtc_bin_init (GstWebRTCBin * webrtc)
   g_cond_init (PC_GET_COND (webrtc));
 
   g_mutex_init (ICE_GET_LOCK (webrtc));
+  g_mutex_init (DC_GET_LOCK (webrtc));
 
   webrtc->rtpbin = _create_rtpbin (webrtc);
   gst_bin_add (GST_BIN (webrtc), webrtc->rtpbin);
@@ -6600,11 +9027,6 @@ gst_webrtc_bin_init (GstWebRTCBin * webrtc)
   webrtc->priv->pending_data_channels =
       g_ptr_array_new_with_free_func ((GDestroyNotify) gst_object_unref);
 
-  webrtc->priv->session_mid_map =
-      g_array_new (FALSE, TRUE, sizeof (SessionMidItem));
-  g_array_set_clear_func (webrtc->priv->session_mid_map,
-      (GDestroyNotify) clear_session_mid_item);
-
   webrtc->priv->ice_stream_map =
       g_array_new (FALSE, TRUE, sizeof (IceStreamItem));
   webrtc->priv->pending_remote_ice_candidates =
@@ -6619,4 +9041,5 @@ gst_webrtc_bin_init (GstWebRTCBin * webrtc)
 
   /* we start off closed until we move to READY */
   webrtc->priv->is_closed = TRUE;
+  webrtc->priv->jb_latency = DEFAULT_JB_LATENCY;
 }
diff --git a/ext/webrtc/gstwebrtcbin.h b/ext/webrtc/gstwebrtcbin.h
index e4b462f2e..9445d9e5a 100644
--- a/ext/webrtc/gstwebrtcbin.h
+++ b/ext/webrtc/gstwebrtcbin.h
@@ -22,8 +22,8 @@
 
 #include <gst/sdp/sdp.h>
 #include "fwd.h"
-#include "gstwebrtcice.h"
 #include "transportstream.h"
+#include "webrtcsctptransport.h"
 
 G_BEGIN_DECLS
 
@@ -38,16 +38,17 @@ GType gst_webrtc_bin_pad_get_type(void);
 typedef struct _GstWebRTCBinPad GstWebRTCBinPad;
 typedef struct _GstWebRTCBinPadClass GstWebRTCBinPadClass;
 
+G_DEFINE_AUTOPTR_CLEANUP_FUNC (GstWebRTCBinPad, gst_object_unref);
+
 struct _GstWebRTCBinPad
 {
   GstGhostPad           parent;
 
-  guint                 mlineindex;
-
   GstWebRTCRTPTransceiver *trans;
   gulong                block_id;
 
   GstCaps              *received_caps;
+  char                 *msid;
 };
 
 struct _GstWebRTCBinPadClass
@@ -55,6 +56,14 @@ struct _GstWebRTCBinPadClass
   GstGhostPadClass      parent_class;
 };
 
+G_DECLARE_FINAL_TYPE (GstWebRTCBinSinkPad, gst_webrtc_bin_sink_pad, GST,
+    WEBRTC_BIN_SINK_PAD, GstWebRTCBinPad);
+#define GST_TYPE_WEBRTC_BIN_SINK_PAD (gst_webrtc_bin_sink_pad_get_type())
+
+G_DECLARE_FINAL_TYPE (GstWebRTCBinSrcPad, gst_webrtc_bin_src_pad, GST,
+    WEBRTC_BIN_SRC_PAD, GstWebRTCBinPad);
+#define GST_TYPE_WEBRTC_BIN_SRC_PAD (gst_webrtc_bin_src_pad_get_type())
+
 GType gst_webrtc_bin_get_type(void);
 #define GST_TYPE_WEBRTC_BIN            (gst_webrtc_bin_get_type())
 #define GST_WEBRTC_BIN(obj)            (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_WEBRTC_BIN,GstWebRTCBin))
@@ -94,19 +103,22 @@ struct _GstWebRTCBinClass
 struct _GstWebRTCBinPrivate
 {
   guint max_sink_pad_serial;
+  guint src_pad_counter;
 
   gboolean bundle;
   GPtrArray *transceivers;
-  GArray *session_mid_map;
   GPtrArray *transports;
   GPtrArray *data_channels;
   /* list of data channels we've received a sctp stream for but no data
    * channel protocol for */
   GPtrArray *pending_data_channels;
+  /* dc_lock protects data_channels and pending_data_channels */
+  /* lock ordering is pc_lock first, then dc_lock */
+  GMutex dc_lock;
 
   guint jb_latency;
 
-  GstWebRTCSCTPTransport *sctp_transport;
+  WebRTCSCTPTransport *sctp_transport;
   TransportStream *data_channel_transport;
 
   GstWebRTCICE *ice;
@@ -140,10 +152,10 @@ struct _GstWebRTCBinPrivate
   GstWebRTCSessionDescription *last_generated_offer;
   GstWebRTCSessionDescription *last_generated_answer;
 
-  GstStructure *stats;
+  gboolean tos_attached;
 };
 
-typedef void (*GstWebRTCBinFunc) (GstWebRTCBin * webrtc, gpointer data);
+typedef GstStructure *(*GstWebRTCBinFunc) (GstWebRTCBin * webrtc, gpointer data);
 
 typedef struct
 {
diff --git a/ext/webrtc/gstwebrtcstats.c b/ext/webrtc/gstwebrtcstats.c
index 7ecf9b9aa..5ff2bd6d2 100644
--- a/ext/webrtc/gstwebrtcstats.c
+++ b/ext/webrtc/gstwebrtcstats.c
@@ -31,6 +31,8 @@
 #include "utils.h"
 #include "webrtctransceiver.h"
 
+#include <stdlib.h>
+
 #define GST_CAT_DEFAULT gst_webrtc_stats_debug
 GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
 
@@ -56,7 +58,7 @@ static void
 _set_base_stats (GstStructure * s, GstWebRTCStatsType type, double ts,
     const char *id)
 {
-  gchar *name = _enum_value_to_string (GST_TYPE_WEBRTC_STATS_TYPE,
+  const gchar *name = _enum_value_to_string (GST_TYPE_WEBRTC_STATS_TYPE,
       type);
 
   g_return_if_fail (name != NULL);
@@ -64,8 +66,6 @@ _set_base_stats (GstStructure * s, GstWebRTCStatsType type, double ts,
   gst_structure_set_name (s, name);
   gst_structure_set (s, "type", GST_TYPE_WEBRTC_STATS_TYPE, type, "timestamp",
       G_TYPE_DOUBLE, ts, "id", G_TYPE_STRING, id, NULL);
-
-  g_free (name);
 }
 
 static GstStructure *
@@ -81,19 +81,136 @@ _get_peer_connection_stats (GstWebRTCBin * webrtc)
   return s;
 }
 
+static void
+_gst_structure_take_structure (GstStructure * s, const char *fieldname,
+    GstStructure ** value_s)
+{
+  GValue v = G_VALUE_INIT;
+
+  g_return_if_fail (GST_IS_STRUCTURE (*value_s));
+
+  g_value_init (&v, GST_TYPE_STRUCTURE);
+  g_value_take_boxed (&v, *value_s);
+
+  gst_structure_take_value (s, fieldname, &v);
+
+  *value_s = NULL;
+}
+
 #define CLOCK_RATE_VALUE_TO_SECONDS(v,r) ((double) v / (double) clock_rate)
 #define FIXED_16_16_TO_DOUBLE(v) ((double) ((v & 0xffff0000) >> 16) + ((v & 0xffff) / 65536.0))
 #define FIXED_32_32_TO_DOUBLE(v) ((double) ((v & G_GUINT64_CONSTANT (0xffffffff00000000)) >> 32) + ((v & G_GUINT64_CONSTANT (0xffffffff)) / 4294967296.0))
 
+/* https://www.w3.org/TR/webrtc-stats/#remoteinboundrtpstats-dict* */
+static gboolean
+_get_stats_from_remote_rtp_source_stats (GstWebRTCBin * webrtc,
+    TransportStream * stream, const GstStructure * source_stats,
+    guint ssrc, guint clock_rate, const gchar * codec_id, const gchar * kind,
+    const gchar * transport_id, GstStructure * s)
+{
+  gboolean have_rb = FALSE, internal = FALSE;
+  int lost;
+  GstStructure *r_in;
+  gchar *r_in_id, *out_id;
+  guint32 rtt;
+  guint fraction_lost, jitter;
+  double ts;
+
+  gst_structure_get_double (s, "timestamp", &ts);
+  gst_structure_get (source_stats, "internal", G_TYPE_BOOLEAN, &internal,
+      "have-rb", G_TYPE_BOOLEAN, &have_rb, NULL);
+
+  /* This isn't what we're looking for */
+  if (internal == TRUE || have_rb == FALSE)
+    return FALSE;
+
+  r_in_id = g_strdup_printf ("rtp-remote-inbound-stream-stats_%u", ssrc);
+  out_id = g_strdup_printf ("rtp-outbound-stream-stats_%u", ssrc);
+
+  r_in = gst_structure_new_empty (r_in_id);
+  _set_base_stats (r_in, GST_WEBRTC_STATS_REMOTE_INBOUND_RTP, ts, r_in_id);
+
+  /* RTCRtpStreamStats */
+  gst_structure_set (r_in, "local-id", G_TYPE_STRING, out_id, NULL);
+  gst_structure_set (r_in, "ssrc", G_TYPE_UINT, ssrc, NULL);
+  gst_structure_set (r_in, "codec-id", G_TYPE_STRING, codec_id, NULL);
+  gst_structure_set (r_in, "transport-id", G_TYPE_STRING, transport_id, NULL);
+  if (kind)
+    gst_structure_set (r_in, "kind", G_TYPE_STRING, kind, NULL);
+
+  /* RTCReceivedRtpStreamStats */
+
+  if (gst_structure_get_int (source_stats, "rb-packetslost", &lost))
+    gst_structure_set (r_in, "packets-lost", G_TYPE_INT64, (gint64) lost, NULL);
+
+  if (clock_rate && gst_structure_get_uint (source_stats, "rb-jitter", &jitter))
+    gst_structure_set (r_in, "jitter", G_TYPE_DOUBLE,
+        CLOCK_RATE_VALUE_TO_SECONDS (jitter, clock_rate), NULL);
+
+  /* RTCReceivedRtpStreamStats:
+
+     unsigned long long  packetsReceived;
+     unsigned long      packetsDiscarded;
+     unsigned long      packetsRepaired;
+     unsigned long      burstPacketsLost;
+     unsigned long      burstPacketsDiscarded;
+     unsigned long      burstLossCount;
+     unsigned long      burstDiscardCount;
+     double             burstLossRate;
+     double             burstDiscardRate;
+     double             gapLossRate;
+     double             gapDiscardRate;
+
+     Can't be implemented frame re-assembly happens after rtpbin:
+
+     unsigned long        framesDropped;
+     unsigned long        partialFramesLost;
+     unsigned long        fullFramesLost;
+   */
+
+  /* RTCRemoteInboundRTPStreamStats */
+
+  if (gst_structure_get_uint (source_stats, "rb-fractionlost", &fraction_lost))
+    gst_structure_set (r_in, "fraction-lost", G_TYPE_DOUBLE,
+        (double) fraction_lost / 256.0, NULL);
+
+  if (gst_structure_get_uint (source_stats, "rb-round-trip", &rtt)) {
+    /* 16.16 fixed point to double */
+    double val = FIXED_16_16_TO_DOUBLE (rtt);
+    gst_structure_set (r_in, "round-trip-time", G_TYPE_DOUBLE, val, NULL);
+  }
+
+  /* RTCRemoteInboundRTPStreamStats:
+
+     To be added:
+
+     DOMString            localId;
+     double               totalRoundTripTime;
+     unsigned long long   reportsReceived;
+     unsigned long long   roundTripTimeMeasurements;
+   */
+
+  gst_structure_set (r_in, "gst-rtpsource-stats", GST_TYPE_STRUCTURE,
+      source_stats, NULL);
+
+  _gst_structure_take_structure (s, r_in_id, &r_in);
+
+  g_free (r_in_id);
+  g_free (out_id);
+
+  return TRUE;
+}
+
 /* https://www.w3.org/TR/webrtc-stats/#inboundrtpstats-dict*
    https://www.w3.org/TR/webrtc-stats/#outboundrtpstats-dict* */
 static void
 _get_stats_from_rtp_source_stats (GstWebRTCBin * webrtc,
-    const GstStructure * source_stats, const gchar * codec_id,
-    const gchar * transport_id, GstStructure * s)
+    TransportStream * stream, const GstStructure * source_stats,
+    const gchar * codec_id, const gchar * kind, const gchar * transport_id,
+    GstStructure * s)
 {
   guint ssrc, fir, pli, nack, jitter;
-  int lost, clock_rate;
+  int clock_rate;
   guint64 packets, bytes;
   gboolean internal;
   double ts;
@@ -103,48 +220,10 @@ _get_stats_from_rtp_source_stats (GstWebRTCBin * webrtc,
       G_TYPE_INT, &clock_rate, "internal", G_TYPE_BOOLEAN, &internal, NULL);
 
   if (internal) {
-    GstStructure *r_in, *out;
+    GstStructure *out;
     gchar *out_id, *r_in_id;
 
     out_id = g_strdup_printf ("rtp-outbound-stream-stats_%u", ssrc);
-    r_in_id = g_strdup_printf ("rtp-remote-inbound-stream-stats_%u", ssrc);
-
-    r_in = gst_structure_new_empty (r_in_id);
-    _set_base_stats (r_in, GST_WEBRTC_STATS_REMOTE_INBOUND_RTP, ts, r_in_id);
-
-    /* RTCStreamStats */
-    gst_structure_set (r_in, "local-id", G_TYPE_STRING, out_id, NULL);
-    gst_structure_set (r_in, "ssrc", G_TYPE_UINT, ssrc, NULL);
-    gst_structure_set (r_in, "codec-id", G_TYPE_STRING, codec_id, NULL);
-    gst_structure_set (r_in, "transport-id", G_TYPE_STRING, transport_id, NULL);
-    /* XXX: mediaType, trackId, sliCount, qpSum */
-
-    if (gst_structure_get_uint64 (source_stats, "packets-received", &packets))
-      gst_structure_set (r_in, "packets-received", G_TYPE_UINT64, packets,
-          NULL);
-    if (gst_structure_get_int (source_stats, "packets-lost", &lost))
-      gst_structure_set (r_in, "packets-lost", G_TYPE_INT, lost, NULL);
-    if (gst_structure_get_uint (source_stats, "jitter", &jitter))
-      gst_structure_set (r_in, "jitter", G_TYPE_DOUBLE,
-          CLOCK_RATE_VALUE_TO_SECONDS (jitter, clock_rate), NULL);
-
-/* XXX: RTCReceivedRTPStreamStats
-    double             fractionLost;
-    unsigned long      packetsDiscarded;
-    unsigned long      packetsFailedDecryption;
-    unsigned long      packetsRepaired;
-    unsigned long      burstPacketsLost;
-    unsigned long      burstPacketsDiscarded;
-    unsigned long      burstLossCount;
-    unsigned long      burstDiscardCount;
-    double             burstLossRate;
-    double             burstDiscardRate;
-    double             gapLossRate;
-    double             gapDiscardRate;
-*/
-
-    /* RTCRemoteInboundRTPStreamStats */
-    /* XXX: framesDecoded, lastPacketReceivedTimestamp */
 
     out = gst_structure_new_empty (out_id);
     _set_base_stats (out, GST_WEBRTC_STATS_OUTBOUND_RTP, ts, out_id);
@@ -153,48 +232,115 @@ _get_stats_from_rtp_source_stats (GstWebRTCBin * webrtc,
     gst_structure_set (out, "ssrc", G_TYPE_UINT, ssrc, NULL);
     gst_structure_set (out, "codec-id", G_TYPE_STRING, codec_id, NULL);
     gst_structure_set (out, "transport-id", G_TYPE_STRING, transport_id, NULL);
-    if (gst_structure_get_uint (source_stats, "sent-fir-count", &fir))
-      gst_structure_set (out, "fir-count", G_TYPE_UINT, fir, NULL);
-    if (gst_structure_get_uint (source_stats, "sent-pli-count", &pli))
-      gst_structure_set (out, "pli-count", G_TYPE_UINT, pli, NULL);
-    if (gst_structure_get_uint (source_stats, "sent-nack-count", &nack))
-      gst_structure_set (out, "nack-count", G_TYPE_UINT, nack, NULL);
-    /* XXX: mediaType, trackId, sliCount, qpSum */
+    if (kind)
+      gst_structure_set (out, "kind", G_TYPE_STRING, kind, NULL);
 
-/* RTCSentRTPStreamStats */
+    /* RTCSentRtpStreamStats  */
     if (gst_structure_get_uint64 (source_stats, "octets-sent", &bytes))
       gst_structure_set (out, "bytes-sent", G_TYPE_UINT64, bytes, NULL);
     if (gst_structure_get_uint64 (source_stats, "packets-sent", &packets))
       gst_structure_set (out, "packets-sent", G_TYPE_UINT64, packets, NULL);
-/* XXX:
-    unsigned long      packetsDiscardedOnSend;
-    unsigned long long bytesDiscardedOnSend;
-*/
 
     /* RTCOutboundRTPStreamStats */
-    gst_structure_set (out, "remote-id", G_TYPE_STRING, r_in_id, NULL);
-/* XXX:
-    DOMHighResTimeStamp lastPacketSentTimestamp;
-    double              targetBitrate;
-    unsigned long       framesEncoded;
-    double              totalEncodeTime;
-    double              averageRTCPInterval;
-*/
-    gst_structure_set (s, out_id, GST_TYPE_STRUCTURE, out, NULL);
-    gst_structure_set (s, r_in_id, GST_TYPE_STRUCTURE, r_in, NULL);
 
-    gst_structure_free (out);
-    gst_structure_free (r_in);
+    if (gst_structure_get_uint (source_stats, "recv-fir-count", &fir))
+      gst_structure_set (out, "fir-count", G_TYPE_UINT, fir, NULL);
+    if (gst_structure_get_uint (source_stats, "recv-pli-count", &pli))
+      gst_structure_set (out, "pli-count", G_TYPE_UINT, pli, NULL);
+    if (gst_structure_get_uint (source_stats, "recv-nack-count", &nack))
+      gst_structure_set (out, "nack-count", G_TYPE_UINT, nack, NULL);
+    /* XXX: mediaType, trackId, sliCount, qpSum */
 
-    g_free (out_id);
+    r_in_id = g_strdup_printf ("rtp-remote-inbound-stream-stats_%u", ssrc);
+    if (gst_structure_has_field (s, r_in_id))
+      gst_structure_set (out, "remote-id", G_TYPE_STRING, r_in_id, NULL);
     g_free (r_in_id);
+
+    /*  RTCOutboundRTPStreamStats:
+
+       To be added:
+
+       unsigned long        sliCount;
+       unsigned long        rtxSsrc;
+       DOMString            mediaSourceId;
+       DOMString            senderId;
+       DOMString            remoteId;
+       DOMString            rid;
+       DOMHighResTimeStamp  lastPacketSentTimestamp;
+       unsigned long long   headerBytesSent;
+       unsigned long        packetsDiscardedOnSend;
+       unsigned long long   bytesDiscardedOnSend;
+       unsigned long        fecPacketsSent;
+       unsigned long long   retransmittedPacketsSent;
+       unsigned long long   retransmittedBytesSent;
+       double               averageRtcpInterval;
+       record<USVString, unsigned long long> perDscpPacketsSent;
+
+       Not relevant because webrtcbin doesn't encode:
+
+       double               targetBitrate;
+       unsigned long long   totalEncodedBytesTarget;
+       unsigned long        frameWidth;
+       unsigned long        frameHeight;
+       unsigned long        frameBitDepth;
+       double               framesPerSecond;
+       unsigned long        framesSent;
+       unsigned long        hugeFramesSent;
+       unsigned long        framesEncoded;
+       unsigned long        keyFramesEncoded;
+       unsigned long        framesDiscardedOnSend;
+       unsigned long long   qpSum;
+       unsigned long long   totalSamplesSent;
+       unsigned long long   samplesEncodedWithSilk;
+       unsigned long long   samplesEncodedWithCelt;
+       boolean              voiceActivityFlag;
+       double               totalEncodeTime;
+       double               totalPacketSendDelay;
+       RTCQualityLimitationReason                 qualityLimitationReason;
+       record<DOMString, double> qualityLimitationDurations;
+       unsigned long        qualityLimitationResolutionChanges;
+       DOMString            encoderImplementation;
+     */
+
+    /* Store the raw stats from GStreamer into the structure for advanced
+     * information.
+     */
+    gst_structure_set (out, "gst-rtpsource-stats", GST_TYPE_STRUCTURE,
+        source_stats, NULL);
+
+    _gst_structure_take_structure (s, out_id, &out);
+
+    g_free (out_id);
   } else {
     GstStructure *in, *r_out;
     gchar *r_out_id, *in_id;
-    gboolean have_rb = FALSE, have_sr = FALSE;
+    gboolean have_sr = FALSE;
+    GstStructure *jb_stats = NULL;
+    guint i;
+    guint64 jb_lost, duplicates, late, rtx_success;
 
-    gst_structure_get (source_stats, "have-rb", G_TYPE_BOOLEAN, &have_rb,
-        "have-sr", G_TYPE_BOOLEAN, &have_sr, NULL);
+    gst_structure_get (source_stats, "have-sr", G_TYPE_BOOLEAN, &have_sr, NULL);
+
+    for (i = 0; i < stream->ssrcmap->len; i++) {
+      SsrcMapItem *item = g_ptr_array_index (stream->ssrcmap, i);
+
+      if (item->direction == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_RECVONLY
+          && item->ssrc == ssrc) {
+        GObject *jb = g_weak_ref_get (&item->rtpjitterbuffer);
+
+        if (jb) {
+          g_object_get (jb, "stats", &jb_stats, NULL);
+          g_object_unref (jb);
+        }
+        break;
+      }
+    }
+
+    if (jb_stats)
+      gst_structure_get (jb_stats, "num-lost", G_TYPE_UINT64, &jb_lost,
+          "num-duplicates", G_TYPE_UINT64, &duplicates, "num-late",
+          G_TYPE_UINT64, &late, "rtx-success-count", G_TYPE_UINT64,
+          &rtx_success, NULL);
 
     in_id = g_strdup_printf ("rtp-inbound-stream-stats_%u", ssrc);
     r_out_id = g_strdup_printf ("rtp-remote-outbound-stream-stats_%u", ssrc);
@@ -202,47 +348,116 @@ _get_stats_from_rtp_source_stats (GstWebRTCBin * webrtc,
     in = gst_structure_new_empty (in_id);
     _set_base_stats (in, GST_WEBRTC_STATS_INBOUND_RTP, ts, in_id);
 
-    /* RTCStreamStats */
+    /* RTCRtpStreamStats */
     gst_structure_set (in, "ssrc", G_TYPE_UINT, ssrc, NULL);
     gst_structure_set (in, "codec-id", G_TYPE_STRING, codec_id, NULL);
     gst_structure_set (in, "transport-id", G_TYPE_STRING, transport_id, NULL);
-    if (gst_structure_get_uint (source_stats, "recv-fir-count", &fir))
-      gst_structure_set (in, "fir-count", G_TYPE_UINT, fir, NULL);
-    if (gst_structure_get_uint (source_stats, "recv-pli-count", &pli))
-      gst_structure_set (in, "pli-count", G_TYPE_UINT, pli, NULL);
-    if (gst_structure_get_uint (source_stats, "recv-nack-count", &nack))
-      gst_structure_set (in, "nack-count", G_TYPE_UINT, nack, NULL);
-    /* XXX: mediaType, trackId, sliCount, qpSum */
+    if (kind)
+      gst_structure_set (in, "kind", G_TYPE_STRING, kind, NULL);
+
+    /* RTCReceivedRtpStreamStats */
 
-    /* RTCReceivedRTPStreamStats */
     if (gst_structure_get_uint64 (source_stats, "packets-received", &packets))
       gst_structure_set (in, "packets-received", G_TYPE_UINT64, packets, NULL);
-    if (gst_structure_get_uint64 (source_stats, "octets-received", &bytes))
-      gst_structure_set (in, "bytes-received", G_TYPE_UINT64, bytes, NULL);
-    if (gst_structure_get_int (source_stats, "packets-lost", &lost))
-      gst_structure_set (in, "packets-lost", G_TYPE_INT, lost, NULL);
+    if (jb_stats) {
+      gint64 packets_lost = jb_lost > G_MAXINT64 ?
+          G_MAXINT64 : (gint64) jb_lost;
+      gst_structure_set (in, "packets-lost", G_TYPE_INT64, packets_lost, NULL);
+    }
     if (gst_structure_get_uint (source_stats, "jitter", &jitter))
       gst_structure_set (in, "jitter", G_TYPE_DOUBLE,
           CLOCK_RATE_VALUE_TO_SECONDS (jitter, clock_rate), NULL);
-/*
-    RTCReceivedRTPStreamStats
-    double             fractionLost;
-    unsigned long      packetsDiscarded;
-    unsigned long      packetsFailedDecryption;
-    unsigned long      packetsRepaired;
-    unsigned long      burstPacketsLost;
-    unsigned long      burstPacketsDiscarded;
-    unsigned long      burstLossCount;
-    unsigned long      burstDiscardCount;
-    double             burstLossRate;
-    double             burstDiscardRate;
-    double             gapLossRate;
-    double             gapDiscardRate;
-*/
 
-    /* RTCInboundRTPStreamStats */
+    if (jb_stats)
+      gst_structure_set (in, "packets-discarded", G_TYPE_UINT64, late,
+          "packets-repaired", G_TYPE_UINT64, rtx_success, NULL);
+
+    /*
+       RTCReceivedRtpStreamStats
+
+       To be added:
+
+       unsigned long long   burstPacketsLost;
+       unsigned long long   burstPacketsDiscarded;
+       unsigned long        burstLossCount;
+       unsigned long        burstDiscardCount;
+       double               burstLossRate;
+       double               burstDiscardRate;
+       double               gapLossRate;
+       double               gapDiscardRate;
+
+       Not relevant because webrtcbin doesn't decode:
+
+       unsigned long        framesDropped;
+       unsigned long        partialFramesLost;
+       unsigned long        fullFramesLost;
+     */
+
+    /* RTCInboundRtpStreamStats */
     gst_structure_set (in, "remote-id", G_TYPE_STRING, r_out_id, NULL);
-    /* XXX: framesDecoded, lastPacketReceivedTimestamp */
+
+    if (gst_structure_get_uint64 (source_stats, "octets-received", &bytes))
+      gst_structure_set (in, "bytes-received", G_TYPE_UINT64, bytes, NULL);
+
+    if (gst_structure_get_uint (source_stats, "sent-fir-count", &fir))
+      gst_structure_set (in, "fir-count", G_TYPE_UINT, fir, NULL);
+    if (gst_structure_get_uint (source_stats, "sent-pli-count", &pli))
+      gst_structure_set (in, "pli-count", G_TYPE_UINT, pli, NULL);
+    if (gst_structure_get_uint (source_stats, "sent-nack-count", &nack))
+      gst_structure_set (in, "nack-count", G_TYPE_UINT, nack, NULL);
+    if (jb_stats)
+      gst_structure_set (in, "packets-duplicated", G_TYPE_UINT64, duplicates,
+          NULL);
+
+    /* RTCInboundRtpStreamStats:
+
+       To be added:
+
+       required DOMString   receiverId;
+       double               averageRtcpInterval;
+       unsigned long long   headerBytesReceived;
+       unsigned long long   fecPacketsReceived;
+       unsigned long long   fecPacketsDiscarded;
+       unsigned long long   bytesReceived;
+       unsigned long long   packetsFailedDecryption;
+       record<USVString, unsigned long long> perDscpPacketsReceived;
+       unsigned long        nackCount;
+       unsigned long        firCount;
+       unsigned long        pliCount;
+       unsigned long        sliCount;
+       double               jitterBufferDelay;
+
+       Not relevant because webrtcbin doesn't decode or depayload:
+       unsigned long        framesDecoded;
+       unsigned long        keyFramesDecoded;
+       unsigned long        frameWidth;
+       unsigned long        frameHeight;
+       unsigned long        frameBitDepth;
+       double               framesPerSecond;
+       unsigned long long   qpSum;
+       double               totalDecodeTime;
+       double               totalInterFrameDelay;
+       double               totalSquaredInterFrameDelay;
+       boolean              voiceActivityFlag;
+       DOMHighResTimeStamp  lastPacketReceivedTimestamp;
+       double               totalProcessingDelay;
+       DOMHighResTimeStamp  estimatedPlayoutTimestamp;
+       unsigned long long   jitterBufferEmittedCount;
+       unsigned long long   totalSamplesReceived;
+       unsigned long long   totalSamplesDecoded;
+       unsigned long long   samplesDecodedWithSilk;
+       unsigned long long   samplesDecodedWithCelt;
+       unsigned long long   concealedSamples;
+       unsigned long long   silentConcealedSamples;
+       unsigned long long   concealmentEvents;
+       unsigned long long   insertedSamplesForDeceleration;
+       unsigned long long   removedSamplesForAcceleration;
+       double               audioLevel;
+       double               totalAudioEnergy;
+       double               totalSamplesDuration;
+       unsigned long        framesReceived;
+       DOMString            decoderImplementation;
+     */
 
     r_out = gst_structure_new_empty (r_out_id);
     _set_base_stats (r_out, GST_WEBRTC_STATS_REMOTE_OUTBOUND_RTP, ts, r_out_id);
@@ -251,30 +466,67 @@ _get_stats_from_rtp_source_stats (GstWebRTCBin * webrtc,
     gst_structure_set (r_out, "codec-id", G_TYPE_STRING, codec_id, NULL);
     gst_structure_set (r_out, "transport-id", G_TYPE_STRING, transport_id,
         NULL);
-    if (have_rb) {
-      guint32 rtt;
-      if (gst_structure_get_uint (source_stats, "rb-round-trip", &rtt)) {
-        /* 16.16 fixed point to double */
-        double val = FIXED_16_16_TO_DOUBLE (rtt);
-        gst_structure_set (r_out, "round-trip-time", G_TYPE_DOUBLE, val, NULL);
-      }
-    } else {
-      /* default values */
-      gst_structure_set (r_out, "round-trip-time", G_TYPE_DOUBLE, 0.0, NULL);
-    }
-    /* XXX: mediaType, trackId, sliCount, qpSum */
+    /* XXX: mediaType, trackId */
+
+    /* RTCSentRtpStreamStats */
 
-/* RTCSentRTPStreamStats */
     if (have_sr) {
-      if (gst_structure_get_uint64 (source_stats, "sr-octet-count", &bytes))
-        gst_structure_set (r_out, "bytes-sent", G_TYPE_UINT64, bytes, NULL);
-      if (gst_structure_get_uint64 (source_stats, "sr-packet-count", &packets))
-        gst_structure_set (r_out, "packets-sent", G_TYPE_UINT64, packets, NULL);
+      guint sr_bytes, sr_packets;
+
+      if (gst_structure_get_uint (source_stats, "sr-octet-count", &sr_bytes))
+        gst_structure_set (r_out, "bytes-sent", G_TYPE_UINT, sr_bytes, NULL);
+      if (gst_structure_get_uint (source_stats, "sr-packet-count", &sr_packets))
+        gst_structure_set (r_out, "packets-sent", G_TYPE_UINT, sr_packets,
+            NULL);
     }
-/* XXX:
-    unsigned long      packetsDiscardedOnSend;
-    unsigned long long bytesDiscardedOnSend;
-*/
+
+    /* RTCSentRtpStreamStats:
+
+       To be added:
+
+       unsigned long        rtxSsrc;
+       DOMString            mediaSourceId;
+       DOMString            senderId;
+       DOMString            remoteId;
+       DOMString            rid;
+       DOMHighResTimeStamp  lastPacketSentTimestamp;
+       unsigned long long   headerBytesSent;
+       unsigned long        packetsDiscardedOnSend;
+       unsigned long long   bytesDiscardedOnSend;
+       unsigned long        fecPacketsSent;
+       unsigned long long   retransmittedPacketsSent;
+       unsigned long long   retransmittedBytesSent;
+       double               averageRtcpInterval;
+       unsigned long        sliCount;
+
+       Can't be implemented because we don't decode:
+
+       double               targetBitrate;
+       unsigned long long   totalEncodedBytesTarget;
+       unsigned long        frameWidth;
+       unsigned long        frameHeight;
+       unsigned long        frameBitDepth;
+       double               framesPerSecond;
+       unsigned long        framesSent;
+       unsigned long        hugeFramesSent;
+       unsigned long        framesEncoded;
+       unsigned long        keyFramesEncoded;
+       unsigned long        framesDiscardedOnSend;
+       unsigned long long   qpSum;
+       unsigned long long   totalSamplesSent;
+       unsigned long long   samplesEncodedWithSilk;
+       unsigned long long   samplesEncodedWithCelt;
+       boolean              voiceActivityFlag;
+       double               totalEncodeTime;
+       double               totalPacketSendDelay;
+       RTCQualityLimitationReason                 qualityLimitationReason;
+       record<DOMString, double> qualityLimitationDurations;
+       unsigned long        qualityLimitationResolutionChanges;
+       record<USVString, unsigned long long> perDscpPacketsSent;
+       DOMString            encoderImplementation;
+     */
+
+    /* RTCRemoteOutboundRtpStreamStats */
 
     if (have_sr) {
       guint64 ntptime;
@@ -290,79 +542,177 @@ _get_stats_from_rtp_source_stats (GstWebRTCBin * webrtc,
 
     gst_structure_set (r_out, "local-id", G_TYPE_STRING, in_id, NULL);
 
-    gst_structure_set (s, in_id, GST_TYPE_STRUCTURE, in, NULL);
-    gst_structure_set (s, r_out_id, GST_TYPE_STRUCTURE, r_out, NULL);
+    /* To be added:
+       reportsSent
+     */
 
-    gst_structure_free (in);
-    gst_structure_free (r_out);
+    /* Store the raw stats from GStreamer into the structure for advanced
+     * information.
+     */
+    if (jb_stats)
+      _gst_structure_take_structure (in, "gst-rtpjitterbuffer-stats",
+          &jb_stats);
+
+    gst_structure_set (in, "gst-rtpsource-stats", GST_TYPE_STRUCTURE,
+        source_stats, NULL);
+
+    _gst_structure_take_structure (s, in_id, &in);
+    _gst_structure_take_structure (s, r_out_id, &r_out);
 
     g_free (in_id);
     g_free (r_out_id);
   }
 }
 
+/* https://www.w3.org/TR/webrtc-stats/#icecandidate-dict* */
+static gchar *
+_get_stats_from_ice_candidates (GstWebRTCBin * webrtc,
+    GstWebRTCICECandidateStats * can, const gchar * transport_id,
+    const gchar * candidate_tag, GstStructure * s)
+{
+  GstStructure *stats;
+  GstWebRTCStatsType type;
+  gchar *id;
+  double ts;
+
+  gst_structure_get_double (s, "timestamp", &ts);
+
+  id = g_strdup_printf ("ice-candidate-%s_%u_%s_%u", candidate_tag,
+      can->stream_id, can->ipaddr, can->port);
+  stats = gst_structure_new_empty (id);
+
+  if (strcmp (candidate_tag, "local")) {
+    type = GST_WEBRTC_STATS_LOCAL_CANDIDATE;
+  } else if (strcmp (candidate_tag, "remote")) {
+    type = GST_WEBRTC_STATS_REMOTE_CANDIDATE;
+  } else {
+    GST_WARNING_OBJECT (webrtc, "Invalid ice candidate tag: %s", candidate_tag);
+    return NULL;
+  }
+  _set_base_stats (stats, type, ts, id);
+
+  /* RTCIceCandidateStats
+     DOMString           transportId;
+     DOMString           address;
+     long                port;
+     DOMString           protocol;
+     RTCIceCandidateType candidateType;
+     long                priority;
+     DOMString           url;
+     DOMString           relayProtocol;
+   */
+
+  if (transport_id)
+    gst_structure_set (stats, "transport-id", G_TYPE_STRING, transport_id,
+        NULL);
+  gst_structure_set (stats, "address", G_TYPE_STRING, can->ipaddr, NULL);
+  gst_structure_set (stats, "port", G_TYPE_UINT, can->port, NULL);
+  gst_structure_set (stats, "candidate-type", G_TYPE_STRING, can->type, NULL);
+  gst_structure_set (stats, "priority", G_TYPE_UINT, can->prio, NULL);
+  gst_structure_set (stats, "protocol", G_TYPE_STRING, can->proto, NULL);
+  if (can->relay_proto)
+    gst_structure_set (stats, "relay-protocol", G_TYPE_STRING, can->relay_proto,
+        NULL);
+  if (can->url)
+    gst_structure_set (stats, "url", G_TYPE_STRING, can->url, NULL);
+
+  gst_structure_set (s, id, GST_TYPE_STRUCTURE, stats, NULL);
+  gst_structure_free (stats);
+
+  return id;
+}
+
 /* https://www.w3.org/TR/webrtc-stats/#candidatepair-dict* */
 static gchar *
 _get_stats_from_ice_transport (GstWebRTCBin * webrtc,
-    GstWebRTCICETransport * transport, GstStructure * s)
+    GstWebRTCICETransport * transport, GstWebRTCICEStream * stream,
+    const GstStructure * twcc_stats, const gchar * transport_id,
+    GstStructure * s)
 {
   GstStructure *stats;
   gchar *id;
+  gchar *local_cand_id = NULL, *remote_cand_id = NULL;
   double ts;
+  GstWebRTCICECandidateStats *local_cand = NULL, *remote_cand = NULL;
 
   gst_structure_get_double (s, "timestamp", &ts);
 
   id = g_strdup_printf ("ice-candidate-pair_%s", GST_OBJECT_NAME (transport));
   stats = gst_structure_new_empty (id);
-  _set_base_stats (stats, GST_WEBRTC_STATS_TRANSPORT, ts, id);
+  _set_base_stats (stats, GST_WEBRTC_STATS_CANDIDATE_PAIR, ts, id);
+
+  /* RTCIceCandidatePairStats
+     DOMString                     transportId;
+     DOMString                     localCandidateId;
+     DOMString                     remoteCandidateId;
+
+     XXX: To be added:
+
+     RTCStatsIceCandidatePairState state;
+     boolean                       nominated;
+     unsigned long                 packetsSent;
+     unsigned long                 packetsReceived;
+     unsigned long long            bytesSent;
+     unsigned long long            bytesReceived;
+     DOMHighResTimeStamp           lastPacketSentTimestamp;
+     DOMHighResTimeStamp           lastPacketReceivedTimestamp;
+     DOMHighResTimeStamp           firstRequestTimestamp;
+     DOMHighResTimeStamp           lastRequestTimestamp;
+     DOMHighResTimeStamp           lastResponseTimestamp;
+     double                        totalRoundTripTime;
+     double                        currentRoundTripTime;
+     double                        availableOutgoingBitrate;
+     double                        availableIncomingBitrate;
+     unsigned long                 circuitBreakerTriggerCount;
+     unsigned long long            requestsReceived;
+     unsigned long long            requestsSent;
+     unsigned long long            responsesReceived;
+     unsigned long long            responsesSent;
+     unsigned long long            retransmissionsReceived;
+     unsigned long long            retransmissionsSent;
+     unsigned long long            consentRequestsSent;
+     DOMHighResTimeStamp           consentExpiredTimestamp;
+     unsigned long                 packetsDiscardedOnSend;
+     unsigned long long            bytesDiscardedOnSend;
+     unsigned long long            requestBytesSent;
+     unsigned long long            consentRequestBytesSent;
+     unsigned long long            responseBytesSent;
+   */
+
+  if (gst_webrtc_ice_get_selected_pair (webrtc->priv->ice, stream,
+          &local_cand, &remote_cand)) {
+    local_cand_id =
+        _get_stats_from_ice_candidates (webrtc, local_cand, transport_id,
+        "local", s);
+    remote_cand_id =
+        _get_stats_from_ice_candidates (webrtc, remote_cand, transport_id,
+        "remote", s);
+
+    gst_structure_set (stats, "local-candidate-id", G_TYPE_STRING,
+        local_cand_id, NULL);
+    gst_structure_set (stats, "remote-candidate-id", G_TYPE_STRING,
+        remote_cand_id, NULL);
+  } else
+    GST_INFO_OBJECT (webrtc,
+        "No selected ICE candidate pair was found for transport %s",
+        GST_OBJECT_NAME (transport));
+
+  /* XXX: these stats are at the rtp session level but there isn't a specific
+   * stats structure for that. The RTCIceCandidatePairStats is the closest with
+   * the 'availableIncomingBitrate' and 'availableOutgoingBitrate' fields
+   */
+  if (twcc_stats)
+    gst_structure_set (stats, "gst-twcc-stats", GST_TYPE_STRUCTURE, twcc_stats,
+        NULL);
 
-/* XXX: RTCIceCandidatePairStats
-    DOMString                     transportId;
-    DOMString                     localCandidateId;
-    DOMString                     remoteCandidateId;
-    RTCStatsIceCandidatePairState state;
-    unsigned long long            priority;
-    boolean                       nominated;
-    unsigned long                 packetsSent;
-    unsigned long                 packetsReceived;
-    unsigned long long            bytesSent;
-    unsigned long long            bytesReceived;
-    DOMHighResTimeStamp           lastPacketSentTimestamp;
-    DOMHighResTimeStamp           lastPacketReceivedTimestamp;
-    DOMHighResTimeStamp           firstRequestTimestamp;
-    DOMHighResTimeStamp           lastRequestTimestamp;
-    DOMHighResTimeStamp           lastResponseTimestamp;
-    double                        totalRoundTripTime;
-    double                        currentRoundTripTime;
-    double                        availableOutgoingBitrate;
-    double                        availableIncomingBitrate;
-    unsigned long                 circuitBreakerTriggerCount;
-    unsigned long long            requestsReceived;
-    unsigned long long            requestsSent;
-    unsigned long long            responsesReceived;
-    unsigned long long            responsesSent;
-    unsigned long long            retransmissionsReceived;
-    unsigned long long            retransmissionsSent;
-    unsigned long long            consentRequestsSent;
-    DOMHighResTimeStamp           consentExpiredTimestamp;
-*/
+  gst_structure_set (s, id, GST_TYPE_STRUCTURE, stats, NULL);
 
-/* XXX: RTCIceCandidateStats
-    DOMString           transportId;
-    boolean             isRemote;
-    RTCNetworkType      networkType;
-    DOMString           ip;
-    long                port;
-    DOMString           protocol;
-    RTCIceCandidateType candidateType;
-    long                priority;
-    DOMString           url;
-    DOMString           relayProtocol;
-    boolean             deleted = false;
-};
-*/
+  g_free (local_cand_id);
+  g_free (remote_cand_id);
+
+  gst_webrtc_ice_candidate_stats_free (local_cand);
+  gst_webrtc_ice_candidate_stats_free (remote_cand);
 
-  gst_structure_set (s, id, GST_TYPE_STRUCTURE, stats, NULL);
   gst_structure_free (stats);
 
   return id;
@@ -371,7 +721,8 @@ _get_stats_from_ice_transport (GstWebRTCBin * webrtc,
 /* https://www.w3.org/TR/webrtc-stats/#dom-rtctransportstats */
 static gchar *
 _get_stats_from_dtls_transport (GstWebRTCBin * webrtc,
-    GstWebRTCDTLSTransport * transport, GstStructure * s)
+    GstWebRTCDTLSTransport * transport, GstWebRTCICEStream * stream,
+    const GstStructure * twcc_stats, GstStructure * s)
 {
   GstStructure *stats;
   gchar *id;
@@ -404,94 +755,34 @@ _get_stats_from_dtls_transport (GstWebRTCBin * webrtc,
     DOMString issuerCertificateId;
 */
 
-/* XXX: RTCIceCandidateStats
-    DOMString           transportId;
-    boolean             isRemote;
-    DOMString           ip;
-    long                port;
-    DOMString           protocol;
-    RTCIceCandidateType candidateType;
-    long                priority;
-    DOMString           url;
-    boolean             deleted = false;
-*/
+  ice_id =
+      _get_stats_from_ice_transport (webrtc, transport->transport, stream,
+      twcc_stats, id, s);
+  if (ice_id) {
+    gst_structure_set (stats, "selected-candidate-pair-id", G_TYPE_STRING,
+        ice_id, NULL);
+    g_free (ice_id);
+  }
 
   gst_structure_set (s, id, GST_TYPE_STRUCTURE, stats, NULL);
   gst_structure_free (stats);
 
-  ice_id = _get_stats_from_ice_transport (webrtc, transport->transport, s);
-  g_free (ice_id);
-
   return id;
 }
 
-static void
-_get_stats_from_transport_channel (GstWebRTCBin * webrtc,
-    TransportStream * stream, const gchar * codec_id, guint ssrc,
-    GstStructure * s)
-{
-  GstWebRTCDTLSTransport *transport;
-  GObject *rtp_session;
-  GstStructure *rtp_stats;
-  GValueArray *source_stats;
-  gchar *transport_id;
-  double ts;
-  int i;
-
-  gst_structure_get_double (s, "timestamp", &ts);
-
-  transport = stream->transport;
-  if (!transport)
-    transport = stream->transport;
-  if (!transport)
-    return;
-
-  g_signal_emit_by_name (webrtc->rtpbin, "get-internal-session",
-      stream->session_id, &rtp_session);
-  g_object_get (rtp_session, "stats", &rtp_stats, NULL);
-
-  gst_structure_get (rtp_stats, "source-stats", G_TYPE_VALUE_ARRAY,
-      &source_stats, NULL);
-
-  GST_DEBUG_OBJECT (webrtc, "retrieving rtp stream stats from transport %"
-      GST_PTR_FORMAT " rtp session %" GST_PTR_FORMAT " with %u rtp sources, "
-      "transport %" GST_PTR_FORMAT, stream, rtp_session, source_stats->n_values,
-      transport);
-
-  transport_id = _get_stats_from_dtls_transport (webrtc, transport, s);
-
-  /* construct stats objects */
-  for (i = 0; i < source_stats->n_values; i++) {
-    const GstStructure *stats;
-    const GValue *val = g_value_array_get_nth (source_stats, i);
-    guint stats_ssrc = 0;
-
-    stats = gst_value_get_structure (val);
-
-    /* skip foreign sources */
-    gst_structure_get (stats, "ssrc", G_TYPE_UINT, &stats_ssrc, NULL);
-    if (ssrc && stats_ssrc && ssrc != stats_ssrc)
-      continue;
-
-    _get_stats_from_rtp_source_stats (webrtc, stats, codec_id, transport_id, s);
-  }
-
-  g_object_unref (rtp_session);
-  gst_structure_free (rtp_stats);
-  g_value_array_free (source_stats);
-  g_free (transport_id);
-}
-
 /* https://www.w3.org/TR/webrtc-stats/#codec-dict* */
-static void
+static gboolean
 _get_codec_stats_from_pad (GstWebRTCBin * webrtc, GstPad * pad,
-    GstStructure * s, gchar ** out_id, guint * out_ssrc)
+    GstStructure * s, gchar ** out_id, guint * out_ssrc, guint * out_clock_rate)
 {
+  GstWebRTCBinPad *wpad = GST_WEBRTC_BIN_PAD (pad);
   GstStructure *stats;
-  GstCaps *caps;
+  GstCaps *caps = NULL;
   gchar *id;
   double ts;
   guint ssrc = 0;
+  gint clock_rate = 0;
+  gboolean has_caps_ssrc = FALSE;
 
   gst_structure_get_double (s, "timestamp", &ts);
 
@@ -499,10 +790,15 @@ _get_codec_stats_from_pad (GstWebRTCBin * webrtc, GstPad * pad,
   id = g_strdup_printf ("codec-stats-%s", GST_OBJECT_NAME (pad));
   _set_base_stats (stats, GST_WEBRTC_STATS_CODEC, ts, id);
 
-  caps = gst_pad_get_current_caps (pad);
+  if (wpad->received_caps)
+    caps = gst_caps_ref (wpad->received_caps);
+  GST_DEBUG_OBJECT (pad, "Pad caps are: %" GST_PTR_FORMAT, caps);
   if (caps && gst_caps_is_fixed (caps)) {
     GstStructure *caps_s = gst_caps_get_structure (caps, 0);
-    gint pt, clock_rate;
+    gint pt;
+    const gchar *encoding_name, *media, *encoding_params;
+    GstSDPMedia sdp_media = { 0 };
+    guint channels = 0;
 
     if (gst_structure_get_int (caps_s, "payload", &pt))
       gst_structure_set (stats, "payload-type", G_TYPE_UINT, pt, NULL);
@@ -510,10 +806,45 @@ _get_codec_stats_from_pad (GstWebRTCBin * webrtc, GstPad * pad,
     if (gst_structure_get_int (caps_s, "clock-rate", &clock_rate))
       gst_structure_set (stats, "clock-rate", G_TYPE_UINT, clock_rate, NULL);
 
-    if (gst_structure_get_uint (caps_s, "ssrc", &ssrc))
+    if (gst_structure_get_uint (caps_s, "ssrc", &ssrc)) {
       gst_structure_set (stats, "ssrc", G_TYPE_UINT, ssrc, NULL);
+      has_caps_ssrc = TRUE;
+    }
+
+    media = gst_structure_get_string (caps_s, "media");
+    encoding_name = gst_structure_get_string (caps_s, "encoding-name");
+    encoding_params = gst_structure_get_string (caps_s, "encoding-params");
+
+    if (media || encoding_name) {
+      gchar *mime_type;
+
+      mime_type = g_strdup_printf ("%s/%s", media ? media : "",
+          encoding_name ? encoding_name : "");
+      gst_structure_set (stats, "mime-type", G_TYPE_STRING, mime_type, NULL);
+      g_free (mime_type);
+    }
+
+    if (encoding_params)
+      channels = atoi (encoding_params);
+    if (channels)
+      gst_structure_set (stats, "channels", G_TYPE_UINT, channels, NULL);
+
+    if (gst_pad_get_direction (pad) == GST_PAD_SRC)
+      gst_structure_set (stats, "codec-type", G_TYPE_STRING, "decode", NULL);
+    else
+      gst_structure_set (stats, "codec-type", G_TYPE_STRING, "encode", NULL);
+
+    gst_sdp_media_init (&sdp_media);
+    if (gst_sdp_media_set_media_from_caps (caps, &sdp_media) == GST_SDP_OK) {
+      const gchar *fmtp = gst_sdp_media_get_attribute_val (&sdp_media, "fmtp");
+
+      if (fmtp) {
+        gst_structure_set (stats, "sdp-fmtp-line", G_TYPE_STRING, fmtp, NULL);
+      }
+    }
+    gst_sdp_media_uninit (&sdp_media);
 
-    /* FIXME: codecType, mimeType, channels, sdpFmtpLine, implementation, transportId */
+    /* FIXME: transportId */
   }
 
   if (caps)
@@ -529,34 +860,139 @@ _get_codec_stats_from_pad (GstWebRTCBin * webrtc, GstPad * pad,
 
   if (out_ssrc)
     *out_ssrc = ssrc;
+
+  if (out_clock_rate)
+    *out_clock_rate = clock_rate;
+
+  return has_caps_ssrc;
+}
+
+struct transport_stream_stats
+{
+  GstWebRTCBin *webrtc;
+  TransportStream *stream;
+  char *transport_id;
+  char *codec_id;
+  const char *kind;
+  guint clock_rate;
+  GValueArray *source_stats;
+  GstStructure *s;
+};
+
+static gboolean
+webrtc_stats_get_from_transport (SsrcMapItem * entry,
+    struct transport_stream_stats *ts_stats)
+{
+  double ts;
+  int i;
+
+  gst_structure_get_double (ts_stats->s, "timestamp", &ts);
+
+  /* construct stats objects */
+  for (i = 0; i < ts_stats->source_stats->n_values; i++) {
+    const GstStructure *stats;
+    const GValue *val = g_value_array_get_nth (ts_stats->source_stats, i);
+    guint stats_ssrc = 0;
+
+    stats = gst_value_get_structure (val);
+
+    /* skip foreign sources */
+    if (gst_structure_get_uint (stats, "ssrc", &stats_ssrc) &&
+        entry->ssrc == stats_ssrc)
+      _get_stats_from_rtp_source_stats (ts_stats->webrtc, ts_stats->stream,
+          stats, ts_stats->codec_id, ts_stats->kind, ts_stats->transport_id,
+          ts_stats->s);
+    else if (gst_structure_get_uint (stats, "rb-ssrc", &stats_ssrc)
+        && entry->ssrc == stats_ssrc)
+      _get_stats_from_remote_rtp_source_stats (ts_stats->webrtc,
+          ts_stats->stream, stats, entry->ssrc, ts_stats->clock_rate,
+          ts_stats->codec_id, ts_stats->kind, ts_stats->transport_id,
+          ts_stats->s);
+  }
+
+  /* we want to look at all the entries */
+  return FALSE;
 }
 
 static gboolean
 _get_stats_from_pad (GstWebRTCBin * webrtc, GstPad * pad, GstStructure * s)
 {
   GstWebRTCBinPad *wpad = GST_WEBRTC_BIN_PAD (pad);
-  TransportStream *stream;
-  gchar *codec_id;
-  guint ssrc;
+  struct transport_stream_stats ts_stats = { NULL, };
+  guint ssrc, clock_rate;
+  GObject *rtp_session;
+  GObject *gst_rtp_session;
+  GstStructure *rtp_stats, *twcc_stats;
+  GstWebRTCKind kind;
 
-  _get_codec_stats_from_pad (webrtc, pad, s, &codec_id, &ssrc);
+  _get_codec_stats_from_pad (webrtc, pad, s, &ts_stats.codec_id, &ssrc,
+      &clock_rate);
 
   if (!wpad->trans)
     goto out;
 
-  stream = WEBRTC_TRANSCEIVER (wpad->trans)->stream;
-  if (!stream)
+  g_object_get (wpad->trans, "kind", &kind, NULL);
+  switch (kind) {
+    case GST_WEBRTC_KIND_AUDIO:
+      ts_stats.kind = "audio";
+      break;
+    case GST_WEBRTC_KIND_VIDEO:
+      ts_stats.kind = "video";
+      break;
+    case GST_WEBRTC_KIND_UNKNOWN:
+      ts_stats.kind = NULL;
+      break;
+  };
+
+  ts_stats.stream = WEBRTC_TRANSCEIVER (wpad->trans)->stream;
+  if (!ts_stats.stream)
     goto out;
 
-  _get_stats_from_transport_channel (webrtc, stream, codec_id, ssrc, s);
+  if (wpad->trans->mline == G_MAXUINT)
+    goto out;
+
+  if (!ts_stats.stream->transport)
+    goto out;
+
+  g_signal_emit_by_name (webrtc->rtpbin, "get-internal-session",
+      ts_stats.stream->session_id, &rtp_session);
+  g_object_get (rtp_session, "stats", &rtp_stats, NULL);
+  g_signal_emit_by_name (webrtc->rtpbin, "get-session",
+      ts_stats.stream->session_id, &gst_rtp_session);
+  g_object_get (gst_rtp_session, "twcc-stats", &twcc_stats, NULL);
+
+  gst_structure_get (rtp_stats, "source-stats", G_TYPE_VALUE_ARRAY,
+      &ts_stats.source_stats, NULL);
+
+  ts_stats.transport_id =
+      _get_stats_from_dtls_transport (webrtc, ts_stats.stream->transport,
+      GST_WEBRTC_ICE_STREAM (ts_stats.stream->stream), twcc_stats, s);
+
+  GST_DEBUG_OBJECT (webrtc, "retrieving rtp stream stats from transport %"
+      GST_PTR_FORMAT " rtp session %" GST_PTR_FORMAT " with %u rtp sources, "
+      "transport %" GST_PTR_FORMAT, ts_stats.stream, rtp_session,
+      ts_stats.source_stats->n_values, ts_stats.stream->transport);
+
+  ts_stats.s = s;
+
+  transport_stream_find_ssrc_map_item (ts_stats.stream, &ts_stats,
+      (FindSsrcMapFunc) webrtc_stats_get_from_transport);
+
+  g_clear_object (&rtp_session);
+  g_clear_object (&gst_rtp_session);
+  gst_clear_structure (&rtp_stats);
+  gst_clear_structure (&twcc_stats);
+  g_value_array_free (ts_stats.source_stats);
+  ts_stats.source_stats = NULL;
+  g_clear_pointer (&ts_stats.transport_id, g_free);
 
 out:
-  g_free (codec_id);
+  g_clear_pointer (&ts_stats.codec_id, g_free);
   return TRUE;
 }
 
-void
-gst_webrtc_bin_update_stats (GstWebRTCBin * webrtc)
+GstStructure *
+gst_webrtc_bin_create_stats (GstWebRTCBin * webrtc, GstPad * pad)
 {
   GstStructure *s = gst_structure_new_empty ("application/x-webrtc-stats");
   double ts = monotonic_time_as_double_milliseconds ();
@@ -579,12 +1015,13 @@ gst_webrtc_bin_update_stats (GstWebRTCBin * webrtc)
     gst_structure_free (pc_stats);
   }
 
-  gst_element_foreach_pad (GST_ELEMENT (webrtc),
-      (GstElementForeachPadFunc) _get_stats_from_pad, s);
+  if (pad)
+    _get_stats_from_pad (webrtc, pad, s);
+  else
+    gst_element_foreach_pad (GST_ELEMENT (webrtc),
+        (GstElementForeachPadFunc) _get_stats_from_pad, s);
 
   gst_structure_remove_field (s, "timestamp");
 
-  if (webrtc->priv->stats)
-    gst_structure_free (webrtc->priv->stats);
-  webrtc->priv->stats = s;
+  return s;
 }
diff --git a/ext/webrtc/gstwebrtcstats.h b/ext/webrtc/gstwebrtcstats.h
index e67ba47d6..0573df76c 100644
--- a/ext/webrtc/gstwebrtcstats.h
+++ b/ext/webrtc/gstwebrtcstats.h
@@ -28,7 +28,8 @@
 G_BEGIN_DECLS
 
 G_GNUC_INTERNAL
-void        gst_webrtc_bin_update_stats         (GstWebRTCBin * webrtc);
+GstStructure *     gst_webrtc_bin_create_stats         (GstWebRTCBin * webrtc,
+                                                        GstPad * pad);
 
 G_END_DECLS
 
diff --git a/ext/webrtc/meson.build b/ext/webrtc/meson.build
index 3e7a5d1d8..151cb9a8e 100644
--- a/ext/webrtc/meson.build
+++ b/ext/webrtc/meson.build
@@ -1,10 +1,7 @@
 webrtc_sources = [
   'gstwebrtc.c',
-  'gstwebrtcice.c',
   'gstwebrtcstats.c',
-  'icestream.c',
-  'nicetransport.c',
-  'sctptransport.c',
+  'webrtcsctptransport.c',
   'gstwebrtcbin.c',
   'transportreceivebin.c',
   'transportsendbin.c',
@@ -15,20 +12,20 @@ webrtc_sources = [
   'webrtcdatachannel.c',
 ]
 
-libnice_dep = dependency('nice', version : '>=0.1.14', required : get_option('webrtc'),
-                         fallback : ['libnice', 'libnice_dep'],
-                         default_options: ['tests=disabled'])
-
-if libnice_dep.found()
-  gstwebrtc_plugin = library('gstwebrtc',
-    webrtc_sources,
-    c_args : gst_plugins_bad_args + ['-DGST_USE_UNSTABLE_API'],
-    include_directories : [configinc],
-    dependencies : [gio_dep, libnice_dep, gstbase_dep, gstsdp_dep,
-                    gstapp_dep, gstwebrtc_dep, gstsctp_dep],
-    install : true,
-    install_dir : plugins_install_dir,
-  )
-  pkgconfig.generate(gstwebrtc_plugin, install_dir : plugins_pkgconfig_install_dir)
-  plugins += [gstwebrtc_plugin]
+webrtc_option = get_option('webrtc').require(
+  libgstwebrtcnice_dep.found(), error_message: 'webrtc plugin requires libgstwebrtcnice.')
+if webrtc_option.disabled()
+  subdir_done()
 endif
+
+gstwebrtc_plugin = library('gstwebrtc',
+  webrtc_sources,
+  c_args : gst_plugins_bad_args + ['-DGST_USE_UNSTABLE_API'],
+  include_directories : [configinc],
+  dependencies : [gstbase_dep, gstsdp_dep,
+                  gstapp_dep, gstwebrtc_dep, gstsctp_dep, gstrtp_dep, gio_dep, libgstwebrtcnice_dep],
+  install : true,
+  install_dir : plugins_install_dir,
+)
+plugins += [gstwebrtc_plugin]
+
diff --git a/ext/webrtc/transportreceivebin.c b/ext/webrtc/transportreceivebin.c
index 6d38a8325..8f8a44452 100644
--- a/ext/webrtc/transportreceivebin.c
+++ b/ext/webrtc/transportreceivebin.c
@@ -23,26 +23,19 @@
 
 #include "transportreceivebin.h"
 #include "utils.h"
+#include "gst/webrtc/webrtc-priv.h"
 
 /*
- * ,----------------------------transport_receive_%u---------------------------,
- * ;     (rtp/data)                                                            ;
- * ;  ,-nicesrc-, ,-capsfilter-, ,--queue--, ,-dtlssrtpdec-,       ,-funnel-,  ;
- * ;  ;     src o-o sink   src o-osink  srco-osink  rtp_srco-------o sink_0 ;  ;
- * ;  '---------' '------------' '---------' ;             ;       ;    src o--o rtp_src
- * ;                                         ;     rtcp_srco---, ,-o sink_1 ;  ;
- * ;                                         ;             ;   ; ; '--------'  ;
- * ;                                         ;     data_srco-, ; ; ,-funnel-,  ;
- * ;     (rtcp)                              '-------------' ; '-+-o sink_0 ;  ;
- * ;  ,-nicesrc-, ,-capsfilter-, ,--queue--, ,-dtlssrtpdec-, ; ,-' ;    src o--o rtcp_src
- * ;  ;     src o-o sink   src o-osink  srco-osink  rtp_srco-+-' ,-o sink_1 ;  ;
- * ;  '---------' '------------' '---------' ;             ; ;   ; '--------'  ;
- * ;                                         ;     rtcp_srco-+---' ,-funnel-,  ;
- * ;                                         ;             ; '-----o sink_0 ;  ;
- * ;                                         ;     data_srco-,     ;    src o--o data_src
- * ;                                         '-------------' '-----o sink_1 ;  ;
- * ;                                                               '--------'  ;
- * '---------------------------------------------------------------------------'
+ * ,-----------------------transport_receive_%u------------------,
+ * ;                                                             ;
+ * ;  ,-nicesrc-, ,-capsfilter-, ,---queue---, ,-dtlssrtpdec-,   ;
+ * ;  ;     src o-o sink   src o-o sink  src o-osink  rtp_srco---o rtp_src
+ * ;  '---------' '------------' '-----------' ;             ;   ; 
+ * ;                                           ;     rtcp_srco---o rtcp_src
+ * ;                                           ;             ;   ;
+ * ;                                           ;     data_srco---o data_src
+ * ;                                           '-------------'   ;
+ * '-------------------------------------------------------------'
  *
  * Do we really wnat to be *that* permissive in what we accept?
  *
@@ -103,7 +96,7 @@ pad_block (GstPad * pad, GstPadProbeInfo * info, TransportReceiveBin * receive)
    * them. Sticky events would be forwarded again later once we unblock
    * and we don't want to forward them here already because that might
    * cause a spurious GST_FLOW_FLUSHING */
-  if (GST_IS_EVENT (info->data))
+  if (GST_IS_EVENT (info->data) || GST_IS_QUERY (info->data))
     return GST_PAD_PROBE_DROP;
 
   /* But block on any actual data-flow so we don't accidentally send that
@@ -119,14 +112,32 @@ void
 transport_receive_bin_set_receive_state (TransportReceiveBin * receive,
     ReceiveState state)
 {
+  GstWebRTCICEConnectionState icestate;
 
   g_mutex_lock (&receive->pad_block_lock);
   if (receive->receive_state != state) {
-    GST_DEBUG_OBJECT (receive, "changing receive state to %s",
+    GST_DEBUG_OBJECT (receive, "Requested change of receive state to %s",
         _receive_state_to_string (state));
   }
 
+  receive->receive_state = state;
+
+  g_object_get (receive->stream->transport->transport, "state", &icestate,
+      NULL);
+  if (state == RECEIVE_STATE_PASS) {
+    if (icestate == GST_WEBRTC_ICE_CONNECTION_STATE_CONNECTED ||
+        icestate == GST_WEBRTC_ICE_CONNECTION_STATE_COMPLETED) {
+      GST_LOG_OBJECT (receive, "Unblocking nicesrc because ICE is connected.");
+    } else {
+      GST_LOG_OBJECT (receive, "Can't unblock nicesrc yet because ICE "
+          "is not connected, it is %d", icestate);
+      state = RECEIVE_STATE_BLOCK;
+    }
+  }
+
   if (state == RECEIVE_STATE_PASS) {
+    g_object_set (receive->queue, "leaky", 0, NULL);
+
     if (receive->rtp_block)
       _free_pad_block (receive->rtp_block);
     receive->rtp_block = NULL;
@@ -136,6 +147,7 @@ transport_receive_bin_set_receive_state (TransportReceiveBin * receive,
     receive->rtcp_block = NULL;
   } else {
     g_assert (state == RECEIVE_STATE_BLOCK);
+    g_object_set (receive->queue, "leaky", 2, NULL);
     if (receive->rtp_block == NULL) {
       GstWebRTCDTLSTransport *transport;
       GstElement *dtlssrtpdec;
@@ -155,28 +167,19 @@ transport_receive_bin_set_receive_state (TransportReceiveBin * receive,
             (GstPadProbeCallback) pad_block, receive, NULL);
         gst_object_unref (peer_pad);
         gst_object_unref (pad);
-
-        transport = receive->stream->rtcp_transport;
-        dtlssrtpdec = transport->dtlssrtpdec;
-        pad = gst_element_get_static_pad (dtlssrtpdec, "sink");
-        peer_pad = gst_pad_get_peer (pad);
-        receive->rtcp_block =
-            _create_pad_block (GST_ELEMENT (receive), peer_pad, 0, NULL, NULL);
-        receive->rtcp_block->block_id =
-            gst_pad_add_probe (peer_pad,
-            GST_PAD_PROBE_TYPE_BLOCK |
-            GST_PAD_PROBE_TYPE_DATA_DOWNSTREAM,
-            (GstPadProbeCallback) pad_block, receive, NULL);
-        gst_object_unref (peer_pad);
-        gst_object_unref (pad);
       }
     }
   }
-
-  receive->receive_state = state;
   g_mutex_unlock (&receive->pad_block_lock);
 }
 
+static void
+_on_notify_ice_connection_state (GstWebRTCICETransport * transport,
+    GParamSpec * pspec, TransportReceiveBin * receive)
+{
+  transport_receive_bin_set_receive_state (receive, receive->receive_state);
+}
+
 static void
 transport_receive_bin_set_property (GObject * object, guint prop_id,
     const GValue * value, GParamSpec * pspec)
@@ -250,9 +253,6 @@ transport_receive_bin_change_state (GstElement * element,
       elem = receive->stream->transport->transport->src;
       gst_element_set_locked_state (elem, TRUE);
       gst_element_set_state (elem, GST_STATE_PLAYING);
-      elem = receive->stream->rtcp_transport->transport->src;
-      gst_element_set_locked_state (elem, TRUE);
-      gst_element_set_state (elem, GST_STATE_PLAYING);
       break;
     }
     default:
@@ -270,9 +270,6 @@ transport_receive_bin_change_state (GstElement * element,
       elem = receive->stream->transport->transport->src;
       gst_element_set_locked_state (elem, FALSE);
       gst_element_set_state (elem, GST_STATE_NULL);
-      elem = receive->stream->rtcp_transport->transport->src;
-      gst_element_set_locked_state (elem, FALSE);
-      gst_element_set_state (elem, GST_STATE_NULL);
 
       if (receive->rtp_block)
         _free_pad_block (receive->rtp_block);
@@ -297,13 +294,25 @@ rtp_queue_overrun (GstElement * queue, TransportReceiveBin * receive)
   GST_WARNING_OBJECT (receive, "Internal receive queue overrun. Dropping data");
 }
 
+static GstPadProbeReturn
+drop_serialized_queries (GstPad * pad, GstPadProbeInfo * info,
+    TransportReceiveBin * receive)
+{
+  GstQuery *query = GST_PAD_PROBE_INFO_QUERY (info);
+
+  if (GST_QUERY_IS_SERIALIZED (query))
+    return GST_PAD_PROBE_DROP;
+  else
+    return GST_PAD_PROBE_PASS;
+}
+
 static void
 transport_receive_bin_constructed (GObject * object)
 {
   TransportReceiveBin *receive = TRANSPORT_RECEIVE_BIN (object);
   GstWebRTCDTLSTransport *transport;
   GstPad *ghost, *pad;
-  GstElement *capsfilter, *funnel, *queue;
+  GstElement *capsfilter;
   GstCaps *caps;
 
   g_return_if_fail (receive->stream);
@@ -317,46 +326,25 @@ transport_receive_bin_constructed (GObject * object)
   g_object_set (capsfilter, "caps", caps, NULL);
   gst_caps_unref (caps);
 
-  queue = gst_element_factory_make ("queue", NULL);
+  receive->queue = gst_element_factory_make ("queue", NULL);
   /* FIXME: make this configurable? */
-  g_object_set (queue, "leaky", 2, "max-size-time", (guint64) 0,
+  g_object_set (receive->queue, "leaky", 2, "max-size-time", (guint64) 0,
       "max-size-buffers", 0, "max-size-bytes", 5 * 1024 * 1024, NULL);
-  g_signal_connect (queue, "overrun", G_CALLBACK (rtp_queue_overrun), receive);
-
-  gst_bin_add (GST_BIN (receive), GST_ELEMENT (queue));
-  gst_bin_add (GST_BIN (receive), GST_ELEMENT (capsfilter));
-  if (!gst_element_link_pads (capsfilter, "src", queue, "sink"))
-    g_warn_if_reached ();
-
-  if (!gst_element_link_pads (queue, "src", transport->dtlssrtpdec, "sink"))
-    g_warn_if_reached ();
-
-  gst_bin_add (GST_BIN (receive), GST_ELEMENT (transport->transport->src));
-  if (!gst_element_link_pads (GST_ELEMENT (transport->transport->src), "src",
-          GST_ELEMENT (capsfilter), "sink"))
-    g_warn_if_reached ();
+  g_signal_connect (receive->queue, "overrun", G_CALLBACK (rtp_queue_overrun),
+      receive);
 
-  /* link ice src, dtlsrtp together for rtcp */
-  transport = receive->stream->rtcp_transport;
-  gst_bin_add (GST_BIN (receive), GST_ELEMENT (transport->dtlssrtpdec));
-
-  capsfilter = gst_element_factory_make ("capsfilter", NULL);
-  caps = gst_caps_new_empty_simple ("application/x-rtcp");
-  g_object_set (capsfilter, "caps", caps, NULL);
-  gst_caps_unref (caps);
-
-  queue = gst_element_factory_make ("queue", NULL);
-  /* FIXME: make this configurable? */
-  g_object_set (queue, "leaky", 2, "max-size-time", (guint64) 0,
-      "max-size-buffers", 0, "max-size-bytes", 5 * 1024 * 1024, NULL);
-  g_signal_connect (queue, "overrun", G_CALLBACK (rtp_queue_overrun), receive);
+  pad = gst_element_get_static_pad (receive->queue, "sink");
+  gst_pad_add_probe (pad, GST_PAD_PROBE_TYPE_QUERY_DOWNSTREAM,
+      (GstPadProbeCallback) drop_serialized_queries, receive, NULL);
+  gst_object_unref (pad);
 
-  gst_bin_add (GST_BIN (receive), queue);
+  gst_bin_add (GST_BIN (receive), GST_ELEMENT (receive->queue));
   gst_bin_add (GST_BIN (receive), GST_ELEMENT (capsfilter));
-  if (!gst_element_link_pads (capsfilter, "src", queue, "sink"))
+  if (!gst_element_link_pads (capsfilter, "src", receive->queue, "sink"))
     g_warn_if_reached ();
 
-  if (!gst_element_link_pads (queue, "src", transport->dtlssrtpdec, "sink"))
+  if (!gst_element_link_pads (receive->queue, "src", transport->dtlssrtpdec,
+          "sink"))
     g_warn_if_reached ();
 
   gst_bin_add (GST_BIN (receive), GST_ELEMENT (transport->transport->src));
@@ -364,52 +352,32 @@ transport_receive_bin_constructed (GObject * object)
           GST_ELEMENT (capsfilter), "sink"))
     g_warn_if_reached ();
 
-  /* create funnel for rtp_src */
-  funnel = gst_element_factory_make ("funnel", NULL);
-  gst_bin_add (GST_BIN (receive), funnel);
-  if (!gst_element_link_pads (receive->stream->transport->dtlssrtpdec,
-          "rtp_src", funnel, "sink_0"))
-    g_warn_if_reached ();
-  if (!gst_element_link_pads (receive->stream->rtcp_transport->dtlssrtpdec,
-          "rtp_src", funnel, "sink_1"))
-    g_warn_if_reached ();
-
-  pad = gst_element_get_static_pad (funnel, "src");
+  /* expose rtp_src */
+  pad =
+      gst_element_get_static_pad (receive->stream->transport->dtlssrtpdec,
+      "rtp_src");
   receive->rtp_src = gst_ghost_pad_new ("rtp_src", pad);
 
   gst_element_add_pad (GST_ELEMENT (receive), receive->rtp_src);
   gst_object_unref (pad);
 
-  /* create funnel for rtcp_src */
-  funnel = gst_element_factory_make ("funnel", NULL);
-  gst_bin_add (GST_BIN (receive), funnel);
-  if (!gst_element_link_pads (receive->stream->transport->dtlssrtpdec,
-          "rtcp_src", funnel, "sink_0"))
-    g_warn_if_reached ();
-  if (!gst_element_link_pads (receive->stream->rtcp_transport->dtlssrtpdec,
-          "rtcp_src", funnel, "sink_1"))
-    g_warn_if_reached ();
-
-  pad = gst_element_get_static_pad (funnel, "src");
+  /* expose rtcp_rtc */
+  pad = gst_element_get_static_pad (receive->stream->transport->dtlssrtpdec,
+      "rtcp_src");
   receive->rtcp_src = gst_ghost_pad_new ("rtcp_src", pad);
   gst_element_add_pad (GST_ELEMENT (receive), receive->rtcp_src);
   gst_object_unref (pad);
 
-  /* create funnel for data_src */
-  funnel = gst_element_factory_make ("funnel", NULL);
-  gst_bin_add (GST_BIN (receive), funnel);
-  if (!gst_element_link_pads (receive->stream->transport->dtlssrtpdec,
-          "data_src", funnel, "sink_0"))
-    g_warn_if_reached ();
-  if (!gst_element_link_pads (receive->stream->rtcp_transport->dtlssrtpdec,
-          "data_src", funnel, "sink_1"))
-    g_warn_if_reached ();
-
-  pad = gst_element_get_static_pad (funnel, "src");
+  /* expose data_src */
+  pad = gst_element_request_pad_simple (receive->stream->transport->dtlssrtpdec,
+      "data_src");
   ghost = gst_ghost_pad_new ("data_src", pad);
   gst_element_add_pad (GST_ELEMENT (receive), ghost);
   gst_object_unref (pad);
 
+  g_signal_connect_after (receive->stream->transport->transport,
+      "notify::state", G_CALLBACK (_on_notify_ice_connection_state), receive);
+
   G_OBJECT_CLASS (parent_class)->constructed (object);
 }
 
diff --git a/ext/webrtc/transportreceivebin.h b/ext/webrtc/transportreceivebin.h
index 50449e327..905628c64 100644
--- a/ext/webrtc/transportreceivebin.h
+++ b/ext/webrtc/transportreceivebin.h
@@ -52,6 +52,7 @@ struct _TransportReceiveBin
   struct pad_block          *rtcp_block;
   GMutex                     pad_block_lock;
   ReceiveState               receive_state;
+  GstElement                *queue;
 };
 
 struct _TransportReceiveBinClass
diff --git a/ext/webrtc/transportsendbin.c b/ext/webrtc/transportsendbin.c
index dc5c1ff0e..ee2312e6a 100644
--- a/ext/webrtc/transportsendbin.c
+++ b/ext/webrtc/transportsendbin.c
@@ -23,22 +23,19 @@
 
 #include "transportsendbin.h"
 #include "utils.h"
+#include "gst/webrtc/webrtc-priv.h"
 
 /*
- *           ,------------------------transport_send_%u-------------------------,
- *           ;                          ,-----dtlssrtpenc---,                   ;
- * data_sink o--------------------------o data_sink         ;                   ;
- *           ;                          ;                   ;  ,---nicesink---, ;
- *  rtp_sink o--------------------------o rtp_sink_0    src o--o sink         ; ;
- *           ;                          ;                   ;  '--------------' ;
- *           ;   ,--outputselector--, ,-o rtcp_sink_0       ;                   ;
- *           ;   ;            src_0 o-' '-------------------'                   ;
- * rtcp_sink ;---o sink             ;   ,----dtlssrtpenc----,  ,---nicesink---, ;
- *           ;   ;            src_1 o---o rtcp_sink_0   src o--o sink         ; ;
- *           ;   '------------------'   '-------------------'  '--------------' ;
- *           '------------------------------------------------------------------'
+ *           ,--------------transport_send_%u-------- ---,
+ *           ;   ,-----dtlssrtpenc---,                   ;
+ * data_sink o---o data_sink         ;                   ;
+ *           ;   ;                   ;  ,---nicesink---, ;
+ *  rtp_sink o---o rtp_sink_0    src o--o sink         ; ;
+ *           ;   ;                   ;  '--------------' ;
+ * rtcp_sink o---o rtcp_sink_0       ;                   ;
+ *           ;   '-------------------'
+ *           '-------------------------------------------'
  *
- * outputselecter is used to switch between rtcp-mux and no rtcp-mux
  *
  * FIXME: Do we need a valve drop=TRUE for the no RTCP case?
  */
@@ -73,7 +70,6 @@ enum
 {
   PROP_0,
   PROP_STREAM,
-  PROP_RTCP_MUX,
 };
 
 #define TSB_GET_LOCK(tsb) (&tsb->lock)
@@ -82,24 +78,6 @@ enum
 
 static void cleanup_blocks (TransportSendBin * send);
 
-static void
-_set_rtcp_mux (TransportSendBin * send, gboolean rtcp_mux)
-{
-  GstPad *active_pad;
-
-  if (rtcp_mux)
-    active_pad = gst_element_get_static_pad (send->outputselector, "src_0");
-  else
-    active_pad = gst_element_get_static_pad (send->outputselector, "src_1");
-  send->rtcp_mux = rtcp_mux;
-  GST_OBJECT_UNLOCK (send);
-
-  g_object_set (send->outputselector, "active-pad", active_pad, NULL);
-
-  gst_object_unref (active_pad);
-  GST_OBJECT_LOCK (send);
-}
-
 static void
 transport_send_bin_set_property (GObject * object, guint prop_id,
     const GValue * value, GParamSpec * pspec)
@@ -112,9 +90,6 @@ transport_send_bin_set_property (GObject * object, guint prop_id,
       /* XXX: weak-ref this? Note, it's construct-only so can't be changed later */
       send->stream = TRANSPORT_STREAM (g_value_get_object (value));
       break;
-    case PROP_RTCP_MUX:
-      _set_rtcp_mux (send, g_value_get_boolean (value));
-      break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
       break;
@@ -133,9 +108,6 @@ transport_send_bin_get_property (GObject * object, guint prop_id,
     case PROP_STREAM:
       g_value_set_object (value, send->stream);
       break;
-    case PROP_RTCP_MUX:
-      g_value_set_boolean (value, send->rtcp_mux);
-      break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
       break;
@@ -200,9 +172,9 @@ transport_send_bin_change_state (GstElement * element,
        * arguably the element should be able to deal with this itself or
        * we should only add it once/if we get the encoding keys */
       TSB_LOCK (send);
-      gst_element_set_locked_state (send->rtp_ctx.dtlssrtpenc, TRUE);
-      gst_element_set_locked_state (send->rtcp_ctx.dtlssrtpenc, TRUE);
+      gst_element_set_locked_state (send->dtlssrtpenc, TRUE);
       send->active = TRUE;
+      send->has_clientness = FALSE;
       TSB_UNLOCK (send);
       break;
     }
@@ -213,20 +185,12 @@ transport_send_bin_change_state (GstElement * element,
       /* RTP */
       /* unblock the encoder once the key is set, this should also be automatic */
       elem = send->stream->transport->dtlssrtpenc;
-      send->rtp_ctx.rtp_block = block_peer_pad (elem, "rtp_sink_0");
+      send->rtp_block = block_peer_pad (elem, "rtp_sink_0");
       /* Also block the RTCP pad on the RTP encoder, in case we mux RTCP */
-      send->rtp_ctx.rtcp_block = block_peer_pad (elem, "rtcp_sink_0");
+      send->rtcp_block = block_peer_pad (elem, "rtcp_sink_0");
       /* unblock ice sink once a connection is made, this should also be automatic */
       elem = send->stream->transport->transport->sink;
-      send->rtp_ctx.nice_block = block_peer_pad (elem, "sink");
 
-      /* RTCP */
-      elem = send->stream->rtcp_transport->dtlssrtpenc;
-      /* Block the RTCP DTLS encoder */
-      send->rtcp_ctx.rtcp_block = block_peer_pad (elem, "rtcp_sink_0");
-      /* unblock ice sink once a connection is made, this should also be automatic */
-      elem = send->stream->rtcp_transport->transport->sink;
-      send->rtcp_ctx.nice_block = block_peer_pad (elem, "sink");
       TSB_UNLOCK (send);
       break;
     }
@@ -256,8 +220,7 @@ transport_send_bin_change_state (GstElement * element,
       send->active = FALSE;
       cleanup_blocks (send);
 
-      gst_element_set_locked_state (send->rtp_ctx.dtlssrtpenc, FALSE);
-      gst_element_set_locked_state (send->rtcp_ctx.dtlssrtpenc, FALSE);
+      gst_element_set_locked_state (send->dtlssrtpenc, FALSE);
       TSB_UNLOCK (send);
 
       break;
@@ -272,13 +235,7 @@ transport_send_bin_change_state (GstElement * element,
 static void
 _on_dtls_enc_key_set (GstElement * dtlssrtpenc, TransportSendBin * send)
 {
-  TransportSendBinDTLSContext *ctx;
-
-  if (dtlssrtpenc == send->rtp_ctx.dtlssrtpenc)
-    ctx = &send->rtp_ctx;
-  else if (dtlssrtpenc == send->rtcp_ctx.dtlssrtpenc)
-    ctx = &send->rtcp_ctx;
-  else {
+  if (dtlssrtpenc != send->dtlssrtpenc) {
     GST_WARNING_OBJECT (send,
         "Received dtls-enc key info for unknown element %" GST_PTR_FORMAT,
         dtlssrtpenc);
@@ -293,24 +250,40 @@ _on_dtls_enc_key_set (GstElement * dtlssrtpenc, TransportSendBin * send)
   }
 
   GST_LOG_OBJECT (send, "Unblocking %" GST_PTR_FORMAT " pads", dtlssrtpenc);
-  _free_pad_block (ctx->rtp_block);
-  _free_pad_block (ctx->rtcp_block);
-  ctx->rtp_block = ctx->rtcp_block = NULL;
+  _free_pad_block (send->rtp_block);
+  _free_pad_block (send->rtcp_block);
+  send->rtp_block = send->rtcp_block = NULL;
 
 done:
   TSB_UNLOCK (send);
 }
 
+static void
+maybe_start_enc (TransportSendBin * send)
+{
+  GstWebRTCICEConnectionState state;
+
+  if (!send->has_clientness) {
+    GST_LOG_OBJECT (send, "Can't start DTLS because doesn't know client-ness");
+    return;
+  }
+
+  g_object_get (send->stream->transport->transport, "state", &state, NULL);
+  if (state != GST_WEBRTC_ICE_CONNECTION_STATE_CONNECTED &&
+      state != GST_WEBRTC_ICE_CONNECTION_STATE_COMPLETED) {
+    GST_LOG_OBJECT (send, "Can't start DTLS yet because ICE is not connected.");
+    return;
+  }
+
+  gst_element_set_locked_state (send->dtlssrtpenc, FALSE);
+  gst_element_sync_state_with_parent (send->dtlssrtpenc);
+}
+
 static void
 _on_notify_dtls_client_status (GstElement * dtlssrtpenc,
     GParamSpec * pspec, TransportSendBin * send)
 {
-  TransportSendBinDTLSContext *ctx;
-  if (dtlssrtpenc == send->rtp_ctx.dtlssrtpenc)
-    ctx = &send->rtp_ctx;
-  else if (dtlssrtpenc == send->rtcp_ctx.dtlssrtpenc)
-    ctx = &send->rtcp_ctx;
-  else {
+  if (dtlssrtpenc != send->dtlssrtpenc) {
     GST_WARNING_OBJECT (send,
         "Received dtls-enc client mode for unknown element %" GST_PTR_FORMAT,
         dtlssrtpenc);
@@ -324,11 +297,12 @@ _on_notify_dtls_client_status (GstElement * dtlssrtpenc,
     goto done;
   }
 
+  send->has_clientness = TRUE;
   GST_DEBUG_OBJECT (send,
-      "DTLS-SRTP encoder configured. Unlocking it and changing state %"
-      GST_PTR_FORMAT, ctx->dtlssrtpenc);
-  gst_element_set_locked_state (ctx->dtlssrtpenc, FALSE);
-  gst_element_sync_state_with_parent (ctx->dtlssrtpenc);
+      "DTLS-SRTP encoder configured. Unlocking it and maybe changing state %"
+      GST_PTR_FORMAT, dtlssrtpenc);
+  maybe_start_enc (send);
+
 done:
   TSB_UNLOCK (send);
 }
@@ -337,116 +311,62 @@ static void
 _on_notify_ice_connection_state (GstWebRTCICETransport * transport,
     GParamSpec * pspec, TransportSendBin * send)
 {
-  GstWebRTCICEConnectionState state;
-
-  g_object_get (transport, "state", &state, NULL);
-
-  if (state == GST_WEBRTC_ICE_CONNECTION_STATE_CONNECTED ||
-      state == GST_WEBRTC_ICE_CONNECTION_STATE_COMPLETED) {
-    TSB_LOCK (send);
-    if (transport == send->stream->transport->transport) {
-      if (send->rtp_ctx.nice_block) {
-        GST_LOG_OBJECT (send, "Unblocking pad %" GST_PTR_FORMAT,
-            send->rtp_ctx.nice_block->pad);
-        _free_pad_block (send->rtp_ctx.nice_block);
-        send->rtp_ctx.nice_block = NULL;
-      }
-    } else if (transport == send->stream->rtcp_transport->transport) {
-      if (send->rtcp_ctx.nice_block) {
-        GST_LOG_OBJECT (send, "Unblocking pad %" GST_PTR_FORMAT,
-            send->rtcp_ctx.nice_block->pad);
-        _free_pad_block (send->rtcp_ctx.nice_block);
-        send->rtcp_ctx.nice_block = NULL;
-      }
-    }
-    TSB_UNLOCK (send);
-  }
-}
-
-static void
-tsb_setup_ctx (TransportSendBin * send, TransportSendBinDTLSContext * ctx,
-    GstWebRTCDTLSTransport * transport)
-{
-  GstElement *dtlssrtpenc, *nicesink;
-
-  dtlssrtpenc = ctx->dtlssrtpenc = transport->dtlssrtpenc;
-  nicesink = ctx->nicesink = transport->transport->sink;
-
-  /* unblock the encoder once the key is set */
-  g_signal_connect (dtlssrtpenc, "on-key-set",
-      G_CALLBACK (_on_dtls_enc_key_set), send);
-  /* Bring the encoder up to current state only once the is-client prop is set */
-  g_signal_connect (dtlssrtpenc, "notify::is-client",
-      G_CALLBACK (_on_notify_dtls_client_status), send);
-  gst_bin_add (GST_BIN (send), GST_ELEMENT (dtlssrtpenc));
-
-  /* unblock ice sink once it signals a connection */
-  g_signal_connect (transport->transport, "notify::state",
-      G_CALLBACK (_on_notify_ice_connection_state), send);
-  gst_bin_add (GST_BIN (send), GST_ELEMENT (nicesink));
-
-  if (!gst_element_link_pads (GST_ELEMENT (dtlssrtpenc), "src", nicesink,
-          "sink"))
-    g_warn_if_reached ();
+  TSB_LOCK (send);
+  maybe_start_enc (send);
+  TSB_UNLOCK (send);
 }
 
 static void
 transport_send_bin_constructed (GObject * object)
 {
   TransportSendBin *send = TRANSPORT_SEND_BIN (object);
-  GstWebRTCDTLSTransport *transport;
   GstPadTemplate *templ;
   GstPad *ghost, *pad;
 
   g_return_if_fail (send->stream);
 
-  g_object_bind_property (send, "rtcp-mux", send->stream, "rtcp-mux",
-      G_BINDING_BIDIRECTIONAL);
+  send->dtlssrtpenc = send->stream->transport->dtlssrtpenc;
+  send->nicesink = send->stream->transport->transport->sink;
 
-  /* Output selector to direct the RTCP for muxed-mode */
-  send->outputselector = gst_element_factory_make ("output-selector", NULL);
-  gst_bin_add (GST_BIN (send), send->outputselector);
-
-  /* RTP */
-  transport = send->stream->transport;
-  /* Do the common init for the context struct */
-  tsb_setup_ctx (send, &send->rtp_ctx, transport);
+  /* unblock the encoder once the key is set */
+  g_signal_connect (send->dtlssrtpenc, "on-key-set",
+      G_CALLBACK (_on_dtls_enc_key_set), send);
+  /* Bring the encoder up to current state only once the is-client prop is set */
+  g_signal_connect (send->dtlssrtpenc, "notify::is-client",
+      G_CALLBACK (_on_notify_dtls_client_status), send);
+  /* unblock ice sink once it signals a connection */
+  g_signal_connect (send->stream->transport->transport, "notify::state",
+      G_CALLBACK (_on_notify_ice_connection_state), send);
 
-  templ = _find_pad_template (transport->dtlssrtpenc,
-      GST_PAD_SINK, GST_PAD_REQUEST, "rtp_sink_%d");
-  pad = gst_element_request_pad (transport->dtlssrtpenc, templ, "rtp_sink_0",
-      NULL);
+  gst_bin_add (GST_BIN (send), GST_ELEMENT (send->dtlssrtpenc));
+  gst_bin_add (GST_BIN (send), GST_ELEMENT (send->nicesink));
 
-  if (!gst_element_link_pads (GST_ELEMENT (send->outputselector), "src_0",
-          GST_ELEMENT (transport->dtlssrtpenc), "rtcp_sink_0"))
+  if (!gst_element_link_pads (GST_ELEMENT (send->dtlssrtpenc), "src",
+          send->nicesink, "sink"))
     g_warn_if_reached ();
 
+  templ = _find_pad_template (send->dtlssrtpenc, GST_PAD_SINK, GST_PAD_REQUEST,
+      "rtp_sink_%d");
+  pad = gst_element_request_pad (send->dtlssrtpenc, templ, "rtp_sink_0", NULL);
+
   ghost = gst_ghost_pad_new ("rtp_sink", pad);
   gst_element_add_pad (GST_ELEMENT (send), ghost);
   gst_object_unref (pad);
 
   /* push the data stream onto the RTP dtls element */
-  templ = _find_pad_template (transport->dtlssrtpenc,
-      GST_PAD_SINK, GST_PAD_REQUEST, "data_sink");
-  pad = gst_element_request_pad (transport->dtlssrtpenc, templ, "data_sink",
-      NULL);
+  templ = _find_pad_template (send->dtlssrtpenc, GST_PAD_SINK, GST_PAD_REQUEST,
+      "data_sink");
+  pad = gst_element_request_pad (send->dtlssrtpenc, templ, "data_sink", NULL);
 
   ghost = gst_ghost_pad_new ("data_sink", pad);
   gst_element_add_pad (GST_ELEMENT (send), ghost);
   gst_object_unref (pad);
 
   /* RTCP */
-  transport = send->stream->rtcp_transport;
   /* Do the common init for the context struct */
-  tsb_setup_ctx (send, &send->rtcp_ctx, transport);
-  templ = _find_pad_template (transport->dtlssrtpenc,
-      GST_PAD_SINK, GST_PAD_REQUEST, "rtcp_sink_%d");
-
-  if (!gst_element_link_pads (GST_ELEMENT (send->outputselector), "src_1",
-          GST_ELEMENT (transport->dtlssrtpenc), "rtcp_sink_0"))
-    g_warn_if_reached ();
-
-  pad = gst_element_get_static_pad (send->outputselector, "sink");
+  templ = _find_pad_template (send->dtlssrtpenc, GST_PAD_SINK, GST_PAD_REQUEST,
+      "rtcp_sink_%d");
+  pad = gst_element_request_pad (send->dtlssrtpenc, templ, "rtcp_sink_0", NULL);
 
   ghost = gst_ghost_pad_new ("rtcp_sink", pad);
   gst_element_add_pad (GST_ELEMENT (send), ghost);
@@ -456,45 +376,30 @@ transport_send_bin_constructed (GObject * object)
 }
 
 static void
-cleanup_ctx_blocks (TransportSendBinDTLSContext * ctx)
+cleanup_blocks (TransportSendBin * send)
 {
-  if (ctx->rtp_block) {
-    _free_pad_block (ctx->rtp_block);
-    ctx->rtp_block = NULL;
-  }
-
-  if (ctx->rtcp_block) {
-    _free_pad_block (ctx->rtcp_block);
-    ctx->rtcp_block = NULL;
+  if (send->rtp_block) {
+    _free_pad_block (send->rtp_block);
+    send->rtp_block = NULL;
   }
 
-  if (ctx->nice_block) {
-    _free_pad_block (ctx->nice_block);
-    ctx->nice_block = NULL;
+  if (send->rtcp_block) {
+    _free_pad_block (send->rtcp_block);
+    send->rtcp_block = NULL;
   }
 }
 
-static void
-cleanup_blocks (TransportSendBin * send)
-{
-  cleanup_ctx_blocks (&send->rtp_ctx);
-  cleanup_ctx_blocks (&send->rtcp_ctx);
-}
-
 static void
 transport_send_bin_dispose (GObject * object)
 {
   TransportSendBin *send = TRANSPORT_SEND_BIN (object);
 
   TSB_LOCK (send);
-  if (send->rtp_ctx.nicesink) {
-    g_signal_handlers_disconnect_by_data (send->rtp_ctx.nicesink, send);
-    send->rtp_ctx.nicesink = NULL;
-  }
-  if (send->rtcp_ctx.nicesink) {
-    g_signal_handlers_disconnect_by_data (send->rtcp_ctx.nicesink, send);
-    send->rtcp_ctx.nicesink = NULL;
+  if (send->nicesink) {
+    g_signal_handlers_disconnect_by_data (send->nicesink, send);
+    send->nicesink = NULL;
   }
+
   cleanup_blocks (send);
 
   TSB_UNLOCK (send);
@@ -623,12 +528,6 @@ transport_send_bin_class_init (TransportSendBinClass * klass)
           "The TransportStream for this sending bin",
           transport_stream_get_type (),
           G_PARAM_READWRITE | G_PARAM_CONSTRUCT_ONLY | G_PARAM_STATIC_STRINGS));
-
-  g_object_class_install_property (gobject_class,
-      PROP_RTCP_MUX,
-      g_param_spec_boolean ("rtcp-mux", "RTCP Mux",
-          "Whether RTCP packets are muxed with RTP packets",
-          FALSE, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
 }
 
 static void
diff --git a/ext/webrtc/transportsendbin.h b/ext/webrtc/transportsendbin.h
index ed10a0723..5266c8ce9 100644
--- a/ext/webrtc/transportsendbin.h
+++ b/ext/webrtc/transportsendbin.h
@@ -34,18 +34,6 @@ GType transport_send_bin_get_type(void);
 
 typedef struct _TransportSendBinDTLSContext TransportSendBinDTLSContext;
 
-struct _TransportSendBinDTLSContext {
-  GstElement *dtlssrtpenc;
-  GstElement *nicesink;
-
-  /* Block on the dtlssrtpenc RTP sink pad, if any */
-  struct pad_block          *rtp_block;
-  /* Block on the dtlssrtpenc RTCP sink pad, if any */
-  struct pad_block          *rtcp_block;
-  /* Block on the nicesink sink pad, if any */
-  struct pad_block          *nice_block;
-};
-
 struct _TransportSendBin
 {
   GstBin                     parent;
@@ -54,21 +42,16 @@ struct _TransportSendBin
   gboolean                   active; /* Flag that's cleared on shutdown */
 
   TransportStream           *stream;        /* parent transport stream */
-  gboolean                   rtcp_mux;
 
-  GstElement                *outputselector;
+  GstElement *dtlssrtpenc;
+  GstElement *nicesink;
 
-  TransportSendBinDTLSContext rtp_ctx;
-  TransportSendBinDTLSContext rtcp_ctx;
+  gboolean has_clientness;
 
-  /*
+  /* Block on the dtlssrtpenc RTP sink pad, if any */
   struct pad_block          *rtp_block;
-  struct pad_block          *rtcp_mux_block;
-  struct pad_block          *rtp_nice_block;
-
+  /* Block on the dtlssrtpenc RTCP sink pad, if any */
   struct pad_block          *rtcp_block;
-  struct pad_block          *rtcp_nice_block;
-  */
 };
 
 struct _TransportSendBinClass
diff --git a/ext/webrtc/transportstream.c b/ext/webrtc/transportstream.c
index 01261ae1b..f1811a025 100644
--- a/ext/webrtc/transportstream.c
+++ b/ext/webrtc/transportstream.c
@@ -24,19 +24,23 @@
 #include "transportstream.h"
 #include "transportsendbin.h"
 #include "transportreceivebin.h"
-#include "gstwebrtcice.h"
 #include "gstwebrtcbin.h"
 #include "utils.h"
+#include "gst/webrtc/webrtc-priv.h"
+
+#define GST_CAT_DEFAULT transport_stream_debug
+GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
 
 #define transport_stream_parent_class parent_class
-G_DEFINE_TYPE (TransportStream, transport_stream, GST_TYPE_OBJECT);
+G_DEFINE_TYPE_WITH_CODE (TransportStream, transport_stream, GST_TYPE_OBJECT,
+    GST_DEBUG_CATEGORY_INIT (GST_CAT_DEFAULT, "webrtctransportstream", 0,
+        "webrtctransportstream"););
 
 enum
 {
   PROP_0,
   PROP_WEBRTC,
   PROP_SESSION_ID,
-  PROP_RTCP_MUX,
   PROP_DTLS_CLIENT,
 };
 
@@ -55,13 +59,18 @@ transport_stream_get_caps_for_pt (TransportStream * stream, guint pt)
 }
 
 int
-transport_stream_get_pt (TransportStream * stream, const gchar * encoding_name)
+transport_stream_get_pt (TransportStream * stream, const gchar * encoding_name,
+    guint media_idx)
 {
   guint i;
-  gint ret = 0;
+  gint ret = -1;
 
   for (i = 0; i < stream->ptmap->len; i++) {
     PtMapItem *item = &g_array_index (stream->ptmap, PtMapItem, i);
+
+    if (media_idx != -1 && media_idx != item->media_idx)
+      continue;
+
     if (!gst_caps_is_empty (item->caps)) {
       GstStructure *s = gst_caps_get_structure (item->caps, 0);
       if (!g_strcmp0 (gst_structure_get_string (s, "encoding-name"),
@@ -124,9 +133,6 @@ transport_stream_set_property (GObject * object, guint prop_id,
     case PROP_SESSION_ID:
       stream->session_id = g_value_get_uint (value);
       break;
-    case PROP_RTCP_MUX:
-      stream->rtcp_mux = g_value_get_boolean (value);
-      break;
     case PROP_DTLS_CLIENT:
       stream->dtls_client = g_value_get_boolean (value);
       break;
@@ -148,9 +154,6 @@ transport_stream_get_property (GObject * object, guint prop_id,
     case PROP_SESSION_ID:
       g_value_set_uint (value, stream->session_id);
       break;
-    case PROP_RTCP_MUX:
-      g_value_set_boolean (value, stream->rtcp_mux);
-      break;
     case PROP_DTLS_CLIENT:
       g_value_set_boolean (value, stream->dtls_client);
       break;
@@ -166,29 +169,14 @@ transport_stream_dispose (GObject * object)
 {
   TransportStream *stream = TRANSPORT_STREAM (object);
 
-  if (stream->send_bin)
-    gst_object_unref (stream->send_bin);
-  stream->send_bin = NULL;
-
-  if (stream->receive_bin)
-    gst_object_unref (stream->receive_bin);
-  stream->receive_bin = NULL;
-
-  if (stream->transport)
-    gst_object_unref (stream->transport);
-  stream->transport = NULL;
-
-  if (stream->rtcp_transport)
-    gst_object_unref (stream->rtcp_transport);
-  stream->rtcp_transport = NULL;
-
-  if (stream->rtxsend)
-    gst_object_unref (stream->rtxsend);
-  stream->rtxsend = NULL;
-
-  if (stream->rtxreceive)
-    gst_object_unref (stream->rtxreceive);
-  stream->rtxreceive = NULL;
+  gst_clear_object (&stream->send_bin);
+  gst_clear_object (&stream->receive_bin);
+  gst_clear_object (&stream->transport);
+  gst_clear_object (&stream->rtxsend);
+  gst_clear_object (&stream->rtxreceive);
+  gst_clear_object (&stream->reddec);
+  g_list_free_full (stream->fecdecs, (GDestroyNotify) gst_object_unref);
+  stream->fecdecs = NULL;
 
   GST_OBJECT_PARENT (object) = NULL;
 
@@ -201,7 +189,12 @@ transport_stream_finalize (GObject * object)
   TransportStream *stream = TRANSPORT_STREAM (object);
 
   g_array_free (stream->ptmap, TRUE);
-  g_array_free (stream->remote_ssrcmap, TRUE);
+  g_ptr_array_free (stream->ssrcmap, TRUE);
+
+  gst_clear_object (&stream->rtxsend_stream_id);
+  gst_clear_object (&stream->rtxsend_repaired_stream_id);
+  gst_clear_object (&stream->rtxreceive_stream_id);
+  gst_clear_object (&stream->rtxreceive_repaired_stream_id);
 
   G_OBJECT_CLASS (parent_class)->finalize (object);
 }
@@ -213,19 +206,12 @@ transport_stream_constructed (GObject * object)
   GstWebRTCBin *webrtc;
   GstWebRTCICETransport *ice_trans;
 
-  stream->transport = gst_webrtc_dtls_transport_new (stream->session_id, FALSE);
-  stream->rtcp_transport =
-      gst_webrtc_dtls_transport_new (stream->session_id, TRUE);
+  stream->transport = gst_webrtc_dtls_transport_new (stream->session_id);
 
   webrtc = GST_WEBRTC_BIN (gst_object_get_parent (GST_OBJECT (object)));
 
   g_object_bind_property (stream->transport, "client", stream, "dtls-client",
       G_BINDING_BIDIRECTIONAL);
-  g_object_bind_property (stream->rtcp_transport, "client", stream,
-      "dtls-client", G_BINDING_BIDIRECTIONAL);
-
-  g_object_bind_property (stream->transport, "certificate",
-      stream->rtcp_transport, "certificate", G_BINDING_BIDIRECTIONAL);
 
   /* Need to go full Java and have a transport manager?
    * Or make the caller set the ICE transport up? */
@@ -242,12 +228,6 @@ transport_stream_constructed (GObject * object)
   gst_webrtc_dtls_transport_set_transport (stream->transport, ice_trans);
   gst_object_unref (ice_trans);
 
-  ice_trans =
-      gst_webrtc_ice_find_transport (webrtc->priv->ice, stream->stream,
-      GST_WEBRTC_ICE_COMPONENT_RTCP);
-  gst_webrtc_dtls_transport_set_transport (stream->rtcp_transport, ice_trans);
-  gst_object_unref (ice_trans);
-
   stream->send_bin = g_object_new (transport_send_bin_get_type (), "stream",
       stream, NULL);
   gst_object_ref_sink (stream->send_bin);
@@ -287,12 +267,6 @@ transport_stream_class_init (TransportStreamClass * klass)
           0, G_MAXUINT, 0,
           G_PARAM_READWRITE | G_PARAM_CONSTRUCT_ONLY | G_PARAM_STATIC_STRINGS));
 
-  g_object_class_install_property (gobject_class,
-      PROP_RTCP_MUX,
-      g_param_spec_boolean ("rtcp-mux", "RTCP Mux",
-          "Whether RTCP packets are muxed with RTP packets",
-          FALSE, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
-
   g_object_class_install_property (gobject_class,
       PROP_DTLS_CLIENT,
       g_param_spec_boolean ("dtls-client", "DTLS client",
@@ -307,12 +281,96 @@ clear_ptmap_item (PtMapItem * item)
     gst_caps_unref (item->caps);
 }
 
+static SsrcMapItem *
+ssrcmap_item_new (GstWebRTCRTPTransceiverDirection direction, guint32 ssrc,
+    guint media_idx)
+{
+  SsrcMapItem *ssrc_item = g_new0 (SsrcMapItem, 1);
+
+  ssrc_item->direction = direction;
+  ssrc_item->media_idx = media_idx;
+  ssrc_item->ssrc = ssrc;
+  g_weak_ref_init (&ssrc_item->rtpjitterbuffer, NULL);
+
+  return ssrc_item;
+}
+
+static void
+ssrcmap_item_free (SsrcMapItem * item)
+{
+  g_weak_ref_clear (&item->rtpjitterbuffer);
+  g_clear_pointer (&item->mid, g_free);
+  g_clear_pointer (&item->rid, g_free);
+  g_free (item);
+}
+
+SsrcMapItem *
+transport_stream_find_ssrc_map_item (TransportStream * stream,
+    gconstpointer data, FindSsrcMapFunc func)
+{
+  int i;
+
+  for (i = 0; i < stream->ssrcmap->len; i++) {
+    SsrcMapItem *item = g_ptr_array_index (stream->ssrcmap, i);
+
+    if (func (item, data))
+      return item;
+  }
+
+  return NULL;
+}
+
+void
+transport_stream_filter_ssrc_map_item (TransportStream * stream,
+    gconstpointer data, FindSsrcMapFunc func)
+{
+  int i;
+
+  for (i = 0; i < stream->ssrcmap->len;) {
+    SsrcMapItem *item = g_ptr_array_index (stream->ssrcmap, i);
+
+    if (!func (item, data)) {
+      GST_TRACE_OBJECT (stream, "removing ssrc %u", item->ssrc);
+      g_ptr_array_remove_index_fast (stream->ssrcmap, i);
+    } else {
+      i++;
+    }
+  }
+}
+
+SsrcMapItem *
+transport_stream_add_ssrc_map_item (TransportStream * stream,
+    GstWebRTCRTPTransceiverDirection direction, guint32 ssrc, guint media_idx)
+{
+  SsrcMapItem *ret = NULL;
+
+  g_return_val_if_fail (direction ==
+      GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_RECVONLY
+      || direction == GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_SENDONLY, NULL);
+  g_return_val_if_fail (ssrc != 0, NULL);
+
+  GST_INFO_OBJECT (stream, "Adding mapping for rtp session %u media_idx %u "
+      "direction %s ssrc %u", stream->session_id, media_idx,
+      gst_webrtc_rtp_transceiver_direction_to_string (direction), ssrc);
+
+  /* XXX: duplicates? */
+  ret = ssrcmap_item_new (direction, ssrc, media_idx);
+
+  g_ptr_array_add (stream->ssrcmap, ret);
+
+  return ret;
+}
+
 static void
 transport_stream_init (TransportStream * stream)
 {
   stream->ptmap = g_array_new (FALSE, TRUE, sizeof (PtMapItem));
   g_array_set_clear_func (stream->ptmap, (GDestroyNotify) clear_ptmap_item);
-  stream->remote_ssrcmap = g_array_new (FALSE, TRUE, sizeof (SsrcMapItem));
+  stream->ssrcmap = g_ptr_array_new_with_free_func (
+      (GDestroyNotify) ssrcmap_item_free);
+
+  stream->rtphdrext_id_stream_id = -1;
+  stream->rtphdrext_id_repaired_stream_id = -1;
 }
 
 TransportStream *
diff --git a/ext/webrtc/transportstream.h b/ext/webrtc/transportstream.h
index 174d93e90..de46009bf 100644
--- a/ext/webrtc/transportstream.h
+++ b/ext/webrtc/transportstream.h
@@ -21,6 +21,7 @@
 #define __TRANSPORT_STREAM_H__
 
 #include "fwd.h"
+#include <gst/rtp/rtp.h>
 #include <gst/webrtc/rtptransceiver.h>
 
 G_BEGIN_DECLS
@@ -34,13 +35,18 @@ GType transport_stream_get_type(void);
 typedef struct
 {
   guint8 pt;
+  guint media_idx;
   GstCaps *caps;
 } PtMapItem;
 
 typedef struct
 {
+  GstWebRTCRTPTransceiverDirection direction;
   guint32 ssrc;
   guint media_idx;
+  char *mid;
+  char *rid;
+  GWeakRef rtpjitterbuffer; /* for stats */
 } SsrcMapItem;
 
 struct _TransportStream
@@ -48,9 +54,6 @@ struct _TransportStream
   GstObject                 parent;
 
   guint                     session_id;             /* session_id */
-  gboolean                  rtcp;
-  gboolean                  rtcp_mux;
-  gboolean                  rtcp_rsize;
   gboolean                  dtls_client;
   gboolean                  active;                 /* TRUE if any mline in the bundle/transport is active */
   TransportSendBin         *send_bin;               /* bin containing all the sending transport elements */
@@ -58,14 +61,22 @@ struct _TransportStream
   GstWebRTCICEStream       *stream;
 
   GstWebRTCDTLSTransport   *transport;
-  GstWebRTCDTLSTransport   *rtcp_transport;
 
   GArray                   *ptmap;                  /* array of PtMapItem's */
-  GArray                   *remote_ssrcmap;         /* array of SsrcMapItem's */
+  GPtrArray                *ssrcmap;                /* array of SsrcMapItem's */
   gboolean                  output_connected;       /* whether receive bin is connected to rtpbin */
 
+  guint                     rtphdrext_id_stream_id;
+  guint                     rtphdrext_id_repaired_stream_id;
   GstElement               *rtxsend;
+  GstRTPHeaderExtension    *rtxsend_stream_id;
+  GstRTPHeaderExtension    *rtxsend_repaired_stream_id;
   GstElement               *rtxreceive;
+  GstRTPHeaderExtension    *rtxreceive_stream_id;
+  GstRTPHeaderExtension    *rtxreceive_repaired_stream_id;
+
+  GstElement               *reddec;
+  GList                    *fecdecs;
 };
 
 struct _TransportStreamClass
@@ -76,13 +87,29 @@ struct _TransportStreamClass
 TransportStream *       transport_stream_new        (GstWebRTCBin * webrtc,
                                                      guint session_id);
 int                     transport_stream_get_pt     (TransportStream * stream,
-                                                     const gchar * encoding_name);
+                                                     const gchar * encoding_name,
+                                                     guint media_idx);
 int *                   transport_stream_get_all_pt (TransportStream * stream,
                                                      const gchar * encoding_name,
                                                      gsize * pt_len);
 GstCaps *               transport_stream_get_caps_for_pt    (TransportStream * stream,
                                                              guint pt);
 
+typedef gboolean (*FindSsrcMapFunc) (SsrcMapItem * e1, gconstpointer data);
+
+SsrcMapItem *           transport_stream_find_ssrc_map_item (TransportStream * stream,
+                                                      gconstpointer data,
+                                                      FindSsrcMapFunc func);
+
+void                    transport_stream_filter_ssrc_map_item (TransportStream * stream,
+                                                      gconstpointer data,
+                                                      FindSsrcMapFunc func);
+
+SsrcMapItem *           transport_stream_add_ssrc_map_item (TransportStream * stream,
+                                                      GstWebRTCRTPTransceiverDirection direction,
+                                                      guint32 ssrc,
+                                                      guint media_idx);
+
 G_END_DECLS
 
 #endif /* __TRANSPORT_STREAM_H__ */
diff --git a/ext/webrtc/utils.c b/ext/webrtc/utils.c
index 044d58322..f0741d1e5 100644
--- a/ext/webrtc/utils.c
+++ b/ext/webrtc/utils.c
@@ -26,12 +26,6 @@
 #include "utils.h"
 #include "gstwebrtcbin.h"
 
-GQuark
-gst_webrtc_bin_error_quark (void)
-{
-  return g_quark_from_static_string ("gst-webrtc-bin-error-quark");
-}
-
 GstPadTemplate *
 _find_pad_template (GstElement * element, GstPadDirection direction,
     GstPadPresence presence, const gchar * name)
@@ -138,18 +132,18 @@ _free_pad_block (struct pad_block *block)
   g_free (block);
 }
 
-gchar *
+const gchar *
 _enum_value_to_string (GType type, guint value)
 {
   GEnumClass *enum_class;
   GEnumValue *enum_value;
-  gchar *str = NULL;
+  const gchar *str = NULL;
 
   enum_class = g_type_class_ref (type);
   enum_value = g_enum_get_value (enum_class, value);
 
   if (enum_value)
-    str = g_strdup (enum_value->value_nick);
+    str = enum_value->value_nick;
 
   g_type_class_unref (enum_class);
 
@@ -205,3 +199,52 @@ _rtp_caps_from_media (const GstSDPMedia * media)
 
   return ret;
 }
+
+GstWebRTCKind
+webrtc_kind_from_caps (const GstCaps * caps)
+{
+  GstStructure *s;
+  const gchar *media;
+
+  if (!caps || gst_caps_get_size (caps) == 0)
+    return GST_WEBRTC_KIND_UNKNOWN;
+
+  s = gst_caps_get_structure (caps, 0);
+
+  media = gst_structure_get_string (s, "media");
+  if (media == NULL)
+    return GST_WEBRTC_KIND_UNKNOWN;
+
+  if (!g_strcmp0 (media, "audio"))
+    return GST_WEBRTC_KIND_AUDIO;
+
+  if (!g_strcmp0 (media, "video"))
+    return GST_WEBRTC_KIND_VIDEO;
+
+  return GST_WEBRTC_KIND_UNKNOWN;
+}
+
+char *
+_get_msid_from_media (const GstSDPMedia * media)
+{
+  int i;
+
+  for (i = 0; i < gst_sdp_media_attributes_len (media); i++) {
+    const GstSDPAttribute *attr = gst_sdp_media_get_attribute (media, i);
+    const char *start, *end;
+
+    if (!attr->value)
+      continue;
+
+    start = strstr (attr->value, "msid:");
+    if (!start)
+      continue;
+
+    start += strlen ("msid:");
+    end = strstr (start, " ");
+    if (end)
+      return g_strndup (start, end - start);
+  }
+
+  return NULL;
+}
diff --git a/ext/webrtc/utils.h b/ext/webrtc/utils.h
index ab4d58e87..e5d3d124a 100644
--- a/ext/webrtc/utils.h
+++ b/ext/webrtc/utils.h
@@ -26,22 +26,6 @@
 
 G_BEGIN_DECLS
 
-#define GST_WEBRTC_BIN_ERROR gst_webrtc_bin_error_quark ()
-GQuark gst_webrtc_bin_error_quark (void);
-
-typedef enum
-{
-  GST_WEBRTC_BIN_ERROR_FAILED,
-  GST_WEBRTC_BIN_ERROR_INVALID_SYNTAX,
-  GST_WEBRTC_BIN_ERROR_INVALID_MODIFICATION,
-  GST_WEBRTC_BIN_ERROR_INVALID_STATE,
-  GST_WEBRTC_BIN_ERROR_BAD_SDP,
-  GST_WEBRTC_BIN_ERROR_FINGERPRINT,
-  GST_WEBRTC_BIN_ERROR_SCTP_FAILURE,
-  GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE,
-  GST_WEBRTC_BIN_ERROR_CLOSED,
-} GstWebRTCError;
-
 GstPadTemplate *        _find_pad_template          (GstElement * element,
                                                      GstPadDirection direction,
                                                      GstPadPresence presence,
@@ -75,11 +59,18 @@ struct pad_block *      _create_pad_block           (GstElement * element,
                                                      GDestroyNotify notify);
 
 G_GNUC_INTERNAL
-gchar *                 _enum_value_to_string       (GType type, guint value);
+const gchar *                 _enum_value_to_string       (GType type, guint value);
 G_GNUC_INTERNAL
 const gchar *           _g_checksum_to_webrtc_string (GChecksumType type);
 G_GNUC_INTERNAL
 GstCaps *               _rtp_caps_from_media        (const GstSDPMedia * media);
+G_GNUC_INTERNAL
+GstWebRTCKind           webrtc_kind_from_caps       (const GstCaps * caps);
+G_GNUC_INTERNAL
+char *                  _get_msid_from_media        (const GstSDPMedia * media);
+
+#define gst_webrtc_kind_to_string(kind) _enum_value_to_string(GST_TYPE_WEBRTC_KIND, kind)
+#define gst_webrtc_rtp_transceiver_direction_to_string(dir) _enum_value_to_string(GST_TYPE_WEBRTC_RTP_TRANSCEIVER_DIRECTION, dir)
 
 G_END_DECLS
 
diff --git a/ext/webrtc/webrtcdatachannel.c b/ext/webrtc/webrtcdatachannel.c
index fde12613c..0260c6172 100644
--- a/ext/webrtc/webrtcdatachannel.c
+++ b/ext/webrtc/webrtcdatachannel.c
@@ -44,12 +44,150 @@
 #define GST_CAT_DEFAULT webrtc_data_channel_debug
 GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
 
+static void _close_procedure (WebRTCDataChannel * channel, gpointer user_data);
+
+typedef void (*ChannelTask) (GstWebRTCDataChannel * channel,
+    gpointer user_data);
+
+struct task
+{
+  GstWebRTCDataChannel *channel;
+  ChannelTask func;
+  gpointer user_data;
+  GDestroyNotify notify;
+};
+
+static GstStructure *
+_execute_task (GstWebRTCBin * webrtc, struct task *task)
+{
+  if (task->func)
+    task->func (task->channel, task->user_data);
+
+  return NULL;
+}
+
+static void
+_free_task (struct task *task)
+{
+  gst_object_unref (task->channel);
+
+  if (task->notify)
+    task->notify (task->user_data);
+  g_free (task);
+}
+
+static void
+_channel_enqueue_task (WebRTCDataChannel * channel, ChannelTask func,
+    gpointer user_data, GDestroyNotify notify)
+{
+  struct task *task = g_new0 (struct task, 1);
+
+  task->channel = gst_object_ref (channel);
+  task->func = func;
+  task->user_data = user_data;
+  task->notify = notify;
+
+  gst_webrtc_bin_enqueue_task (channel->webrtcbin,
+      (GstWebRTCBinFunc) _execute_task, task, (GDestroyNotify) _free_task,
+      NULL);
+}
+
+static void
+_channel_store_error (WebRTCDataChannel * channel, GError * error)
+{
+  GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
+  if (error) {
+    GST_WARNING_OBJECT (channel, "Error: %s",
+        error ? error->message : "Unknown");
+    if (!channel->stored_error)
+      channel->stored_error = error;
+    else
+      g_clear_error (&error);
+  }
+  GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
+}
+
+struct _WebRTCErrorIgnoreBin
+{
+  GstBin bin;
+
+  WebRTCDataChannel *data_channel;
+};
+
+G_DEFINE_TYPE (WebRTCErrorIgnoreBin, webrtc_error_ignore_bin, GST_TYPE_BIN);
+
+static void
+webrtc_error_ignore_bin_handle_message (GstBin * bin, GstMessage * message)
+{
+  WebRTCErrorIgnoreBin *self = WEBRTC_ERROR_IGNORE_BIN (bin);
+
+  switch (GST_MESSAGE_TYPE (message)) {
+    case GST_MESSAGE_ERROR:{
+      GError *error = NULL;
+      gst_message_parse_error (message, &error, NULL);
+      GST_DEBUG_OBJECT (bin, "handling error message from internal element");
+      _channel_store_error (self->data_channel, error);
+      _channel_enqueue_task (self->data_channel, (ChannelTask) _close_procedure,
+          NULL, NULL);
+      break;
+    }
+    default:
+      GST_BIN_CLASS (webrtc_error_ignore_bin_parent_class)->handle_message (bin,
+          message);
+      break;
+  }
+}
+
+static void
+webrtc_error_ignore_bin_class_init (WebRTCErrorIgnoreBinClass * klass)
+{
+  GstBinClass *bin_class = (GstBinClass *) klass;
+
+  bin_class->handle_message = webrtc_error_ignore_bin_handle_message;
+}
+
+static void
+webrtc_error_ignore_bin_init (WebRTCErrorIgnoreBin * bin)
+{
+}
+
+static GstElement *
+webrtc_error_ignore_bin_new (WebRTCDataChannel * data_channel,
+    GstElement * other)
+{
+  WebRTCErrorIgnoreBin *self;
+  GstPad *pad;
+
+  self = g_object_new (webrtc_error_ignore_bin_get_type (), NULL);
+  self->data_channel = data_channel;
+
+  gst_bin_add (GST_BIN (self), other);
+
+  pad = gst_element_get_static_pad (other, "src");
+  if (pad) {
+    GstPad *ghost_pad = gst_ghost_pad_new ("src", pad);
+    gst_element_add_pad (GST_ELEMENT (self), ghost_pad);
+    gst_clear_object (&pad);
+  }
+  pad = gst_element_get_static_pad (other, "sink");
+  if (pad) {
+    GstPad *ghost_pad = gst_ghost_pad_new ("sink", pad);
+    gst_element_add_pad (GST_ELEMENT (self), ghost_pad);
+    gst_clear_object (&pad);
+  }
+
+  return (GstElement *) self;
+}
+
 #define webrtc_data_channel_parent_class parent_class
 G_DEFINE_TYPE_WITH_CODE (WebRTCDataChannel, webrtc_data_channel,
     GST_TYPE_WEBRTC_DATA_CHANNEL,
     GST_DEBUG_CATEGORY_INIT (webrtc_data_channel_debug, "webrtcdatachannel", 0,
         "webrtcdatachannel"););
 
+G_LOCK_DEFINE_STATIC (outstanding_channels_lock);
+static GList *outstanding_channels;
+
 typedef enum
 {
   DATA_CHANNEL_PPID_WEBRTC_CONTROL = 50,
@@ -210,65 +348,6 @@ construct_ack_packet (WebRTCDataChannel * channel)
   return buf;
 }
 
-typedef void (*ChannelTask) (GstWebRTCDataChannel * channel,
-    gpointer user_data);
-
-struct task
-{
-  GstWebRTCDataChannel *channel;
-  ChannelTask func;
-  gpointer user_data;
-  GDestroyNotify notify;
-};
-
-static void
-_execute_task (GstWebRTCBin * webrtc, struct task *task)
-{
-  if (task->func)
-    task->func (task->channel, task->user_data);
-}
-
-static void
-_free_task (struct task *task)
-{
-  gst_object_unref (task->channel);
-
-  if (task->notify)
-    task->notify (task->user_data);
-  g_free (task);
-}
-
-static void
-_channel_enqueue_task (WebRTCDataChannel * channel, ChannelTask func,
-    gpointer user_data, GDestroyNotify notify)
-{
-  struct task *task = g_new0 (struct task, 1);
-
-  task->channel = gst_object_ref (channel);
-  task->func = func;
-  task->user_data = user_data;
-  task->notify = notify;
-
-  gst_webrtc_bin_enqueue_task (channel->webrtcbin,
-      (GstWebRTCBinFunc) _execute_task, task, (GDestroyNotify) _free_task,
-      NULL);
-}
-
-static void
-_channel_store_error (WebRTCDataChannel * channel, GError * error)
-{
-  GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
-  if (error) {
-    GST_WARNING_OBJECT (channel, "Error: %s",
-        error ? error->message : "Unknown");
-    if (!channel->stored_error)
-      channel->stored_error = error;
-    else
-      g_clear_error (&error);
-  }
-  GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
-}
-
 static void
 _emit_on_open (WebRTCDataChannel * channel, gpointer user_data)
 {
@@ -279,17 +358,30 @@ static void
 _transport_closed (WebRTCDataChannel * channel)
 {
   GError *error;
+  gboolean both_sides_closed;
 
   GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
   error = channel->stored_error;
   channel->stored_error = NULL;
+
+  GST_TRACE_OBJECT (channel, "transport closed, peer closed %u error %p "
+      "buffered %" G_GUINT64_FORMAT, channel->peer_closed, error,
+      channel->parent.buffered_amount);
+
+  both_sides_closed =
+      channel->peer_closed && channel->parent.buffered_amount <= 0;
+  if (both_sides_closed || error) {
+    channel->peer_closed = FALSE;
+  }
   GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
 
   if (error) {
     gst_webrtc_data_channel_on_error (GST_WEBRTC_DATA_CHANNEL (channel), error);
     g_clear_error (&error);
   }
-  gst_webrtc_data_channel_on_close (GST_WEBRTC_DATA_CHANNEL (channel));
+  if (both_sides_closed || error) {
+    gst_webrtc_data_channel_on_close (GST_WEBRTC_DATA_CHANNEL (channel));
+  }
 }
 
 static void
@@ -297,7 +389,10 @@ _close_sctp_stream (WebRTCDataChannel * channel, gpointer user_data)
 {
   GstPad *pad, *peer;
 
-  pad = gst_element_get_static_pad (channel->appsrc, "src");
+  GST_INFO_OBJECT (channel, "Closing outgoing SCTP stream %i label \"%s\"",
+      channel->parent.id, channel->parent.label);
+
+  pad = gst_element_get_static_pad (channel->src_bin, "src");
   peer = gst_pad_get_peer (pad);
   gst_object_unref (pad);
 
@@ -305,6 +400,7 @@ _close_sctp_stream (WebRTCDataChannel * channel, gpointer user_data)
     GstElement *sctpenc = gst_pad_get_parent_element (peer);
 
     if (sctpenc) {
+      GST_TRACE_OBJECT (channel, "removing sctpenc pad %" GST_PTR_FORMAT, peer);
       gst_element_release_request_pad (sctpenc, peer);
       gst_object_unref (sctpenc);
     }
@@ -319,31 +415,44 @@ _close_procedure (WebRTCDataChannel * channel, gpointer user_data)
 {
   /* https://www.w3.org/TR/webrtc/#data-transport-closing-procedure */
   GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
-  if (channel->parent.ready_state == GST_WEBRTC_DATA_CHANNEL_STATE_CLOSED
-      || channel->parent.ready_state == GST_WEBRTC_DATA_CHANNEL_STATE_CLOSING) {
+  if (channel->parent.ready_state == GST_WEBRTC_DATA_CHANNEL_STATE_CLOSED) {
     GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
     return;
-  }
-  channel->parent.ready_state = GST_WEBRTC_DATA_CHANNEL_STATE_CLOSING;
-  GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
-  g_object_notify (G_OBJECT (channel), "ready-state");
+  } else if (channel->parent.ready_state ==
+      GST_WEBRTC_DATA_CHANNEL_STATE_CLOSING) {
+    _channel_enqueue_task (channel, (ChannelTask) _transport_closed, NULL,
+        NULL);
+  } else if (channel->parent.ready_state == GST_WEBRTC_DATA_CHANNEL_STATE_OPEN) {
+    channel->parent.ready_state = GST_WEBRTC_DATA_CHANNEL_STATE_CLOSING;
+    GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
+    g_object_notify (G_OBJECT (channel), "ready-state");
 
-  GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
-  if (channel->parent.buffered_amount <= 0) {
-    _channel_enqueue_task (channel, (ChannelTask) _close_sctp_stream,
-        NULL, NULL);
+    GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
+    if (channel->parent.buffered_amount <= 0) {
+      _channel_enqueue_task (channel, (ChannelTask) _close_sctp_stream,
+          NULL, NULL);
+    }
   }
 
   GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
 }
 
 static void
-_on_sctp_reset_stream (GstWebRTCSCTPTransport * sctp, guint stream_id,
+_on_sctp_stream_reset (WebRTCSCTPTransport * sctp, guint stream_id,
     WebRTCDataChannel * channel)
 {
-  if (channel->parent.id == stream_id)
-    _channel_enqueue_task (channel, (ChannelTask) _transport_closed,
+  if (channel->parent.id == stream_id) {
+    GST_INFO_OBJECT (channel,
+        "Received channel close for SCTP stream %i label \"%s\"",
+        channel->parent.id, channel->parent.label);
+
+    GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
+    channel->peer_closed = TRUE;
+    GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
+
+    _channel_enqueue_task (channel, (ChannelTask) _close_procedure,
         GUINT_TO_POINTER (stream_id), NULL);
+  }
 }
 
 static void
@@ -386,8 +495,8 @@ _parse_control_packet (WebRTCDataChannel * channel, guint8 * data,
     GST_INFO_OBJECT (channel, "Received channel open");
 
     if (channel->parent.negotiated) {
-      g_set_error (error, GST_WEBRTC_BIN_ERROR,
-          GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE,
+      g_set_error (error, GST_WEBRTC_ERROR,
+          GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE,
           "Data channel was signalled as negotiated already");
       g_return_val_if_reached (GST_FLOW_ERROR);
     }
@@ -437,7 +546,7 @@ _parse_control_packet (WebRTCDataChannel * channel, guint8 * data,
     channel->opened = TRUE;
 
     GST_INFO_OBJECT (channel, "Received channel open for SCTP stream %i "
-        "label %s protocol %s ordered %s", channel->parent.id,
+        "label \"%s\" protocol %s ordered %s", channel->parent.id,
         channel->parent.label, channel->parent.protocol,
         channel->parent.ordered ? "true" : "false");
 
@@ -452,16 +561,17 @@ _parse_control_packet (WebRTCDataChannel * channel, guint8 * data,
 
     ret = gst_app_src_push_buffer (GST_APP_SRC (channel->appsrc), buffer);
     if (ret != GST_FLOW_OK) {
-      g_set_error (error, GST_WEBRTC_BIN_ERROR,
-          GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE,
-          "Could not send ack packet");
+      g_set_error (error, GST_WEBRTC_ERROR,
+          GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE, "Could not send ack packet");
+      GST_WARNING_OBJECT (channel, "push returned %i, %s", ret,
+          gst_flow_get_name (ret));
       return ret;
     }
 
     return ret;
   } else {
-    g_set_error (error, GST_WEBRTC_BIN_ERROR,
-        GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE,
+    g_set_error (error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE,
         "Unknown message type in control protocol");
     return GST_FLOW_ERROR;
   }
@@ -470,8 +580,8 @@ parse_error:
   {
     g_free (label);
     g_free (proto);
-    g_set_error (error, GST_WEBRTC_BIN_ERROR,
-        GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE, "Failed to parse packet");
+    g_set_error (error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE, "Failed to parse packet");
     g_return_val_if_reached (GST_FLOW_ERROR);
   }
 }
@@ -523,14 +633,14 @@ _data_channel_have_sample (WebRTCDataChannel * channel, GstSample * sample,
 
   buffer = gst_sample_get_buffer (sample);
   if (!buffer) {
-    g_set_error (error, GST_WEBRTC_BIN_ERROR,
-        GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE, "No buffer to handle");
+    g_set_error (error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE, "No buffer to handle");
     return GST_FLOW_ERROR;
   }
   receive = gst_sctp_buffer_get_receive_meta (buffer);
   if (!receive) {
-    g_set_error (error, GST_WEBRTC_BIN_ERROR,
-        GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE,
+    g_set_error (error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE,
         "No SCTP Receive meta on the buffer");
     return GST_FLOW_ERROR;
   }
@@ -539,8 +649,8 @@ _data_channel_have_sample (WebRTCDataChannel * channel, GstSample * sample,
     case DATA_CHANNEL_PPID_WEBRTC_CONTROL:{
       GstMapInfo info = GST_MAP_INFO_INIT;
       if (!gst_buffer_map (buffer, &info, GST_MAP_READ)) {
-        g_set_error (error, GST_WEBRTC_BIN_ERROR,
-            GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE,
+        g_set_error (error, GST_WEBRTC_ERROR,
+            GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE,
             "Failed to map received buffer");
         ret = GST_FLOW_ERROR;
       } else {
@@ -553,8 +663,8 @@ _data_channel_have_sample (WebRTCDataChannel * channel, GstSample * sample,
     case DATA_CHANNEL_PPID_WEBRTC_STRING_PARTIAL:{
       GstMapInfo info = GST_MAP_INFO_INIT;
       if (!gst_buffer_map (buffer, &info, GST_MAP_READ)) {
-        g_set_error (error, GST_WEBRTC_BIN_ERROR,
-            GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE,
+        g_set_error (error, GST_WEBRTC_ERROR,
+            GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE,
             "Failed to map received buffer");
         ret = GST_FLOW_ERROR;
       } else {
@@ -569,8 +679,8 @@ _data_channel_have_sample (WebRTCDataChannel * channel, GstSample * sample,
     case DATA_CHANNEL_PPID_WEBRTC_BINARY_PARTIAL:{
       struct map_info *info = g_new0 (struct map_info, 1);
       if (!gst_buffer_map (buffer, &info->map_info, GST_MAP_READ)) {
-        g_set_error (error, GST_WEBRTC_BIN_ERROR,
-            GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE,
+        g_set_error (error, GST_WEBRTC_ERROR,
+            GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE,
             "Failed to map received buffer");
         ret = GST_FLOW_ERROR;
       } else {
@@ -591,8 +701,8 @@ _data_channel_have_sample (WebRTCDataChannel * channel, GstSample * sample,
           NULL);
       break;
     default:
-      g_set_error (error, GST_WEBRTC_BIN_ERROR,
-          GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE,
+      g_set_error (error, GST_WEBRTC_ERROR,
+          GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE,
           "Unknown SCTP PPID %u received", receive->ppid);
       ret = GST_FLOW_ERROR;
       break;
@@ -671,13 +781,14 @@ webrtc_data_channel_start_negotiation (WebRTCDataChannel * channel)
   buffer = construct_open_packet (channel);
 
   GST_INFO_OBJECT (channel, "Sending channel open for SCTP stream %i "
-      "label %s protocol %s ordered %s", channel->parent.id,
+      "label \"%s\" protocol %s ordered %s", channel->parent.id,
       channel->parent.label, channel->parent.protocol,
       channel->parent.ordered ? "true" : "false");
 
   GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
   channel->parent.buffered_amount += gst_buffer_get_size (buffer);
   GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
+  g_object_notify (G_OBJECT (&channel->parent), "buffered-amount");
 
   if (gst_app_src_push_buffer (GST_APP_SRC (channel->appsrc),
           buffer) == GST_FLOW_OK) {
@@ -685,8 +796,8 @@ webrtc_data_channel_start_negotiation (WebRTCDataChannel * channel)
     _channel_enqueue_task (channel, (ChannelTask) _emit_on_open, NULL, NULL);
   } else {
     GError *error = NULL;
-    g_set_error (&error, GST_WEBRTC_BIN_ERROR,
-        GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE,
+    g_set_error (&error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE,
         "Failed to send DCEP open packet");
     _channel_store_error (channel, error);
     _channel_enqueue_task (channel, (ChannelTask) _close_procedure, NULL, NULL);
@@ -715,35 +826,30 @@ _is_within_max_message_size (WebRTCDataChannel * channel, gsize size)
   return size <= channel->sctp_transport->max_message_size;
 }
 
-static void
+static gboolean
 webrtc_data_channel_send_data (GstWebRTCDataChannel * base_channel,
-    GBytes * bytes)
+    GBytes * bytes, GError ** error)
 {
   WebRTCDataChannel *channel = WEBRTC_DATA_CHANNEL (base_channel);
   GstSctpSendMetaPartiallyReliability reliability;
   guint rel_param;
   guint32 ppid;
   GstBuffer *buffer;
+  gsize size = 0;
   GstFlowReturn ret;
 
   if (!bytes) {
     buffer = gst_buffer_new ();
     ppid = DATA_CHANNEL_PPID_WEBRTC_BINARY_EMPTY;
   } else {
-    gsize size;
     guint8 *data;
 
     data = (guint8 *) g_bytes_get_data (bytes, &size);
-    g_return_if_fail (data != NULL);
+    g_return_val_if_fail (data != NULL, FALSE);
     if (!_is_within_max_message_size (channel, size)) {
-      GError *error = NULL;
-      g_set_error (&error, GST_WEBRTC_BIN_ERROR,
-          GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE,
+      g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_TYPE_ERROR,
           "Requested to send data that is too large");
-      _channel_store_error (channel, error);
-      _channel_enqueue_task (channel, (ChannelTask) _close_procedure, NULL,
-          NULL);
-      return;
+      return FALSE;
     }
 
     buffer = gst_buffer_new_wrapped_full (GST_MEMORY_FLAG_READONLY, data, size,
@@ -759,53 +865,66 @@ webrtc_data_channel_send_data (GstWebRTCDataChannel * base_channel,
       buffer);
 
   GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
-  channel->parent.buffered_amount += gst_buffer_get_size (buffer);
+  if (channel->parent.ready_state == GST_WEBRTC_DATA_CHANNEL_STATE_OPEN) {
+    channel->parent.buffered_amount += size;
+  } else {
+    GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
+    g_set_error (error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_INVALID_STATE, "channel is not open");
+    return FALSE;
+  }
   GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
 
   ret = gst_app_src_push_buffer (GST_APP_SRC (channel->appsrc), buffer);
+  if (ret == GST_FLOW_OK) {
+    g_object_notify (G_OBJECT (&channel->parent), "buffered-amount");
+  } else {
+    g_set_error (error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE, "Failed to send data");
+    GST_WARNING_OBJECT (channel, "push returned %i, %s", ret,
+        gst_flow_get_name (ret));
+
+    GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
+    channel->parent.buffered_amount -= size;
+    GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
 
-  if (ret != GST_FLOW_OK) {
-    GError *error = NULL;
-    g_set_error (&error, GST_WEBRTC_BIN_ERROR,
-        GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE, "Failed to send data");
-    _channel_store_error (channel, error);
     _channel_enqueue_task (channel, (ChannelTask) _close_procedure, NULL, NULL);
+    return FALSE;
   }
+
+  return TRUE;
 }
 
-static void
+static gboolean
 webrtc_data_channel_send_string (GstWebRTCDataChannel * base_channel,
-    const gchar * str)
+    const gchar * str, GError ** error)
 {
   WebRTCDataChannel *channel = WEBRTC_DATA_CHANNEL (base_channel);
   GstSctpSendMetaPartiallyReliability reliability;
   guint rel_param;
   guint32 ppid;
   GstBuffer *buffer;
+  gsize size = 0;
   GstFlowReturn ret;
 
   if (!channel->parent.negotiated)
-    g_return_if_fail (channel->opened);
-  g_return_if_fail (channel->sctp_transport != NULL);
+    g_return_val_if_fail (channel->opened, FALSE);
+  g_return_val_if_fail (channel->sctp_transport != NULL, FALSE);
 
   if (!str) {
     buffer = gst_buffer_new ();
     ppid = DATA_CHANNEL_PPID_WEBRTC_STRING_EMPTY;
   } else {
-    gsize size = strlen (str);
-    gchar *str_copy = g_strdup (str);
+    gchar *str_copy;
+    size = strlen (str);
 
     if (!_is_within_max_message_size (channel, size)) {
-      GError *error = NULL;
-      g_set_error (&error, GST_WEBRTC_BIN_ERROR,
-          GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE,
+      g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_TYPE_ERROR,
           "Requested to send a string that is too large");
-      _channel_store_error (channel, error);
-      _channel_enqueue_task (channel, (ChannelTask) _close_procedure, NULL,
-          NULL);
-      return;
+      return FALSE;
     }
 
+    str_copy = g_strdup (str);
     buffer =
         gst_buffer_new_wrapped_full (GST_MEMORY_FLAG_READONLY, str_copy,
         size, 0, size, str_copy, g_free);
@@ -820,18 +939,32 @@ webrtc_data_channel_send_string (GstWebRTCDataChannel * base_channel,
       buffer);
 
   GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
-  channel->parent.buffered_amount += gst_buffer_get_size (buffer);
+  if (channel->parent.ready_state == GST_WEBRTC_DATA_CHANNEL_STATE_OPEN) {
+    channel->parent.buffered_amount += size;
+  } else {
+    GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
+    g_set_error (error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_INVALID_STATE, "channel is not open");
+    return FALSE;
+  }
   GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
 
   ret = gst_app_src_push_buffer (GST_APP_SRC (channel->appsrc), buffer);
+  if (ret == GST_FLOW_OK) {
+    g_object_notify (G_OBJECT (&channel->parent), "buffered-amount");
+  } else {
+    g_set_error (error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE, "Failed to send string");
+
+    GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
+    channel->parent.buffered_amount -= size;
+    GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
 
-  if (ret != GST_FLOW_OK) {
-    GError *error = NULL;
-    g_set_error (&error, GST_WEBRTC_BIN_ERROR,
-        GST_WEBRTC_BIN_ERROR_DATA_CHANNEL_FAILURE, "Failed to send string");
-    _channel_store_error (channel, error);
     _channel_enqueue_task (channel, (ChannelTask) _close_procedure, NULL, NULL);
+    return FALSE;
   }
+
+  return TRUE;
 }
 
 static void
@@ -847,13 +980,37 @@ _on_sctp_notify_state_unlocked (GObject * sctp_transport,
   }
 }
 
+static WebRTCDataChannel *
+ensure_channel_alive (WebRTCDataChannel * channel)
+{
+  /* ghetto impl of, does the channel still exist?.
+   * Needed because g_signal_handler_disconnect*() will not disconnect any
+   * running functions and _finalize() implementation can complete and
+   * invalidate channel */
+  G_LOCK (outstanding_channels_lock);
+  if (g_list_find (outstanding_channels, channel)) {
+    g_object_ref (channel);
+  } else {
+    G_UNLOCK (outstanding_channels_lock);
+    return NULL;
+  }
+  G_UNLOCK (outstanding_channels_lock);
+
+  return channel;
+}
+
 static void
 _on_sctp_notify_state (GObject * sctp_transport, GParamSpec * pspec,
     WebRTCDataChannel * channel)
 {
+  if (!(channel = ensure_channel_alive (channel)))
+    return;
+
   GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
   _on_sctp_notify_state_unlocked (sctp_transport, channel);
   GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
+
+  g_object_unref (channel);
 }
 
 static void
@@ -888,7 +1045,7 @@ on_appsrc_data (GstPad * pad, GstPadProbeInfo * info, gpointer user_data)
         channel->parent.buffered_amount_low_threshold,
         channel->parent.buffered_amount);
     if (prev_amount >= channel->parent.buffered_amount_low_threshold
-        && channel->parent.buffered_amount <
+        && channel->parent.buffered_amount <=
         channel->parent.buffered_amount_low_threshold) {
       _channel_enqueue_task (channel, (ChannelTask) _emit_low_threshold, NULL,
           NULL);
@@ -900,6 +1057,7 @@ on_appsrc_data (GstPad * pad, GstPadProbeInfo * info, gpointer user_data)
           NULL);
     }
     GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
+    g_object_notify (G_OBJECT (&channel->parent), "buffered-amount");
   }
 
   return GST_PAD_PROBE_OK;
@@ -908,10 +1066,15 @@ on_appsrc_data (GstPad * pad, GstPadProbeInfo * info, gpointer user_data)
 static void
 gst_webrtc_data_channel_constructed (GObject * object)
 {
-  WebRTCDataChannel *channel = WEBRTC_DATA_CHANNEL (object);
+  WebRTCDataChannel *channel;
   GstPad *pad;
   GstCaps *caps;
 
+  G_OBJECT_CLASS (parent_class)->constructed (object);
+
+  channel = WEBRTC_DATA_CHANNEL (object);
+  GST_DEBUG ("New channel %p constructed", channel);
+
   caps = gst_caps_new_any ();
 
   channel->appsrc = gst_element_factory_make ("appsrc", NULL);
@@ -921,6 +1084,8 @@ gst_webrtc_data_channel_constructed (GObject * object)
   channel->src_probe = gst_pad_add_probe (pad, GST_PAD_PROBE_TYPE_DATA_BOTH,
       (GstPadProbeCallback) on_appsrc_data, channel, NULL);
 
+  channel->src_bin = webrtc_error_ignore_bin_new (channel, channel->appsrc);
+
   channel->appsink = gst_element_factory_make ("appsink", NULL);
   gst_object_ref_sink (channel->appsink);
   g_object_set (channel->appsink, "sync", FALSE, "async", FALSE, "caps", caps,
@@ -928,10 +1093,22 @@ gst_webrtc_data_channel_constructed (GObject * object)
   gst_app_sink_set_callbacks (GST_APP_SINK (channel->appsink), &sink_callbacks,
       channel, NULL);
 
+  channel->sink_bin = webrtc_error_ignore_bin_new (channel, channel->appsink);
+
   gst_object_unref (pad);
   gst_caps_unref (caps);
 }
 
+static void
+gst_webrtc_data_channel_dispose (GObject * object)
+{
+  G_LOCK (outstanding_channels_lock);
+  outstanding_channels = g_list_remove (outstanding_channels, object);
+  G_UNLOCK (outstanding_channels_lock);
+
+  G_OBJECT_CLASS (parent_class)->dispose (object);
+}
+
 static void
 gst_webrtc_data_channel_finalize (GObject * object)
 {
@@ -962,6 +1139,7 @@ webrtc_data_channel_class_init (WebRTCDataChannelClass * klass)
       (GstWebRTCDataChannelClass *) klass;
 
   gobject_class->constructed = gst_webrtc_data_channel_constructed;
+  gobject_class->dispose = gst_webrtc_data_channel_dispose;
   gobject_class->finalize = gst_webrtc_data_channel_finalize;
 
   channel_class->send_data = webrtc_data_channel_send_data;
@@ -972,11 +1150,14 @@ webrtc_data_channel_class_init (WebRTCDataChannelClass * klass)
 static void
 webrtc_data_channel_init (WebRTCDataChannel * channel)
 {
+  G_LOCK (outstanding_channels_lock);
+  outstanding_channels = g_list_prepend (outstanding_channels, channel);
+  G_UNLOCK (outstanding_channels_lock);
 }
 
 static void
 _data_channel_set_sctp_transport (WebRTCDataChannel * channel,
-    GstWebRTCSCTPTransport * sctp)
+    WebRTCSCTPTransport * sctp)
 {
   g_return_if_fail (GST_IS_WEBRTC_DATA_CHANNEL (channel));
   g_return_if_fail (GST_IS_WEBRTC_SCTP_TRANSPORT (sctp));
@@ -984,23 +1165,23 @@ _data_channel_set_sctp_transport (WebRTCDataChannel * channel,
   GST_WEBRTC_DATA_CHANNEL_LOCK (channel);
   if (channel->sctp_transport)
     g_signal_handlers_disconnect_by_data (channel->sctp_transport, channel);
+  GST_TRACE_OBJECT (channel, "set sctp %p", sctp);
 
   gst_object_replace ((GstObject **) & channel->sctp_transport,
       GST_OBJECT (sctp));
 
   if (sctp) {
-    g_signal_connect (sctp, "stream-reset", G_CALLBACK (_on_sctp_reset_stream),
+    g_signal_connect (sctp, "stream-reset", G_CALLBACK (_on_sctp_stream_reset),
         channel);
     g_signal_connect (sctp, "notify::state", G_CALLBACK (_on_sctp_notify_state),
         channel);
-    _on_sctp_notify_state_unlocked (G_OBJECT (sctp), channel);
   }
   GST_WEBRTC_DATA_CHANNEL_UNLOCK (channel);
 }
 
 void
 webrtc_data_channel_link_to_sctp (WebRTCDataChannel * channel,
-    GstWebRTCSCTPTransport * sctp_transport)
+    WebRTCSCTPTransport * sctp_transport)
 {
   if (sctp_transport && !channel->sctp_transport) {
     gint id;
@@ -1012,10 +1193,12 @@ webrtc_data_channel_link_to_sctp (WebRTCDataChannel * channel,
 
       _data_channel_set_sctp_transport (channel, sctp_transport);
       pad_name = g_strdup_printf ("sink_%u", id);
-      if (!gst_element_link_pads (channel->appsrc, "src",
+      if (!gst_element_link_pads (channel->src_bin, "src",
               channel->sctp_transport->sctpenc, pad_name))
         g_warn_if_reached ();
       g_free (pad_name);
+
+      _on_sctp_notify_state_unlocked (G_OBJECT (sctp_transport), channel);
     }
   }
 }
diff --git a/ext/webrtc/webrtcdatachannel.h b/ext/webrtc/webrtcdatachannel.h
index 7ca3c0d17..dd65a66ae 100644
--- a/ext/webrtc/webrtcdatachannel.h
+++ b/ext/webrtc/webrtcdatachannel.h
@@ -24,7 +24,9 @@
 #include <gst/webrtc/webrtc_fwd.h>
 #include <gst/webrtc/dtlstransport.h>
 #include <gst/webrtc/datachannel.h>
-#include "sctptransport.h"
+#include "webrtcsctptransport.h"
+
+#include "gst/webrtc/webrtc-priv.h"
 
 G_BEGIN_DECLS
 
@@ -43,14 +45,17 @@ struct _WebRTCDataChannel
 {
   GstWebRTCDataChannel              parent;
 
-  GstWebRTCSCTPTransport           *sctp_transport;
+  WebRTCSCTPTransport              *sctp_transport;
+  GstElement                       *src_bin;
   GstElement                       *appsrc;
+  GstElement                       *sink_bin;
   GstElement                       *appsink;
 
   GstWebRTCBin                     *webrtcbin;
   gboolean                          opened;
   gulong                            src_probe;
   GError                           *stored_error;
+  gboolean                          peer_closed;
 
   gpointer                          _padding[GST_PADDING];
 };
@@ -65,7 +70,9 @@ struct _WebRTCDataChannelClass
 void    webrtc_data_channel_start_negotiation   (WebRTCDataChannel       *channel);
 G_GNUC_INTERNAL
 void    webrtc_data_channel_link_to_sctp (WebRTCDataChannel                 *channel,
-                                          GstWebRTCSCTPTransport            *sctp_transport);
+                                          WebRTCSCTPTransport               *sctp_transport);
+
+G_DECLARE_FINAL_TYPE (WebRTCErrorIgnoreBin, webrtc_error_ignore_bin, WEBRTC, ERROR_IGNORE_BIN, GstBin);
 
 G_END_DECLS
 
diff --git a/ext/webrtc/webrtcsctptransport.c b/ext/webrtc/webrtcsctptransport.c
new file mode 100644
index 000000000..c65dd1973
--- /dev/null
+++ b/ext/webrtc/webrtcsctptransport.c
@@ -0,0 +1,251 @@
+/* GStreamer
+ * Copyright (C) 2018 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include <stdio.h>
+
+#include "webrtcsctptransport.h"
+#include "gstwebrtcbin.h"
+
+#define GST_CAT_DEFAULT webrtc_sctp_transport_debug
+GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
+
+enum
+{
+  SIGNAL_0,
+  ON_STREAM_RESET_SIGNAL,
+  LAST_SIGNAL,
+};
+
+enum
+{
+  PROP_0,
+  PROP_TRANSPORT,
+  PROP_STATE,
+  PROP_MAX_MESSAGE_SIZE,
+  PROP_MAX_CHANNELS,
+};
+
+static guint webrtc_sctp_transport_signals[LAST_SIGNAL] = { 0 };
+
+#define webrtc_sctp_transport_parent_class parent_class
+G_DEFINE_TYPE_WITH_CODE (WebRTCSCTPTransport, webrtc_sctp_transport,
+    GST_TYPE_WEBRTC_SCTP_TRANSPORT,
+    GST_DEBUG_CATEGORY_INIT (webrtc_sctp_transport_debug,
+        "webrtcsctptransport", 0, "webrtcsctptransport"););
+
+typedef void (*SCTPTask) (WebRTCSCTPTransport * sctp, gpointer user_data);
+
+struct task
+{
+  WebRTCSCTPTransport *sctp;
+  SCTPTask func;
+  gpointer user_data;
+  GDestroyNotify notify;
+};
+
+static GstStructure *
+_execute_task (GstWebRTCBin * webrtc, struct task *task)
+{
+  if (task->func)
+    task->func (task->sctp, task->user_data);
+  return NULL;
+}
+
+static void
+_free_task (struct task *task)
+{
+  gst_object_unref (task->sctp);
+
+  if (task->notify)
+    task->notify (task->user_data);
+  g_free (task);
+}
+
+static void
+_sctp_enqueue_task (WebRTCSCTPTransport * sctp, SCTPTask func,
+    gpointer user_data, GDestroyNotify notify)
+{
+  struct task *task = g_new0 (struct task, 1);
+
+  task->sctp = gst_object_ref (sctp);
+  task->func = func;
+  task->user_data = user_data;
+  task->notify = notify;
+
+  gst_webrtc_bin_enqueue_task (sctp->webrtcbin,
+      (GstWebRTCBinFunc) _execute_task, task, (GDestroyNotify) _free_task,
+      NULL);
+}
+
+static void
+_emit_stream_reset (WebRTCSCTPTransport * sctp, gpointer user_data)
+{
+  guint stream_id = GPOINTER_TO_UINT (user_data);
+
+  g_signal_emit (sctp,
+      webrtc_sctp_transport_signals[ON_STREAM_RESET_SIGNAL], 0, stream_id);
+}
+
+static void
+_on_sctp_dec_pad_removed (GstElement * sctpdec, GstPad * pad,
+    WebRTCSCTPTransport * sctp)
+{
+  guint stream_id;
+
+  if (sscanf (GST_PAD_NAME (pad), "src_%u", &stream_id) != 1)
+    return;
+
+  _sctp_enqueue_task (sctp, (SCTPTask) _emit_stream_reset,
+      GUINT_TO_POINTER (stream_id), NULL);
+}
+
+static void
+_on_sctp_association_established (GstElement * sctpenc, gboolean established,
+    WebRTCSCTPTransport * sctp)
+{
+  GST_OBJECT_LOCK (sctp);
+  if (established)
+    sctp->state = GST_WEBRTC_SCTP_TRANSPORT_STATE_CONNECTED;
+  else
+    sctp->state = GST_WEBRTC_SCTP_TRANSPORT_STATE_CLOSED;
+  sctp->association_established = established;
+  GST_OBJECT_UNLOCK (sctp);
+
+  g_object_notify (G_OBJECT (sctp), "state");
+}
+
+void
+webrtc_sctp_transport_set_priority (WebRTCSCTPTransport * sctp,
+    GstWebRTCPriorityType priority)
+{
+  GstPad *pad;
+
+  pad = gst_element_get_static_pad (sctp->sctpenc, "src");
+  gst_pad_push_event (pad,
+      gst_event_new_custom (GST_EVENT_CUSTOM_DOWNSTREAM_STICKY,
+          gst_structure_new ("GstWebRtcBinUpdateTos", "sctp-priority",
+              GST_TYPE_WEBRTC_PRIORITY_TYPE, priority, NULL)));
+  gst_object_unref (pad);
+}
+
+static void
+webrtc_sctp_transport_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  WebRTCSCTPTransport *sctp = WEBRTC_SCTP_TRANSPORT (object);
+
+  switch (prop_id) {
+    case PROP_TRANSPORT:
+      g_value_set_object (value, sctp->transport);
+      break;
+    case PROP_STATE:
+      g_value_set_enum (value, sctp->state);
+      break;
+    case PROP_MAX_MESSAGE_SIZE:
+      g_value_set_uint64 (value, sctp->max_message_size);
+      break;
+    case PROP_MAX_CHANNELS:
+      g_value_set_uint (value, sctp->max_channels);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+webrtc_sctp_transport_finalize (GObject * object)
+{
+  WebRTCSCTPTransport *sctp = WEBRTC_SCTP_TRANSPORT (object);
+
+  g_signal_handlers_disconnect_by_data (sctp->sctpdec, sctp);
+  g_signal_handlers_disconnect_by_data (sctp->sctpenc, sctp);
+
+  gst_object_unref (sctp->sctpdec);
+  gst_object_unref (sctp->sctpenc);
+
+  g_clear_object (&sctp->transport);
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
+static void
+webrtc_sctp_transport_constructed (GObject * object)
+{
+  WebRTCSCTPTransport *sctp = WEBRTC_SCTP_TRANSPORT (object);
+  guint association_id;
+
+  association_id = g_random_int_range (0, G_MAXUINT16);
+
+  sctp->sctpdec =
+      g_object_ref_sink (gst_element_factory_make ("sctpdec", NULL));
+  g_object_set (sctp->sctpdec, "sctp-association-id", association_id, NULL);
+  sctp->sctpenc =
+      g_object_ref_sink (gst_element_factory_make ("sctpenc", NULL));
+  g_object_set (sctp->sctpenc, "sctp-association-id", association_id, NULL);
+  g_object_set (sctp->sctpenc, "use-sock-stream", TRUE, NULL);
+
+  g_signal_connect (sctp->sctpdec, "pad-removed",
+      G_CALLBACK (_on_sctp_dec_pad_removed), sctp);
+  g_signal_connect (sctp->sctpenc, "sctp-association-established",
+      G_CALLBACK (_on_sctp_association_established), sctp);
+
+  G_OBJECT_CLASS (parent_class)->constructed (object);
+}
+
+static void
+webrtc_sctp_transport_class_init (WebRTCSCTPTransportClass * klass)
+{
+  GObjectClass *gobject_class = (GObjectClass *) klass;
+
+  gobject_class->constructed = webrtc_sctp_transport_constructed;
+  gobject_class->get_property = webrtc_sctp_transport_get_property;
+  gobject_class->finalize = webrtc_sctp_transport_finalize;
+
+  g_object_class_override_property (gobject_class, PROP_TRANSPORT, "transport");
+  g_object_class_override_property (gobject_class, PROP_STATE, "state");
+  g_object_class_override_property (gobject_class,
+      PROP_MAX_MESSAGE_SIZE, "max-message-size");
+  g_object_class_override_property (gobject_class,
+      PROP_MAX_CHANNELS, "max-channels");
+
+  /**
+   * WebRTCSCTPTransport::stream-reset:
+   * @object: the #WebRTCSCTPTransport
+   * @stream_id: the SCTP stream that was reset
+   */
+  webrtc_sctp_transport_signals[ON_STREAM_RESET_SIGNAL] =
+      g_signal_new ("stream-reset", G_TYPE_FROM_CLASS (klass),
+      G_SIGNAL_RUN_LAST, 0, NULL, NULL, NULL, G_TYPE_NONE, 1, G_TYPE_UINT);
+}
+
+static void
+webrtc_sctp_transport_init (WebRTCSCTPTransport * nice)
+{
+}
+
+WebRTCSCTPTransport *
+webrtc_sctp_transport_new (void)
+{
+  return g_object_new (TYPE_WEBRTC_SCTP_TRANSPORT, NULL);
+}
diff --git a/ext/webrtc/webrtcsctptransport.h b/ext/webrtc/webrtcsctptransport.h
new file mode 100644
index 000000000..5661fc349
--- /dev/null
+++ b/ext/webrtc/webrtcsctptransport.h
@@ -0,0 +1,74 @@
+/* GStreamer
+ * Copyright (C) 2018 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef __WEBRTC_SCTP_TRANSPORT_H__
+#define __WEBRTC_SCTP_TRANSPORT_H__
+
+#include <gst/gst.h>
+#include <gst/webrtc/webrtc.h>
+#include <gst/webrtc/sctptransport.h>
+#include "fwd.h"
+
+#include "gst/webrtc/webrtc-priv.h"
+
+G_BEGIN_DECLS
+
+GType webrtc_sctp_transport_get_type(void);
+#define TYPE_WEBRTC_SCTP_TRANSPORT            (webrtc_sctp_transport_get_type())
+#define WEBRTC_SCTP_TRANSPORT(obj)            (G_TYPE_CHECK_INSTANCE_CAST((obj),TYPE_WEBRTC_SCTP_TRANSPORT,WebRTCSCTPTransport))
+#define WEBRTC_IS_SCTP_TRANSPORT(obj)         (G_TYPE_CHECK_INSTANCE_TYPE((obj),TYPE_WEBRTC_SCTP_TRANSPORT))
+#define WEBRTC_SCTP_TRANSPORT_CLASS(klass)    (G_TYPE_CHECK_CLASS_CAST((klass) ,TYPE_WEBRTC_SCTP_TRANSPORT,WebRTCSCTPTransportClass))
+#define WEBRTC_SCTP_IS_TRANSPORT_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE((klass) ,TYPE_WEBRTC_SCTP_TRANSPORT))
+#define WEBRTC_SCTP_TRANSPORT_GET_CLASS(obj)  (G_TYPE_INSTANCE_GET_CLASS((obj) ,TYPE_WEBRTC_SCTP_TRANSPORT,WebRTCSCTPTransportClass))
+
+typedef struct _WebRTCSCTPTransport WebRTCSCTPTransport;
+typedef struct _WebRTCSCTPTransportClass WebRTCSCTPTransportClass;
+
+struct _WebRTCSCTPTransport
+{
+  GstWebRTCSCTPTransport        parent;
+
+  GstWebRTCDTLSTransport       *transport;
+  GstWebRTCSCTPTransportState   state;
+  guint64                       max_message_size;
+  guint                         max_channels;
+
+  gboolean                      association_established;
+
+  gulong                        sctpdec_block_id;
+  GstElement                   *sctpdec;
+  GstElement                   *sctpenc;
+
+  GstWebRTCBin                 *webrtcbin;
+};
+
+struct _WebRTCSCTPTransportClass
+{
+  GstWebRTCSCTPTransportClass   parent_class;
+};
+
+WebRTCSCTPTransport *           webrtc_sctp_transport_new               (void);
+
+void
+webrtc_sctp_transport_set_priority (WebRTCSCTPTransport *sctp,
+                                    GstWebRTCPriorityType priority);
+
+G_END_DECLS
+
+#endif /* __WEBRTC_SCTP_TRANSPORT_H__ */
diff --git a/ext/webrtc/webrtcsdp.c b/ext/webrtc/webrtcsdp.c
index 6e7f4b3d1..1abd4b115 100644
--- a/ext/webrtc/webrtcsdp.c
+++ b/ext/webrtc/webrtcsdp.c
@@ -81,15 +81,14 @@ _check_valid_state_for_sdp_change (GstWebRTCSignalingState state,
     return TRUE;
 
   {
-    gchar *state_str = _enum_value_to_string (GST_TYPE_WEBRTC_SIGNALING_STATE,
+    const gchar *state_str =
+        _enum_value_to_string (GST_TYPE_WEBRTC_SIGNALING_STATE,
         state);
-    gchar *type_str = _enum_value_to_string (GST_TYPE_WEBRTC_SDP_TYPE, type);
-    g_set_error (error, GST_WEBRTC_BIN_ERROR,
-        GST_WEBRTC_BIN_ERROR_INVALID_STATE,
+    const gchar *type_str =
+        _enum_value_to_string (GST_TYPE_WEBRTC_SDP_TYPE, type);
+    g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_INVALID_STATE,
         "Not in the correct state (%s) for setting %s %s description",
         state_str, _sdp_source_to_string (source), type_str);
-    g_free (state_str);
-    g_free (type_str);
   }
 
   return FALSE;
@@ -108,8 +107,8 @@ _check_sdp_crypto (SDPSource source, GstWebRTCSessionDescription * sdp,
 
   key = gst_sdp_message_get_key (sdp->sdp);
   if (!IS_EMPTY_SDP_ATTRIBUTE (key->data)) {
-    g_set_error_literal (error, GST_WEBRTC_BIN_ERROR,
-        GST_WEBRTC_BIN_ERROR_BAD_SDP, "sdp contains a k line");
+    g_set_error_literal (error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR, "sdp contains a k line");
     return FALSE;
   }
 
@@ -122,8 +121,8 @@ _check_sdp_crypto (SDPSource source, GstWebRTCSessionDescription * sdp,
 
     if (!IS_EMPTY_SDP_ATTRIBUTE (message_fingerprint)
         && !IS_EMPTY_SDP_ATTRIBUTE (media_fingerprint)) {
-      g_set_error (error, GST_WEBRTC_BIN_ERROR,
-          GST_WEBRTC_BIN_ERROR_FINGERPRINT,
+      g_set_error (error, GST_WEBRTC_ERROR,
+          GST_WEBRTC_ERROR_FINGERPRINT_FAILURE,
           "No fingerprint lines in sdp for media %u", i);
       return FALSE;
     }
@@ -132,8 +131,8 @@ _check_sdp_crypto (SDPSource source, GstWebRTCSessionDescription * sdp,
     }
     if (!IS_EMPTY_SDP_ATTRIBUTE (media_fingerprint)
         && g_strcmp0 (fingerprint, media_fingerprint) != 0) {
-      g_set_error (error, GST_WEBRTC_BIN_ERROR,
-          GST_WEBRTC_BIN_ERROR_FINGERPRINT,
+      g_set_error (error, GST_WEBRTC_ERROR,
+          GST_WEBRTC_ERROR_FINGERPRINT_FAILURE,
           "Fingerprint in media %u differs from %s fingerprint. "
           "\'%s\' != \'%s\'", i, message_fingerprint ? "global" : "previous",
           fingerprint, media_fingerprint);
@@ -178,8 +177,8 @@ static gboolean
 _check_trickle_ice (GstSDPMessage * msg, GError ** error)
 {
   if (!_session_has_attribute_key_value (msg, "ice-options", "trickle")) {
-    g_set_error_literal (error, GST_WEBRTC_BIN_ERROR,
-        GST_WEBRTC_BIN_ERROR_BAD_SDP,
+    g_set_error_literal (error, GST_WEBRTC_ERROR,
+        GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
         "No required \'a=ice-options:trickle\' line in sdp");
   }
   return TRUE;
@@ -204,7 +203,7 @@ _media_has_mid (const GstSDPMedia * media, guint media_idx, GError ** error)
 {
   const gchar *mid = gst_sdp_media_get_attribute_val (media, "mid");
   if (IS_EMPTY_SDP_ATTRIBUTE (mid)) {
-    g_set_error (error, GST_WEBRTC_BIN_ERROR, GST_WEBRTC_BIN_ERROR_BAD_SDP,
+    g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
         "media %u is missing or contains an empty \'mid\' attribute",
         media_idx);
     return FALSE;
@@ -248,13 +247,13 @@ _media_has_setup (const GstSDPMedia * media, guint media_idx, GError ** error)
   static const gchar *valid_setups[] = { "actpass", "active", "passive", NULL };
   const gchar *setup = gst_sdp_media_get_attribute_val (media, "setup");
   if (IS_EMPTY_SDP_ATTRIBUTE (setup)) {
-    g_set_error (error, GST_WEBRTC_BIN_ERROR, GST_WEBRTC_BIN_ERROR_BAD_SDP,
+    g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
         "media %u is missing or contains an empty \'setup\' attribute",
         media_idx);
     return FALSE;
   }
   if (!g_strv_contains (valid_setups, setup)) {
-    g_set_error (error, GST_WEBRTC_BIN_ERROR, GST_WEBRTC_BIN_ERROR_BAD_SDP,
+    g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
         "media %u contains unknown \'setup\' attribute, \'%s\'", media_idx,
         setup);
     return FALSE;
@@ -268,7 +267,7 @@ _media_has_dtls_id (const GstSDPMedia * media, guint media_idx, GError ** error)
 {
   const gchar *dtls_id = gst_sdp_media_get_attribute_val (media, "ice-pwd");
   if (IS_EMPTY_SDP_ATTRIBUTE (dtls_id)) {
-    g_set_error (error, GST_WEBRTC_BIN_ERROR, GST_WEBRTC_BIN_ERROR_BAD_SDP,
+    g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
         "media %u is missing or contains an empty \'dtls-id\' attribute",
         media_idx);
     return FALSE;
@@ -307,13 +306,13 @@ validate_sdp (GstWebRTCSignalingState state, SDPSource source,
     media_in_bundle = is_bundle
         && g_strv_contains ((const gchar **) group_members, mid);
     if (!_media_get_ice_ufrag (sdp->sdp, i)) {
-      g_set_error (error, GST_WEBRTC_BIN_ERROR, GST_WEBRTC_BIN_ERROR_BAD_SDP,
+      g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
           "media %u is missing or contains an empty \'ice-ufrag\' attribute",
           i);
       goto fail;
     }
     if (!_media_get_ice_pwd (sdp->sdp, i)) {
-      g_set_error (error, GST_WEBRTC_BIN_ERROR, GST_WEBRTC_BIN_ERROR_BAD_SDP,
+      g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
           "media %u is missing or contains an empty \'ice-pwd\' attribute", i);
       goto fail;
     }
@@ -327,7 +326,7 @@ validate_sdp (GstWebRTCSignalingState state, SDPSource source,
       if (!bundle_ice_ufrag)
         bundle_ice_ufrag = ice_ufrag;
       else if (g_strcmp0 (bundle_ice_ufrag, ice_ufrag) != 0) {
-        g_set_error (error, GST_WEBRTC_BIN_ERROR, GST_WEBRTC_BIN_ERROR_BAD_SDP,
+        g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
             "media %u has different ice-ufrag values in bundle. "
             "%s != %s", i, bundle_ice_ufrag, ice_ufrag);
         goto fail;
@@ -335,7 +334,7 @@ validate_sdp (GstWebRTCSignalingState state, SDPSource source,
       if (!bundle_ice_pwd) {
         bundle_ice_pwd = ice_pwd;
       } else if (g_strcmp0 (bundle_ice_pwd, ice_pwd) != 0) {
-        g_set_error (error, GST_WEBRTC_BIN_ERROR, GST_WEBRTC_BIN_ERROR_BAD_SDP,
+        g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
             "media %u has different ice-pwd values in bundle. "
             "%s != %s", i, bundle_ice_pwd, ice_pwd);
         goto fail;
@@ -425,12 +424,10 @@ void
 _media_replace_direction (GstSDPMedia * media,
     GstWebRTCRTPTransceiverDirection direction)
 {
-  gchar *dir_str;
+  const gchar *dir_str;
   int i;
 
-  dir_str =
-      _enum_value_to_string (GST_TYPE_WEBRTC_RTP_TRANSCEIVER_DIRECTION,
-      direction);
+  dir_str = gst_webrtc_rtp_transceiver_direction_to_string (direction);
 
   for (i = 0; i < gst_sdp_media_attributes_len (media); i++) {
     const GstSDPAttribute *attr = gst_sdp_media_get_attribute (media, i);
@@ -443,14 +440,12 @@ _media_replace_direction (GstSDPMedia * media,
       GST_TRACE ("replace %s with %s", attr->key, dir_str);
       gst_sdp_attribute_set (&new_attr, dir_str, "");
       gst_sdp_media_replace_attribute (media, i, &new_attr);
-      g_free (dir_str);
       return;
     }
   }
 
   GST_TRACE ("add %s", dir_str);
   gst_sdp_media_add_attribute (media, dir_str, "");
-  g_free (dir_str);
 }
 
 GstWebRTCRTPTransceiverDirection
@@ -556,7 +551,7 @@ _intersect_dtls_setup (GstWebRTCDTLSSetup offer)
 void
 _media_replace_setup (GstSDPMedia * media, GstWebRTCDTLSSetup setup)
 {
-  gchar *setup_str;
+  const gchar *setup_str;
   int i;
 
   setup_str = _enum_value_to_string (GST_TYPE_WEBRTC_DTLS_SETUP, setup);
@@ -575,7 +570,6 @@ _media_replace_setup (GstSDPMedia * media, GstWebRTCDTLSSetup setup)
 
   GST_TRACE ("add setup:%s", setup_str);
   gst_sdp_media_add_attribute (media, "setup", setup_str);
-  g_free (setup_str);
 }
 
 GstWebRTCDTLSSetup
@@ -872,7 +866,7 @@ _get_ice_credentials_from_sdp_media (const GstSDPMessage * sdp, guint media_idx,
 }
 
 gboolean
-_parse_bundle (GstSDPMessage * sdp, GStrv * bundled)
+_parse_bundle (GstSDPMessage * sdp, GStrv * bundled, GError ** error)
 {
   const gchar *group;
   gboolean ret = FALSE;
@@ -883,8 +877,9 @@ _parse_bundle (GstSDPMessage * sdp, GStrv * bundled)
     *bundled = g_strsplit (group + strlen ("BUNDLE "), " ", 0);
 
     if (!(*bundled)[0]) {
-      GST_ERROR ("Invalid format for BUNDLE group, expected at least "
-          "one mid (%s)", group);
+      g_set_error (error, GST_WEBRTC_ERROR, GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
+          "Invalid format for BUNDLE group, expected at least one mid (%s)",
+          group);
       g_strfreev (*bundled);
       *bundled = NULL;
       goto done;
diff --git a/ext/webrtc/webrtcsdp.h b/ext/webrtc/webrtcsdp.h
index 1501cbc93..c55709b50 100644
--- a/ext/webrtc/webrtcsdp.h
+++ b/ext/webrtc/webrtcsdp.h
@@ -101,7 +101,8 @@ gboolean                            _get_bundle_index                       (Gst
                                                                              guint * idx);
 G_GNUC_INTERNAL
 gboolean                            _parse_bundle                           (GstSDPMessage * sdp,
-                                                                             GStrv * bundled);
+                                                                             GStrv * bundled,
+                                                                             GError ** error);
 
 G_GNUC_INTERNAL
 const gchar *                       _media_get_ice_pwd                  (const GstSDPMessage * msg,
diff --git a/ext/webrtc/webrtctransceiver.c b/ext/webrtc/webrtctransceiver.c
index f26536741..ba9c944d3 100644
--- a/ext/webrtc/webrtctransceiver.c
+++ b/ext/webrtc/webrtctransceiver.c
@@ -32,7 +32,8 @@ GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
 G_DEFINE_TYPE_WITH_CODE (WebRTCTransceiver, webrtc_transceiver,
     GST_TYPE_WEBRTC_RTP_TRANSCEIVER,
     GST_DEBUG_CATEGORY_INIT (webrtc_transceiver_debug,
-        "webrtctransceiver", 0, "webrtctransceiver"););
+        "webrtctransceiver", 0, "webrtctransceiver");
+    );
 
 #define DEFAULT_FEC_TYPE GST_WEBRTC_FEC_TYPE_NONE
 #define DEFAULT_DO_NACK FALSE
@@ -59,19 +60,17 @@ webrtc_transceiver_set_transport (WebRTCTransceiver * trans,
 
   gst_object_replace ((GstObject **) & trans->stream, (GstObject *) stream);
 
-  if (rtp_trans->sender)
+  if (rtp_trans->sender) {
     gst_object_replace ((GstObject **) & rtp_trans->sender->transport,
         (GstObject *) stream->transport);
-  if (rtp_trans->receiver)
+    g_object_notify (G_OBJECT (rtp_trans->sender), "transport");
+  }
+
+  if (rtp_trans->receiver) {
     gst_object_replace ((GstObject **) & rtp_trans->receiver->transport,
         (GstObject *) stream->transport);
-
-  if (rtp_trans->sender)
-    gst_object_replace ((GstObject **) & rtp_trans->sender->rtcp_transport,
-        (GstObject *) stream->rtcp_transport);
-  if (rtp_trans->receiver)
-    gst_object_replace ((GstObject **) & rtp_trans->receiver->rtcp_transport,
-        (GstObject *) stream->rtcp_transport);
+    g_object_notify (G_OBJECT (rtp_trans->receiver), "transport");
+  }
 }
 
 GstWebRTCDTLSTransport *
@@ -88,20 +87,6 @@ webrtc_transceiver_get_dtls_transport (GstWebRTCRTPTransceiver * trans)
   return NULL;
 }
 
-GstWebRTCDTLSTransport *
-webrtc_transceiver_get_rtcp_dtls_transport (GstWebRTCRTPTransceiver * trans)
-{
-  g_return_val_if_fail (WEBRTC_IS_TRANSCEIVER (trans), NULL);
-
-  if (trans->sender) {
-    return trans->sender->rtcp_transport;
-  } else if (trans->receiver) {
-    return trans->receiver->rtcp_transport;
-  }
-
-  return NULL;
-}
-
 static void
 webrtc_transceiver_set_property (GObject * object, guint prop_id,
     const GValue * value, GParamSpec * pspec)
@@ -163,15 +148,21 @@ webrtc_transceiver_finalize (GObject * object)
 {
   WebRTCTransceiver *trans = WEBRTC_TRANSCEIVER (object);
 
-  if (trans->stream)
-    gst_object_unref (trans->stream);
-  trans->stream = NULL;
+  gst_clear_object (&trans->stream);
+  gst_clear_object (&trans->ulpfecdec);
+  gst_clear_object (&trans->ulpfecenc);
+  gst_clear_object (&trans->redenc);
 
   if (trans->local_rtx_ssrc_map)
     gst_structure_free (trans->local_rtx_ssrc_map);
   trans->local_rtx_ssrc_map = NULL;
 
-  gst_caps_replace (&trans->last_configured_caps, NULL);
+  gst_caps_replace (&trans->last_retrieved_caps, NULL);
+  gst_caps_replace (&trans->last_send_configured_caps, NULL);
+
+  g_free (trans->pending_mid);
+
+  gst_event_replace (&trans->tos_event, NULL);
 
   G_OBJECT_CLASS (parent_class)->finalize (object);
 }
diff --git a/ext/webrtc/webrtctransceiver.h b/ext/webrtc/webrtctransceiver.h
index c03730415..9f0e93c01 100644
--- a/ext/webrtc/webrtctransceiver.h
+++ b/ext/webrtc/webrtctransceiver.h
@@ -22,6 +22,7 @@
 
 #include "fwd.h"
 #include <gst/webrtc/rtptransceiver.h>
+#include "gst/webrtc/webrtc-priv.h"
 #include "transportstream.h"
 
 G_BEGIN_DECLS
@@ -39,13 +40,27 @@ struct _WebRTCTransceiver
 
   TransportStream          *stream;
   GstStructure             *local_rtx_ssrc_map;
+  GstEvent                 *tos_event;
 
   /* Properties */
   GstWebRTCFECType         fec_type;
   guint                    fec_percentage;
   gboolean                 do_nack;
 
-  GstCaps                  *last_configured_caps;
+  /* The last caps that we put into to a SDP media section */
+  GstCaps                  *last_retrieved_caps;
+  /* The last caps that we successfully configured from a valid
+   * set_local/remote description call.
+   */
+  GstCaps                  *last_send_configured_caps;
+
+  gchar                    *pending_mid;
+
+  gboolean                 mline_locked;
+
+  GstElement               *ulpfecdec;
+  GstElement               *ulpfecenc;
+  GstElement               *redenc;
 };
 
 struct _WebRTCTransceiverClass
@@ -61,7 +76,6 @@ void                      webrtc_transceiver_set_transport  (WebRTCTransceiver *
                                                              TransportStream * stream);
 
 GstWebRTCDTLSTransport *  webrtc_transceiver_get_dtls_transport (GstWebRTCRTPTransceiver * trans);
-GstWebRTCDTLSTransport *  webrtc_transceiver_get_rtcp_dtls_transport (GstWebRTCRTPTransceiver * trans);
 
 G_END_DECLS
 
diff --git a/gst-libs/gst/codecparsers/gstav1parser.c b/gst-libs/gst/codecparsers/gstav1parser.c
index 6f6b74125..3e8038097 100644
--- a/gst-libs/gst/codecparsers/gstav1parser.c
+++ b/gst-libs/gst/codecparsers/gstav1parser.c
@@ -67,10 +67,6 @@
  * should call gst_av1_parser_reference_frame_update() to update the parser's inside
  * state(such as reference information, global segmentation information, etc).
  *
- * Note: If the frame is actived by show_existing_frame in #GST_AV1_OBU_FRAME_HEADER,
- * the function of gst_av1_parser_reference_frame_loading() should be called before
- * really showing that frame.
- *
  * @since: 1.18.00
  */
 
@@ -195,6 +191,88 @@ av1_helper_inverse_recenter (gint r, gint v)
     return r + (v >> 1);
 }
 
+/* Shift down with rounding for use when n >= 0, value >= 0 */
+static guint64
+av1_helper_round_power_of_two (guint64 value, guint16 n)
+{
+  return (value + (((guint64) (1) << n) >> 1)) >> n;
+}
+
+ /* Shift down with rounding for signed integers, for use when n >= 0 */
+static gint64
+av1_helper_round_power_of_two_signed (gint64 value, guint16 n)
+{
+  return (value < 0) ? -((gint64) (av1_helper_round_power_of_two (-value, n)))
+      : (gint64) av1_helper_round_power_of_two (value, n);
+}
+
+static gint
+av1_helper_msb (guint n)
+{
+  int log = 0;
+  guint value = n;
+  int i;
+
+  g_assert (n != 0);
+
+  for (i = 4; i >= 0; --i) {
+    const gint shift = (1 << i);
+    const guint x = value >> shift;
+    if (x != 0) {
+      value = x;
+      log += shift;
+    }
+  }
+  return log;
+}
+
+static const guint16 div_lut[GST_AV1_DIV_LUT_NUM + 1] = {
+  16384, 16320, 16257, 16194, 16132, 16070, 16009, 15948, 15888, 15828, 15768,
+  15709, 15650, 15592, 15534, 15477, 15420, 15364, 15308, 15252, 15197, 15142,
+  15087, 15033, 14980, 14926, 14873, 14821, 14769, 14717, 14665, 14614, 14564,
+  14513, 14463, 14413, 14364, 14315, 14266, 14218, 14170, 14122, 14075, 14028,
+  13981, 13935, 13888, 13843, 13797, 13752, 13707, 13662, 13618, 13574, 13530,
+  13487, 13443, 13400, 13358, 13315, 13273, 13231, 13190, 13148, 13107, 13066,
+  13026, 12985, 12945, 12906, 12866, 12827, 12788, 12749, 12710, 12672, 12633,
+  12596, 12558, 12520, 12483, 12446, 12409, 12373, 12336, 12300, 12264, 12228,
+  12193, 12157, 12122, 12087, 12053, 12018, 11984, 11950, 11916, 11882, 11848,
+  11815, 11782, 11749, 11716, 11683, 11651, 11619, 11586, 11555, 11523, 11491,
+  11460, 11429, 11398, 11367, 11336, 11305, 11275, 11245, 11215, 11185, 11155,
+  11125, 11096, 11067, 11038, 11009, 10980, 10951, 10923, 10894, 10866, 10838,
+  10810, 10782, 10755, 10727, 10700, 10673, 10645, 10618, 10592, 10565, 10538,
+  10512, 10486, 10460, 10434, 10408, 10382, 10356, 10331, 10305, 10280, 10255,
+  10230, 10205, 10180, 10156, 10131, 10107, 10082, 10058, 10034, 10010, 9986,
+  9963, 9939, 9916, 9892, 9869, 9846, 9823, 9800, 9777, 9754, 9732,
+  9709, 9687, 9664, 9642, 9620, 9598, 9576, 9554, 9533, 9511, 9489,
+  9468, 9447, 9425, 9404, 9383, 9362, 9341, 9321, 9300, 9279, 9259,
+  9239, 9218, 9198, 9178, 9158, 9138, 9118, 9098, 9079, 9059, 9039,
+  9020, 9001, 8981, 8962, 8943, 8924, 8905, 8886, 8867, 8849, 8830,
+  8812, 8793, 8775, 8756, 8738, 8720, 8702, 8684, 8666, 8648, 8630,
+  8613, 8595, 8577, 8560, 8542, 8525, 8508, 8490, 8473, 8456, 8439,
+  8422, 8405, 8389, 8372, 8355, 8339, 8322, 8306, 8289, 8273, 8257,
+  8240, 8224, 8208, 8192,
+};
+
+static gint16
+av1_helper_resolve_divisor_32 (guint32 D, gint16 * shift)
+{
+  gint32 f;
+  gint32 e;
+
+  *shift = av1_helper_msb (D);
+  // e is obtained from D after resetting the most significant 1 bit.
+  e = D - ((guint32) 1 << *shift);
+  // Get the most significant DIV_LUT_BITS (8) bits of e into f
+  if (*shift > GST_AV1_DIV_LUT_BITS)
+    f = av1_helper_round_power_of_two (e, *shift - GST_AV1_DIV_LUT_BITS);
+  else
+    f = e << (GST_AV1_DIV_LUT_BITS - *shift);
+  g_assert (f <= GST_AV1_DIV_LUT_NUM);
+  *shift += GST_AV1_DIV_LUT_PREC_BITS;
+  // Use f as lookup into the precomputed table of multipliers
+  return div_lut[f];
+}
+
 /*************************************
  *                                   *
  * Bitstream Functions               *
@@ -293,8 +371,8 @@ av1_bitstreamfn_su (GstBitReader * br, guint8 n, GstAV1ParserResult * retval)
 /* 4.10.7
  *
  * Unsigned encoded integer with maximum number of values n */
-static guint8
-av1_bitstreamfn_ns (GstBitReader * br, guint8 n, GstAV1ParserResult * retval)
+static guint32
+av1_bitstreamfn_ns (GstBitReader * br, guint32 n, GstAV1ParserResult * retval)
 {
   gint w, m, v;
   gint extra_bit;
@@ -438,7 +516,6 @@ av1_parser_init_sequence_header (GstAV1SequenceHeaderOBU * seq_header)
 static void
 gst_av1_parse_reset_state (GstAV1Parser * parser, gboolean free_sps)
 {
-  parser->state.seen_frame_header = 0;
   parser->state.begin_first_frame = FALSE;
 
   parser->state.prev_frame_id = 0;
@@ -487,29 +564,44 @@ gst_av1_parser_reset (GstAV1Parser * parser, gboolean annex_b)
 {
   g_return_if_fail (parser != NULL);
 
-  if (parser->annex_b) {
-    g_assert (parser->temporal_unit_consumed <= parser->temporal_unit_size);
-    if (parser->temporal_unit_consumed < parser->temporal_unit_size)
-      GST_DEBUG ("temporal_unit_consumed: %d, temporal_unit_size:%d, "
-          "discard the left %d bytes for a temporal_unit.",
-          parser->temporal_unit_consumed, parser->temporal_unit_size,
-          parser->temporal_unit_size - parser->temporal_unit_consumed);
-
-    g_assert (parser->frame_unit_consumed <= parser->frame_unit_size);
-    if (parser->frame_unit_consumed < parser->frame_unit_size)
-      GST_DEBUG (" frame_unit_consumed %d, frame_unit_size: %d "
-          "discard the left %d bytes for a frame_unit.",
-          parser->frame_unit_consumed, parser->frame_unit_size,
-          parser->frame_unit_size - parser->frame_unit_consumed);
-  }
+  parser->annex_b = annex_b;
+  if (parser->annex_b)
+    gst_av1_parser_reset_annex_b (parser);
+
+  gst_av1_parse_reset_state (parser, TRUE);
+}
+
+/**
+ * gst_av1_parser_reset_annex_b:
+ * @parser: the #GstAV1Parser
+ *
+ * Only reset the current #GstAV1Parser's annex b context.
+ * The other part of the state is kept.
+ *
+ * Since: 1.20
+ */
+void
+gst_av1_parser_reset_annex_b (GstAV1Parser * parser)
+{
+  g_return_if_fail (parser != NULL);
+  g_return_if_fail (parser->annex_b);
+
+  if (parser->temporal_unit_consumed < parser->temporal_unit_size)
+    GST_DEBUG ("temporal_unit_consumed: %d, temporal_unit_size:%d, "
+        "discard the left %d bytes for a temporal_unit.",
+        parser->temporal_unit_consumed, parser->temporal_unit_size,
+        parser->temporal_unit_size - parser->temporal_unit_consumed);
+
+  if (parser->frame_unit_consumed < parser->frame_unit_size)
+    GST_DEBUG (" frame_unit_consumed %d, frame_unit_size: %d "
+        "discard the left %d bytes for a frame_unit.",
+        parser->frame_unit_consumed, parser->frame_unit_size,
+        parser->frame_unit_size - parser->frame_unit_consumed);
 
   parser->temporal_unit_consumed = 0;
   parser->temporal_unit_size = 0;
   parser->frame_unit_consumed = 0;
   parser->frame_unit_size = 0;
-  parser->annex_b = annex_b;
-
-  gst_av1_parse_reset_state (parser, TRUE);
 }
 
 /* 5.3.2 */
@@ -615,14 +707,17 @@ gst_av1_parser_identify_one_obu (GstAV1Parser * parser, const guint8 * data,
   annex_b_again:
     last_pos = 0;
 
-    g_assert (*consumed <= size);
+    if (*consumed > size)
+      goto error;
     if (*consumed == size) {
       ret = GST_AV1_PARSER_NO_MORE_DATA;
       goto error;
     }
     gst_bit_reader_init (&br, data + *consumed, size - *consumed);
 
-    g_assert (parser->temporal_unit_consumed <= parser->temporal_unit_size);
+    if (parser->temporal_unit_consumed > parser->temporal_unit_size)
+      goto error;
+
     if (parser->temporal_unit_consumed &&
         parser->temporal_unit_consumed == parser->temporal_unit_size) {
       GST_LOG ("Complete a temporal unit of size %d",
@@ -647,7 +742,9 @@ gst_av1_parser_identify_one_obu (GstAV1Parser * parser, const guint8 * data,
       }
     }
 
-    g_assert (parser->frame_unit_consumed <= parser->frame_unit_size);
+    if (parser->frame_unit_consumed > parser->frame_unit_size)
+      goto error;
+
     if (parser->frame_unit_consumed &&
         parser->frame_unit_consumed == parser->frame_unit_size) {
       GST_LOG ("Complete a frame unit of size %d", parser->frame_unit_size);
@@ -702,12 +799,12 @@ gst_av1_parser_identify_one_obu (GstAV1Parser * parser, const guint8 * data,
 
     if (obu_length == 0) {
       /* An empty obu? let continue to the next */
-      ret = GST_AV1_PARSER_DROP;
-      goto error;
+      return GST_AV1_PARSER_DROP;
     }
   }
 
-  g_assert (*consumed <= size);
+  if (*consumed > size)
+    goto error;
   if (*consumed == size) {
     ret = GST_AV1_PARSER_NO_MORE_DATA;
     goto error;
@@ -722,12 +819,16 @@ gst_av1_parser_identify_one_obu (GstAV1Parser * parser, const guint8 * data,
   GST_LOG ("identify obu type is %d", obu->obu_type);
 
   if (obu->header.obu_has_size_field) {
+    guint size_sz = gst_bit_reader_get_pos (&br) / 8;
+
     obu->obu_size = av1_bitstreamfn_leb128 (&br, &ret);
     if (ret != GST_AV1_PARSER_OK)
       goto error;
 
+    size_sz = gst_bit_reader_get_pos (&br) / 8 - size_sz;
     if (obu_length
-        && obu_length - 1 - obu->header.obu_extention_flag != obu->obu_size) {
+        && obu_length - 1 - obu->header.obu_extention_flag - size_sz !=
+        obu->obu_size) {
       /* If obu_size and obu_length are both present, but inconsistent,
          then the packed bitstream is deemed invalid. */
       ret = GST_AV1_PARSER_BITSTREAM_ERROR;
@@ -779,8 +880,7 @@ gst_av1_parser_identify_one_obu (GstAV1Parser * parser, const guint8 * data,
         (parser->state.operating_point_idc >> (obu->header.obu_spatial_id +
             8)) & 1;
     if (!inTemporalLayer || !inSpatialLayer) {
-      ret = GST_AV1_PARSER_DROP;
-      goto error;
+      return GST_AV1_PARSER_DROP;
     }
   }
 
@@ -1133,12 +1233,12 @@ gst_av1_parser_parse_sequence_header_obu (GstAV1Parser * parser,
       seq_header->operating_points[i].idc = AV1_READ_BITS (br, 12);
       seq_header->operating_points[i].seq_level_idx = AV1_READ_BITS (br, 5);
       if (!av1_seq_level_idx_is_valid
-          (seq_header->operating_points[0].seq_level_idx)) {
+          (seq_header->operating_points[i].seq_level_idx)) {
         GST_INFO ("The seq_level_idx is unsupported");
         retval = GST_AV1_PARSER_BITSTREAM_ERROR;
         goto error;
       }
-      if (seq_header->operating_points[i].seq_level_idx > GST_AV1_SEQ_LEVEL_4_0) {
+      if (seq_header->operating_points[i].seq_level_idx > GST_AV1_SEQ_LEVEL_3_3) {
         seq_header->operating_points[i].seq_tier = AV1_READ_BIT (br);
       } else {
         seq_header->operating_points[i].seq_tier = 0;
@@ -1187,7 +1287,8 @@ gst_av1_parser_parse_sequence_header_obu (GstAV1Parser * parser,
     }
   }
 
-  /* Let user decide the operatingPoint, move it later
+  /* Let user decide the operatingPoint,
+     implemented by calling gst_av1_parser_set_operating_point()
      operatingPoint = choose_operating_point( )
      operating_point_idc = operating_point_idc[ operatingPoint ] */
 
@@ -1346,10 +1447,8 @@ gst_av1_parser_parse_sequence_header_obu (GstAV1Parser * parser,
   gst_av1_parse_reset_state (parser, FALSE);
 
   /* choose_operating_point() set the operating_point */
-  if (parser->state.operating_point < 0 ||
-      parser->state.operating_point >
-      seq_header->operating_points_cnt_minus_1) {
-    GST_INFO ("Invalid operating_point %d set by user, just use 0",
+  if (parser->state.operating_point > seq_header->operating_points_cnt_minus_1) {
+    GST_WARNING ("Invalid operating_point %d set by user, just use 0",
         parser->state.operating_point);
     parser->state.operating_point_idc = seq_header->operating_points[0].idc;
   } else {
@@ -1414,7 +1513,7 @@ gst_av1_parse_metadata_itut_t35 (GstAV1Parser * parser, GstBitReader * br,
   if (ret != GST_AV1_PARSER_OK)
     return ret;
 
-  if (itut_t35->itu_t_t35_country_code) {
+  if (itut_t35->itu_t_t35_country_code == 0xFF) {
     itut_t35->itu_t_t35_country_code_extention_byte =
         AV1_READ_BITS_CHECKED (br, 8, &ret);
     if (ret != GST_AV1_PARSER_OK)
@@ -1512,7 +1611,7 @@ gst_av1_parse_metadata_scalability (GstAV1Parser * parser,
 
   if (scalability->spatial_layer_description_present_flag) {
     for (i = 0; i <= scalability->spatial_layers_cnt_minus_1; i++) {
-      scalability->spatial_layer_ref_id[i] = AV1_READ_BIT_CHECKED (br, &ret);
+      scalability->spatial_layer_ref_id[i] = AV1_READ_UINT8_CHECKED (br, &ret);
       if (ret != GST_AV1_PARSER_OK)
         goto error;
     }
@@ -1689,6 +1788,12 @@ gst_av1_parser_parse_metadata_obu (GstAV1Parser * parser, GstAV1OBU * obu,
     goto error;
 
   retval = av1_skip_trailing_bits (parser, &bit_reader, obu);
+  if (retval != GST_AV1_PARSER_OK) {
+    GST_WARNING ("Metadata type %d may have wrong trailings.",
+        metadata->metadata_type);
+    retval = GST_AV1_PARSER_OK;
+  }
+
   return retval;
 
 error:
@@ -2005,7 +2110,8 @@ gst_av1_parse_segmentation_params (GstAV1Parser * parser, GstBitReader * br,
             gint bits_to_read = segmentation_feature_bits[j];
             gint limit = segmentation_feature_max[j];
             if (segmentation_feature_signed[j]) {
-              feature_value = av1_bitstreamfn_su (br, bits_to_read, &retval);
+              feature_value =
+                  av1_bitstreamfn_su (br, 1 + bits_to_read, &retval);
               if (retval != GST_AV1_PARSER_OK)
                 goto error;
 
@@ -2096,7 +2202,6 @@ gst_av1_parse_tile_info (GstAV1Parser * parser, GstBitReader * br,
   gint max_width /* maxWidth */ , max_height /* maxHeight */ ;
   gint size_sb /* sizeSb */ ;
   gint widest_tile_sb /* widestTileSb */ ;
-  gint min_inner_tile_width = G_MAXINT /* min width of non-rightmost tile */ ;
 
   g_assert (parser->seq_header);
   seq_header = parser->seq_header;
@@ -2143,8 +2248,13 @@ gst_av1_parse_tile_info (GstAV1Parser * parser, GstBitReader * br,
     }
     parser->state.mi_col_starts[i] = parser->state.mi_cols;
     parser->state.tile_cols = i;
-    if (parser->state.tile_cols > 1)
-      min_inner_tile_width = tile_width_sb << sb_size;
+
+    while (i >= 1) {
+      tile_info->width_in_sbs_minus_1[i - 1] =
+          ((parser->state.mi_col_starts[i] - parser->state.mi_col_starts[i - 1]
+              + ((1 << sb_shift) - 1)) >> sb_shift) - 1;
+      i--;
+    }
 
     min_log2_tile_rows = MAX (min_log2_tiles - parser->state.tile_cols_log2, 0);
     parser->state.tile_rows_log2 = min_log2_tile_rows;
@@ -2167,6 +2277,12 @@ gst_av1_parse_tile_info (GstAV1Parser * parser, GstBitReader * br,
     }
     parser->state.mi_row_starts[i] = parser->state.mi_rows;
     parser->state.tile_rows = i;
+    while (i >= 1) {
+      tile_info->height_in_sbs_minus_1[i - 1] =
+          ((parser->state.mi_row_starts[i] - parser->state.mi_row_starts[i - 1]
+              + ((1 << sb_shift) - 1)) >> sb_shift) - 1;
+      i--;
+    }
   } else {
     widest_tile_sb = 0;
     start_sb = 0;
@@ -2181,8 +2297,6 @@ gst_av1_parse_tile_info (GstAV1Parser * parser, GstBitReader * br,
       size_sb = tile_info->width_in_sbs_minus_1[i] + 1;
       widest_tile_sb = MAX (size_sb, widest_tile_sb);
       start_sb += size_sb;
-      if (i > 0 && ((size_sb << sb_size) < min_inner_tile_width))
-        min_inner_tile_width = size_sb << sb_size;
     }
     parser->state.mi_col_starts[i] = parser->state.mi_cols;
     parser->state.tile_cols = i;
@@ -2222,7 +2336,7 @@ gst_av1_parse_tile_info (GstAV1Parser * parser, GstBitReader * br,
     if (retval != GST_AV1_PARSER_OK)
       goto error;
 
-    tile_info->tile_size_bytes_minus_1 = AV1_READ_BIT_CHECKED (br, &retval);
+    tile_info->tile_size_bytes_minus_1 = AV1_READ_BITS_CHECKED (br, 2, &retval);
     if (retval != GST_AV1_PARSER_OK)
       goto error;
 
@@ -2231,13 +2345,6 @@ gst_av1_parse_tile_info (GstAV1Parser * parser, GstBitReader * br,
     tile_info->context_update_tile_id = 0;
   }
 
-  if (min_inner_tile_width < (64 << (parser->state.upscaled_width !=
-              parser->state.frame_width))) {
-    GST_INFO ("Minimum tile width requirement not satisfied");
-    retval = GST_AV1_PARSER_BITSTREAM_ERROR;
-    goto error;
-  }
-
   memcpy (tile_info->mi_col_starts, parser->state.mi_col_starts,
       sizeof (guint32) * (GST_AV1_MAX_TILE_COLS + 1));
   memcpy (tile_info->mi_row_starts, parser->state.mi_row_starts,
@@ -2270,13 +2377,8 @@ gst_av1_parse_loop_filter_params (GstAV1Parser * parser,
   lf_params = &frame_header->loop_filter_params;
 
   if (frame_header->coded_lossless || frame_header->allow_intrabc) {
-    lf_params->loop_filter_delta_enabled = 0;
-    lf_params->loop_filter_delta_update = 0;
-    lf_params->loop_filter_sharpness = 0;
     lf_params->loop_filter_level[0] = 0;
     lf_params->loop_filter_level[1] = 0;
-    lf_params->loop_filter_level[2] = 0;
-    lf_params->loop_filter_level[3] = 0;
     lf_params->loop_filter_ref_deltas[GST_AV1_REF_INTRA_FRAME] = 1;
     lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST_FRAME] = 0;
     lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST2_FRAME] = 0;
@@ -2291,58 +2393,6 @@ gst_av1_parse_loop_filter_params (GstAV1Parser * parser,
     goto success;
   }
 
-  lf_params->loop_filter_delta_enabled = 0;
-  lf_params->loop_filter_delta_update = 0;
-  lf_params->loop_filter_sharpness = 0;
-  lf_params->loop_filter_level[0] = 0;
-  lf_params->loop_filter_level[1] = 0;
-  lf_params->loop_filter_level[2] = 0;
-  lf_params->loop_filter_level[3] = 0;
-  if (frame_header->primary_ref_frame != GST_AV1_PRIMARY_REF_NONE) {
-    /* Copy it from prime_ref */
-    GstAV1LoopFilterParams *ref_lf_params =
-        &parser->state.ref_info.entry[frame_header->
-        ref_frame_idx[frame_header->primary_ref_frame]].ref_lf_params;
-
-    g_assert (parser->state.ref_info.
-        entry[frame_header->ref_frame_idx[frame_header->primary_ref_frame]].
-        ref_valid);
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_INTRA_FRAME] =
-        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_INTRA_FRAME];
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST_FRAME] =
-        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST_FRAME];
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST2_FRAME] =
-        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST2_FRAME];
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST3_FRAME] =
-        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST3_FRAME];
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_BWDREF_FRAME] =
-        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_BWDREF_FRAME];
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_GOLDEN_FRAME] =
-        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_GOLDEN_FRAME];
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_ALTREF2_FRAME] =
-        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_ALTREF2_FRAME];
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_ALTREF_FRAME] =
-        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_ALTREF_FRAME];
-    for (i = 0; i < 2; i++)
-      lf_params->loop_filter_mode_deltas[i] =
-          ref_lf_params->loop_filter_mode_deltas[i];
-  } else {
-    /* Set default value */
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_INTRA_FRAME] = 1;
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST_FRAME] = 0;
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST2_FRAME] =
-        lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST_FRAME];
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST3_FRAME] =
-        lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST_FRAME];
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_BWDREF_FRAME] =
-        lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST_FRAME];
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_GOLDEN_FRAME] = -1;
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_ALTREF2_FRAME] = -1;
-    lf_params->loop_filter_ref_deltas[GST_AV1_REF_ALTREF_FRAME] = -1;
-    for (i = 0; i < 2; i++)
-      lf_params->loop_filter_mode_deltas[i] = 0;
-  }
-
   if (AV1_REMAINING_BITS (br) < 6 + 6) {
     retval = GST_AV1_PARSER_NO_MORE_DATA;
     goto error;
@@ -2386,8 +2436,7 @@ gst_av1_parse_loop_filter_params (GstAV1Parser * parser,
               av1_bitstreamfn_su (br, 7, &retval);
           if (retval != GST_AV1_PARSER_OK)
             goto error;
-        } else
-          lf_params->loop_filter_ref_deltas[i] = 0;
+        }
       }
       for (i = 0; i < 2; i++) {
         update_mode_deltas = AV1_READ_BIT_CHECKED (br, &retval);
@@ -2399,8 +2448,7 @@ gst_av1_parse_loop_filter_params (GstAV1Parser * parser,
               av1_bitstreamfn_su (br, 7, &retval);
           if (retval != GST_AV1_PARSER_OK)
             goto error;
-        } else
-          lf_params->loop_filter_mode_deltas[i] = 0;
+        }
       }
     }
   }
@@ -2546,9 +2594,9 @@ gst_av1_parse_loop_restoration_params (GstAV1Parser * parser,
 
   if (frame_header->all_lossless || frame_header->allow_intrabc
       || !seq_header->enable_restoration) {
-    lr_params->frame_restoration_type[0] = GST_AV1_FRAME_RESTORE_NONE;
-    lr_params->frame_restoration_type[0] = GST_AV1_FRAME_RESTORE_NONE;
-    lr_params->frame_restoration_type[0] = GST_AV1_FRAME_RESTORE_NONE;
+    for (i = 0; i < GST_AV1_MAX_NUM_PLANES; i++)
+      lr_params->frame_restoration_type[i] = GST_AV1_FRAME_RESTORE_NONE;
+
     lr_params->uses_lr = 0;
     goto success;
   }
@@ -2851,6 +2899,66 @@ gst_av1_parse_global_param (GstAV1Parser * parser,
   return GST_AV1_PARSER_OK;
 }
 
+static gboolean
+gst_av1_parser_is_shear_params_valid (gint32 gm_params[6])
+{
+  const gint32 *mat = gm_params;
+  gint16 alpha, beta, gamma, delta;
+  gint16 shift;
+  gint16 y;
+  gint16 v;
+  guint i;
+  gboolean default_warp_params;
+
+  if (!(mat[2] > 0))
+    return FALSE;
+
+  default_warp_params = TRUE;
+  for (i = 0; i < 6; i++) {
+    if (gm_params[i] != ((i % 3 == 2) ? 1 << GST_AV1_WARPEDMODEL_PREC_BITS : 0)) {
+      default_warp_params = FALSE;
+      break;
+    }
+  }
+  if (default_warp_params)
+    return TRUE;
+
+  alpha = CLAMP (mat[2] - (1 << GST_AV1_WARPEDMODEL_PREC_BITS),
+      G_MININT16, G_MAXINT16);
+  beta = CLAMP (mat[3], G_MININT16, G_MAXINT16);
+  y = av1_helper_resolve_divisor_32 (ABS (mat[2]), &shift)
+      * (mat[2] < 0 ? -1 : 1);
+  v = ((gint64) mat[4] * (1 << GST_AV1_WARPEDMODEL_PREC_BITS)) * y;
+  gamma =
+      CLAMP ((gint) av1_helper_round_power_of_two_signed (v, shift), G_MININT16,
+      G_MAXINT16);
+  v = ((gint64) mat[3] * mat[4]) * y;
+  delta =
+      CLAMP (mat[5] - (gint) av1_helper_round_power_of_two_signed (v,
+          shift) - (1 << GST_AV1_WARPEDMODEL_PREC_BITS), G_MININT16,
+      G_MAXINT16);
+
+  alpha =
+      av1_helper_round_power_of_two_signed (alpha,
+      GST_AV1_WARP_PARAM_REDUCE_BITS) * (1 << GST_AV1_WARP_PARAM_REDUCE_BITS);
+  beta =
+      av1_helper_round_power_of_two_signed (beta,
+      GST_AV1_WARP_PARAM_REDUCE_BITS) * (1 << GST_AV1_WARP_PARAM_REDUCE_BITS);
+  gamma =
+      av1_helper_round_power_of_two_signed (gamma,
+      GST_AV1_WARP_PARAM_REDUCE_BITS) * (1 << GST_AV1_WARP_PARAM_REDUCE_BITS);
+  delta =
+      av1_helper_round_power_of_two_signed (delta,
+      GST_AV1_WARP_PARAM_REDUCE_BITS) * (1 << GST_AV1_WARP_PARAM_REDUCE_BITS);
+
+  if ((4 * ABS (alpha) + 7 * ABS (beta) >= (1 << GST_AV1_WARPEDMODEL_PREC_BITS))
+      || (4 * ABS (gamma) + 4 * ABS (delta) >=
+          (1 << GST_AV1_WARPEDMODEL_PREC_BITS)))
+    return FALSE;
+
+  return TRUE;
+}
+
 /* 5.9.24 */
 static GstAV1ParserResult
 gst_av1_parse_global_motion_params (GstAV1Parser * parser,
@@ -2865,6 +2973,7 @@ gst_av1_parse_global_motion_params (GstAV1Parser * parser,
   /* init value */
   gm_params->gm_type[GST_AV1_REF_INTRA_FRAME] = GST_AV1_WARP_MODEL_IDENTITY;
   for (ref = GST_AV1_REF_LAST_FRAME; ref <= GST_AV1_REF_ALTREF_FRAME; ref++) {
+    gm_params->invalid[ref] = 0;
     gm_params->gm_type[ref] = GST_AV1_WARP_MODEL_IDENTITY;
     for (i = 0; i < 6; i++) {
       gm_params->gm_params[ref][i] =
@@ -2956,6 +3065,10 @@ gst_av1_parse_global_motion_params (GstAV1Parser * parser,
       if (retval != GST_AV1_PARSER_OK)
         goto error;
     }
+
+    if (type <= GST_AV1_WARP_MODEL_AFFINE)
+      gm_params->invalid[ref] =
+          !gst_av1_parser_is_shear_params_valid (gm_params->gm_params[ref]);
   }
 
 success:
@@ -3375,6 +3488,64 @@ gst_av1_set_frame_refs (GstAV1Parser * parser,
       frame_header->ref_frame_idx[i] = ref;
 }
 
+/* 7.21 */
+static void
+gst_av1_parser_reference_frame_loading (GstAV1Parser * parser,
+    GstAV1FrameHeaderOBU * frame_header)
+{
+  GstAV1ReferenceFrameInfo *ref_info = &(parser->state.ref_info);
+  gint idx = frame_header->frame_to_show_map_idx;
+  GstAV1TileInfo *ref_tile_info = &ref_info->entry[idx].ref_tile_info;
+  const gint all_frames = (1 << GST_AV1_NUM_REF_FRAMES) - 1;
+
+  /* copy the relevant frame information as these will be needed by
+   * all subclasses. */
+  frame_header->frame_type = ref_info->entry[idx].ref_frame_type;
+  frame_header->upscaled_width = ref_info->entry[idx].ref_upscaled_width;
+  frame_header->frame_width = ref_info->entry[idx].ref_frame_width;
+  frame_header->frame_height = ref_info->entry[idx].ref_frame_height;
+  frame_header->render_width = ref_info->entry[idx].ref_render_width;
+  frame_header->render_height = ref_info->entry[idx].ref_render_height;
+
+  if (parser->seq_header->film_grain_params_present)
+    frame_header->film_grain_params =
+        ref_info->entry[idx].ref_film_grain_params;
+
+  /* the remaining is only relevant to ensure proper state update and only
+   * keyframe updates the state. */
+  if (frame_header->frame_type != GST_AV1_KEY_FRAME)
+    return;
+
+  frame_header->refresh_frame_flags = all_frames;
+  frame_header->current_frame_id = ref_info->entry[idx].ref_frame_id;
+  frame_header->order_hint = ref_info->entry[idx].ref_order_hint;
+  frame_header->segmentation_params =
+      ref_info->entry[idx].ref_segmentation_params;
+  frame_header->global_motion_params =
+      ref_info->entry[idx].ref_global_motion_params;
+  frame_header->loop_filter_params = ref_info->entry[idx].ref_lf_params;
+  frame_header->tile_info = *ref_tile_info;
+
+  parser->state.current_frame_id = ref_info->entry[idx].ref_frame_id;
+  parser->state.upscaled_width = ref_info->entry[idx].ref_upscaled_width;
+  parser->state.frame_width = ref_info->entry[idx].ref_frame_width;
+  parser->state.frame_height = ref_info->entry[idx].ref_frame_height;
+  parser->state.render_width = ref_info->entry[idx].ref_render_width;
+  parser->state.render_height = ref_info->entry[idx].ref_render_height;
+  parser->state.mi_cols = ref_info->entry[idx].ref_mi_cols;
+  parser->state.mi_rows = ref_info->entry[idx].ref_mi_rows;
+
+  memcpy (parser->state.mi_col_starts, ref_tile_info->mi_col_starts,
+      sizeof (guint32) * (GST_AV1_MAX_TILE_COLS + 1));
+  memcpy (parser->state.mi_row_starts, ref_tile_info->mi_row_starts,
+      sizeof (guint32) * (GST_AV1_MAX_TILE_ROWS + 1));
+  parser->state.tile_cols_log2 = ref_tile_info->tile_cols_log2;
+  parser->state.tile_cols = ref_tile_info->tile_cols;
+  parser->state.tile_rows_log2 = ref_tile_info->tile_rows_log2;
+  parser->state.tile_rows = ref_tile_info->tile_rows;
+  parser->state.tile_size_bytes = ref_tile_info->tile_size_bytes;
+}
+
 /* 5.9.2 */
 static GstAV1ParserResult
 gst_av1_parse_uncompressed_frame_header (GstAV1Parser * parser, GstAV1OBU * obu,
@@ -3460,16 +3631,7 @@ gst_av1_parse_uncompressed_frame_header (GstAV1Parser * parser, GstAV1OBU * obu,
         }
       }
 
-      frame_header->frame_type =
-          ref_info->entry[frame_header->frame_to_show_map_idx].ref_frame_type;
-      if (frame_header->frame_type == GST_AV1_KEY_FRAME) {
-        frame_header->refresh_frame_flags = all_frames;
-      }
-
-      /* just use the frame_to_show's grain_params
-       * if (seq_header->film_grain_params_present)
-       *     load_grain_params () */
-
+      gst_av1_parser_reference_frame_loading (parser, frame_header);
       goto success;
     }
 
@@ -3875,13 +4037,61 @@ gst_av1_parse_uncompressed_frame_header (GstAV1Parser * parser, GstAV1OBU * obu,
     goto error;
   }
 
+  if (frame_header->primary_ref_frame == GST_AV1_PRIMARY_REF_NONE) {
+    /* do something in setup_past_independence() of parser level */
+    gint8 *loop_filter_ref_deltas =
+        frame_header->loop_filter_params.loop_filter_ref_deltas;
+
+    frame_header->loop_filter_params.loop_filter_delta_enabled = 1;
+    loop_filter_ref_deltas[GST_AV1_REF_INTRA_FRAME] = 1;
+    loop_filter_ref_deltas[GST_AV1_REF_LAST_FRAME] = 0;
+    loop_filter_ref_deltas[GST_AV1_REF_LAST2_FRAME] = 0;
+    loop_filter_ref_deltas[GST_AV1_REF_LAST3_FRAME] = 0;
+    loop_filter_ref_deltas[GST_AV1_REF_BWDREF_FRAME] = 0;
+    loop_filter_ref_deltas[GST_AV1_REF_GOLDEN_FRAME] = -1;
+    loop_filter_ref_deltas[GST_AV1_REF_ALTREF_FRAME] = -1;
+    loop_filter_ref_deltas[GST_AV1_REF_ALTREF2_FRAME] = -1;
+    frame_header->loop_filter_params.loop_filter_mode_deltas[0] = 0;
+    frame_header->loop_filter_params.loop_filter_mode_deltas[1] = 0;
+  } else {
+    /* do something in load_previous() of parser level */
+    /*   load_loop_filter_params() */
+    GstAV1LoopFilterParams *ref_lf_params =
+        &parser->state.ref_info.entry[frame_header->
+        ref_frame_idx[frame_header->primary_ref_frame]].ref_lf_params;
+    gint8 *loop_filter_ref_deltas =
+        frame_header->loop_filter_params.loop_filter_ref_deltas;
+
+    /* Copy all from prime_ref */
+    g_assert (parser->state.ref_info.
+        entry[frame_header->ref_frame_idx[frame_header->primary_ref_frame]].
+        ref_valid);
+    loop_filter_ref_deltas[GST_AV1_REF_INTRA_FRAME] =
+        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_INTRA_FRAME];
+    loop_filter_ref_deltas[GST_AV1_REF_LAST_FRAME] =
+        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST_FRAME];
+    loop_filter_ref_deltas[GST_AV1_REF_LAST2_FRAME] =
+        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST2_FRAME];
+    loop_filter_ref_deltas[GST_AV1_REF_LAST3_FRAME] =
+        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_LAST3_FRAME];
+    loop_filter_ref_deltas[GST_AV1_REF_BWDREF_FRAME] =
+        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_BWDREF_FRAME];
+    loop_filter_ref_deltas[GST_AV1_REF_GOLDEN_FRAME] =
+        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_GOLDEN_FRAME];
+    loop_filter_ref_deltas[GST_AV1_REF_ALTREF2_FRAME] =
+        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_ALTREF2_FRAME];
+    loop_filter_ref_deltas[GST_AV1_REF_ALTREF_FRAME] =
+        ref_lf_params->loop_filter_ref_deltas[GST_AV1_REF_ALTREF_FRAME];
+    for (i = 0; i < 2; i++)
+      frame_header->loop_filter_params.loop_filter_mode_deltas[i] =
+          ref_lf_params->loop_filter_mode_deltas[i];
+  }
+
   /* @TODO:
      if ( primary_ref_frame == PRIMARY_REF_NONE ) {
      init_non_coeff_cdfs( )
-     setup_past_independence( )
      } else {
      load_cdfs( ref_frame_idx[primary_ref_frame] )
-     load_previous( )
      }
    */
   /* @TODO:
@@ -4005,74 +4215,6 @@ error:
   return retval;
 }
 
-/* 7.21 */
-/**
- * gst_av1_parser_reference_frame_loading:
- * @parser: the #GstAV1Parser
- * @frame_header: a #GstAV1FrameHeaderOBU to load
- *
- * Load the context of @frame_header to parser's state. This function is
- * used when we want to show already parsed frames before.
- *
- * Returns: The #GstAV1ParserResult.
- *
- * Since: 1.18
- */
-GstAV1ParserResult
-gst_av1_parser_reference_frame_loading (GstAV1Parser * parser,
-    GstAV1FrameHeaderOBU * frame_header)
-{
-  GstAV1ReferenceFrameInfo *ref_info;
-  GstAV1TileInfo *ref_tile_info;
-
-  g_return_val_if_fail (parser != NULL, GST_AV1_PARSER_INVALID_OPERATION);
-  g_return_val_if_fail (frame_header != NULL, GST_AV1_PARSER_INVALID_OPERATION);
-
-  if (!parser->seq_header) {
-    GST_WARNING ("Missing OBU Reference: seq_header");
-    return GST_AV1_PARSER_MISSING_OBU_REFERENCE;
-  }
-
-  ref_info = &(parser->state.ref_info);
-
-  if (frame_header->frame_to_show_map_idx > GST_AV1_NUM_REF_FRAMES - 1)
-    return GST_AV1_PARSER_BITSTREAM_ERROR;
-
-  g_assert (ref_info->entry[frame_header->frame_to_show_map_idx].ref_valid);
-
-  parser->state.current_frame_id =
-      ref_info->entry[frame_header->frame_to_show_map_idx].ref_frame_id;
-  parser->state.upscaled_width =
-      ref_info->entry[frame_header->frame_to_show_map_idx].ref_upscaled_width;
-  parser->state.frame_width =
-      ref_info->entry[frame_header->frame_to_show_map_idx].ref_frame_width;
-  parser->state.frame_height =
-      ref_info->entry[frame_header->frame_to_show_map_idx].ref_frame_height;
-  parser->state.render_width =
-      ref_info->entry[frame_header->frame_to_show_map_idx].ref_render_width;
-  parser->state.render_height =
-      ref_info->entry[frame_header->frame_to_show_map_idx].ref_render_height;
-  parser->state.mi_cols =
-      ref_info->entry[frame_header->frame_to_show_map_idx].ref_mi_cols;
-  parser->state.mi_rows =
-      ref_info->entry[frame_header->frame_to_show_map_idx].ref_mi_rows;
-
-  ref_tile_info =
-      &ref_info->entry[frame_header->frame_to_show_map_idx].ref_tile_info;
-
-  memcpy (parser->state.mi_col_starts, ref_tile_info->mi_col_starts,
-      sizeof (guint32) * (GST_AV1_MAX_TILE_COLS + 1));
-  memcpy (parser->state.mi_row_starts, ref_tile_info->mi_row_starts,
-      sizeof (guint32) * (GST_AV1_MAX_TILE_ROWS + 1));
-  parser->state.tile_cols_log2 = ref_tile_info->tile_cols_log2;
-  parser->state.tile_cols = ref_tile_info->tile_cols;
-  parser->state.tile_rows_log2 = ref_tile_info->tile_rows_log2;
-  parser->state.tile_rows = ref_tile_info->tile_rows;
-  parser->state.tile_size_bytes = ref_tile_info->tile_size_bytes;
-
-  return GST_AV1_PARSER_OK;
-}
-
 /**
  * gst_av1_parser_reference_frame_update:
  * @parser: the #GstAV1Parser
@@ -4253,6 +4395,11 @@ gst_av1_parse_tile_group (GstAV1Parser * parser, GstBitReader * br,
       goto error;
   }
 
+  if (tile_group->tg_end < tile_group->tg_start) {
+    retval = GST_AV1_PARSER_NO_MORE_DATA;
+    goto error;
+  }
+
   if (!gst_bit_reader_skip_to_byte (br)) {
     retval = GST_AV1_PARSER_NO_MORE_DATA;
     goto error;
@@ -4261,6 +4408,7 @@ gst_av1_parse_tile_group (GstAV1Parser * parser, GstBitReader * br,
   end_bit_pos = gst_bit_reader_get_pos (br);
   header_bytes = (end_bit_pos - start_bitpos) / 8;
   sz -= header_bytes;
+
   for (tile_num = tile_group->tg_start; tile_num <= tile_group->tg_end;
       tile_num++) {
     tile_row = tile_num / parser->state.tile_cols;
@@ -4274,9 +4422,14 @@ gst_av1_parse_tile_group (GstAV1Parser * parser, GstBitReader * br,
       if (retval != GST_AV1_PARSER_OK)
         goto error;
       tile_size = tile_size_minus_1 + 1;
-      sz -= tile_size - parser->state.tile_size_bytes;
+      sz -= (tile_size + parser->state.tile_size_bytes);
     }
 
+    tile_group->entry[tile_num].tile_size = tile_size;
+    tile_group->entry[tile_num].tile_offset = gst_bit_reader_get_pos (br) / 8;
+    tile_group->entry[tile_num].tile_row = tile_row;
+    tile_group->entry[tile_num].tile_col = tile_col;
+
     tile_group->entry[tile_num].mi_row_start =
         parser->state.mi_row_starts[tile_row];
     tile_group->entry[tile_num].mi_row_end =
@@ -4292,20 +4445,22 @@ gst_av1_parse_tile_group (GstAV1Parser * parser, GstBitReader * br,
      */
 
     /* Skip the real data to the next one */
-    if (!gst_bit_reader_skip (br, tile_size)) {
+    if (tile_num < tile_group->tg_end &&
+        !gst_bit_reader_skip (br, tile_size * 8)) {
       retval = GST_AV1_PARSER_NO_MORE_DATA;
       goto error;
     }
   }
 
-  /* Not implement here, the real decoder process
-     if (tile_group->tg_end == tile_group->num_tiles - 1) {
-     if ( !disable_frame_end_update_cdf ) {
-     frame_end_update_cdf( )
-     }
-     decode_frame_wrapup( )
-     }
-   */
+  if (tile_group->tg_end == tile_group->num_tiles - 1) {
+    /* Not implement here, the real decoder process
+       if ( !disable_frame_end_update_cdf ) {
+       frame_end_update_cdf( )
+       }
+       decode_frame_wrapup( )
+     */
+    parser->state.seen_frame_header = 0;
+  }
 
   return GST_AV1_PARSER_OK;
 
@@ -4355,9 +4510,14 @@ gst_av1_parse_frame_header (GstAV1Parser * parser, GstAV1OBU * obu,
     GstBitReader * bit_reader, GstAV1FrameHeaderOBU * frame_header)
 {
   GstAV1ParserResult ret;
+  guint i;
 
   memset (frame_header, 0, sizeof (*frame_header));
   frame_header->frame_is_intra = 1;
+  frame_header->last_frame_idx = -1;
+  frame_header->gold_frame_idx = -1;
+  for (i = 0; i < GST_AV1_REFS_PER_FRAME; i++)
+    frame_header->ref_frame_idx[i] = -1;
 
   ret = gst_av1_parse_uncompressed_frame_header (parser, obu, bit_reader,
       frame_header);
@@ -4462,10 +4622,36 @@ gst_av1_parser_parse_frame_obu (GstAV1Parser * parser, GstAV1OBU * obu,
     return GST_AV1_PARSER_NO_MORE_DATA;
 
   retval = gst_av1_parse_tile_group (parser, &bit_reader, &(frame->tile_group));
-  parser->state.seen_frame_header = 0;
   return retval;
 }
 
+/**
+ * gst_av1_parser_set_operating_point:
+ * @parser: the #GstAV1Parser
+ * @operating_point: the operating point to set
+ *
+ * Set the operating point to filter OBUs.
+ *
+ * Returns: The #GstAV1ParserResult.
+ *
+ * Since: 1.20
+ */
+GstAV1ParserResult
+gst_av1_parser_set_operating_point (GstAV1Parser * parser,
+    gint32 operating_point)
+{
+  g_return_val_if_fail (parser != NULL, GST_AV1_PARSER_INVALID_OPERATION);
+  g_return_val_if_fail (operating_point >= 0, GST_AV1_PARSER_INVALID_OPERATION);
+
+  if (parser->seq_header &&
+      operating_point > parser->seq_header->operating_points_cnt_minus_1)
+    return GST_AV1_PARSER_INVALID_OPERATION;
+
+  /* Decide whether it is valid when sequence comes. */
+  parser->state.operating_point = operating_point;
+  return GST_AV1_PARSER_OK;
+}
+
 /**
  * gst_av1_parser_new:
  *
diff --git a/gst-libs/gst/codecparsers/gstav1parser.h b/gst-libs/gst/codecparsers/gstav1parser.h
index 4b49a356e..a5f1c761f 100644
--- a/gst-libs/gst/codecparsers/gstav1parser.h
+++ b/gst-libs/gst/codecparsers/gstav1parser.h
@@ -52,7 +52,6 @@ G_BEGIN_DECLS
 #define GST_AV1_SUPERRES_DENOM_MIN             9
 #define GST_AV1_SUPERRES_DENOM_BITS            3
 #define GST_AV1_MAX_LOOP_FILTER                63
-#define GST_AV1_GM_ABS_ALPHA_BITS              12
 #define GST_AV1_GM_ABS_TRANS_BITS              12
 #define GST_AV1_GM_ABS_TRANS_ONLY_BITS         9
 #define GST_AV1_GM_ABS_ALPHA_BITS              12
@@ -60,6 +59,7 @@ G_BEGIN_DECLS
 #define GST_AV1_GM_TRANS_PREC_BITS             6
 #define GST_AV1_GM_TRANS_ONLY_PREC_BITS        3
 #define GST_AV1_WARPEDMODEL_PREC_BITS          16
+#define GST_AV1_WARP_PARAM_REDUCE_BITS         6
 #define GST_AV1_SELECT_SCREEN_CONTENT_TOOLS    2
 #define GST_AV1_SELECT_INTEGER_MV              2
 #define GST_AV1_RESTORATION_TILESIZE_MAX       256
@@ -80,6 +80,11 @@ G_BEGIN_DECLS
 #define GST_AV1_MAX_NUM_POS_LUMA               25
 #define GST_AV1_MAX_NUM_PLANES                 3
 
+#define GST_AV1_DIV_LUT_PREC_BITS              14
+#define GST_AV1_DIV_LUT_BITS                   8
+#define GST_AV1_DIV_LUT_NUM                    (1 << GST_AV1_DIV_LUT_BITS)
+
+
 typedef struct _GstAV1Parser GstAV1Parser;
 
 typedef struct _GstAV1OBUHeader GstAV1OBUHeader;
@@ -137,13 +142,22 @@ typedef enum {
  * @GST_AV1_PROFILE_0: 8-bit and 10-bit 4:2:0 and 4:0:0 only.
  * @GST_AV1_PROFILE_1: 8-bit and 10-bit 4:4:4.
  * @GST_AV1_PROFILE_2: 8-bit and 10-bit 4:2:2, 12-bit 4:0:0 4:2:2 and 4:4:4
+ * @GST_AV1_PROFILE_UNDEFINED: unknow AV1 profile (Since: 1.20)
  *
  * Defines the AV1 profiles
  */
+/**
+ * GST_AV1_PROFILE_UNDEFINED:
+ *
+ * unknow AV1 profile
+ *
+ * Since: 1.20
+ */
 typedef enum {
   GST_AV1_PROFILE_0 = 0,
   GST_AV1_PROFILE_1 = 1,
   GST_AV1_PROFILE_2 = 2,
+  GST_AV1_PROFILE_UNDEFINED,
 } GstAV1Profile;
 
 /**
@@ -1087,8 +1101,8 @@ struct _GstAV1LoopFilterParams {
   gboolean loop_filter_delta_enabled;
   gboolean loop_filter_delta_update;
 
-  guint8 loop_filter_ref_deltas[GST_AV1_TOTAL_REFS_PER_FRAME];
-  guint8 loop_filter_mode_deltas[2];
+  gint8 loop_filter_ref_deltas[GST_AV1_TOTAL_REFS_PER_FRAME];
+  gint8 loop_filter_mode_deltas[2];
 
   gboolean delta_lf_present;
   guint8 delta_lf_res;
@@ -1258,6 +1272,14 @@ struct _GstAV1LoopRestorationParams {
  * @gm_params: is set equal to SavedGmParams[ frame_to_show_map_idx ][ ref ][ j ] for
  *   ref = LAST_FRAME..ALTREF_FRAME, for j = 0..5.
  * @gm_type: specifying the type of global motion.
+ * @invalid: whether this global motion parameters is invalid. (Since: 1.20)
+ */
+/**
+ * _GstAV1GlobalMotionParams.invalid:
+ *
+ * whether this global motion parameters is invalid.
+ *
+ * Since: 1.20
  */
 struct _GstAV1GlobalMotionParams {
   gboolean is_global[GST_AV1_NUM_REF_FRAMES];
@@ -1266,6 +1288,7 @@ struct _GstAV1GlobalMotionParams {
   gint32 gm_params[GST_AV1_NUM_REF_FRAMES][6];
 
   GstAV1WarpModelType gm_type[GST_AV1_NUM_REF_FRAMES]; /* GmType */
+  gboolean invalid[GST_AV1_NUM_REF_FRAMES];
 };
 
 /**
@@ -1398,7 +1421,7 @@ struct _GstAV1FilmGrainParams {
  *   of bitstream conformance that whenever @display_frame_id is read, the value matches
  *   @ref_frame_id[ @frame_to_show_map_idx ] (the value of @current_frame_id at the time that the
  *   frame indexed by @frame_to_show_map_idx was stored), and that
- *   @ref_valid[ @frame_to_show_map_idx ] is equjal to 1. It is a requirement of bitstream
+ *   @ref_valid[ @frame_to_show_map_idx ] is equal to 1. It is a requirement of bitstream
  *   conformance that the number of bits needed to read @display_frame_id does not exceed 16.
  *   This is equivalent to the constraint that idLen <= 16
  * @frame_type: specifies the type of the frame.
@@ -1516,7 +1539,7 @@ struct _GstAV1FilmGrainParams {
  */
 struct _GstAV1FrameHeaderOBU {
   gboolean show_existing_frame;
-  guint8 frame_to_show_map_idx;
+  gint8 frame_to_show_map_idx;
   guint32 frame_presentation_time;
   guint32 tu_presentation_delay;
   guint32 display_frame_id;
@@ -1537,9 +1560,9 @@ struct _GstAV1FrameHeaderOBU {
   guint32 ref_order_hint[GST_AV1_NUM_REF_FRAMES];
   gboolean allow_intrabc;
   gboolean frame_refs_short_signaling;
-  guint8 last_frame_idx;
-  guint8 gold_frame_idx;
-  guint8 ref_frame_idx[GST_AV1_REFS_PER_FRAME];
+  gint8 last_frame_idx;
+  gint8 gold_frame_idx;
+  gint8 ref_frame_idx[GST_AV1_REFS_PER_FRAME];
   gboolean allow_high_precision_mv;
   gboolean is_motion_mode_switchable;
   gboolean use_ref_frame_mvs;
@@ -1636,7 +1659,7 @@ struct _GstAV1TileListOBU {
   guint8 output_frame_height_in_tiles_minus_1;
   guint16 tile_count_minus_1;
   struct {
-    guint8 anchor_frame_idx;
+    gint8 anchor_frame_idx;
     guint8 anchor_tile_row;
     guint8 anchor_tile_col;
     guint16 tile_data_size_minus_1;
@@ -1659,6 +1682,10 @@ struct _GstAV1TileListOBU {
  *   It is a requirement of bitstream conformance that the value of tg_end is greater
  *   than or equal to tg_start. It is a requirement of bitstream conformance that the
  *   value of tg_end for the last tile group in each frame is equal to num_tiles-1.
+ * @tile_offset: Offset from the OBU data, the real data start of this tile.
+ * @tg_size: Data size of this tile.
+ * @tile_row: Tile index in row.
+ * @tile_col: Tile index in column.
  * @mi_row_start: start position in mi rows
  * @mi_row_end: end position in mi rows
  * @mi_col_start: start position in mi cols
@@ -1670,6 +1697,10 @@ struct _GstAV1TileGroupOBU {
   guint8 tg_start;
   guint8 tg_end;
   struct {
+    guint32 tile_offset; /* Tile data offset from the OBU data. */
+    guint32 tile_size; /* Data size of this tile */
+    guint32 tile_row; /* tileRow */
+    guint32 tile_col; /* tileCol */
     /* global varialbes */
     guint32 mi_row_start; /* MiRowStart */
     guint32 mi_row_end; /* MiRowEnd */
@@ -1745,6 +1776,10 @@ GST_CODEC_PARSERS_API
 void
 gst_av1_parser_reset (GstAV1Parser * parser, gboolean annex_b);
 
+GST_CODEC_PARSERS_API
+void
+gst_av1_parser_reset_annex_b (GstAV1Parser * parser);
+
 GST_CODEC_PARSERS_API
 GstAV1ParserResult
 gst_av1_parser_identify_one_obu (GstAV1Parser * parser, const guint8 * data,
@@ -1787,13 +1822,13 @@ gst_av1_parser_parse_frame_obu (GstAV1Parser * parser, GstAV1OBU * obu,
 
 GST_CODEC_PARSERS_API
 GstAV1ParserResult
-gst_av1_parser_reference_frame_loading (GstAV1Parser * parser,
+gst_av1_parser_reference_frame_update (GstAV1Parser * parser,
     GstAV1FrameHeaderOBU * frame_header);
 
 GST_CODEC_PARSERS_API
 GstAV1ParserResult
-gst_av1_parser_reference_frame_update (GstAV1Parser * parser,
-    GstAV1FrameHeaderOBU * frame_header);
+gst_av1_parser_set_operating_point (GstAV1Parser * parser,
+    gint32 operating_point);
 
 GST_CODEC_PARSERS_API
 GstAV1Parser * gst_av1_parser_new (void);
diff --git a/gst-libs/gst/codecparsers/gsth264bitwriter.c b/gst-libs/gst/codecparsers/gsth264bitwriter.c
new file mode 100644
index 000000000..d13de6d6d
--- /dev/null
+++ b/gst-libs/gst/codecparsers/gsth264bitwriter.c
@@ -0,0 +1,1642 @@
+/* GStreamer
+ *  Copyright (C) 2020 Intel Corporation
+ *     Author: He Junyan <junyan.he@intel.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the0
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+#  include "config.h"
+#endif
+
+#include "gsth264bitwriter.h"
+#include <gst/codecparsers/nalutils.h>
+#include <gst/base/gstbitwriter.h>
+
+/********************************  Utils ********************************/
+#define SIGNED(val)    (2 * ABS(val) - ((val) > 0))
+
+/* Write an unsigned integer Exp-Golomb-coded syntax element. i.e. ue(v) */
+static gboolean
+_bs_write_ue (GstBitWriter * bs, guint32 value)
+{
+  guint32 size_in_bits = 0;
+  guint32 tmp_value = ++value;
+
+  while (tmp_value) {
+    ++size_in_bits;
+    tmp_value >>= 1;
+  }
+  if (size_in_bits > 1
+      && !gst_bit_writer_put_bits_uint32 (bs, 0, size_in_bits - 1))
+    return FALSE;
+  if (!gst_bit_writer_put_bits_uint32 (bs, value, size_in_bits))
+    return FALSE;
+  return TRUE;
+}
+
+#define WRITE_BITS_UNCHECK(bw, val, nbits)                                    \
+  (nbits <= 8 ? gst_bit_writer_put_bits_uint8 (bw, val, nbits) :              \
+   (nbits <= 16 ? gst_bit_writer_put_bits_uint16 (bw, val, nbits) :           \
+    (nbits <= 32 ? gst_bit_writer_put_bits_uint32 (bw, val, nbits) :          \
+     FALSE)))
+
+#define WRITE_BITS(bw, val, nbits)                                            \
+  if (!WRITE_BITS_UNCHECK (bw, val, nbits)) {                                 \
+    g_warning ("Unsupported bit size: %u", nbits);                            \
+    have_space = FALSE;                                                       \
+    goto error;                                                               \
+  }
+
+#define WRITE_UE_UNCHECK(bw, val)  _bs_write_ue (bw, val)
+
+#ifdef WRITE_UE
+#undef WRITE_UE
+#endif
+#define WRITE_UE(bw, val)                                                     \
+  if (!(have_space = WRITE_UE_UNCHECK (bw, val)))                             \
+    goto error;                                                               \
+
+#define WRITE_UE_MAX(bw, val, max)                                            \
+  if ((guint32) val > (max) || !(have_space = WRITE_UE_UNCHECK (bw, val)))    \
+    goto error;
+
+#define WRITE_SE(bw, val) WRITE_UE (bw, SIGNED (val))
+
+#define WRITE_SE_RANGE(bw, val, min, max)                                     \
+  if (val > max || val < min ||                                               \
+      !(have_space = WRITE_UE_UNCHECK (bw, SIGNED (val))))                    \
+    goto error;
+
+#define WRITE_BYTES_UNCHECK(bw, ptr, nbytes)                                  \
+  gst_bit_writer_put_bytes(bw, ptr, nbytes)
+
+#ifdef WRITE_BYTES
+#undef WRITE_BYTES
+#endif
+#define WRITE_BYTES(bw, ptr, nbytes)                                          \
+  if (!(have_space = WRITE_BYTES_UNCHECK (bw, ptr, nbytes)))                  \
+    goto error;
+
+/*****************************  End of Utils ****************************/
+
+/**** Default scaling_lists according to Table 7-2 *****/
+static const guint8 default_4x4_intra[16] = {
+  6, 13, 13, 20, 20, 20, 28, 28, 28, 28, 32, 32,
+  32, 37, 37, 42
+};
+
+static const guint8 default_4x4_inter[16] = {
+  10, 14, 14, 20, 20, 20, 24, 24, 24, 24, 27, 27,
+  27, 30, 30, 34
+};
+
+static const guint8 default_8x8_intra[64] = {
+  6, 10, 10, 13, 11, 13, 16, 16, 16, 16, 18, 18,
+  18, 18, 18, 23, 23, 23, 23, 23, 23, 25, 25, 25, 25, 25, 25, 25, 27, 27, 27,
+  27, 27, 27, 27, 27, 29, 29, 29, 29, 29, 29, 29, 31, 31, 31, 31, 31, 31, 33,
+  33, 33, 33, 33, 36, 36, 36, 36, 38, 38, 38, 40, 40, 42
+};
+
+static const guint8 default_8x8_inter[64] = {
+  9, 13, 13, 15, 13, 15, 17, 17, 17, 17, 19, 19,
+  19, 19, 19, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 24, 24, 24,
+  24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 27, 27, 27, 27, 27, 27, 28,
+  28, 28, 28, 28, 30, 30, 30, 30, 32, 32, 32, 33, 33, 35
+};
+
+static gboolean
+_h264_bit_writer_scaling_list (GstBitWriter * bw, gboolean * space,
+    const guint8 scaling_lists_4x4[6][16],
+    const guint8 scaling_lists_8x8[6][64], const guint8 fallback_4x4_inter[16],
+    const guint8 fallback_4x4_intra[16], const guint8 fallback_8x8_inter[64],
+    const guint8 fallback_8x8_intra[64], guint8 n_lists)
+{
+  gboolean have_space = TRUE;
+  guint i, j;
+
+  const guint8 *default_lists[12] = {
+    fallback_4x4_intra, fallback_4x4_intra, fallback_4x4_intra,
+    fallback_4x4_inter, fallback_4x4_inter, fallback_4x4_inter,
+    fallback_8x8_intra, fallback_8x8_inter,
+    fallback_8x8_intra, fallback_8x8_inter,
+    fallback_8x8_intra, fallback_8x8_inter
+  };
+
+  GST_DEBUG ("writing scaling lists");
+
+  for (i = 0; i < 12; i++) {
+    if (i < n_lists) {
+      guint8 scaling_list_present_flag = FALSE;
+      const guint8 *scaling_list;
+      guint size;
+
+      if (i < 6) {
+        scaling_list = scaling_lists_4x4[i];
+        size = 16;
+      } else {
+        scaling_list = scaling_lists_8x8[i - 6];
+        size = 64;
+      }
+
+      if (memcmp (scaling_list, default_lists[i], size))
+        scaling_list_present_flag = TRUE;
+
+      WRITE_BITS (bw, scaling_list_present_flag, 1);
+      if (scaling_list_present_flag) {
+        guint8 last_scale, next_scale;
+        gint8 delta_scale;
+
+        for (j = 0; j < size; j++) {
+          last_scale = next_scale = 8;
+
+          for (j = 0; j < size; j++) {
+            if (next_scale != 0) {
+              delta_scale = (gint8) (scaling_list[j] - last_scale);
+
+              WRITE_SE (bw, delta_scale);
+
+              next_scale = scaling_list[j];
+            }
+            last_scale = (next_scale == 0) ? last_scale : next_scale;
+          }
+        }
+      }
+    }
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write scaling lists");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h264_bit_writer_hrd_parameters (const GstH264HRDParams * hrd,
+    GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+  guint sched_sel_idx;
+
+  GST_DEBUG ("writing \"HRD Parameters\"");
+
+  WRITE_UE_MAX (bw, hrd->cpb_cnt_minus1, 31);
+  WRITE_BITS (bw, hrd->bit_rate_scale, 4);
+  WRITE_BITS (bw, hrd->cpb_size_scale, 4);
+
+  for (sched_sel_idx = 0; sched_sel_idx <= hrd->cpb_cnt_minus1; sched_sel_idx++) {
+    WRITE_UE (bw, hrd->bit_rate_value_minus1[sched_sel_idx]);
+    WRITE_UE (bw, hrd->cpb_size_value_minus1[sched_sel_idx]);
+    WRITE_BITS (bw, hrd->cbr_flag[sched_sel_idx], 1);
+  }
+
+  WRITE_BITS (bw, hrd->initial_cpb_removal_delay_length_minus1, 5);
+  WRITE_BITS (bw, hrd->cpb_removal_delay_length_minus1, 5);
+  WRITE_BITS (bw, hrd->dpb_output_delay_length_minus1, 5);
+  WRITE_BITS (bw, hrd->time_offset_length, 5);
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write \"HRD Parameters\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+#define EXTENDED_SAR 255
+
+static gboolean
+_h264_bit_writer_vui_parameters (const GstH264SPS * sps, GstBitWriter * bw,
+    gboolean * space)
+{
+  gboolean have_space = TRUE;
+  const GstH264VUIParams *vui = &sps->vui_parameters;
+
+  GST_DEBUG ("writing \"VUI Parameters\"");
+
+  WRITE_BITS (bw, vui->aspect_ratio_info_present_flag, 1);
+  if (vui->aspect_ratio_info_present_flag) {
+    WRITE_BITS (bw, vui->aspect_ratio_idc, 8);
+    if (vui->aspect_ratio_idc == EXTENDED_SAR) {
+      WRITE_BITS (bw, vui->sar_width, 16);
+      WRITE_BITS (bw, vui->sar_height, 16);
+    }
+  }
+
+  WRITE_BITS (bw, vui->overscan_info_present_flag, 1);
+  if (vui->overscan_info_present_flag)
+    WRITE_BITS (bw, vui->overscan_appropriate_flag, 1);
+
+  WRITE_BITS (bw, vui->video_signal_type_present_flag, 1);
+  if (vui->video_signal_type_present_flag) {
+    WRITE_BITS (bw, vui->video_format, 3);
+    WRITE_BITS (bw, vui->video_full_range_flag, 1);
+    WRITE_BITS (bw, vui->colour_description_present_flag, 1);
+    if (vui->colour_description_present_flag) {
+      WRITE_BITS (bw, vui->colour_primaries, 8);
+      WRITE_BITS (bw, vui->transfer_characteristics, 8);
+      WRITE_BITS (bw, vui->matrix_coefficients, 8);
+    }
+  }
+
+  WRITE_BITS (bw, vui->chroma_loc_info_present_flag, 1);
+  if (vui->chroma_loc_info_present_flag) {
+    WRITE_UE_MAX (bw, vui->chroma_sample_loc_type_top_field, 5);
+    WRITE_UE_MAX (bw, vui->chroma_sample_loc_type_bottom_field, 5);
+  }
+
+  WRITE_BITS (bw, vui->timing_info_present_flag, 1);
+  if (vui->timing_info_present_flag) {
+    WRITE_BITS (bw, vui->num_units_in_tick, 32);
+    if (vui->num_units_in_tick == 0)
+      GST_WARNING ("num_units_in_tick = 0 write to stream "
+          "(incompliant to H.264 E.2.1).");
+
+    WRITE_BITS (bw, vui->time_scale, 32);
+    if (vui->time_scale == 0)
+      GST_WARNING ("time_scale = 0 write to stream "
+          "(incompliant to H.264 E.2.1).");
+
+    WRITE_BITS (bw, vui->fixed_frame_rate_flag, 1);
+  }
+
+  WRITE_BITS (bw, vui->nal_hrd_parameters_present_flag, 1);
+  if (vui->nal_hrd_parameters_present_flag) {
+    if (!_h264_bit_writer_hrd_parameters (&vui->nal_hrd_parameters, bw,
+            &have_space))
+      goto error;
+  }
+
+  WRITE_BITS (bw, vui->vcl_hrd_parameters_present_flag, 1);
+  if (vui->vcl_hrd_parameters_present_flag) {
+    if (!_h264_bit_writer_hrd_parameters (&vui->vcl_hrd_parameters, bw,
+            &have_space))
+      goto error;
+  }
+
+  if (vui->nal_hrd_parameters_present_flag ||
+      vui->vcl_hrd_parameters_present_flag)
+    WRITE_BITS (bw, vui->low_delay_hrd_flag, 1);
+
+  WRITE_BITS (bw, vui->pic_struct_present_flag, 1);
+  WRITE_BITS (bw, vui->bitstream_restriction_flag, 1);
+  if (vui->bitstream_restriction_flag) {
+    WRITE_BITS (bw, vui->motion_vectors_over_pic_boundaries_flag, 1);
+    WRITE_UE (bw, vui->max_bytes_per_pic_denom);
+    WRITE_UE_MAX (bw, vui->max_bits_per_mb_denom, 16);
+    WRITE_UE_MAX (bw, vui->log2_max_mv_length_horizontal, 16);
+    WRITE_UE_MAX (bw, vui->log2_max_mv_length_vertical, 16);
+    WRITE_UE (bw, vui->num_reorder_frames);
+    WRITE_UE (bw, vui->max_dec_frame_buffering);
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write \"VUI Parameters\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h264_bit_writer_sps (const GstH264SPS * sps, GstBitWriter * bw,
+    gboolean * space)
+{
+  gboolean have_space = TRUE;
+
+  GST_DEBUG ("writing SPS");
+
+  WRITE_BITS (bw, sps->profile_idc, 8);
+  WRITE_BITS (bw, sps->constraint_set0_flag, 1);
+  WRITE_BITS (bw, sps->constraint_set1_flag, 1);
+  WRITE_BITS (bw, sps->constraint_set2_flag, 1);
+  WRITE_BITS (bw, sps->constraint_set3_flag, 1);
+  WRITE_BITS (bw, sps->constraint_set4_flag, 1);
+  WRITE_BITS (bw, sps->constraint_set5_flag, 1);
+  /* reserved_zero_2bits */
+  WRITE_BITS (bw, 0, 2);
+
+  WRITE_BITS (bw, sps->level_idc, 8);
+
+  WRITE_UE_MAX (bw, sps->id, GST_H264_MAX_SPS_COUNT - 1);
+
+  if (sps->profile_idc == 100 || sps->profile_idc == 110 ||
+      sps->profile_idc == 122 || sps->profile_idc == 244 ||
+      sps->profile_idc == 44 || sps->profile_idc == 83 ||
+      sps->profile_idc == 86 || sps->profile_idc == 118 ||
+      sps->profile_idc == 128 || sps->profile_idc == 138 ||
+      sps->profile_idc == 139 || sps->profile_idc == 134 ||
+      sps->profile_idc == 135) {
+    WRITE_UE_MAX (bw, sps->chroma_format_idc, 3);
+    if (sps->chroma_format_idc == 3)
+      WRITE_BITS (bw, sps->separate_colour_plane_flag, 1);
+
+    WRITE_UE_MAX (bw, sps->bit_depth_luma_minus8, 6);
+    WRITE_UE_MAX (bw, sps->bit_depth_chroma_minus8, 6);
+    WRITE_BITS (bw, sps->qpprime_y_zero_transform_bypass_flag, 1);
+
+    WRITE_BITS (bw, sps->scaling_matrix_present_flag, 1);
+    if (sps->scaling_matrix_present_flag) {
+      guint8 n_lists;
+
+      n_lists = (sps->chroma_format_idc != 3) ? 8 : 12;
+      if (!_h264_bit_writer_scaling_list (bw, &have_space,
+              sps->scaling_lists_4x4, sps->scaling_lists_8x8,
+              default_4x4_inter, default_4x4_intra,
+              default_8x8_inter, default_8x8_intra, n_lists))
+        goto error;
+    }
+  }
+
+  WRITE_UE_MAX (bw, sps->log2_max_frame_num_minus4, 12);
+
+  WRITE_UE_MAX (bw, sps->pic_order_cnt_type, 2);
+  if (sps->pic_order_cnt_type == 0) {
+    WRITE_UE_MAX (bw, sps->log2_max_pic_order_cnt_lsb_minus4, 12);
+  } else if (sps->pic_order_cnt_type == 1) {
+    guint i;
+
+    WRITE_BITS (bw, sps->delta_pic_order_always_zero_flag, 1);
+    WRITE_SE (bw, sps->offset_for_non_ref_pic);
+    WRITE_SE (bw, sps->offset_for_top_to_bottom_field);
+    WRITE_UE_MAX (bw, sps->num_ref_frames_in_pic_order_cnt_cycle, 255);
+
+    for (i = 0; i < sps->num_ref_frames_in_pic_order_cnt_cycle; i++)
+      WRITE_SE (bw, sps->offset_for_ref_frame[i]);
+  }
+
+  WRITE_UE (bw, sps->num_ref_frames);
+  WRITE_BITS (bw, sps->gaps_in_frame_num_value_allowed_flag, 1);
+  WRITE_UE (bw, sps->pic_width_in_mbs_minus1);
+  WRITE_UE (bw, sps->pic_height_in_map_units_minus1);
+  WRITE_BITS (bw, sps->frame_mbs_only_flag, 1);
+
+  if (!sps->frame_mbs_only_flag)
+    WRITE_BITS (bw, sps->mb_adaptive_frame_field_flag, 1);
+
+  WRITE_BITS (bw, sps->direct_8x8_inference_flag, 1);
+  WRITE_BITS (bw, sps->frame_cropping_flag, 1);
+  if (sps->frame_cropping_flag) {
+    WRITE_UE (bw, sps->frame_crop_left_offset);
+    WRITE_UE (bw, sps->frame_crop_right_offset);
+    WRITE_UE (bw, sps->frame_crop_top_offset);
+    WRITE_UE (bw, sps->frame_crop_bottom_offset);
+  }
+
+  WRITE_BITS (bw, sps->vui_parameters_present_flag, 1);
+  if (sps->vui_parameters_present_flag)
+    if (!_h264_bit_writer_vui_parameters (sps, bw, &have_space))
+      goto error;
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write sps");
+
+  *space = have_space;
+  return FALSE;
+}
+
+/**
+ * gst_h264_bit_writer_sps:
+ * @sps: the sps of #GstH264SPS to write
+ * @start_code: whether adding the nal start code
+ * @data: (out): the bit stream generated by the sps
+ * @size: (inout): the size in bytes of the input and output
+ *
+ * Generating the according h264 bit stream by providing the sps.
+ *
+ * Returns: a #GstH264BitWriterResult
+ *
+ * Since: 1.22
+ **/
+GstH264BitWriterResult
+gst_h264_bit_writer_sps (const GstH264SPS * sps, gboolean start_code,
+    guint8 * data, guint * size)
+{
+  gboolean have_space = TRUE;
+  GstBitWriter bw;
+
+  g_return_val_if_fail (sps != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (data != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (size != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (*size > 0, GST_H264_BIT_WRITER_ERROR);
+
+  gst_bit_writer_init_with_data (&bw, data, *size, FALSE);
+
+  if (start_code)
+    WRITE_BITS (&bw, 0x00000001, 32);
+
+  /* nal header */
+  /* forbidden_zero_bit */
+  WRITE_BITS (&bw, 0, 1);
+  /* nal_ref_idc */
+  WRITE_BITS (&bw, 1, 2);
+  /* nal_unit_type */
+  WRITE_BITS (&bw, GST_H264_NAL_SPS, 5);
+
+  if (!_h264_bit_writer_sps (sps, &bw, &have_space))
+    goto error;
+
+  /* Add trailings. */
+  WRITE_BITS (&bw, 1, 1);
+  if (!gst_bit_writer_align_bytes (&bw, 0)) {
+    have_space = FALSE;
+    goto error;
+  }
+
+  *size = (gst_bit_writer_get_size (&bw)) / 8;
+  gst_bit_writer_reset (&bw);
+
+  return GST_H264_BIT_WRITER_OK;
+
+error:
+  gst_bit_writer_reset (&bw);
+  *size = 0;
+
+  return have_space ? GST_H264_BIT_WRITER_INVALID_DATA :
+      GST_H264_BIT_WRITER_NO_MORE_SPACE;
+}
+
+static gboolean
+_h264_bit_writer_pps (const GstH264PPS * pps, GstBitWriter * bw,
+    gboolean * space)
+{
+  gboolean have_space = TRUE;
+  gint qp_bd_offset;
+
+  GST_DEBUG ("writing SPS");
+
+  qp_bd_offset = 6 * (pps->sequence->bit_depth_luma_minus8 +
+      pps->sequence->separate_colour_plane_flag);
+
+  WRITE_UE_MAX (bw, pps->id, GST_H264_MAX_PPS_COUNT - 1);
+  WRITE_UE_MAX (bw, pps->sequence->id, GST_H264_MAX_SPS_COUNT - 1);
+
+  WRITE_BITS (bw, pps->entropy_coding_mode_flag, 1);
+  WRITE_BITS (bw, pps->pic_order_present_flag, 1);
+
+  WRITE_UE_MAX (bw, pps->num_slice_groups_minus1, 7);
+  if (pps->num_slice_groups_minus1 > 0) {
+    WRITE_UE_MAX (bw, pps->slice_group_map_type, 6);
+
+    if (pps->slice_group_map_type == 0) {
+      gint i;
+
+      for (i = 0; i <= pps->num_slice_groups_minus1; i++)
+        WRITE_UE (bw, pps->run_length_minus1[i]);
+    } else if (pps->slice_group_map_type == 2) {
+      gint i;
+
+      for (i = 0; i < pps->num_slice_groups_minus1; i++) {
+        WRITE_UE (bw, pps->top_left[i]);
+        WRITE_UE (bw, pps->bottom_right[i]);
+      }
+    } else if (pps->slice_group_map_type >= 3 && pps->slice_group_map_type <= 5) {
+      WRITE_BITS (bw, pps->slice_group_change_direction_flag, 1);
+      WRITE_UE (bw, pps->slice_group_change_rate_minus1);
+    } else if (pps->slice_group_map_type == 6) {
+      gint bits;
+      gint i;
+
+      WRITE_UE (bw, pps->pic_size_in_map_units_minus1);
+      bits = g_bit_storage (pps->num_slice_groups_minus1);
+
+      g_assert (pps->slice_group_id);
+      for (i = 0; i <= pps->pic_size_in_map_units_minus1; i++)
+        WRITE_BITS (bw, pps->slice_group_id[i], bits);
+    }
+  }
+
+  WRITE_UE_MAX (bw, pps->num_ref_idx_l0_active_minus1, 31);
+  WRITE_UE_MAX (bw, pps->num_ref_idx_l1_active_minus1, 31);
+  WRITE_BITS (bw, pps->weighted_pred_flag, 1);
+  WRITE_BITS (bw, pps->weighted_bipred_idc, 2);
+  WRITE_SE_RANGE (bw, pps->pic_init_qp_minus26, -(26 + qp_bd_offset), 25);
+  WRITE_SE_RANGE (bw, pps->pic_init_qs_minus26, -26, 25);
+  WRITE_SE_RANGE (bw, pps->chroma_qp_index_offset, -12, 12);
+
+  WRITE_BITS (bw, pps->deblocking_filter_control_present_flag, 1);
+  WRITE_BITS (bw, pps->constrained_intra_pred_flag, 1);
+  WRITE_BITS (bw, pps->redundant_pic_cnt_present_flag, 1);
+
+  /* A.2.1 Baseline profile, A.2.2 Main profile and
+     A.2.3 Extended profile:
+     The syntax elements transform_8x8_mode_flag,
+     pic_scaling_matrix_present_flag, second_chroma_qp_index_offset
+     shall not be present in picture parameter sets. */
+  if (pps->sequence->profile_idc == 66 ||
+      pps->sequence->profile_idc == 77 || pps->sequence->profile_idc == 88)
+    return TRUE;
+
+  WRITE_BITS (bw, pps->transform_8x8_mode_flag, 1);
+
+  WRITE_BITS (bw, pps->pic_scaling_matrix_present_flag, 1);
+
+  if (pps->pic_scaling_matrix_present_flag) {
+    guint8 n_lists;
+
+    n_lists = 6 + ((pps->sequence->chroma_format_idc != 3) ? 2 : 6) *
+        pps->transform_8x8_mode_flag;
+
+    if (pps->sequence->scaling_matrix_present_flag) {
+      if (!_h264_bit_writer_scaling_list (bw, &have_space,
+              pps->scaling_lists_4x4, pps->scaling_lists_8x8,
+              pps->sequence->scaling_lists_4x4[3],
+              pps->sequence->scaling_lists_4x4[0],
+              pps->sequence->scaling_lists_8x8[3],
+              pps->sequence->scaling_lists_8x8[0], n_lists))
+        goto error;
+    } else {
+      if (!_h264_bit_writer_scaling_list (bw, &have_space,
+              pps->scaling_lists_4x4, pps->scaling_lists_8x8,
+              default_4x4_inter, default_4x4_intra,
+              default_8x8_inter, default_8x8_intra, n_lists))
+        goto error;
+    }
+  }
+
+  WRITE_SE_RANGE (bw, ((gint) pps->second_chroma_qp_index_offset), -12, 12);
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write pps");
+
+  *space = have_space;
+  return FALSE;
+}
+
+/**
+ * gst_h264_bit_writer_pps:
+ * @pps: the pps of #GstH264PPS to write
+ * @start_code: whether adding the nal start code
+ * @data: (out): the bit stream generated by the pps
+ * @size: (inout): the size in bytes of the input and output
+ *
+ * Generating the according h264 bit stream by providing the pps.
+ *
+ * Returns: a #GstH264BitWriterResult
+ *
+ * Since: 1.22
+ **/
+GstH264BitWriterResult
+gst_h264_bit_writer_pps (const GstH264PPS * pps, gboolean start_code,
+    guint8 * data, guint * size)
+{
+  gboolean have_space = TRUE;
+  GstBitWriter bw;
+
+  g_return_val_if_fail (pps != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (pps->sequence != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (data != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (size != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (*size > 0, GST_H264_BIT_WRITER_ERROR);
+
+  gst_bit_writer_init_with_data (&bw, data, *size, FALSE);
+
+  if (start_code)
+    WRITE_BITS (&bw, 0x00000001, 32);
+
+  /* nal header */
+  /* forbidden_zero_bit */
+  WRITE_BITS (&bw, 0, 1);
+  /* nal_ref_idc */
+  WRITE_BITS (&bw, 1, 2);
+  /* nal_unit_type */
+  WRITE_BITS (&bw, GST_H264_NAL_PPS, 5);
+
+  if (!_h264_bit_writer_pps (pps, &bw, &have_space))
+    goto error;
+
+  /* Add trailings. */
+  WRITE_BITS (&bw, 1, 1);
+  if (!gst_bit_writer_align_bytes (&bw, 0)) {
+    have_space = FALSE;
+    goto error;
+  }
+
+  *size = (gst_bit_writer_get_size (&bw)) / 8;
+  gst_bit_writer_reset (&bw);
+  return GST_H264_BIT_WRITER_OK;
+
+error:
+  gst_bit_writer_reset (&bw);
+  *size = 0;
+
+  return have_space ? GST_H264_BIT_WRITER_INVALID_DATA :
+      GST_H264_BIT_WRITER_NO_MORE_SPACE;
+}
+
+static gboolean
+_h264_slice_bit_writer_ref_pic_list_modification_1 (const GstH264SliceHdr *
+    slice, guint list, gboolean is_mvc, GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+  const GstH264RefPicListModification *entries;
+  guint8 ref_pic_list_modification_flag = 0;
+  guint i;
+
+  if (list == 0) {
+    entries = slice->ref_pic_list_modification_l0;
+    ref_pic_list_modification_flag = slice->ref_pic_list_modification_flag_l0;
+  } else {
+    entries = slice->ref_pic_list_modification_l1;
+    ref_pic_list_modification_flag = slice->ref_pic_list_modification_flag_l1;
+  }
+
+  WRITE_BITS (bw, ref_pic_list_modification_flag, 1);
+  if (ref_pic_list_modification_flag) {
+    i = 0;
+    do {
+      g_assert (i < 32);
+
+      WRITE_UE (bw, entries[i].modification_of_pic_nums_idc);
+      if (entries[i].modification_of_pic_nums_idc == 0 ||
+          entries[i].modification_of_pic_nums_idc == 1) {
+        WRITE_UE_MAX (bw, entries[i].value.abs_diff_pic_num_minus1,
+            slice->max_pic_num - 1);
+      } else if (entries[i].modification_of_pic_nums_idc == 2) {
+        WRITE_UE (bw, entries[i].value.long_term_pic_num);
+      } else if (is_mvc && (entries[i].modification_of_pic_nums_idc == 4 ||
+              entries[i].modification_of_pic_nums_idc == 5)) {
+        WRITE_UE (bw, entries[i].value.abs_diff_view_idx_minus1);
+      }
+    } while (entries[i++].modification_of_pic_nums_idc != 3);
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write \"Reference picture list %u modification\"",
+      list);
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h264_slice_bit_writer_ref_pic_list_modification (const GstH264SliceHdr *
+    slice, gboolean is_mvc, GstBitWriter * bw, gboolean * space)
+{
+  if (!GST_H264_IS_I_SLICE (slice) && !GST_H264_IS_SI_SLICE (slice)) {
+    if (!_h264_slice_bit_writer_ref_pic_list_modification_1 (slice, 0,
+            is_mvc, bw, space))
+      return FALSE;
+  }
+
+  if (GST_H264_IS_B_SLICE (slice)) {
+    if (!_h264_slice_bit_writer_ref_pic_list_modification_1 (slice, 1,
+            is_mvc, bw, space))
+      return FALSE;
+  }
+
+  *space = TRUE;
+  return TRUE;
+}
+
+static gboolean
+_h264_slice_bit_writer_pred_weight_table (const GstH264SliceHdr * slice,
+    guint8 chroma_array_type, GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+  const GstH264PredWeightTable *p;
+  gint i;
+  gint16 default_luma_weight, default_chroma_weight;
+
+  GST_DEBUG ("writing \"Prediction weight table\"");
+
+  p = &slice->pred_weight_table;
+  default_luma_weight = 1 << p->luma_log2_weight_denom;
+  default_chroma_weight = 1 << p->chroma_log2_weight_denom;
+
+  WRITE_UE_MAX (bw, p->luma_log2_weight_denom, 7);
+
+  if (chroma_array_type != 0)
+    WRITE_UE_MAX (bw, p->chroma_log2_weight_denom, 7);
+
+  for (i = 0; i <= slice->num_ref_idx_l0_active_minus1; i++) {
+    guint8 luma_weight_l0_flag = 0;
+
+    if (p->luma_weight_l0[i] != default_luma_weight ||
+        p->luma_offset_l0[i] != 0)
+      luma_weight_l0_flag = 1;
+
+    WRITE_BITS (bw, luma_weight_l0_flag, 1);
+    if (luma_weight_l0_flag) {
+      WRITE_SE_RANGE (bw, p->luma_weight_l0[i], -128, 127);
+      WRITE_SE_RANGE (bw, p->luma_offset_l0[i], -128, 127);
+    }
+    if (chroma_array_type != 0) {
+      guint8 chroma_weight_l0_flag = 0;
+      gint j;
+
+      for (j = 0; j < 2; j++) {
+        if (p->chroma_weight_l0[i][j] != default_chroma_weight ||
+            p->chroma_offset_l0[i][j] != 0)
+          chroma_weight_l0_flag = 1;
+      }
+
+      WRITE_BITS (bw, chroma_weight_l0_flag, 1);
+      if (chroma_weight_l0_flag) {
+        for (j = 0; j < 2; j++) {
+          WRITE_SE_RANGE (bw, p->chroma_weight_l0[i][j], -128, 127);
+          WRITE_SE_RANGE (bw, p->chroma_offset_l0[i][j], -128, 127);
+        }
+      }
+    }
+  }
+
+  if (GST_H264_IS_B_SLICE (slice)) {
+    for (i = 0; i <= slice->num_ref_idx_l1_active_minus1; i++) {
+      guint8 luma_weight_l1_flag = 0;
+
+      if (p->luma_weight_l1[i] != default_luma_weight ||
+          p->luma_offset_l1[i] != 0)
+        luma_weight_l1_flag = 1;
+
+      WRITE_BITS (bw, luma_weight_l1_flag, 1);
+      if (luma_weight_l1_flag) {
+        WRITE_SE_RANGE (bw, p->luma_weight_l1[i], -128, 127);
+        WRITE_SE_RANGE (bw, p->luma_offset_l1[i], -128, 127);
+      }
+      if (chroma_array_type != 0) {
+        guint8 chroma_weight_l1_flag = 0;
+        gint j;
+
+        for (j = 0; j < 2; j++) {
+          if (p->chroma_weight_l1[i][j] != default_chroma_weight ||
+              p->chroma_offset_l1[i][j] != 0)
+            chroma_weight_l1_flag = 1;
+        }
+
+        WRITE_BITS (bw, chroma_weight_l1_flag, 1);
+        if (chroma_weight_l1_flag) {
+          for (j = 0; j < 2; j++) {
+            WRITE_SE_RANGE (bw, p->chroma_weight_l1[i][j], -128, 127);
+            WRITE_SE_RANGE (bw, p->chroma_offset_l1[i][j], -128, 127);
+          }
+        }
+      }
+    }
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write \"Prediction weight table\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h264_bit_writer_slice_dec_ref_pic_marking (const GstH264SliceHdr * slice,
+    guint32 nal_type, GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+
+  GST_DEBUG ("writing \"Dec Ref Pic Marking\"");
+
+  if (nal_type == GST_H264_NAL_SLICE_IDR) {
+    WRITE_BITS (bw, slice->dec_ref_pic_marking.no_output_of_prior_pics_flag, 1);
+    WRITE_BITS (bw, slice->dec_ref_pic_marking.long_term_reference_flag, 1);
+  } else {
+    WRITE_BITS (bw,
+        slice->dec_ref_pic_marking.adaptive_ref_pic_marking_mode_flag, 1);
+
+    if (slice->dec_ref_pic_marking.adaptive_ref_pic_marking_mode_flag) {
+      const GstH264RefPicMarking *refpicmarking;
+      guint i;
+
+      for (i = 0; i < slice->dec_ref_pic_marking.n_ref_pic_marking; i++) {
+        refpicmarking = &slice->dec_ref_pic_marking.ref_pic_marking[i];
+
+        WRITE_UE_MAX (bw,
+            refpicmarking->memory_management_control_operation, 6);
+
+        if (refpicmarking->memory_management_control_operation == 0)
+          break;
+
+        if (refpicmarking->memory_management_control_operation == 1
+            || refpicmarking->memory_management_control_operation == 3)
+          WRITE_UE (bw, refpicmarking->difference_of_pic_nums_minus1);
+
+        if (refpicmarking->memory_management_control_operation == 2)
+          WRITE_UE (bw, refpicmarking->long_term_pic_num);
+
+        if (refpicmarking->memory_management_control_operation == 3
+            || refpicmarking->memory_management_control_operation == 6)
+          WRITE_UE (bw, refpicmarking->long_term_frame_idx);
+
+        if (refpicmarking->memory_management_control_operation == 4)
+          WRITE_UE (bw, refpicmarking->max_long_term_frame_idx_plus1);
+      }
+    }
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write \"Dec Ref Pic Marking\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h264_bit_writer_slice_hdr (const GstH264SliceHdr * slice, guint32 nal_type,
+    guint32 ext_type, gboolean is_ref, GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+
+  GST_DEBUG ("writing slice header");
+
+  WRITE_UE (bw, slice->first_mb_in_slice);
+  WRITE_UE (bw, slice->type);
+
+  WRITE_UE_MAX (bw, slice->pps->id, GST_H264_MAX_PPS_COUNT - 1);
+
+  if (slice->pps->sequence->separate_colour_plane_flag)
+    WRITE_BITS (bw, slice->colour_plane_id, 2);
+
+  WRITE_BITS (bw, slice->frame_num,
+      slice->pps->sequence->log2_max_frame_num_minus4 + 4);
+
+  if (!slice->pps->sequence->frame_mbs_only_flag) {
+    WRITE_BITS (bw, slice->field_pic_flag, 1);
+    if (slice->field_pic_flag)
+      WRITE_BITS (bw, slice->bottom_field_flag, 1);
+  }
+
+  if (nal_type == GST_H264_NAL_SLICE_IDR)
+    WRITE_UE_MAX (bw, slice->idr_pic_id, G_MAXUINT16);
+
+  if (slice->pps->sequence->pic_order_cnt_type == 0) {
+    WRITE_BITS (bw, slice->pic_order_cnt_lsb,
+        slice->pps->sequence->log2_max_pic_order_cnt_lsb_minus4 + 4);
+
+    if (slice->pps->pic_order_present_flag && !slice->field_pic_flag)
+      WRITE_SE (bw, slice->delta_pic_order_cnt_bottom);
+  }
+
+  if (slice->pps->sequence->pic_order_cnt_type == 1
+      && !slice->pps->sequence->delta_pic_order_always_zero_flag) {
+    WRITE_SE (bw, slice->delta_pic_order_cnt[0]);
+    if (slice->pps->pic_order_present_flag && !slice->field_pic_flag)
+      WRITE_SE (bw, slice->delta_pic_order_cnt[1]);
+  }
+
+  if (slice->pps->redundant_pic_cnt_present_flag)
+    WRITE_UE_MAX (bw, slice->redundant_pic_cnt, G_MAXINT8);
+
+  if (GST_H264_IS_B_SLICE (slice))
+    WRITE_BITS (bw, slice->direct_spatial_mv_pred_flag, 1);
+
+  if (GST_H264_IS_P_SLICE (slice) || GST_H264_IS_SP_SLICE (slice) ||
+      GST_H264_IS_B_SLICE (slice)) {
+    WRITE_BITS (bw, slice->num_ref_idx_active_override_flag, 1);
+    if (slice->num_ref_idx_active_override_flag) {
+      WRITE_UE_MAX (bw, slice->num_ref_idx_l0_active_minus1, 31);
+
+      if (GST_H264_IS_B_SLICE (slice))
+        WRITE_UE_MAX (bw, slice->num_ref_idx_l1_active_minus1, 31);
+    }
+  }
+
+  if (!_h264_slice_bit_writer_ref_pic_list_modification (slice,
+          ext_type == GST_H264_NAL_EXTENSION_MVC, bw, &have_space))
+    goto error;
+
+  if ((slice->pps->weighted_pred_flag && (GST_H264_IS_P_SLICE (slice)
+              || GST_H264_IS_SP_SLICE (slice)))
+      || (slice->pps->weighted_bipred_idc == 1 && GST_H264_IS_B_SLICE (slice))) {
+    if (!_h264_slice_bit_writer_pred_weight_table (slice,
+            slice->pps->sequence->chroma_array_type, bw, &have_space))
+      goto error;
+  }
+
+  if (is_ref) {
+    if (!_h264_bit_writer_slice_dec_ref_pic_marking (slice, nal_type, bw,
+            &have_space))
+      goto error;
+  }
+
+  if (slice->pps->entropy_coding_mode_flag && !GST_H264_IS_I_SLICE (slice) &&
+      !GST_H264_IS_SI_SLICE (slice))
+    WRITE_UE_MAX (bw, slice->cabac_init_idc, 2);
+
+  WRITE_SE_RANGE (bw, slice->slice_qp_delta, -87, 77);
+
+  if (GST_H264_IS_SP_SLICE (slice) || GST_H264_IS_SI_SLICE (slice)) {
+    if (GST_H264_IS_SP_SLICE (slice))
+      WRITE_BITS (bw, slice->sp_for_switch_flag, 1);
+
+    WRITE_SE_RANGE (bw, slice->slice_qs_delta, -51, 51);
+  }
+
+  if (slice->pps->deblocking_filter_control_present_flag) {
+    WRITE_UE_MAX (bw, slice->disable_deblocking_filter_idc, 2);
+    if (slice->disable_deblocking_filter_idc != 1) {
+      WRITE_SE_RANGE (bw, slice->slice_alpha_c0_offset_div2, -6, 6);
+      WRITE_SE_RANGE (bw, slice->slice_beta_offset_div2, -6, 6);
+    }
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write slice header");
+
+  *space = have_space;
+  return FALSE;
+}
+
+/**
+ * gst_h264_bit_writer_slice_hdr:
+ * @slice: the slice header of #GstH264SliceHdr to write
+ * @start_code: whether adding the nal start code
+ * @nal_type: the slice's nal type of #GstH264NalUnitType
+ * @is_ref: whether the slice is a reference
+ * @data: (out): the bit stream generated by the slice header
+ * @size: (inout): the size in bytes of the input and output
+ * @trail_bits_num: (out): the trail bits number which is not byte aligned.
+ *
+ * Generating the according h264 bit stream by providing the slice header.
+ *
+ * Returns: a #GstH264BitWriterResult
+ *
+ * Since: 1.22
+ **/
+GstH264BitWriterResult
+gst_h264_bit_writer_slice_hdr (const GstH264SliceHdr * slice,
+    gboolean start_code, GstH264NalUnitType nal_type, gboolean is_ref,
+    guint8 * data, guint * size, guint * trail_bits_num)
+{
+  gboolean have_space = TRUE;
+  GstBitWriter bw;
+
+  g_return_val_if_fail (slice != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (slice->pps != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (slice->pps->sequence != NULL,
+      GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (nal_type >= GST_H264_NAL_SLICE
+      && nal_type <= GST_H264_NAL_SLICE_IDR, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (data != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (size != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (*size > 0, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (trail_bits_num != NULL, GST_H264_BIT_WRITER_ERROR);
+
+  if (nal_type == GST_H264_NAL_SLICE_IDR)
+    g_return_val_if_fail (is_ref, GST_H264_BIT_WRITER_ERROR);
+
+  gst_bit_writer_init_with_data (&bw, data, *size, FALSE);
+
+  if (start_code)
+    WRITE_BITS (&bw, 0x00000001, 32);
+
+  /* nal header */
+  /* forbidden_zero_bit */
+  WRITE_BITS (&bw, 0, 1);
+  /* nal_ref_idc, zero for non-reference picture */
+  WRITE_BITS (&bw, is_ref, 2);
+  /* nal_unit_type */
+  WRITE_BITS (&bw, nal_type, 5);
+
+  if (!_h264_bit_writer_slice_hdr (slice, nal_type,
+          GST_H264_NAL_EXTENSION_NONE, is_ref, &bw, &have_space))
+    goto error;
+
+  /* We do not add trailing bits here, the slice data should follow it. */
+
+  *size = gst_bit_writer_get_size (&bw) / 8;
+  *trail_bits_num = gst_bit_writer_get_size (&bw) % 8;
+  gst_bit_writer_reset (&bw);
+  return GST_H264_BIT_WRITER_OK;
+
+error:
+  gst_bit_writer_reset (&bw);
+  *size = 0;
+
+  return have_space ? GST_H264_BIT_WRITER_INVALID_DATA :
+      GST_H264_BIT_WRITER_NO_MORE_SPACE;
+}
+
+static gboolean
+_h264_bit_writer_sei_registered_user_data (const GstH264RegisteredUserData *
+    rud, GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+
+  GST_DEBUG ("Writing \"Registered user data\"");
+
+  WRITE_BITS (bw, rud->country_code, 8);
+  if (rud->country_code == 0xff)
+    WRITE_BITS (bw, rud->country_code_extension, 8);
+
+  WRITE_BYTES (bw, rud->data, rud->size);
+
+  *space = TRUE;
+  return TRUE;
+
+error:GST_WARNING ("Failed to write \"Registered user data\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h264_bit_writer_sei_frame_packing (const GstH264FramePacking *
+    frame_packing, GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+
+  GST_DEBUG ("Writing \"Frame packing\"");
+
+  WRITE_UE (bw, frame_packing->frame_packing_id);
+  WRITE_BITS (bw, frame_packing->frame_packing_cancel_flag, 1);
+
+  if (!frame_packing->frame_packing_cancel_flag) {
+    WRITE_BITS (bw, frame_packing->frame_packing_type, 7);
+    WRITE_BITS (bw, frame_packing->quincunx_sampling_flag, 1);
+    WRITE_BITS (bw, frame_packing->content_interpretation_type, 6);
+    WRITE_BITS (bw, frame_packing->spatial_flipping_flag, 1);
+    WRITE_BITS (bw, frame_packing->frame0_flipped_flag, 1);
+    WRITE_BITS (bw, frame_packing->field_views_flag, 1);
+    WRITE_BITS (bw, frame_packing->current_frame_is_frame0_flag, 1);
+    WRITE_BITS (bw, frame_packing->frame0_self_contained_flag, 1);
+    WRITE_BITS (bw, frame_packing->frame1_self_contained_flag, 1);
+
+    if (!frame_packing->quincunx_sampling_flag &&
+        frame_packing->frame_packing_type !=
+        GST_H264_FRAME_PACKING_TEMPORAL_INTERLEAVING) {
+      WRITE_BITS (bw, frame_packing->frame0_grid_position_x, 4);
+      WRITE_BITS (bw, frame_packing->frame0_grid_position_y, 4);
+      WRITE_BITS (bw, frame_packing->frame1_grid_position_x, 4);
+      WRITE_BITS (bw, frame_packing->frame1_grid_position_y, 4);
+    }
+
+    /* frame_packing_arrangement_reserved_byte */
+    WRITE_BITS (bw, 0, 8);
+    WRITE_UE (bw, frame_packing->frame_packing_repetition_period);
+  }
+
+  /* frame_packing_arrangement_extension_flag */
+  WRITE_BITS (bw, 0, 1);
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("Failed to write \"Frame packing\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h264_bit_writer_sei_mastering_display_colour_volume (const
+    GstH264MasteringDisplayColourVolume * mdcv, GstBitWriter * bw,
+    gboolean * space)
+{
+  gboolean have_space = TRUE;
+  gint i;
+
+  GST_DEBUG ("Wrtiting \"Mastering display colour volume\"");
+
+  for (i = 0; i < 3; i++) {
+    WRITE_BITS (bw, mdcv->display_primaries_x[i], 16);
+    WRITE_BITS (bw, mdcv->display_primaries_y[i], 16);
+  }
+
+  WRITE_BITS (bw, mdcv->white_point_x, 16);
+  WRITE_BITS (bw, mdcv->white_point_y, 16);
+  WRITE_BITS (bw, mdcv->max_display_mastering_luminance, 32);
+  WRITE_BITS (bw, mdcv->min_display_mastering_luminance, 32);
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("Failed to write \"Mastering display colour volume\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h264_bit_writer_sei_content_light_level_info (const
+    GstH264ContentLightLevel * cll, GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+
+  GST_DEBUG ("Writing \"Content light level\"");
+
+  WRITE_BITS (bw, cll->max_content_light_level, 16);
+  WRITE_BITS (bw, cll->max_pic_average_light_level, 16);
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("Failed to write \"Content light level\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h264_bit_writer_sei_pic_timing (const GstH264PicTiming * tim,
+    GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+
+  GST_DEBUG ("Writing \"Picture timing\"");
+
+  if (tim->CpbDpbDelaysPresentFlag) {
+    WRITE_BITS (bw, tim->cpb_removal_delay,
+        tim->cpb_removal_delay_length_minus1 + 1);
+    WRITE_BITS (bw, tim->dpb_output_delay,
+        tim->dpb_output_delay_length_minus1 + 1);
+  }
+
+  if (tim->pic_struct_present_flag) {
+    const guint8 num_clock_ts_table[9] = {
+      1, 1, 1, 2, 2, 3, 3, 2, 3
+    };
+    guint8 num_clock_num_ts;
+    guint i;
+
+    WRITE_BITS (bw, tim->pic_struct, 4);
+
+    num_clock_num_ts = num_clock_ts_table[tim->pic_struct];
+    for (i = 0; i < num_clock_num_ts; i++) {
+      WRITE_BITS (bw, tim->clock_timestamp_flag[i], 1);
+      if (tim->clock_timestamp_flag[i]) {
+        const GstH264ClockTimestamp *timestamp = &tim->clock_timestamp[i];
+
+        WRITE_BITS (bw, timestamp->ct_type, 2);
+        WRITE_BITS (bw, timestamp->nuit_field_based_flag, 1);
+        WRITE_BITS (bw, timestamp->counting_type, 5);
+        WRITE_BITS (bw, timestamp->full_timestamp_flag, 1);
+        WRITE_BITS (bw, timestamp->discontinuity_flag, 1);
+        WRITE_BITS (bw, timestamp->cnt_dropped_flag, 1);
+        WRITE_BITS (bw, timestamp->n_frames, 8);
+
+        if (timestamp->full_timestamp_flag) {
+          if (!timestamp->seconds_flag || !timestamp->minutes_flag
+              || !timestamp->hours_flag)
+            goto error;
+
+          WRITE_BITS (bw, timestamp->seconds_value, 6);
+          WRITE_BITS (bw, timestamp->minutes_value, 6);
+          WRITE_BITS (bw, timestamp->hours_value, 5);
+        } else {
+          WRITE_BITS (bw, timestamp->seconds_flag, 1);
+          if (timestamp->seconds_flag) {
+            WRITE_BITS (bw, timestamp->seconds_value, 6);
+            WRITE_BITS (bw, timestamp->minutes_flag, 1);
+            if (timestamp->minutes_flag) {
+              WRITE_BITS (bw, timestamp->minutes_value, 6);
+              WRITE_BITS (bw, timestamp->hours_flag, 1);
+              if (timestamp->hours_flag)
+                WRITE_BITS (bw, timestamp->hours_value, 5);
+            }
+          }
+        }
+
+        if (tim->time_offset_length > 0) {
+          WRITE_BITS (bw, timestamp->time_offset, tim->time_offset_length);
+        }
+      }
+    }
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("Failed to write \"Picture timing\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h264_bit_writer_sei_buffering_period (const GstH264BufferingPeriod * per,
+    GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+
+  GST_DEBUG ("Writing \"Buffering period\"");
+
+  if (!per->sps)
+    goto error;
+
+  WRITE_UE_MAX (bw, per->sps->id, GST_H264_MAX_SPS_COUNT - 1);
+
+  if (per->sps->vui_parameters_present_flag) {
+    GstH264VUIParams *vui = &per->sps->vui_parameters;
+
+    if (vui->nal_hrd_parameters_present_flag) {
+      GstH264HRDParams *hrd = &vui->nal_hrd_parameters;
+      const guint8 nbits = hrd->initial_cpb_removal_delay_length_minus1 + 1;
+      guint8 sched_sel_idx;
+
+      for (sched_sel_idx = 0; sched_sel_idx <= hrd->cpb_cnt_minus1;
+          sched_sel_idx++) {
+        WRITE_BITS (bw, per->nal_initial_cpb_removal_delay[sched_sel_idx],
+            nbits);
+        WRITE_BITS (bw,
+            per->nal_initial_cpb_removal_delay_offset[sched_sel_idx], nbits);
+      }
+    }
+
+    if (vui->vcl_hrd_parameters_present_flag) {
+      GstH264HRDParams *hrd = &vui->vcl_hrd_parameters;
+      const guint8 nbits = hrd->initial_cpb_removal_delay_length_minus1 + 1;
+      guint8 sched_sel_idx;
+
+      for (sched_sel_idx = 0; sched_sel_idx <= hrd->cpb_cnt_minus1;
+          sched_sel_idx++) {
+        WRITE_BITS (bw, per->vcl_initial_cpb_removal_delay[sched_sel_idx],
+            nbits);
+        WRITE_BITS (bw,
+            per->vcl_initial_cpb_removal_delay_offset[sched_sel_idx], nbits);
+      }
+    }
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("Failed to write \"Buffering period\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h264_bit_writer_sei_message (const GstH264SEIMessage * msg,
+    GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+
+  GST_DEBUG ("writing SEI message");
+
+  switch (msg->payloadType) {
+    case GST_H264_SEI_REGISTERED_USER_DATA:
+      if (!_h264_bit_writer_sei_registered_user_data
+          (&msg->payload.registered_user_data, bw, &have_space))
+        goto error;
+      break;
+    case GST_H264_SEI_FRAME_PACKING:
+      if (!_h264_bit_writer_sei_frame_packing
+          (&msg->payload.frame_packing, bw, &have_space))
+        goto error;
+      break;
+    case GST_H264_SEI_MASTERING_DISPLAY_COLOUR_VOLUME:
+      if (!_h264_bit_writer_sei_mastering_display_colour_volume
+          (&msg->payload.mastering_display_colour_volume, bw, &have_space))
+        goto error;
+      break;
+    case GST_H264_SEI_CONTENT_LIGHT_LEVEL:
+      if (!_h264_bit_writer_sei_content_light_level_info
+          (&msg->payload.content_light_level, bw, &have_space))
+        goto error;
+      break;
+    case GST_H264_SEI_PIC_TIMING:
+      if (!_h264_bit_writer_sei_pic_timing (&msg->payload.pic_timing, bw,
+              &have_space))
+        goto error;
+      break;
+    case GST_H264_SEI_BUF_PERIOD:
+      if (!_h264_bit_writer_sei_buffering_period
+          (&msg->payload.buffering_period, bw, &have_space))
+        goto error;
+      break;
+    default:
+      break;
+  }
+
+  /* Add trailings. */
+  WRITE_BITS (bw, 1, 1);
+  gst_bit_writer_align_bytes_unchecked (bw, 0);
+
+  *space = TRUE;
+
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write SEI message");
+
+  *space = have_space;
+  return FALSE;
+}
+
+/**
+ * gst_h264_bit_writer_sei:
+ * @sei_messages: An array of #GstH264SEIMessage to write
+ * @start_code: whether adding the nal start code
+ * @data: (out): the bit stream generated by the sei messages
+ * @size: (inout): the size in bytes of the input and output
+ *
+ * Generating the according h264 bit stream by providing sei messages.
+ *
+ * Returns: a #GstH264BitWriterResult
+ *
+ * Since: 1.22
+ **/
+GstH264BitWriterResult
+gst_h264_bit_writer_sei (GArray * sei_messages, gboolean start_code,
+    guint8 * data, guint * size)
+{
+  gboolean have_space = TRUE;
+  GstBitWriter bw;
+  GstBitWriter bw_msg;
+  GstH264SEIMessage *sei;
+  gboolean have_written_data = FALSE;
+  guint i;
+
+  g_return_val_if_fail (sei_messages != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (data != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (size != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (*size > 0, GST_H264_BIT_WRITER_ERROR);
+
+  gst_bit_writer_init_with_data (&bw, data, *size, FALSE);
+
+  if (start_code)
+    WRITE_BITS (&bw, 0x00000001, 32);
+
+  /* nal header */
+  /* forbidden_zero_bit */
+  WRITE_BITS (&bw, 0, 1);
+  /* nal_ref_idc, zero for sei nalu */
+  WRITE_BITS (&bw, 0, 2);
+  /* nal_unit_type */
+  WRITE_BITS (&bw, GST_H264_NAL_SEI, 5);
+
+  for (i = 0; i < sei_messages->len; i++) {
+    guint32 payload_size_data;
+    guint32 payload_type_data;
+    guint32 sz;
+
+    gst_bit_writer_init (&bw_msg);
+
+    sei = &g_array_index (sei_messages, GstH264SEIMessage, i);
+    if (!_h264_bit_writer_sei_message (sei, &bw_msg, &have_space))
+      goto error;
+
+    if (gst_bit_writer_get_size (&bw_msg) == 0) {
+      GST_FIXME ("Unsupported SEI type %d", sei->payloadType);
+      continue;
+    }
+
+    have_written_data = TRUE;
+
+    g_assert (gst_bit_writer_get_size (&bw_msg) % 8 == 0);
+    payload_size_data = gst_bit_writer_get_size (&bw_msg) / 8;
+    payload_type_data = sei->payloadType;
+
+    /* write payload type bytes */
+    while (payload_type_data >= 0xff) {
+      WRITE_BITS (&bw, 0xff, 8);
+      payload_type_data -= 0xff;
+    }
+    WRITE_BITS (&bw, payload_type_data, 8);
+
+    /* write payload size bytes */
+    sz = payload_size_data;
+    while (sz >= 0xff) {
+      WRITE_BITS (&bw, 0xff, 8);
+      sz -= 0xff;
+    }
+    WRITE_BITS (&bw, sz, 8);
+
+    if (payload_size_data > 0)
+      WRITE_BYTES (&bw, gst_bit_writer_get_data (&bw_msg), payload_size_data);
+
+    gst_bit_writer_reset (&bw_msg);
+  }
+
+  if (!have_written_data) {
+    GST_WARNING ("No written sei data");
+    goto error;
+  }
+
+  /* Add trailings. */
+  WRITE_BITS (&bw, 1, 1);
+  if (!gst_bit_writer_align_bytes (&bw, 0)) {
+    have_space = FALSE;
+    goto error;
+  }
+
+  *size = (gst_bit_writer_get_size (&bw)) / 8;
+  gst_bit_writer_reset (&bw);
+  return GST_H264_BIT_WRITER_OK;
+
+error:
+  gst_bit_writer_reset (&bw);
+  *size = 0;
+
+  return have_space ? GST_H264_BIT_WRITER_INVALID_DATA :
+      GST_H264_BIT_WRITER_NO_MORE_SPACE;
+}
+
+/**
+ * gst_h264_bit_writer_aud:
+ * @primary_pic_type: indicate the possible slice types list just
+ *   as the H264 spec defines
+ * @start_code: whether adding the nal start code
+ * @data: (out): the bit stream generated by the aud
+ * @size: (inout): the size in bytes of the input and output
+ *
+ * Generating the according h264 bit stream of an aud.
+ *
+ * Returns: a #GstH264BitWriterResult
+ *
+ * Since: 1.22
+ **/
+GstH264BitWriterResult
+gst_h264_bit_writer_aud (guint8 primary_pic_type, gboolean start_code,
+    guint8 * data, guint * size)
+{
+  gboolean have_space = TRUE;
+  GstBitWriter bw;
+
+  g_return_val_if_fail (primary_pic_type >= 0
+      && primary_pic_type <= 7, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (data != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (size != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (*size > 0, GST_H264_BIT_WRITER_ERROR);
+
+  gst_bit_writer_init_with_data (&bw, data, *size, FALSE);
+
+  if (start_code)
+    WRITE_BITS (&bw, 0x00000001, 32);
+
+  /* nal header */
+  /* forbidden_zero_bit */
+  WRITE_BITS (&bw, 0, 1);
+  /* nal_ref_idc */
+  WRITE_BITS (&bw, 0, 2);
+  /* nal_unit_type */
+  WRITE_BITS (&bw, GST_H264_NAL_AU_DELIMITER, 5);
+
+  WRITE_BITS (&bw, primary_pic_type, 3);
+
+  /* Add trailings. */
+  WRITE_BITS (&bw, 1, 1);
+  if (!gst_bit_writer_align_bytes (&bw, 0)) {
+    goto error;
+  }
+
+  *size = (gst_bit_writer_get_size (&bw)) / 8;
+  gst_bit_writer_reset (&bw);
+
+  return GST_H264_BIT_WRITER_OK;
+
+error:
+  gst_bit_writer_reset (&bw);
+  *size = 0;
+
+  return have_space ? GST_H264_BIT_WRITER_INVALID_DATA :
+      GST_H264_BIT_WRITER_NO_MORE_SPACE;
+}
+
+/**
+ * gst_h264_bit_writer_convert_to_nal:
+ * @nal_prefix_size: the size in bytes for the prefix of a nal, may
+ *   be 2, 3 or 4
+ * @packetized: whether to write the bit stream in packetized format,
+ *   which does not have the start code but has a @nal_prefix_size bytes'
+ *   size prepending to the real nal data
+ * @has_startcode: whether the input already has a start code
+ * @add_trailings: whether to add rbsp trailing bits to make the output
+ *   aligned to byte
+ * @raw_data: the input bit stream
+ * @raw_size: the size in bits of the input bit stream
+ * @nal_data: (out): the output bit stream converted to a real nal
+ * @nal_size: (inout): the size in bytes of the output
+ *
+ * Converting a bit stream into a real nal packet. If the bit stream already
+ * has a start code, it will be replaced by the new one specified by the
+ * @nal_prefix_size and @packetized. It is assured that the output aligns to
+ * the byte and the all the emulations are inserted.
+ *
+ * Returns: a #GstH264BitWriterResult
+ *
+ * Since: 1.22
+ **/
+GstH264BitWriterResult
+gst_h264_bit_writer_convert_to_nal (guint nal_prefix_size, gboolean packetized,
+    gboolean has_startcode, gboolean add_trailings, const guint8 * raw_data,
+    gsize raw_size, guint8 * nal_data, guint * nal_size)
+{
+  NalWriter nw;
+  guint8 *data;
+  guint32 size = 0;
+  gboolean need_more_space = FALSE;
+
+  g_return_val_if_fail (
+      (packetized && nal_prefix_size > 1 && nal_prefix_size < 5) ||
+      (!packetized && (nal_prefix_size == 3 || nal_prefix_size == 4)),
+      GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (raw_data != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (raw_size > 0, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (nal_data != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (nal_size != NULL, GST_H264_BIT_WRITER_ERROR);
+  g_return_val_if_fail (*nal_size > 0, GST_H264_BIT_WRITER_ERROR);
+
+  if (has_startcode) {
+    /* Skip the start code, the NalWriter will add it automatically. */
+    if (raw_size >= 4 && raw_data[0] == 0
+        && raw_data[1] == 0 && raw_data[2] == 0 && raw_data[3] == 0x01) {
+      raw_data += 4;
+      raw_size -= 4 * 8;
+    } else if (raw_size >= 3 && raw_data[0] == 0 && raw_data[1] == 0
+        && raw_data[2] == 0x01) {
+      raw_data += 3;
+      raw_size -= 3 * 8;
+    } else {
+      /* Fail to find the start code. */
+      g_return_val_if_reached (GST_H264_BIT_WRITER_ERROR);
+    }
+  }
+
+  /* If no RBSP trailing needed, it must align to byte. We assume
+     that the rbsp trailing bits are already added. */
+  if (!add_trailings)
+    g_return_val_if_fail (raw_size % 8 == 0, GST_H264_BIT_WRITER_ERROR);
+
+  nal_writer_init (&nw, nal_prefix_size, packetized);
+
+  if (!nal_writer_put_bytes (&nw, raw_data, raw_size / 8))
+    goto error;
+
+  if (raw_size % 8) {
+    guint8 data = *(raw_data + raw_size / 8);
+
+    if (!nal_writer_put_bits_uint8 (&nw,
+            data >> (8 - raw_size % 8), raw_size % 8))
+      goto error;
+  }
+
+  if (add_trailings) {
+    if (!nal_writer_do_rbsp_trailing_bits (&nw))
+      goto error;
+  }
+
+  data = nal_writer_reset_and_get_data (&nw, &size);
+  if (!data)
+    goto error;
+
+  if (size > *nal_size) {
+    need_more_space = TRUE;
+    g_free (data);
+    goto error;
+  }
+
+  memcpy (nal_data, data, size);
+  *nal_size = size;
+  g_free (data);
+  nal_writer_reset (&nw);
+  return GST_H264_BIT_WRITER_OK;
+
+error:
+  nal_writer_reset (&nw);
+  *nal_size = 0;
+
+  GST_WARNING ("Failed to convert nal data");
+
+  return need_more_space ? GST_H264_BIT_WRITER_INVALID_DATA :
+      GST_H264_BIT_WRITER_NO_MORE_SPACE;
+}
diff --git a/gst-libs/gst/codecparsers/gsth264bitwriter.h b/gst-libs/gst/codecparsers/gsth264bitwriter.h
new file mode 100644
index 000000000..67e526152
--- /dev/null
+++ b/gst-libs/gst/codecparsers/gsth264bitwriter.h
@@ -0,0 +1,88 @@
+/* GStreamer
+ *  Copyright (C) 2020 Intel Corporation
+ *     Author: He Junyan <junyan.he@intel.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the0
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef __GST_H264_BIT_WRITER_H__
+#define __GST_H264_BIT_WRITER_H__
+
+#include <gst/codecparsers/codecparsers-prelude.h>
+#include <gst/codecparsers/gsth264parser.h>
+
+G_BEGIN_DECLS
+
+/**
+ * GstH264BitWriterResult:
+ * @GST_H264_BIT_WRITER_OK: The writing succeeded
+ * @GST_H264_BIT_WRITER_INVALID_DATA: The input data to write is invalid
+ * @GST_H264_BIT_WRITER_NO_MORE_SPACE: The output does not have enough size
+ * @GST_H264_BIT_WRITER_ERROR: An general error occurred when writing
+ *
+ * The result of writing H264 data into bit stream.
+ *
+ * Since: 1.22
+ */
+typedef enum
+{
+  GST_H264_BIT_WRITER_OK,
+  GST_H264_BIT_WRITER_INVALID_DATA,
+  GST_H264_BIT_WRITER_NO_MORE_SPACE,
+  GST_H264_BIT_WRITER_ERROR
+} GstH264BitWriterResult;
+
+GST_CODEC_PARSERS_API
+GstH264BitWriterResult     gst_h264_bit_writer_sps       (const GstH264SPS * sps,
+                                                          gboolean start_code,
+                                                          guint8 * data,
+                                                          guint * size);
+GST_CODEC_PARSERS_API
+GstH264BitWriterResult     gst_h264_bit_writer_pps       (const GstH264PPS * pps,
+                                                          gboolean start_code,
+                                                          guint8 * data,
+                                                          guint * size);
+GST_CODEC_PARSERS_API
+GstH264BitWriterResult     gst_h264_bit_writer_slice_hdr (const GstH264SliceHdr * slice,
+                                                          gboolean start_code,
+                                                          GstH264NalUnitType nal_type,
+                                                          gboolean is_ref,
+                                                          guint8 * data,
+                                                          guint * size,
+                                                          guint * trail_bits_num);
+GST_CODEC_PARSERS_API
+GstH264BitWriterResult     gst_h264_bit_writer_sei       (GArray * sei_messages,
+                                                          gboolean start_code,
+                                                          guint8 * data,
+                                                          guint * size);
+GST_CODEC_PARSERS_API
+GstH264BitWriterResult     gst_h264_bit_writer_aud       (guint8 primary_pic_type,
+                                                          gboolean start_code,
+                                                          guint8 * data,
+                                                          guint * size);
+GST_CODEC_PARSERS_API
+GstH264BitWriterResult     gst_h264_bit_writer_convert_to_nal (guint nal_prefix_size,
+                                                               gboolean packetized,
+                                                               gboolean has_startcode,
+                                                               gboolean add_trailings,
+                                                               const guint8 * raw_data,
+                                                               gsize raw_size,
+                                                               guint8 * nal_data,
+                                                               guint * nal_size);
+
+G_END_DECLS
+
+#endif /* __GST_H264_BIT_WRITER_H__ */
diff --git a/gst-libs/gst/codecparsers/gsth264parser.c b/gst-libs/gst/codecparsers/gsth264parser.c
index 68aa25068..349d6d23b 100644
--- a/gst-libs/gst/codecparsers/gsth264parser.c
+++ b/gst-libs/gst/codecparsers/gsth264parser.c
@@ -271,7 +271,7 @@ gst_h264_pps_copy (GstH264PPS * dst_pps, const GstH264PPS * src_pps)
   *dst_pps = *src_pps;
 
   if (src_pps->slice_group_id)
-    dst_pps->slice_group_id = g_memdup (src_pps->slice_group_id,
+    dst_pps->slice_group_id = g_memdup2 (src_pps->slice_group_id,
         src_pps->pic_size_in_map_units_minus1 + 1);
 
   return TRUE;
@@ -704,11 +704,12 @@ gst_h264_slice_parse_dec_ref_pic_marking (GstH264SliceHdr * slice,
     GstH264NalUnit * nalu, NalReader * nr)
 {
   GstH264DecRefPicMarking *dec_ref_pic_m;
-  guint start_pos;
+  guint start_pos, start_epb;
 
   GST_DEBUG ("parsing \"Decoded reference picture marking\"");
 
   start_pos = nal_reader_get_pos (nr);
+  start_epb = nal_reader_get_epb_count (nr);
 
   dec_ref_pic_m = &slice->dec_ref_pic_marking;
 
@@ -723,7 +724,7 @@ gst_h264_slice_parse_dec_ref_pic_marking (GstH264SliceHdr * slice,
 
       dec_ref_pic_m->n_ref_pic_marking = 0;
       while (1) {
-        READ_UE (nr, mem_mgmt_ctrl_op);
+        READ_UE_MAX (nr, mem_mgmt_ctrl_op, 6);
         if (mem_mgmt_ctrl_op == 0)
           break;
 
@@ -753,7 +754,8 @@ gst_h264_slice_parse_dec_ref_pic_marking (GstH264SliceHdr * slice,
     }
   }
 
-  dec_ref_pic_m->bit_size = nal_reader_get_pos (nr) - start_pos;
+  dec_ref_pic_m->bit_size = (nal_reader_get_pos (nr) - start_pos) -
+      (8 * (nal_reader_get_epb_count (nr) - start_epb));
 
   return TRUE;
 
@@ -793,7 +795,7 @@ gst_h264_slice_parse_pred_weight_table (GstH264SliceHdr * slice,
       p->chroma_weight_l0[i][1] = default_chroma_weight;
     }
     if (GST_H264_IS_B_SLICE (slice)) {
-      for (i = 0; i <= slice->num_ref_idx_l0_active_minus1; i++) {
+      for (i = 0; i <= slice->num_ref_idx_l1_active_minus1; i++) {
         p->chroma_weight_l1[i][0] = default_chroma_weight;
         p->chroma_weight_l1[i][1] = default_chroma_weight;
       }
@@ -1086,6 +1088,48 @@ error:
   }
 }
 
+static GstH264ParserResult
+gst_h264_parser_parse_user_data_unregistered (GstH264NalParser * nalparser,
+    GstH264UserDataUnregistered * urud, NalReader * nr, guint payload_size)
+{
+  guint8 *data = NULL;
+  gint i;
+
+  if (payload_size < 16) {
+    GST_WARNING ("Too small payload size %d", payload_size);
+    return GST_H264_PARSER_BROKEN_DATA;
+  }
+
+  for (int i = 0; i < 16; i++) {
+    READ_UINT8 (nr, urud->uuid[i], 8);
+    --payload_size;
+  }
+
+  urud->size = payload_size;
+
+  data = g_malloc0 (payload_size);
+  for (i = 0; i < payload_size; ++i) {
+    READ_UINT8 (nr, data[i], 8);
+  }
+
+  if (payload_size < 1) {
+    GST_WARNING ("No more remaining payload data to store");
+    g_clear_pointer (&data, g_free);
+    return GST_H264_PARSER_BROKEN_DATA;
+  }
+
+  urud->data = data;
+  GST_MEMDUMP ("SEI user data unregistered", data, payload_size);
+  return GST_H264_PARSER_OK;
+
+error:
+  {
+    GST_WARNING ("error parsing \"User Data Unregistered\"");
+    g_clear_pointer (&data, g_free);
+    return GST_H264_PARSER_ERROR;
+  }
+}
+
 static GstH264ParserResult
 gst_h264_parser_parse_recovery_point (GstH264NalParser * nalparser,
     GstH264RecoveryPoint * rp, NalReader * nr)
@@ -1308,6 +1352,10 @@ gst_h264_parser_parse_sei_message (GstH264NalParser * nalparser,
       res = gst_h264_parser_parse_registered_user_data (nalparser,
           &sei->payload.registered_user_data, nr, payload_size >> 3);
       break;
+    case GST_H264_SEI_USER_DATA_UNREGISTERED:
+      res = gst_h264_parser_parse_user_data_unregistered (nalparser,
+          &sei->payload.user_data_unregistered, nr, payload_size >> 3);
+      break;
     case GST_H264_SEI_RECOVERY_POINT:
       res = gst_h264_parser_parse_recovery_point (nalparser,
           &sei->payload.recovery_point, nr);
@@ -2228,7 +2276,7 @@ gst_h264_parser_parse_slice_hdr (GstH264NalParser * nalparser,
   gint pps_id;
   GstH264PPS *pps;
   GstH264SPS *sps;
-  guint start_pos;
+  guint start_pos, start_epb;
 
   memset (slice, 0, sizeof (*slice));
 
@@ -2304,6 +2352,7 @@ gst_h264_parser_parse_slice_hdr (GstH264NalParser * nalparser,
     READ_UE_MAX (&nr, slice->idr_pic_id, G_MAXUINT16);
 
   start_pos = nal_reader_get_pos (&nr);
+  start_epb = nal_reader_get_epb_count (&nr);
 
   if (sps->pic_order_cnt_type == 0) {
     READ_UINT16 (&nr, slice->pic_order_cnt_lsb,
@@ -2319,7 +2368,8 @@ gst_h264_parser_parse_slice_hdr (GstH264NalParser * nalparser,
       READ_SE (&nr, slice->delta_pic_order_cnt[1]);
   }
 
-  slice->pic_order_cnt_bit_size = nal_reader_get_pos (&nr) - start_pos;
+  slice->pic_order_cnt_bit_size = (nal_reader_get_pos (&nr) - start_pos) -
+      (8 * (nal_reader_get_epb_count (&nr) - start_epb));
 
   if (pps->redundant_pic_cnt_present_flag)
     READ_UE_MAX (&nr, slice->redundant_pic_cnt, G_MAXINT8);
@@ -2465,6 +2515,13 @@ gst_h264_sei_clear (GstH264SEIMessage * sei)
       rud->data = NULL;
       break;
     }
+    case GST_H264_SEI_USER_DATA_UNREGISTERED:{
+      GstH264UserDataUnregistered *udu = &sei->payload.user_data_unregistered;
+
+      g_free ((guint8 *) udu->data);
+      udu->data = NULL;
+      break;
+    }
     case GST_H264_SEI_UNHANDLED_PAYLOAD:{
       GstH264SEIUnhandledPayload *payload = &sei->payload.unhandled_payload;
 
@@ -3138,14 +3195,14 @@ gst_h264_create_sei_memory_internal (guint8 nal_prefix_size,
     /* write payload type bytes */
     while (payload_type_data >= 0xff) {
       WRITE_UINT8 (&nw, 0xff, 8);
-      payload_type_data -= -0xff;
+      payload_type_data -= 0xff;
     }
     WRITE_UINT8 (&nw, payload_type_data, 8);
 
     /* write payload size bytes */
     while (payload_size_data >= 0xff) {
       WRITE_UINT8 (&nw, 0xff, 8);
-      payload_size_data -= -0xff;
+      payload_size_data -= 0xff;
     }
     WRITE_UINT8 (&nw, payload_size_data, 8);
 
@@ -3169,7 +3226,7 @@ gst_h264_create_sei_memory_internal (guint8 nal_prefix_size,
         have_written_data = TRUE;
         break;
       case GST_H264_SEI_MASTERING_DISPLAY_COLOUR_VOLUME:
-        GST_DEBUG ("Wrtiting \"Mastering display colour volume\"");
+        GST_DEBUG ("Writing \"Mastering display colour volume\"");
         if (!gst_h264_write_sei_mastering_display_colour_volume (&nw,
                 &msg->payload.mastering_display_colour_volume)) {
           GST_WARNING ("Failed to write \"Mastering display colour volume\"");
@@ -3406,3 +3463,229 @@ gst_h264_parser_insert_sei_avc (GstH264NalParser * nalparser,
   return gst_h264_parser_insert_sei_internal (nalparser, nal_length_size, TRUE,
       au, sei);
 }
+
+static GstH264DecoderConfigRecord *
+gst_h264_decoder_config_record_new (void)
+{
+  GstH264DecoderConfigRecord *config;
+
+  config = g_new0 (GstH264DecoderConfigRecord, 1);
+  config->sps = g_array_new (FALSE, FALSE, sizeof (GstH264NalUnit));
+  config->pps = g_array_new (FALSE, FALSE, sizeof (GstH264NalUnit));
+  config->sps_ext = g_array_new (FALSE, FALSE, sizeof (GstH264NalUnit));
+
+  return config;
+}
+
+/**
+ * gst_h264_decoder_config_record_free:
+ * @config: (nullable): a #GstH264DecoderConfigRecord data
+ *
+ * Free @config data
+ *
+ * Since: 1.22
+ */
+void
+gst_h264_decoder_config_record_free (GstH264DecoderConfigRecord * config)
+{
+  if (!config)
+    return;
+
+  if (config->sps)
+    g_array_unref (config->sps);
+
+  if (config->pps)
+    g_array_unref (config->pps);
+
+  if (config->sps_ext)
+    g_array_unref (config->sps_ext);
+
+  g_free (config);
+}
+
+/**
+ * gst_h264_parser_parse_decoder_config_record:
+ * @nalparser: a #GstH264NalParser
+ * @data: the data to parse
+ * @size: the size of @data
+ * @config: (out): parsed #GstH264DecoderConfigRecord data
+ *
+ * Parses AVCDecoderConfigurationRecord data and fill into @config.
+ * The caller must free @config via gst_h264_decoder_config_record_free()
+ *
+ * This method does not parse SPS and PPS and therefore the caller needs to
+ * parse each NAL unit via appropriate parsing method.
+ *
+ * Returns: a #GstH264ParserResult
+ *
+ * Since: 1.22
+ */
+GstH264ParserResult
+gst_h264_parser_parse_decoder_config_record (GstH264NalParser * nalparser,
+    const guint8 * data, gsize size, GstH264DecoderConfigRecord ** config)
+{
+  GstH264DecoderConfigRecord *ret;
+  GstBitReader br;
+  GstH264ParserResult result = GST_H264_PARSER_OK;
+  guint8 num_sps, num_pps, i;
+  guint offset;
+
+  g_return_val_if_fail (nalparser != NULL, GST_H264_PARSER_ERROR);
+  g_return_val_if_fail (data != NULL, GST_H264_PARSER_ERROR);
+  g_return_val_if_fail (config != NULL, GST_H264_PARSER_ERROR);
+
+#define READ_CONFIG_UINT8(val, nbits) G_STMT_START { \
+  if (!gst_bit_reader_get_bits_uint8 (&br, &val, nbits)) { \
+    GST_WARNING ("Failed to read " G_STRINGIFY (val)); \
+    result = GST_H264_PARSER_ERROR; \
+    goto error; \
+  } \
+} G_STMT_END;
+
+#define SKIP_CONFIG_BITS(nbits) G_STMT_START { \
+  if (!gst_bit_reader_skip (&br, nbits)) { \
+    GST_WARNING ("Failed to skip %d bits", nbits); \
+    result = GST_H264_PARSER_ERROR; \
+    goto error; \
+  } \
+} G_STMT_END;
+
+  *config = NULL;
+
+  if (size < 7) {
+    GST_WARNING ("Too small size avcC");
+    return GST_H264_PARSER_ERROR;
+  }
+
+  gst_bit_reader_init (&br, data, size);
+
+  ret = gst_h264_decoder_config_record_new ();
+
+  READ_CONFIG_UINT8 (ret->configuration_version, 8);
+  /* Keep parsing, caller can decide whether this data needs to be discarded
+   * or not */
+  if (ret->configuration_version != 1) {
+    GST_WARNING ("Wrong configurationVersion %d", ret->configuration_version);
+    result = GST_H264_PARSER_ERROR;
+    goto error;
+  }
+
+  READ_CONFIG_UINT8 (ret->profile_indication, 8);
+  READ_CONFIG_UINT8 (ret->profile_compatibility, 8);
+  READ_CONFIG_UINT8 (ret->level_indication, 8);
+  /* reserved 6bits */
+  SKIP_CONFIG_BITS (6);
+  READ_CONFIG_UINT8 (ret->length_size_minus_one, 2);
+  if (ret->length_size_minus_one == 2) {
+    /* "length_size_minus_one + 1" should be 1, 2, or 4 */
+    GST_WARNING ("Wrong nal-length-size");
+    result = GST_H264_PARSER_ERROR;
+    goto error;
+  }
+
+  /* reserved 3bits */
+  SKIP_CONFIG_BITS (3);
+
+  READ_CONFIG_UINT8 (num_sps, 5);
+  offset = gst_bit_reader_get_pos (&br);
+
+  g_assert (offset % 8 == 0);
+  offset /= 8;
+  for (i = 0; i < num_sps; i++) {
+    GstH264NalUnit nalu;
+
+    result = gst_h264_parser_identify_nalu_avc (nalparser,
+        data, offset, size, 2, &nalu);
+    if (result != GST_H264_PARSER_OK)
+      goto error;
+
+    g_array_append_val (ret->sps, nalu);
+    offset = nalu.offset + nalu.size;
+  }
+
+  if (!gst_bit_reader_set_pos (&br, offset * 8)) {
+    result = GST_H264_PARSER_ERROR;
+    goto error;
+  }
+
+  READ_CONFIG_UINT8 (num_pps, 8);
+  offset = gst_bit_reader_get_pos (&br);
+
+  g_assert (offset % 8 == 0);
+  offset /= 8;
+  for (i = 0; i < num_pps; i++) {
+    GstH264NalUnit nalu;
+
+    result = gst_h264_parser_identify_nalu_avc (nalparser,
+        data, offset, size, 2, &nalu);
+    if (result != GST_H264_PARSER_OK)
+      goto error;
+
+    g_array_append_val (ret->pps, nalu);
+    offset = nalu.offset + nalu.size;
+  }
+
+  /* Parse chroma format and SPS ext data. We will silently ignore any
+   * error while parsing below data since it's not essential data for
+   * decoding */
+  if (ret->profile_indication == 100 || ret->profile_indication == 110 ||
+      ret->profile_indication == 122 || ret->profile_indication == 144) {
+    guint8 num_sps_ext;
+
+    if (!gst_bit_reader_set_pos (&br, offset * 8))
+      goto out;
+
+    if (!gst_bit_reader_skip (&br, 6))
+      goto out;
+
+    if (!gst_bit_reader_get_bits_uint8 (&br, &ret->chroma_format, 2))
+      goto out;
+
+    if (!gst_bit_reader_skip (&br, 5))
+      goto out;
+
+    if (!gst_bit_reader_get_bits_uint8 (&br, &ret->bit_depth_luma_minus8, 3))
+      goto out;
+
+    if (!gst_bit_reader_skip (&br, 5))
+      goto out;
+
+    if (!gst_bit_reader_get_bits_uint8 (&br, &ret->bit_depth_chroma_minus8, 3))
+      goto out;
+
+    if (!gst_bit_reader_get_bits_uint8 (&br, &num_sps_ext, 8))
+      goto out;
+
+    offset = gst_bit_reader_get_pos (&br);
+
+    g_assert (offset % 8 == 0);
+    offset /= 8;
+    for (i = 0; i < num_sps_ext; i++) {
+      GstH264NalUnit nalu;
+
+      result = gst_h264_parser_identify_nalu_avc (nalparser,
+          data, offset, size, 2, &nalu);
+      if (result != GST_H264_PARSER_OK)
+        goto out;
+
+      g_array_append_val (ret->sps_ext, nalu);
+      offset = nalu.offset + nalu.size;
+    }
+
+    ret->chroma_format_present = TRUE;
+  }
+
+out:
+  {
+    *config = ret;
+    return GST_H264_PARSER_OK;
+  }
+error:
+  {
+    gst_h264_decoder_config_record_free (ret);
+    return result;
+  }
+
+#undef READ_CONFIG_UINT8
+#undef SKIP_CONFIG_BITS
+}
diff --git a/gst-libs/gst/codecparsers/gsth264parser.h b/gst-libs/gst/codecparsers/gsth264parser.h
index d2f954232..eb99b6aa0 100644
--- a/gst-libs/gst/codecparsers/gsth264parser.h
+++ b/gst-libs/gst/codecparsers/gsth264parser.h
@@ -218,7 +218,8 @@ typedef enum
  * @GST_H264_FRAME_PACKING_COLUMN_INTERLEAVING: Column based interleaving
  * @GST_H264_FRAME_PACKING_ROW_INTERLEAVING: Row based interleaving
  * @GST_H264_FRAME_PACKING_SIDE_BY_SIDE: Side-by-side packing
- * @GST_H264_FRMAE_PACKING_TOP_BOTTOM: Top-Bottom packing
+ * @GST_H264_FRMAE_PACKING_TOP_BOTTOM: Deprecated; use GST_H264_FRAME_PACKING_TOP_BOTTOM instead
+ * @GST_H264_FRAME_PACKING_TOP_BOTTOM: Top-Bottom packing (Since: 1.22)
  * @GST_H264_FRAME_PACKING_TEMPORAL_INTERLEAVING: Temporal interleaving
  *
  * Frame packing arrangement types.
@@ -233,6 +234,15 @@ typedef enum
   GST_H264_FRAME_PACKING_ROW_INTERLEAVING               = 2,
   GST_H264_FRAME_PACKING_SIDE_BY_SIDE                   = 3,
   GST_H264_FRMAE_PACKING_TOP_BOTTOM                     = 4,
+
+  /**
+   * GST_H264_FRAME_PACKING_TOP_BOTTOM:
+   *
+   * Top-Bottom packing
+   *
+   * Since: 1.22
+   */
+  GST_H264_FRAME_PACKING_TOP_BOTTOM                     = 4,
   GST_H264_FRAME_PACKING_TEMPORAL_INTERLEAVING          = 5
 } GstH264FramePackingType;
 
@@ -253,11 +263,20 @@ typedef enum
  *
  * The type of SEI message.
  */
+/**
+ * GST_H264_SEI_USER_DATA_UNREGISTERED:
+ *
+ * User Data Unregistered (D.2.6)
+ *
+ * Since: 1.22
+ */
+
 typedef enum
 {
   GST_H264_SEI_BUF_PERIOD = 0,
   GST_H264_SEI_PIC_TIMING = 1,
   GST_H264_SEI_REGISTERED_USER_DATA = 4,
+  GST_H264_SEI_USER_DATA_UNREGISTERED = 5,
   GST_H264_SEI_RECOVERY_POINT = 6,
   GST_H264_SEI_STEREO_VIDEO_INFO = 21,
   GST_H264_SEI_FRAME_PACKING = 45,
@@ -357,6 +376,7 @@ typedef struct _GstH264SliceHdr               GstH264SliceHdr;
 typedef struct _GstH264ClockTimestamp         GstH264ClockTimestamp;
 typedef struct _GstH264PicTiming              GstH264PicTiming;
 typedef struct _GstH264RegisteredUserData     GstH264RegisteredUserData;
+typedef struct _GstH264UserDataUnregistered   GstH264UserDataUnregistered;
 typedef struct _GstH264BufferingPeriod        GstH264BufferingPeriod;
 typedef struct _GstH264RecoveryPoint          GstH264RecoveryPoint;
 typedef struct _GstH264StereoVideoInfo        GstH264StereoVideoInfo;
@@ -365,6 +385,7 @@ typedef struct _GstH264MasteringDisplayColourVolume GstH264MasteringDisplayColou
 typedef struct _GstH264ContentLightLevel        GstH264ContentLightLevel;
 typedef struct _GstH264SEIUnhandledPayload    GstH264SEIUnhandledPayload;
 typedef struct _GstH264SEIMessage             GstH264SEIMessage;
+typedef struct _GstH264DecoderConfigRecord    GstH264DecoderConfigRecord;
 
 /**
  * GstH264NalUnitExtensionMVC:
@@ -1111,6 +1132,23 @@ struct _GstH264RegisteredUserData
   guint size;
 };
 
+/**
+ * GstH264UserDataUnregistered:
+ * @uuid: an uuid_iso_iec_11578.
+ * @data: the data of user_data_payload_byte
+ * @size: the size of @data in bytes
+ *
+ * The User data unregistered SEI message syntax.
+ *
+ * Since: 1.22
+ */
+struct _GstH264UserDataUnregistered
+{
+  guint8 uuid[16];
+  const guint8 *data;
+  guint size;
+};
+
 struct _GstH264BufferingPeriod
 {
   GstH264SPS *sps;
@@ -1185,6 +1223,13 @@ struct _GstH264SEIUnhandledPayload
   guint size;
 };
 
+/**
+ * _GstH264SEIMessage.payload.user_data_unregistered:
+ *
+ * User Data Unregistered
+ *
+ * Since: 1.22
+ */
 struct _GstH264SEIMessage
 {
   GstH264SEIPayloadType payloadType;
@@ -1199,10 +1244,111 @@ struct _GstH264SEIMessage
     GstH264MasteringDisplayColourVolume mastering_display_colour_volume;
     GstH264ContentLightLevel content_light_level;
     GstH264SEIUnhandledPayload unhandled_payload;
+    GstH264UserDataUnregistered user_data_unregistered;
     /* ... could implement more */
   } payload;
 };
 
+/**
+ * GstH264DecoderConfigRecord:
+ *
+ * Contains AVCDecoderConfigurationRecord data as defined in ISO/IEC 14496-15
+ *
+ * Since: 1.22
+ */
+struct _GstH264DecoderConfigRecord
+{
+  /**
+   * GstH264DecoderConfigRecord.configuration_version:
+   *
+   * Indicates configurationVersion, must be 1
+   */
+  guint8 configuration_version;
+
+  /**
+   * GstH264DecoderConfigRecord.profile_indication:
+   *
+   * H.264 profile indication
+   */
+  guint8 profile_indication;
+
+  /**
+   * GstH264DecoderConfigRecord.profile_compatibility:
+   *
+   * H.264 profile compatibility
+   */
+  guint8 profile_compatibility;
+
+  /**
+   * GstH264DecoderConfigRecord.level_indication:
+   *
+   * H.264 level indiction
+   */
+  guint8 level_indication;
+
+  /**
+   * GstH264DecoderConfigRecord.length_size_minus_one:
+   *
+   * Indicates the length in bytes of the NAL unit length field
+   */
+  guint8 length_size_minus_one;
+
+  /**
+   * GstH264DecoderConfigRecord.sps
+   *
+   * Array of identified #GstH264NalUnit from sequenceParameterSetNALUnit.
+   * This array may contain non-SPS nal units such as SEI message
+   */
+  GArray *sps;
+
+  /**
+   * GstH264DecoderConfigRecord.pps
+   *
+   * Array of identified #GstH264NalUnit from pictureParameterSetNALUnit.
+   * This array may contain non-PPS nal units such as SEI message
+   */
+  GArray *pps;
+
+  /**
+   * GstH264DecoderConfigRecord.chroma_format_present
+   *
+   * %TRUE if chroma information is present. Otherwise below values
+   * have no meaning
+   */
+  gboolean chroma_format_present;
+
+  /**
+   * GstH264DecoderConfigRecord.chroma_format
+   *
+   * chroma_format_idc defined in ISO/IEC 14496-10
+   */
+  guint8 chroma_format;
+
+  /**
+   * GstH264DecoderConfigRecord.bit_depth_luma_minus8
+   *
+   * Indicates bit depth of luma component
+   */
+  guint8 bit_depth_luma_minus8;
+
+  /**
+   * GstH264DecoderConfigRecord.bit_depth_chroma_minus8
+   *
+   * Indicates bit depth of chroma component
+   */
+  guint8 bit_depth_chroma_minus8;
+
+  /**
+   * GstH264DecoderConfigRecord.sps_ext
+   *
+   * Array of identified #GstH264NalUnit from sequenceParameterSetExtNALUnit.
+   */
+  GArray *sps_ext;
+
+  /*< private >*/
+  gpointer _gst_reserved[GST_PADDING];
+};
+
 /**
  * GstH264NalParser:
  *
@@ -1331,6 +1477,15 @@ GstBuffer * gst_h264_parser_insert_sei_avc (GstH264NalParser * nalparser,
                                             GstBuffer * au,
                                             GstMemory * sei);
 
+GST_CODEC_PARSERS_API
+void        gst_h264_decoder_config_record_free (GstH264DecoderConfigRecord * config);
+
+GST_CODEC_PARSERS_API
+GstH264ParserResult gst_h264_parser_parse_decoder_config_record (GstH264NalParser * nalparser,
+                                                                 const guint8 * data,
+                                                                 gsize size,
+                                                                 GstH264DecoderConfigRecord ** config);
+
 G_END_DECLS
 
 #endif
diff --git a/gst-libs/gst/codecparsers/gsth265bitwriter.c b/gst-libs/gst/codecparsers/gsth265bitwriter.c
new file mode 100644
index 000000000..e87de3b78
--- /dev/null
+++ b/gst-libs/gst/codecparsers/gsth265bitwriter.c
@@ -0,0 +1,2307 @@
+/* GStreamer
+ *  Copyright (C) 2021 Intel Corporation
+ *     Author: He Junyan <junyan.he@intel.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the0
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include "gsth265bitwriter.h"
+#include <gst/codecparsers/nalutils.h>
+#include <gst/base/gstbitwriter.h>
+#include <math.h>
+
+/********************************  Utils ********************************/
+#define SIGNED(val)    (2 * ABS(val) - ((val) > 0))
+
+/* Write an unsigned integer Exp-Golomb-coded syntax element. i.e. ue(v) */
+static gboolean
+_bs_write_ue (GstBitWriter * bs, guint32 value)
+{
+  guint32 size_in_bits = 0;
+  guint32 tmp_value = ++value;
+
+  while (tmp_value) {
+    ++size_in_bits;
+    tmp_value >>= 1;
+  }
+  if (size_in_bits > 1
+      && !gst_bit_writer_put_bits_uint32 (bs, 0, size_in_bits - 1))
+    return FALSE;
+  if (!gst_bit_writer_put_bits_uint32 (bs, value, size_in_bits))
+    return FALSE;
+  return TRUE;
+}
+
+#define WRITE_BITS_UNCHECK(bw, val, nbits)                                    \
+  (nbits <= 8 ? gst_bit_writer_put_bits_uint8 (bw, val, nbits) :              \
+   (nbits <= 16 ? gst_bit_writer_put_bits_uint16 (bw, val, nbits) :           \
+    (nbits <= 32 ? gst_bit_writer_put_bits_uint32 (bw, val, nbits) :          \
+     FALSE)))
+
+#define WRITE_BITS(bw, val, nbits)                                            \
+  if (!WRITE_BITS_UNCHECK (bw, val, nbits)) {                                 \
+    g_warning ("Unsupported bit size: %u", nbits);                            \
+    have_space = FALSE;                                                       \
+    goto error;                                                               \
+  }
+
+#define WRITE_UE_UNCHECK(bw, val)  _bs_write_ue (bw, val)
+
+#ifdef WRITE_UE
+#undef WRITE_UE
+#endif
+#define WRITE_UE(bw, val)                                                     \
+  if (!(have_space = WRITE_UE_UNCHECK (bw, val)))                             \
+    goto error;                                                               \
+
+#define WRITE_UE_MAX(bw, val, max)                                            \
+  if ((guint32) val > (max) || !(have_space = WRITE_UE_UNCHECK (bw, val)))    \
+    goto error;
+
+#define WRITE_SE(bw, val) WRITE_UE (bw, SIGNED (val))
+
+#define WRITE_SE_RANGE(bw, val, min, max)                                     \
+  if (val > max || val < min ||                                               \
+      !(have_space = WRITE_UE_UNCHECK (bw, SIGNED (val))))                    \
+    goto error;
+
+#define WRITE_BYTES_UNCHECK(bw, ptr, nbytes)                                  \
+  gst_bit_writer_put_bytes(bw, ptr, nbytes)
+
+#ifdef WRITE_BYTES
+#undef WRITE_BYTES
+#endif
+#define WRITE_BYTES(bw, ptr, nbytes)                                          \
+  if (!(have_space = WRITE_BYTES_UNCHECK (bw, ptr, nbytes)))                  \
+    goto error;
+
+/*****************************  End of Utils ****************************/
+
+#define EXTENDED_SAR 255
+
+/**** Default scaling_lists according to Table 7-5 and 7-6 *****/
+/* Table 7-5 */
+static const guint8 default_scaling_list0[16] = {
+  16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,
+  16, 16, 16, 16
+};
+
+/*  Combined the values in Table  7-6 to make the calculation easier
+ *  Default scaling list of 8x8 and 16x16 matrices for matrixId = 0, 1 and 2
+ *  Default scaling list of 32x32 matrix for matrixId = 0
+ */
+static const guint8 default_scaling_list1[64] = {
+  16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 16,
+  17, 16, 17, 18, 17, 18, 18, 17, 18, 21, 19, 20,
+  21, 20, 19, 21, 24, 22, 22, 24, 24, 22, 22, 24,
+  25, 25, 27, 30, 27, 25, 25, 29, 31, 35, 35, 31,
+  29, 36, 41, 44, 41, 36, 47, 54, 54, 47, 65, 70,
+  65, 88, 88, 115
+};
+
+/*  Combined the values in Table 7-6 to make the calculation easier
+ *  Default scaling list of 8x8 and 16x16 matrices for matrixId = 3, 4 and 5
+ *  Default scaling list of 32x32 matrix for matrixId = 1
+ */
+static const guint8 default_scaling_list2[64] = {
+  16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17,
+  17, 17, 17, 18, 18, 18, 18, 18, 18, 20, 20, 20,
+  20, 20, 20, 20, 24, 24, 24, 24, 24, 24, 24, 24,
+  25, 25, 25, 25, 25, 25, 25, 28, 28, 28, 28, 28,
+  28, 33, 33, 33, 33, 33, 41, 41, 41, 41, 54, 54,
+  54, 71, 71, 91
+};
+
+static gboolean
+_h265_bit_writer_profile_tier_level (const GstH265ProfileTierLevel * ptl,
+    guint8 maxNumSubLayersMinus1, GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+  guint i, j;
+
+  GST_DEBUG ("writing profile_tier_level");
+
+  WRITE_BITS (bw, ptl->profile_space, 2);
+  WRITE_BITS (bw, ptl->tier_flag, 1);
+  WRITE_BITS (bw, ptl->profile_idc, 5);
+
+  for (j = 0; j < 32; j++)
+    WRITE_BITS (bw, ptl->profile_compatibility_flag[j], 1);
+
+  WRITE_BITS (bw, ptl->progressive_source_flag, 1);
+  WRITE_BITS (bw, ptl->interlaced_source_flag, 1);
+  WRITE_BITS (bw, ptl->non_packed_constraint_flag, 1);
+  WRITE_BITS (bw, ptl->frame_only_constraint_flag, 1);
+
+  if (ptl->profile_idc == 4 || ptl->profile_compatibility_flag[4] ||
+      ptl->profile_idc == 5 || ptl->profile_compatibility_flag[5] ||
+      ptl->profile_idc == 6 || ptl->profile_compatibility_flag[6] ||
+      ptl->profile_idc == 7 || ptl->profile_compatibility_flag[7] ||
+      ptl->profile_idc == 8 || ptl->profile_compatibility_flag[8] ||
+      ptl->profile_idc == 9 || ptl->profile_compatibility_flag[9] ||
+      ptl->profile_idc == 10 || ptl->profile_compatibility_flag[10] ||
+      ptl->profile_idc == 11 || ptl->profile_compatibility_flag[11]) {
+    WRITE_BITS (bw, ptl->max_12bit_constraint_flag, 1);
+    WRITE_BITS (bw, ptl->max_10bit_constraint_flag, 1);
+    WRITE_BITS (bw, ptl->max_8bit_constraint_flag, 1);
+    WRITE_BITS (bw, ptl->max_422chroma_constraint_flag, 1);
+    WRITE_BITS (bw, ptl->max_420chroma_constraint_flag, 1);
+    WRITE_BITS (bw, ptl->max_monochrome_constraint_flag, 1);
+    WRITE_BITS (bw, ptl->intra_constraint_flag, 1);
+    WRITE_BITS (bw, ptl->one_picture_only_constraint_flag, 1);
+    WRITE_BITS (bw, ptl->lower_bit_rate_constraint_flag, 1);
+
+    if (ptl->profile_idc == 5 || ptl->profile_compatibility_flag[5] ||
+        ptl->profile_idc == 9 || ptl->profile_compatibility_flag[9] ||
+        ptl->profile_idc == 10 || ptl->profile_compatibility_flag[10] ||
+        ptl->profile_idc == 11 || ptl->profile_compatibility_flag[11]) {
+      WRITE_BITS (bw, ptl->max_14bit_constraint_flag, 1);
+      /* general_reserved_zero_33bits */
+      WRITE_BITS (bw, 0, 32);
+      WRITE_BITS (bw, 0, 1);
+    } else {
+      /* general_reserved_zero_34bits */
+      WRITE_BITS (bw, 0, 32);
+      WRITE_BITS (bw, 0, 2);
+    }
+  } else if (ptl->profile_idc == 2 || ptl->profile_compatibility_flag[2]) {
+    /* general_reserved_zero_7bits */
+    WRITE_BITS (bw, 0, 7);
+    WRITE_BITS (bw, ptl->one_picture_only_constraint_flag, 1);
+    /* general_reserved_zero_35bits */
+    WRITE_BITS (bw, 0, 32);
+    WRITE_BITS (bw, 0, 3);
+  } else {
+    /* general_reserved_zero_43bits */
+    WRITE_BITS (bw, 0, 32);
+    WRITE_BITS (bw, 0, 11);
+  }
+
+  /* general_inbld_flag, just set to 0 */
+  WRITE_BITS (bw, 0, 1);
+
+  WRITE_BITS (bw, ptl->level_idc, 8);
+
+  for (j = 0; j < maxNumSubLayersMinus1; j++) {
+    if (ptl->sub_layer_profile_present_flag[j]) {
+      GST_WARNING ("sub layer profile does not supported now");
+      goto error;
+    }
+    WRITE_BITS (bw, ptl->sub_layer_profile_present_flag[j], 1);
+
+    if (ptl->sub_layer_level_present_flag[j]) {
+      GST_WARNING ("sub layer level does not supported now");
+      goto error;
+    }
+    WRITE_BITS (bw, ptl->sub_layer_level_present_flag[j], 1);
+  }
+
+  if (maxNumSubLayersMinus1 > 0) {
+    for (i = maxNumSubLayersMinus1; i < 8; i++)
+      /* reserved_zero_2bits */
+      WRITE_BITS (bw, 0, 2);
+  }
+
+  /* TODO: Add sub layers profiles. */
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write profile_tier_level");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h265_bit_writer_sub_layer_hrd_parameters (const GstH265SubLayerHRDParams *
+    sub_hrd, guint8 CpbCnt, guint8 sub_pic_hrd_params_present_flag,
+    GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+  guint i;
+
+  GST_DEBUG ("writing \"subLayer HRD Parameters\"");
+
+  for (i = 0; i <= CpbCnt; i++) {
+    WRITE_UE_MAX (bw, sub_hrd->bit_rate_value_minus1[i], G_MAXUINT32 - 1);
+    WRITE_UE_MAX (bw, sub_hrd->cpb_size_value_minus1[i], G_MAXUINT32 - 1);
+
+    if (sub_pic_hrd_params_present_flag) {
+      WRITE_UE_MAX (bw, sub_hrd->cpb_size_du_value_minus1[i], G_MAXUINT32 - 1);
+      WRITE_UE_MAX (bw, sub_hrd->bit_rate_du_value_minus1[i], G_MAXUINT32 - 1);
+    }
+
+    WRITE_BITS (bw, sub_hrd->cbr_flag[i], 1);
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write \"subLayer HRD Parameters \"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h265_bit_writer_hrd_parameters (const GstH265HRDParams * hrd,
+    guint8 commonInfPresentFlag, guint8 maxNumSubLayersMinus1,
+    GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+  guint i;
+
+  GST_DEBUG ("writing \"HRD Parameters\"");
+
+  if (commonInfPresentFlag) {
+    WRITE_BITS (bw, hrd->nal_hrd_parameters_present_flag, 1);
+    WRITE_BITS (bw, hrd->vcl_hrd_parameters_present_flag, 1);
+
+    if (hrd->nal_hrd_parameters_present_flag
+        || hrd->vcl_hrd_parameters_present_flag) {
+      WRITE_BITS (bw, hrd->sub_pic_hrd_params_present_flag, 1);
+
+      if (hrd->sub_pic_hrd_params_present_flag) {
+        WRITE_BITS (bw, hrd->tick_divisor_minus2, 8);
+        WRITE_BITS (bw, hrd->du_cpb_removal_delay_increment_length_minus1, 5);
+        WRITE_BITS (bw, hrd->sub_pic_cpb_params_in_pic_timing_sei_flag, 1);
+        WRITE_BITS (bw, hrd->dpb_output_delay_du_length_minus1, 5);
+      }
+
+      WRITE_BITS (bw, hrd->bit_rate_scale, 4);
+      WRITE_BITS (bw, hrd->cpb_size_scale, 4);
+
+      if (hrd->sub_pic_hrd_params_present_flag)
+        WRITE_BITS (bw, hrd->cpb_size_du_scale, 4);
+
+      WRITE_BITS (bw, hrd->initial_cpb_removal_delay_length_minus1, 5);
+      WRITE_BITS (bw, hrd->au_cpb_removal_delay_length_minus1, 5);
+      WRITE_BITS (bw, hrd->dpb_output_delay_length_minus1, 5);
+    }
+  }
+
+  for (i = 0; i <= maxNumSubLayersMinus1; i++) {
+    WRITE_BITS (bw, hrd->fixed_pic_rate_general_flag[i], 1);
+
+    if (!hrd->fixed_pic_rate_general_flag[i]) {
+      WRITE_BITS (bw, hrd->fixed_pic_rate_within_cvs_flag[i], 1);
+    } else {
+      if (hrd->fixed_pic_rate_within_cvs_flag[i] == 0)
+        goto error;
+    }
+
+    if (hrd->fixed_pic_rate_within_cvs_flag[i]) {
+      WRITE_UE_MAX (bw, hrd->elemental_duration_in_tc_minus1[i], 2047);
+    } else {
+      WRITE_BITS (bw, hrd->low_delay_hrd_flag[i], 1);
+    }
+
+    if (!hrd->low_delay_hrd_flag[i])
+      WRITE_UE_MAX (bw, hrd->cpb_cnt_minus1[i], 31);
+
+    if (hrd->nal_hrd_parameters_present_flag)
+      if (!_h265_bit_writer_sub_layer_hrd_parameters
+          (&hrd->sublayer_hrd_params[i], hrd->cpb_cnt_minus1[i],
+              hrd->sub_pic_hrd_params_present_flag, bw, &have_space))
+        goto error;
+
+    /* TODO: need to separate nal and vcl from hrd_parameters. */
+    if (hrd->vcl_hrd_parameters_present_flag)
+      if (!_h265_bit_writer_sub_layer_hrd_parameters
+          (&hrd->sublayer_hrd_params[i], hrd->cpb_cnt_minus1[i],
+              hrd->sub_pic_hrd_params_present_flag, bw, &have_space))
+        goto error;
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write \"HRD Parameters\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h265_bit_writer_vps (const GstH265VPS * vps, GstBitWriter * bw,
+    gboolean * space)
+{
+  gboolean have_space = TRUE;
+  guint i, j;
+
+  GST_DEBUG ("writing VPS");
+
+  WRITE_BITS (bw, vps->id, 4);
+
+  WRITE_BITS (bw, vps->base_layer_internal_flag, 1);
+  WRITE_BITS (bw, vps->base_layer_available_flag, 1);
+
+  WRITE_BITS (bw, vps->max_layers_minus1, 6);
+  WRITE_BITS (bw, vps->max_sub_layers_minus1, 3);
+  WRITE_BITS (bw, vps->temporal_id_nesting_flag, 1);
+
+  /* reserved_0xffff_16bits */
+  WRITE_BITS (bw, 0xffff, 16);
+
+  if (!_h265_bit_writer_profile_tier_level (&vps->profile_tier_level,
+          vps->max_sub_layers_minus1, bw, &have_space))
+    goto error;
+
+  WRITE_BITS (bw, vps->sub_layer_ordering_info_present_flag, 1);
+
+  for (i = (vps->sub_layer_ordering_info_present_flag ? 0 :
+          vps->max_sub_layers_minus1); i <= vps->max_sub_layers_minus1; i++) {
+    WRITE_UE (bw, vps->max_dec_pic_buffering_minus1[i]);
+    WRITE_UE_MAX (bw, vps->max_num_reorder_pics[i],
+        vps->max_dec_pic_buffering_minus1[i]);
+    WRITE_UE_MAX (bw, vps->max_latency_increase_plus1[i], G_MAXUINT32 - 1);
+  }
+
+  /* max_layer_id should be <63, but only support 1 layer now. */
+  if (vps->max_layer_id > 1) {
+    GST_WARNING ("multi layers are not supported now");
+    goto error;
+  }
+
+  WRITE_BITS (bw, vps->max_layer_id, 6);
+
+  if (vps->num_layer_sets_minus1 >= 1) {
+    GST_WARNING ("layer set is not supported now");
+    goto error;
+  }
+  WRITE_UE_MAX (bw, vps->num_layer_sets_minus1, 1023);
+
+  /* TODO: support multi-layer. */
+  for (i = 1; i <= vps->num_layer_sets_minus1; i++) {
+    for (j = 0; j <= vps->max_layer_id; j++) {
+      /* layer_id_included_flag[i][j] */
+      WRITE_BITS (bw, 0, 1);
+    }
+  }
+
+  WRITE_BITS (bw, vps->timing_info_present_flag, 1);
+  if (vps->timing_info_present_flag) {
+    WRITE_BITS (bw, vps->num_units_in_tick, 32);
+    WRITE_BITS (bw, vps->time_scale, 32);
+    WRITE_BITS (bw, vps->poc_proportional_to_timing_flag, 1);
+
+    if (vps->poc_proportional_to_timing_flag)
+      WRITE_UE_MAX (bw, vps->num_ticks_poc_diff_one_minus1, G_MAXUINT32 - 1);
+
+    /* TODO: VPS can have multiple hrd parameters, and therefore hrd_params
+     * should be an array (like Garray). Just support 1 hdr parameter now.
+     */
+    if (vps->num_hrd_parameters > 1) {
+      GST_WARNING ("HRD parameters > 1 is not supported now");
+      goto error;
+    }
+    WRITE_UE_MAX (bw, vps->num_hrd_parameters, vps->num_layer_sets_minus1 + 1);
+
+    if (vps->num_hrd_parameters) {
+      WRITE_UE_MAX (bw, vps->hrd_layer_set_idx, vps->num_layer_sets_minus1);
+
+      if (!_h265_bit_writer_hrd_parameters (&vps->hrd_params,
+              vps->cprms_present_flag, vps->max_sub_layers_minus1,
+              bw, &have_space))
+        goto error;
+    }
+
+  }
+
+  if (vps->vps_extension) {
+    GST_WARNING ("vps extension is not supported now");
+    goto error;
+  }
+  WRITE_BITS (bw, 0, 1);
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("failed to write VPS");
+
+  *space = have_space;
+  return FALSE;
+}
+
+/**
+ * gst_h265_bit_writer_vps:
+ * @vps: the vps of #GstH265VPS to write
+ * @start_code: whether adding the nal start code
+ * @data: (out): the bit stream generated by the sps
+ * @size: (inout): the size in bytes of the input and output
+ *
+ * Generating the according h265 bit stream by providing the vps.
+ *
+ * Returns: a #GstH265BitWriterResult
+ *
+ * Since: 1.22
+ **/
+GstH265BitWriterResult
+gst_h265_bit_writer_vps (const GstH265VPS * vps, gboolean start_code,
+    guint8 * data, guint * size)
+{
+  gboolean have_space = TRUE;
+  GstBitWriter bw;
+
+  g_return_val_if_fail (vps != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (data != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (size != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (*size > 0, GST_H265_BIT_WRITER_ERROR);
+
+  gst_bit_writer_init_with_data (&bw, data, *size, FALSE);
+
+  if (start_code)
+    WRITE_BITS (&bw, 0x00000001, 32);
+
+  /* NAL unit header */
+  /* forbidden_zero_bit */
+  WRITE_BITS (&bw, 0, 1);
+  /* nal_unit_type */
+  WRITE_BITS (&bw, GST_H265_NAL_VPS, 6);
+  /* nuh_layer_id, only support 0 now */
+  WRITE_BITS (&bw, 0, 6);
+  /* nuh_temporal_id_plus1, only support 1 now */
+  WRITE_BITS (&bw, 1, 3);
+
+  if (!_h265_bit_writer_vps (vps, &bw, &have_space))
+    goto error;
+
+  /* Add trailings. */
+  WRITE_BITS (&bw, 1, 1);
+  if (!gst_bit_writer_align_bytes (&bw, 0)) {
+    have_space = FALSE;
+    goto error;
+  }
+
+  *size = gst_bit_writer_get_size (&bw) / 8;
+  gst_bit_writer_reset (&bw);
+
+  return GST_H265_BIT_WRITER_OK;
+
+error:
+  gst_bit_writer_reset (&bw);
+  *size = 0;
+
+  if (!have_space)
+    return GST_H265_BIT_WRITER_NO_MORE_SPACE;
+  return GST_H265_BIT_WRITER_INVALID_DATA;
+}
+
+static gboolean
+_get_scaling_list_params (const GstH265ScalingList * dest_scaling_list,
+    guint8 sizeId, guint8 matrixId, const guint8 ** sl, guint8 * size,
+    gint16 * scaling_list_dc_coef_minus8)
+{
+  switch (sizeId) {
+    case GST_H265_QUANT_MATIX_4X4:
+      *sl = dest_scaling_list->scaling_lists_4x4[matrixId];
+      if (size)
+        *size = 16;
+      break;
+    case GST_H265_QUANT_MATIX_8X8:
+      *sl = dest_scaling_list->scaling_lists_8x8[matrixId];
+      if (size)
+        *size = 64;
+      break;
+    case GST_H265_QUANT_MATIX_16X16:
+      *sl = dest_scaling_list->scaling_lists_16x16[matrixId];
+      if (size)
+        *size = 64;
+      if (scaling_list_dc_coef_minus8)
+        *scaling_list_dc_coef_minus8 =
+            dest_scaling_list->scaling_list_dc_coef_minus8_16x16[matrixId];
+      break;
+    case GST_H265_QUANT_MATIX_32X32:
+      *sl = dest_scaling_list->scaling_lists_32x32[matrixId];
+      if (size)
+        *size = 64;
+      if (scaling_list_dc_coef_minus8)
+        *scaling_list_dc_coef_minus8 =
+            dest_scaling_list->scaling_list_dc_coef_minus8_32x32[matrixId];
+      break;
+    default:
+      g_assert_not_reached ();
+      return FALSE;
+  }
+
+  return TRUE;
+}
+
+static const guint8 *
+_get_default_scaling_lists (GstH265QuantMatrixSize sizeId, guint8 matrixId)
+{
+  const guint8 *sl;
+
+  switch (sizeId) {
+    case GST_H265_QUANT_MATIX_4X4:
+      sl = default_scaling_list0;
+      break;
+
+    case GST_H265_QUANT_MATIX_8X8:
+    case GST_H265_QUANT_MATIX_16X16:
+      if (matrixId <= 2) {
+        sl = default_scaling_list1;
+      } else {
+        sl = default_scaling_list2;
+      }
+      break;
+
+    case GST_H265_QUANT_MATIX_32X32:
+      if (matrixId == 0) {
+        sl = default_scaling_list1;
+      } else {
+        sl = default_scaling_list2;
+      }
+      break;
+
+    default:
+      g_assert_not_reached ();
+      return NULL;
+  }
+
+  return sl;
+}
+
+static gboolean
+_compare_scaling_list_matrix (GstH265QuantMatrixSize sizeId,
+    const guint8 * sl0, const guint8 * sl1,
+    gint16 dc_coef_minus8_0, gint16 dc_coef_minus8_1)
+{
+  guint size = sizeId == GST_H265_QUANT_MATIX_4X4 ? 16 : 64;
+
+  if (memcmp (sl0, sl1, size * sizeof (guint8)))
+    return FALSE;
+
+  if (sizeId <= GST_H265_QUANT_MATIX_8X8)
+    return TRUE;
+
+  return dc_coef_minus8_0 == dc_coef_minus8_1;
+}
+
+static gboolean
+_h265_bit_writer_scaling_lists (const GstH265ScalingList * src_scaling_list,
+    GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+  GstH265QuantMatrixSize sizeId;
+  guint8 matrixId;
+  guint8 scaling_list_pred_mode_flag = 0;
+  guint8 size, i, j;
+
+  GST_DEBUG ("writing scaling lists");
+
+  for (sizeId = 0; sizeId <= GST_H265_QUANT_MATIX_32X32; sizeId++) {
+    for (matrixId = 0;
+        matrixId < ((sizeId == GST_H265_QUANT_MATIX_32X32) ? 2 : 6);
+        matrixId++) {
+      gint16 scaling_list_dc_coef_minus8 = 8;
+      const guint8 *sl;
+      const guint8 *default_sl;
+      guint8 nextCoef;
+      gint8 coef_val;
+      guint8 scaling_list_pred_matrix_id_delta;
+
+      if (!_get_scaling_list_params (src_scaling_list, sizeId, matrixId,
+              &sl, &size, &scaling_list_dc_coef_minus8))
+        goto error;
+
+      /* Check whether it is the default matrix. */
+      default_sl = _get_default_scaling_lists (sizeId, matrixId);
+      if (_compare_scaling_list_matrix (sizeId, sl, default_sl,
+              scaling_list_dc_coef_minus8, 8)) {
+        scaling_list_pred_mode_flag = 0;
+        WRITE_BITS (bw, scaling_list_pred_mode_flag, 1);
+        scaling_list_pred_matrix_id_delta = 0;
+        WRITE_UE_MAX (bw, scaling_list_pred_matrix_id_delta, matrixId);
+        continue;
+      }
+
+      /* If some previous matrix is the same, just ref it. */
+      scaling_list_pred_matrix_id_delta = 0;
+      for (j = 0; j < matrixId; j++) {
+        gboolean ret;
+        guint8 size2;
+        const guint8 *sl2;
+        gint16 scaling_list_dc_coef_minus8_2 = 8;
+
+        ret = _get_scaling_list_params (src_scaling_list, sizeId, j,
+            &sl2, &size2, &scaling_list_dc_coef_minus8_2);
+        g_assert (ret);
+        g_assert (size == size2);
+
+        if (_compare_scaling_list_matrix (sizeId, sl, sl2,
+                scaling_list_dc_coef_minus8, scaling_list_dc_coef_minus8_2)) {
+          scaling_list_pred_matrix_id_delta = matrixId - j;
+          break;
+        }
+      }
+
+      if (scaling_list_pred_matrix_id_delta > 0) {
+        scaling_list_pred_mode_flag = 0;
+        WRITE_BITS (bw, scaling_list_pred_mode_flag, 1);
+        WRITE_UE_MAX (bw, scaling_list_pred_matrix_id_delta, matrixId);
+        continue;
+      }
+
+      /* Just explicitly signal all matrix coef. */
+      scaling_list_pred_mode_flag = 1;
+      WRITE_BITS (bw, scaling_list_pred_mode_flag, 1);
+
+      nextCoef = 8;
+
+      if (sizeId > 1) {
+        WRITE_SE_RANGE (bw, scaling_list_dc_coef_minus8, -7, 247);
+        nextCoef = scaling_list_dc_coef_minus8 + 8;
+      }
+
+      for (i = 0; i < size; i++) {
+        coef_val = sl[i] - nextCoef;
+        nextCoef = sl[i];
+
+        if (coef_val > 127) {
+          coef_val = coef_val - 256;
+        }
+        if (coef_val < -128) {
+          coef_val = coef_val + 256;
+        }
+
+        WRITE_SE_RANGE (bw, coef_val, -128, 127);
+      }
+    }
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write scaling lists");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h265_bit_writer_short_term_ref_pic_set (const GstH265ShortTermRefPicSet *
+    stRPS, guint8 stRpsIdx, const GstH265SPS * sps,
+    GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+  gint32 prev;
+  gint i = 0;
+
+  GST_DEBUG ("writing \"ShortTermRefPicSetParameter\"");
+
+  if (stRPS->inter_ref_pic_set_prediction_flag) {
+    /* TODO */
+    GST_WARNING ("inter_ref_pic_set_prediction_flag mode not supported");
+    goto error;
+  }
+
+  if (stRpsIdx != 0)
+    WRITE_BITS (bw, stRPS->inter_ref_pic_set_prediction_flag, 1);
+
+  if (stRPS->NumNegativePics + stRPS->NumPositivePics != stRPS->NumDeltaPocs)
+    goto error;
+
+  /* 7-49 */
+  WRITE_UE_MAX (bw, stRPS->NumNegativePics,
+      sps->max_dec_pic_buffering_minus1[sps->max_sub_layers_minus1]);
+  /* 7-50 */
+  WRITE_UE_MAX (bw, stRPS->NumPositivePics,
+      (sps->max_dec_pic_buffering_minus1[sps->max_sub_layers_minus1] -
+          stRPS->NumNegativePics));
+
+  prev = 0;
+  for (i = 0; i < stRPS->NumNegativePics; i++) {
+    WRITE_UE_MAX (bw, prev - stRPS->DeltaPocS0[i] - 1, 32767);
+    prev = stRPS->DeltaPocS0[i];
+    /* 7-51 */
+    WRITE_BITS (bw, stRPS->UsedByCurrPicS0[i], 1);
+  }
+
+  prev = 0;
+  for (i = 0; i < stRPS->NumPositivePics; i++) {
+    WRITE_UE_MAX (bw, stRPS->DeltaPocS1[i] - prev - 1, 32767);
+    prev = stRPS->DeltaPocS1[i];
+    /* 7-52 */
+    WRITE_BITS (bw, stRPS->UsedByCurrPicS1[i], 1);
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write \"ShortTermRefPicSet Parameters\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h265_bit_writer_vui_parameters (const GstH265SPS * sps,
+    GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+  const GstH265VUIParams *vui = &sps->vui_params;
+
+  GST_DEBUG ("writing \"VUI Parameters\"");
+
+  WRITE_BITS (bw, vui->aspect_ratio_info_present_flag, 1);
+  if (vui->aspect_ratio_info_present_flag) {
+    WRITE_BITS (bw, vui->aspect_ratio_idc, 8);
+    if (vui->aspect_ratio_idc == EXTENDED_SAR) {
+      WRITE_BITS (bw, vui->sar_width, 16);
+      WRITE_BITS (bw, vui->sar_height, 16);
+    }
+  }
+
+  WRITE_BITS (bw, vui->overscan_info_present_flag, 1);
+  if (vui->overscan_info_present_flag)
+    WRITE_BITS (bw, vui->overscan_appropriate_flag, 1);
+
+  WRITE_BITS (bw, vui->video_signal_type_present_flag, 1);
+  if (vui->video_signal_type_present_flag) {
+    WRITE_BITS (bw, vui->video_format, 3);
+    WRITE_BITS (bw, vui->video_full_range_flag, 1);
+    WRITE_BITS (bw, vui->colour_description_present_flag, 1);
+    if (vui->colour_description_present_flag) {
+      WRITE_BITS (bw, vui->colour_primaries, 8);
+      WRITE_BITS (bw, vui->transfer_characteristics, 8);
+      WRITE_BITS (bw, vui->matrix_coefficients, 8);
+    }
+  }
+
+  WRITE_BITS (bw, vui->chroma_loc_info_present_flag, 1);
+  if (vui->chroma_loc_info_present_flag) {
+    WRITE_UE_MAX (bw, vui->chroma_sample_loc_type_top_field, 5);
+    WRITE_UE_MAX (bw, vui->chroma_sample_loc_type_bottom_field, 5);
+  }
+
+  WRITE_BITS (bw, vui->neutral_chroma_indication_flag, 1);
+  WRITE_BITS (bw, vui->field_seq_flag, 1);
+  WRITE_BITS (bw, vui->frame_field_info_present_flag, 1);
+
+  WRITE_BITS (bw, vui->default_display_window_flag, 1);
+  if (vui->default_display_window_flag) {
+    WRITE_UE (bw, vui->def_disp_win_left_offset);
+    WRITE_UE (bw, vui->def_disp_win_right_offset);
+    WRITE_UE (bw, vui->def_disp_win_top_offset);
+    WRITE_UE (bw, vui->def_disp_win_bottom_offset);
+  }
+
+  WRITE_BITS (bw, vui->timing_info_present_flag, 1);
+  if (vui->timing_info_present_flag) {
+    if (vui->num_units_in_tick == 0)
+      GST_WARNING ("num_units_in_tick = 0 (incompliant to H.265 E.2.1).");
+    WRITE_BITS (bw, vui->num_units_in_tick, 32);
+
+    if (vui->time_scale == 0)
+      GST_WARNING ("time_scale = 0 (incompliant to H.265 E.2.1).");
+    WRITE_BITS (bw, vui->time_scale, 32);
+
+    WRITE_BITS (bw, vui->poc_proportional_to_timing_flag, 1);
+    if (vui->poc_proportional_to_timing_flag)
+      WRITE_UE_MAX (bw, vui->num_ticks_poc_diff_one_minus1, G_MAXUINT32 - 1);
+
+    WRITE_BITS (bw, vui->hrd_parameters_present_flag, 1);
+    if (vui->hrd_parameters_present_flag)
+      if (!_h265_bit_writer_hrd_parameters (&vui->hrd_params, 1,
+              sps->max_sub_layers_minus1, bw, &have_space))
+        goto error;
+  }
+
+  WRITE_BITS (bw, vui->bitstream_restriction_flag, 1);
+  if (vui->bitstream_restriction_flag) {
+    WRITE_BITS (bw, vui->tiles_fixed_structure_flag, 1);
+    WRITE_BITS (bw, vui->motion_vectors_over_pic_boundaries_flag, 1);
+    WRITE_BITS (bw, vui->restricted_ref_pic_lists_flag, 1);
+    WRITE_UE_MAX (bw, vui->min_spatial_segmentation_idc, 4096);
+    WRITE_UE_MAX (bw, vui->max_bytes_per_pic_denom, 16);
+    WRITE_UE_MAX (bw, vui->max_bits_per_min_cu_denom, 16);
+    WRITE_UE_MAX (bw, vui->log2_max_mv_length_horizontal, 16);
+    WRITE_UE_MAX (bw, vui->log2_max_mv_length_vertical, 15);
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write \"VUI Parameters\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h265_bit_writer_sps (const GstH265SPS * sps,
+    GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+  guint i;
+
+  GST_DEBUG ("writing SPS");
+
+  WRITE_BITS (bw, sps->vps->id, 4);
+
+  WRITE_BITS (bw, sps->max_sub_layers_minus1, 3);
+  WRITE_BITS (bw, sps->temporal_id_nesting_flag, 1);
+
+  if (!_h265_bit_writer_profile_tier_level (&sps->profile_tier_level,
+          sps->max_sub_layers_minus1, bw, &have_space))
+    goto error;
+
+  WRITE_UE_MAX (bw, sps->id, GST_H265_MAX_SPS_COUNT - 1);
+
+  WRITE_UE_MAX (bw, sps->chroma_format_idc, 3);
+  if (sps->chroma_format_idc == 3)
+    WRITE_BITS (bw, sps->separate_colour_plane_flag, 1);
+
+  if (sps->pic_width_in_luma_samples < 1)
+    goto error;
+  WRITE_UE_MAX (bw, sps->pic_width_in_luma_samples, 16888);
+
+  if (sps->pic_height_in_luma_samples < 1)
+    goto error;
+  WRITE_UE_MAX (bw, sps->pic_height_in_luma_samples, 16888);
+
+  WRITE_BITS (bw, sps->conformance_window_flag, 1);
+  if (sps->conformance_window_flag) {
+    WRITE_UE (bw, sps->conf_win_left_offset);
+    WRITE_UE (bw, sps->conf_win_right_offset);
+    WRITE_UE (bw, sps->conf_win_top_offset);
+    WRITE_UE (bw, sps->conf_win_bottom_offset);
+  }
+
+  WRITE_UE_MAX (bw, sps->bit_depth_luma_minus8, 6);
+  WRITE_UE_MAX (bw, sps->bit_depth_chroma_minus8, 6);
+  WRITE_UE_MAX (bw, sps->log2_max_pic_order_cnt_lsb_minus4, 12);
+
+  WRITE_BITS (bw, sps->sub_layer_ordering_info_present_flag, 1);
+  for (i = (sps->sub_layer_ordering_info_present_flag ? 0 :
+          sps->max_sub_layers_minus1); i <= sps->max_sub_layers_minus1; i++) {
+    WRITE_UE_MAX (bw, sps->max_dec_pic_buffering_minus1[i], 16);
+    WRITE_UE_MAX (bw, sps->max_num_reorder_pics[i],
+        sps->max_dec_pic_buffering_minus1[i]);
+    WRITE_UE (bw, sps->max_latency_increase_plus1[i]);
+  }
+
+  /* The limits are calculted based on the profile_tier_level constraint
+   * in Annex-A: CtbLog2SizeY = 4 to 6 */
+  WRITE_UE_MAX (bw, sps->log2_min_luma_coding_block_size_minus3, 3);
+  WRITE_UE_MAX (bw, sps->log2_diff_max_min_luma_coding_block_size, 6);
+  WRITE_UE_MAX (bw, sps->log2_min_transform_block_size_minus2, 3);
+  WRITE_UE_MAX (bw, sps->log2_diff_max_min_transform_block_size, 3);
+  WRITE_UE_MAX (bw, sps->max_transform_hierarchy_depth_inter, 4);
+  WRITE_UE_MAX (bw, sps->max_transform_hierarchy_depth_intra, 4);
+
+  WRITE_BITS (bw, sps->scaling_list_enabled_flag, 1);
+  if (sps->scaling_list_enabled_flag) {
+    WRITE_BITS (bw, sps->scaling_list_data_present_flag, 1);
+
+    if (sps->scaling_list_data_present_flag)
+      if (!_h265_bit_writer_scaling_lists (&sps->scaling_list, bw, &have_space))
+        goto error;
+  }
+
+  WRITE_BITS (bw, sps->amp_enabled_flag, 1);
+  WRITE_BITS (bw, sps->sample_adaptive_offset_enabled_flag, 1);
+  WRITE_BITS (bw, sps->pcm_enabled_flag, 1);
+
+  if (sps->pcm_enabled_flag) {
+    WRITE_BITS (bw, sps->pcm_sample_bit_depth_luma_minus1, 4);
+    WRITE_BITS (bw, sps->pcm_sample_bit_depth_chroma_minus1, 4);
+    WRITE_UE_MAX (bw, sps->log2_min_pcm_luma_coding_block_size_minus3, 2);
+    WRITE_UE_MAX (bw, sps->log2_diff_max_min_pcm_luma_coding_block_size, 2);
+    WRITE_BITS (bw, sps->pcm_loop_filter_disabled_flag, 1);
+  }
+
+  WRITE_UE_MAX (bw, sps->num_short_term_ref_pic_sets, 64);
+  for (i = 0; i < sps->num_short_term_ref_pic_sets; i++) {
+    if (!_h265_bit_writer_short_term_ref_pic_set
+        (&sps->short_term_ref_pic_set[i], i, sps, bw, &have_space))
+      goto error;
+  }
+
+  WRITE_BITS (bw, sps->long_term_ref_pics_present_flag, 1);
+  if (sps->long_term_ref_pics_present_flag) {
+    WRITE_UE_MAX (bw, sps->num_long_term_ref_pics_sps, 32);
+    for (i = 0; i < sps->num_long_term_ref_pics_sps; i++) {
+      WRITE_BITS (bw, sps->lt_ref_pic_poc_lsb_sps[i],
+          sps->log2_max_pic_order_cnt_lsb_minus4 + 4);
+      WRITE_BITS (bw, sps->used_by_curr_pic_lt_sps_flag[i], 1);
+    }
+  }
+
+  WRITE_BITS (bw, sps->temporal_mvp_enabled_flag, 1);
+  WRITE_BITS (bw, sps->strong_intra_smoothing_enabled_flag, 1);
+  WRITE_BITS (bw, sps->vui_parameters_present_flag, 1);
+
+  if (sps->vui_parameters_present_flag) {
+    if (!_h265_bit_writer_vui_parameters (sps, bw, &have_space))
+      goto error;
+  }
+
+  WRITE_BITS (bw, sps->sps_extension_flag, 1);
+
+  if (sps->sps_extension_flag) {
+    WRITE_BITS (bw, sps->sps_range_extension_flag, 1);
+    WRITE_BITS (bw, sps->sps_multilayer_extension_flag, 1);
+    WRITE_BITS (bw, sps->sps_3d_extension_flag, 1);
+    WRITE_BITS (bw, sps->sps_scc_extension_flag, 1);
+    WRITE_BITS (bw, sps->sps_extension_4bits, 4);
+  }
+
+  if (sps->sps_range_extension_flag) {
+    WRITE_BITS (bw,
+        sps->sps_extension_params.transform_skip_rotation_enabled_flag, 1);
+    WRITE_BITS (bw,
+        sps->sps_extension_params.transform_skip_context_enabled_flag, 1);
+    WRITE_BITS (bw, sps->sps_extension_params.implicit_rdpcm_enabled_flag, 1);
+    WRITE_BITS (bw, sps->sps_extension_params.explicit_rdpcm_enabled_flag, 1);
+    WRITE_BITS (bw,
+        sps->sps_extension_params.extended_precision_processing_flag, 1);
+    WRITE_BITS (bw, sps->sps_extension_params.intra_smoothing_disabled_flag, 1);
+    WRITE_BITS (bw,
+        sps->sps_extension_params.high_precision_offsets_enabled_flag, 1);
+    WRITE_BITS (bw,
+        sps->sps_extension_params.persistent_rice_adaptation_enabled_flag, 1);
+    WRITE_BITS (bw,
+        sps->sps_extension_params.cabac_bypass_alignment_enabled_flag, 1);
+  }
+
+  if (sps->sps_multilayer_extension_flag) {
+    GST_WARNING ("do not support multilayer extension");
+    goto error;
+  }
+  if (sps->sps_3d_extension_flag) {
+    GST_WARNING ("do not support 3d extension");
+    goto error;
+  }
+
+  if (sps->sps_scc_extension_flag) {
+    const GstH265SPSSccExtensionParams *scc_params =
+        &sps->sps_scc_extension_params;
+
+    WRITE_BITS (bw, scc_params->sps_curr_pic_ref_enabled_flag, 1);
+    WRITE_BITS (bw, scc_params->palette_mode_enabled_flag, 1);
+    if (scc_params->palette_mode_enabled_flag) {
+      WRITE_UE_MAX (bw, scc_params->palette_max_size, 64);
+      WRITE_UE_MAX (bw, scc_params->delta_palette_max_predictor_size,
+          128 - scc_params->palette_max_size);
+
+      WRITE_BITS (bw,
+          scc_params->sps_palette_predictor_initializers_present_flag, 1);
+      if (scc_params->sps_palette_predictor_initializers_present_flag) {
+        guint comp;
+        WRITE_UE_MAX (bw,
+            scc_params->sps_num_palette_predictor_initializer_minus1,
+            scc_params->palette_max_size +
+            scc_params->delta_palette_max_predictor_size - 1);
+
+        for (comp = 0; comp < (sps->chroma_format_idc == 0 ? 1 : 3); comp++) {
+          guint num_bits;
+          guint num =
+              scc_params->sps_num_palette_predictor_initializer_minus1 + 1;
+
+          num_bits = (comp == 0 ? sps->bit_depth_luma_minus8 + 8 :
+              sps->bit_depth_chroma_minus8 + 8);
+          for (i = 0; i < num; i++)
+            WRITE_BITS (bw,
+                scc_params->sps_palette_predictor_initializer[comp][i],
+                num_bits);
+        }
+      }
+    }
+
+    WRITE_BITS (bw, scc_params->motion_vector_resolution_control_idc, 2);
+    WRITE_BITS (bw, scc_params->intra_boundary_filtering_disabled_flag, 1);
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("failed to write SPS");
+
+  *space = have_space;
+  return FALSE;
+}
+
+/**
+ * gst_h265_bit_writer_sps:
+ * @sps: the sps of #GstH265SPS to write
+ * @start_code: whether adding the nal start code
+ * @data: (out): the bit stream generated by the sps
+ * @size: (inout): the size in bytes of the input and output
+ *
+ * Generating the according h265 bit stream by providing the sps.
+ *
+ * Returns: a #GstH265BitWriterResult
+ *
+ * Since: 1.22
+ **/
+GstH265BitWriterResult
+gst_h265_bit_writer_sps (const GstH265SPS * sps, gboolean start_code,
+    guint8 * data, guint * size)
+{
+  gboolean have_space = TRUE;
+  GstBitWriter bw;
+
+  g_return_val_if_fail (sps != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (sps->vps != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (data != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (size != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (*size > 0, GST_H265_BIT_WRITER_ERROR);
+
+  gst_bit_writer_init_with_data (&bw, data, *size, FALSE);
+
+  if (start_code)
+    WRITE_BITS (&bw, 0x00000001, 32);
+
+  /* NAL unit header */
+  /* forbidden_zero_bit */
+  WRITE_BITS (&bw, 0, 1);
+  /* nal_unit_type */
+  WRITE_BITS (&bw, GST_H265_NAL_SPS, 6);
+  /* nuh_layer_id, only support 0 now */
+  WRITE_BITS (&bw, 0, 6);
+  /* nuh_temporal_id_plus1, only support 1 now */
+  WRITE_BITS (&bw, 1, 3);
+
+  if (!_h265_bit_writer_sps (sps, &bw, &have_space))
+    goto error;
+
+  /* Add trailings. */
+  WRITE_BITS (&bw, 1, 1);
+  if (!gst_bit_writer_align_bytes (&bw, 0)) {
+    have_space = FALSE;
+    goto error;
+  }
+
+  *size = gst_bit_writer_get_size (&bw) / 8;
+  gst_bit_writer_reset (&bw);
+
+  return GST_H265_BIT_WRITER_OK;
+
+error:
+  gst_bit_writer_reset (&bw);
+  *size = 0;
+
+  if (!have_space)
+    return GST_H265_BIT_WRITER_NO_MORE_SPACE;
+  return GST_H265_BIT_WRITER_INVALID_DATA;
+}
+
+static gboolean
+_h265_bit_writer_pps (const GstH265PPS * pps, GstBitWriter * bw,
+    gboolean * space)
+{
+  gboolean have_space = TRUE;
+
+  GST_DEBUG ("writing PPS");
+
+  WRITE_UE_MAX (bw, pps->id, GST_H265_MAX_PPS_COUNT - 1);
+  WRITE_UE_MAX (bw, pps->sps->id, GST_H265_MAX_SPS_COUNT - 1);
+
+  WRITE_BITS (bw, pps->dependent_slice_segments_enabled_flag, 1);
+  WRITE_BITS (bw, pps->output_flag_present_flag, 1);
+  WRITE_BITS (bw, pps->num_extra_slice_header_bits, 3);
+  WRITE_BITS (bw, pps->sign_data_hiding_enabled_flag, 1);
+  WRITE_BITS (bw, pps->cabac_init_present_flag, 1);
+
+  WRITE_UE_MAX (bw, pps->num_ref_idx_l0_default_active_minus1, 14);
+  WRITE_UE_MAX (bw, pps->num_ref_idx_l1_default_active_minus1, 14);
+  WRITE_SE_RANGE (bw, pps->init_qp_minus26,
+      -(26 + 6 * pps->sps->bit_depth_luma_minus8), 25);
+
+  WRITE_BITS (bw, pps->constrained_intra_pred_flag, 1);
+  WRITE_BITS (bw, pps->transform_skip_enabled_flag, 1);
+
+  WRITE_BITS (bw, pps->cu_qp_delta_enabled_flag, 1);
+  if (pps->cu_qp_delta_enabled_flag)
+    WRITE_UE_MAX (bw, pps->diff_cu_qp_delta_depth,
+        pps->sps->log2_diff_max_min_luma_coding_block_size);
+
+  WRITE_SE_RANGE (bw, pps->cb_qp_offset, -12, 12);
+  WRITE_SE_RANGE (bw, pps->cr_qp_offset, -12, 12);
+
+  WRITE_BITS (bw, pps->slice_chroma_qp_offsets_present_flag, 1);
+  WRITE_BITS (bw, pps->weighted_pred_flag, 1);
+  WRITE_BITS (bw, pps->weighted_bipred_flag, 1);
+  WRITE_BITS (bw, pps->transquant_bypass_enabled_flag, 1);
+  WRITE_BITS (bw, pps->tiles_enabled_flag, 1);
+  WRITE_BITS (bw, pps->entropy_coding_sync_enabled_flag, 1);
+
+  if (pps->tiles_enabled_flag) {
+    if (pps->num_tile_columns_minus1 + 1 >
+        G_N_ELEMENTS (pps->column_width_minus1)) {
+      GST_WARNING ("Invalid \"num_tile_columns_minus1\" %d",
+          pps->num_tile_columns_minus1);
+      goto error;
+    }
+
+    if (pps->num_tile_rows_minus1 + 1 > G_N_ELEMENTS (pps->row_height_minus1)) {
+      GST_WARNING ("Invalid \"num_tile_rows_minus1\" %d",
+          pps->num_tile_rows_minus1);
+      goto error;
+    }
+
+    WRITE_UE_MAX (bw, pps->num_tile_columns_minus1, pps->PicWidthInCtbsY - 1);
+    WRITE_UE_MAX (bw, pps->num_tile_rows_minus1, pps->PicHeightInCtbsY - 1);
+
+    WRITE_BITS (bw, pps->uniform_spacing_flag, 1);
+
+    /* 6.5.1, 6-4, 6-5, 7.4.3.3.1 */
+    if (!pps->uniform_spacing_flag) {
+      guint i;
+
+      for (i = 0; i < pps->num_tile_columns_minus1; i++)
+        WRITE_UE (bw, pps->column_width_minus1[i]);
+
+      for (i = 0; i < pps->num_tile_rows_minus1; i++)
+        WRITE_UE (bw, pps->row_height_minus1[i]);
+    }
+    WRITE_BITS (bw, pps->loop_filter_across_tiles_enabled_flag, 1);
+  }
+
+  WRITE_BITS (bw, pps->loop_filter_across_slices_enabled_flag, 1);
+
+  WRITE_BITS (bw, pps->deblocking_filter_control_present_flag, 1);
+  if (pps->deblocking_filter_control_present_flag) {
+    WRITE_BITS (bw, pps->deblocking_filter_override_enabled_flag, 1);
+
+    WRITE_BITS (bw, pps->deblocking_filter_disabled_flag, 1);
+    if (!pps->deblocking_filter_disabled_flag) {
+      WRITE_SE_RANGE (bw, pps->beta_offset_div2, -6, 6);
+      WRITE_SE_RANGE (bw, pps->tc_offset_div2, -6, +6);
+    }
+  }
+
+  WRITE_BITS (bw, pps->scaling_list_data_present_flag, 1);
+  if (pps->scaling_list_data_present_flag)
+    if (!_h265_bit_writer_scaling_lists (&pps->scaling_list, bw, &have_space))
+      goto error;
+
+  WRITE_BITS (bw, pps->lists_modification_present_flag, 1);
+  WRITE_UE_MAX (bw, pps->log2_parallel_merge_level_minus2, 4);
+
+  /* TODO: slice_segment_header */
+  if (pps->slice_segment_header_extension_present_flag) {
+    GST_WARNING
+        ("slice_segment_header_extension_present_flag is not supported");
+    goto error;
+  }
+  WRITE_BITS (bw, pps->slice_segment_header_extension_present_flag, 1);
+
+  WRITE_BITS (bw, pps->pps_extension_flag, 1);
+
+  if (pps->pps_extension_flag) {
+    WRITE_BITS (bw, pps->pps_range_extension_flag, 1);
+    WRITE_BITS (bw, pps->pps_multilayer_extension_flag, 1);
+    WRITE_BITS (bw, pps->pps_3d_extension_flag, 1);
+    WRITE_BITS (bw, pps->pps_scc_extension_flag, 1);
+    WRITE_BITS (bw, pps->pps_extension_4bits, 4);
+  }
+
+  if (pps->pps_range_extension_flag) {
+    guint i;
+    guint32 MaxBitDepthY, MaxBitDepthC;
+
+    if (pps->transform_skip_enabled_flag)
+      WRITE_UE (bw,
+          pps->pps_extension_params.log2_max_transform_skip_block_size_minus2);
+
+    WRITE_BITS (bw,
+        pps->pps_extension_params.cross_component_prediction_enabled_flag, 1);
+    WRITE_BITS (bw,
+        pps->pps_extension_params.chroma_qp_offset_list_enabled_flag, 1);
+
+    if (pps->pps_extension_params.chroma_qp_offset_list_enabled_flag) {
+      WRITE_UE_MAX (bw,
+          pps->pps_extension_params.diff_cu_chroma_qp_offset_depth,
+          pps->sps->log2_diff_max_min_luma_coding_block_size);
+
+      WRITE_UE_MAX (bw,
+          pps->pps_extension_params.chroma_qp_offset_list_len_minus1, 5);
+      for (i = 0;
+          i <= pps->pps_extension_params.chroma_qp_offset_list_len_minus1;
+          i++) {
+        WRITE_SE_RANGE (bw, pps->pps_extension_params.cb_qp_offset_list[i],
+            -12, 12);
+        WRITE_SE_RANGE (bw, pps->pps_extension_params.cr_qp_offset_list[i],
+            -12, 12);
+      }
+    }
+
+    MaxBitDepthY = pps->sps->bit_depth_luma_minus8 > 2 ?
+        pps->sps->bit_depth_luma_minus8 - 2 : 0;
+    MaxBitDepthC = pps->sps->bit_depth_chroma_minus8 > 2 ?
+        pps->sps->bit_depth_chroma_minus8 - 2 : 0;
+    WRITE_UE_MAX (bw, pps->pps_extension_params.log2_sao_offset_scale_luma,
+        MaxBitDepthY);
+    WRITE_UE_MAX (bw, pps->pps_extension_params.log2_sao_offset_scale_chroma,
+        MaxBitDepthC);
+  }
+
+  if (pps->pps_multilayer_extension_flag) {
+    GST_WARNING ("do not support multilayer extension");
+    goto error;
+  }
+
+  if (pps->pps_3d_extension_flag) {
+    GST_WARNING ("do not support 3d extension");
+    goto error;
+  }
+
+  if (pps->pps_scc_extension_flag) {
+    const GstH265PPSSccExtensionParams *pps_scc =
+        &pps->pps_scc_extension_params;
+
+    WRITE_BITS (bw, pps_scc->pps_curr_pic_ref_enabled_flag, 1);
+    WRITE_BITS (bw,
+        pps_scc->residual_adaptive_colour_transform_enabled_flag, 1);
+    if (pps_scc->residual_adaptive_colour_transform_enabled_flag) {
+      WRITE_BITS (bw, pps_scc->pps_slice_act_qp_offsets_present_flag, 1);
+      WRITE_SE_RANGE (bw, (gint8) pps_scc->pps_act_y_qp_offset_plus5, -7, 17);
+      WRITE_SE_RANGE (bw, (gint8) pps_scc->pps_act_cb_qp_offset_plus5, -7, 17);
+      WRITE_SE_RANGE (bw, (gint8) pps_scc->pps_act_cr_qp_offset_plus3, -9, 15);
+    }
+
+    WRITE_BITS (bw,
+        pps_scc->pps_palette_predictor_initializers_present_flag, 1);
+    if (pps_scc->pps_palette_predictor_initializers_present_flag) {
+      guint i;
+
+      WRITE_UE_MAX (bw,
+          pps_scc->pps_num_palette_predictor_initializer,
+          pps->sps->sps_scc_extension_params.palette_max_size +
+          pps->sps->sps_scc_extension_params.delta_palette_max_predictor_size);
+      if (pps_scc->pps_num_palette_predictor_initializer > 0) {
+        guint comp;
+
+        WRITE_BITS (bw, pps_scc->monochrome_palette_flag, 1);
+        /* It is a requirement of bitstream conformance that the value of
+           luma_bit_depth_entry_minus8 shall be equal to the value of
+           bit_depth_luma_minus8 */
+        WRITE_UE_MAX (bw, pps_scc->luma_bit_depth_entry_minus8,
+            pps->sps->bit_depth_luma_minus8);
+        if (!pps_scc->monochrome_palette_flag) {
+          /* It is a requirement of bitstream conformance that the value
+             of chroma_bit_depth_entry_minus8 shall be equal to the value
+             of bit_depth_chroma_minus8. */
+          WRITE_UE_MAX (bw, pps_scc->chroma_bit_depth_entry_minus8,
+              pps->sps->bit_depth_chroma_minus8);
+        }
+
+        for (comp = 0; comp < (pps_scc->monochrome_palette_flag ? 1 : 3);
+            comp++) {
+          guint num_bits;
+          guint num = pps_scc->pps_num_palette_predictor_initializer;
+
+          num_bits = (comp == 0 ?
+              pps_scc->luma_bit_depth_entry_minus8 + 8 :
+              pps_scc->chroma_bit_depth_entry_minus8 + 8);
+          for (i = 0; i < num; i++)
+            WRITE_BITS (bw,
+                pps_scc->pps_palette_predictor_initializer[comp][i], num_bits);
+        }
+      }
+    }
+  }
+
+  return TRUE;
+
+error:
+  GST_WARNING ("failed to write PPS");
+  return FALSE;
+}
+
+/**
+ * gst_h265_bit_writer_pps:
+ * @pps: the pps of #GstH265PPS to write
+ * @start_code: whether adding the nal start code
+ * @data: (out): the bit stream generated by the pps
+ * @size: (inout): the size in bytes of the input and output
+ *
+ * Generating the according h265 bit stream by providing the pps.
+ *
+ * Returns: a #GstH265BitWriterResult
+ *
+ * Since: 1.22
+ **/
+GstH265BitWriterResult
+gst_h265_bit_writer_pps (const GstH265PPS * pps, gboolean start_code,
+    guint8 * data, guint * size)
+{
+  gboolean have_space = TRUE;
+  GstBitWriter bw;
+
+  g_return_val_if_fail (pps != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (pps->sps != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (data != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (size != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (*size > 0, GST_H265_BIT_WRITER_ERROR);
+
+  gst_bit_writer_init_with_data (&bw, data, *size, FALSE);
+
+  if (start_code)
+    WRITE_BITS (&bw, 0x00000001, 32);
+
+  /* NAL unit header */
+  /* forbidden_zero_bit */
+  WRITE_BITS (&bw, 0, 1);
+  /* nal_unit_type */
+  WRITE_BITS (&bw, GST_H265_NAL_PPS, 6);
+  /* nuh_layer_id, only support 0 now */
+  WRITE_BITS (&bw, 0, 6);
+  /* nuh_temporal_id_plus1, only support 1 now */
+  WRITE_BITS (&bw, 1, 3);
+
+  if (!_h265_bit_writer_pps (pps, &bw, &have_space))
+    goto error;
+
+  /* Add trailings. */
+  WRITE_BITS (&bw, 1, 1);
+  if (!gst_bit_writer_align_bytes (&bw, 0)) {
+    have_space = FALSE;
+    goto error;
+  }
+
+  *size = gst_bit_writer_get_size (&bw) / 8;
+  gst_bit_writer_reset (&bw);
+
+  return GST_H265_BIT_WRITER_OK;
+
+error:
+  gst_bit_writer_reset (&bw);
+  *size = 0;
+
+  if (!have_space)
+    return GST_H265_BIT_WRITER_NO_MORE_SPACE;
+  return GST_H265_BIT_WRITER_INVALID_DATA;
+}
+
+static gboolean
+_h265_slice_bit_writer_ref_pic_list_modification (const GstH265SliceHdr *
+    slice, gint NumPocTotalCurr, GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+  guint i;
+  const GstH265RefPicListModification *rpl_mod =
+      &slice->ref_pic_list_modification;
+  const guint n = ceil_log2 (NumPocTotalCurr);
+
+  WRITE_BITS (bw, rpl_mod->ref_pic_list_modification_flag_l0, 1);
+
+  if (rpl_mod->ref_pic_list_modification_flag_l0) {
+    for (i = 0; i <= slice->num_ref_idx_l0_active_minus1; i++) {
+      WRITE_BITS (bw, rpl_mod->list_entry_l0[i], n);
+    }
+  }
+
+  if (GST_H265_IS_B_SLICE (slice)) {
+    WRITE_BITS (bw, rpl_mod->ref_pic_list_modification_flag_l1, 1);
+
+    if (rpl_mod->ref_pic_list_modification_flag_l1)
+      for (i = 0; i <= slice->num_ref_idx_l1_active_minus1; i++) {
+        WRITE_BITS (bw, rpl_mod->list_entry_l1[i], n);
+      }
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write \"Reference picture list modifications\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h265_slice_bit_writer_pred_weight_table (const GstH265SliceHdr * slice,
+    GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+  const GstH265PredWeightTable *p;
+  const GstH265PPS *pps = slice->pps;
+  const GstH265SPS *sps = pps->sps;
+  gint i, j;
+
+  GST_DEBUG ("writing \"Prediction weight table\"");
+
+  p = &slice->pred_weight_table;
+
+  WRITE_UE_MAX (bw, p->luma_log2_weight_denom, 7);
+
+  if (sps->chroma_format_idc != 0) {
+    WRITE_SE_RANGE (bw, p->delta_chroma_log2_weight_denom,
+        (0 - p->luma_log2_weight_denom), (7 - p->luma_log2_weight_denom));
+  }
+
+  for (i = 0; i <= slice->num_ref_idx_l0_active_minus1; i++)
+    WRITE_BITS (bw, p->luma_weight_l0_flag[i], 1);
+
+  if (sps->chroma_format_idc != 0)
+    for (i = 0; i <= slice->num_ref_idx_l0_active_minus1; i++)
+      WRITE_BITS (bw, p->chroma_weight_l0_flag[i], 1);
+
+  for (i = 0; i <= slice->num_ref_idx_l0_active_minus1; i++) {
+    if (p->luma_weight_l0_flag[i]) {
+      WRITE_SE_RANGE (bw, p->delta_luma_weight_l0[i], -128, 127);
+      WRITE_SE_RANGE (bw, p->luma_offset_l0[i], -128, 127);
+    }
+    if (p->chroma_weight_l0_flag[i])
+      for (j = 0; j < 2; j++) {
+        WRITE_SE_RANGE (bw, p->delta_chroma_weight_l0[i][j], -128, 127);
+        WRITE_SE_RANGE (bw, p->delta_chroma_offset_l0[i][j], -512, 511);
+      }
+  }
+
+  if (GST_H265_IS_B_SLICE (slice)) {
+    for (i = 0; i <= slice->num_ref_idx_l1_active_minus1; i++)
+      WRITE_BITS (bw, p->luma_weight_l1_flag[i], 1);
+
+    if (sps->chroma_format_idc != 0)
+      for (i = 0; i <= slice->num_ref_idx_l1_active_minus1; i++)
+        WRITE_BITS (bw, p->chroma_weight_l1_flag[i], 1);
+
+    for (i = 0; i <= slice->num_ref_idx_l1_active_minus1; i++) {
+      if (p->luma_weight_l1_flag[i]) {
+        WRITE_SE_RANGE (bw, p->delta_luma_weight_l1[i], -128, 127);
+        WRITE_SE_RANGE (bw, p->luma_offset_l1[i], -128, 127);
+      }
+      if (p->chroma_weight_l1_flag[i])
+        for (j = 0; j < 2; j++) {
+          WRITE_SE_RANGE (bw, p->delta_chroma_weight_l1[i][j], -128, 127);
+          WRITE_SE_RANGE (bw, p->delta_chroma_offset_l1[i][j], -512, 511);
+        }
+    }
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write \"Prediction weight table\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h265_bit_writer_slice_header (const GstH265SliceHdr * slice,
+    guint32 nal_type, GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+  guint i;
+  const GstH265SPS *sps = slice->pps->sps;
+  const GstH265PPSSccExtensionParams *pps_scc_extension_params =
+      &slice->pps->pps_scc_extension_params;
+  const GstH265PPSExtensionParams *pps_extension_params =
+      &slice->pps->pps_extension_params;
+
+  GST_DEBUG ("writing slice header");
+
+  WRITE_BITS (bw, slice->first_slice_segment_in_pic_flag, 1);
+
+  if (GST_H265_IS_NAL_TYPE_IRAP (nal_type))
+    WRITE_BITS (bw, slice->no_output_of_prior_pics_flag, 1);
+
+  WRITE_UE_MAX (bw, slice->pps->id, GST_H265_MAX_PPS_COUNT - 1);
+
+  if (!slice->first_slice_segment_in_pic_flag) {
+    guint32 PicSizeInCtbsY;
+    guint32 PicWidthInCtbsY;
+    guint32 PicHeightInCtbsY;
+    guint32 CtbSizeY, MinCbLog2SizeY, CtbLog2SizeY;
+    guint n;
+
+    /* We can not directly use slice->pps->PicWidthInCtbsY/PicHeightInCtbsY,
+       they are calculated value when parsing but may not have value here. */
+    MinCbLog2SizeY = sps->log2_min_luma_coding_block_size_minus3 + 3;
+    CtbLog2SizeY =
+        MinCbLog2SizeY + sps->log2_diff_max_min_luma_coding_block_size;
+    CtbSizeY = 1 << CtbLog2SizeY;
+    PicHeightInCtbsY =
+        ceil ((gdouble) sps->pic_height_in_luma_samples / (gdouble) CtbSizeY);
+    PicWidthInCtbsY =
+        ceil ((gdouble) sps->pic_width_in_luma_samples / (gdouble) CtbSizeY);
+    PicSizeInCtbsY = PicWidthInCtbsY * PicHeightInCtbsY;
+
+    n = ceil_log2 (PicSizeInCtbsY);
+
+    if (slice->pps->dependent_slice_segments_enabled_flag)
+      WRITE_BITS (bw, slice->dependent_slice_segment_flag, 1);
+    /* sice_segment_address parsing */
+    WRITE_BITS (bw, slice->segment_address, n);
+  }
+
+  if (!slice->dependent_slice_segment_flag) {
+    for (i = 0; i < slice->pps->num_extra_slice_header_bits; i++) {
+      /* slice_reserved_flag */
+      WRITE_BITS (bw, 0, 1);
+    }
+
+    WRITE_UE_MAX (bw, slice->type, 63);
+
+    if (slice->pps->output_flag_present_flag)
+      WRITE_BITS (bw, slice->pic_output_flag, 1);
+
+    if (sps->separate_colour_plane_flag == 1)
+      WRITE_BITS (bw, slice->colour_plane_id, 2);
+
+    if (!GST_H265_IS_NAL_TYPE_IDR (nal_type)) {
+      WRITE_BITS (bw, slice->pic_order_cnt_lsb,
+          (sps->log2_max_pic_order_cnt_lsb_minus4 + 4));
+
+      WRITE_BITS (bw, slice->short_term_ref_pic_set_sps_flag, 1);
+      if (!slice->short_term_ref_pic_set_sps_flag) {
+        if (!_h265_bit_writer_short_term_ref_pic_set
+            (&slice->short_term_ref_pic_sets, sps->num_short_term_ref_pic_sets,
+                slice->pps->sps, bw, &have_space))
+          goto error;
+      } else if (sps->num_short_term_ref_pic_sets > 1) {
+        const guint n = ceil_log2 (sps->num_short_term_ref_pic_sets);
+
+        if (slice->short_term_ref_pic_set_idx >
+            sps->num_short_term_ref_pic_sets - 1)
+          goto error;
+
+        WRITE_BITS (bw, slice->short_term_ref_pic_set_idx, n);
+      }
+
+      if (sps->long_term_ref_pics_present_flag) {
+        guint32 limit;
+
+        if (sps->num_long_term_ref_pics_sps > 0)
+          WRITE_UE_MAX (bw, slice->num_long_term_sps,
+              sps->num_long_term_ref_pics_sps);
+
+        WRITE_UE_MAX (bw, slice->num_long_term_pics, 16);
+        limit = slice->num_long_term_sps + slice->num_long_term_pics;
+        for (i = 0; i < limit; i++) {
+          if (i < slice->num_long_term_sps) {
+            if (sps->num_long_term_ref_pics_sps > 1) {
+              const guint n = ceil_log2 (sps->num_long_term_ref_pics_sps);
+              WRITE_BITS (bw, slice->lt_idx_sps[i], n);
+            }
+          } else {
+            WRITE_BITS (bw, slice->poc_lsb_lt[i],
+                (sps->log2_max_pic_order_cnt_lsb_minus4 + 4));
+            WRITE_BITS (bw, slice->used_by_curr_pic_lt_flag[i], 1);
+          }
+
+          WRITE_BITS (bw, slice->delta_poc_msb_present_flag[i], 1);
+          if (slice->delta_poc_msb_present_flag[i])
+            WRITE_UE (bw, slice->delta_poc_msb_cycle_lt[i]);
+        }
+      }
+
+      if (sps->temporal_mvp_enabled_flag)
+        WRITE_BITS (bw, slice->temporal_mvp_enabled_flag, 1);
+    }
+
+    if (sps->sample_adaptive_offset_enabled_flag) {
+      gboolean ChromaArrayType =
+          sps->separate_colour_plane_flag == 0 ? sps->chroma_format_idc : 0;
+
+      WRITE_BITS (bw, slice->sao_luma_flag, 1);
+      if (ChromaArrayType)
+        WRITE_BITS (bw, slice->sao_chroma_flag, 1);
+    }
+
+    if (GST_H265_IS_B_SLICE (slice) || GST_H265_IS_P_SLICE (slice)) {
+      WRITE_BITS (bw, slice->num_ref_idx_active_override_flag, 1);
+
+      if (slice->num_ref_idx_active_override_flag) {
+        WRITE_UE_MAX (bw, slice->num_ref_idx_l0_active_minus1, 14);
+        if (GST_H265_IS_B_SLICE (slice))
+          WRITE_UE_MAX (bw, slice->num_ref_idx_l1_active_minus1, 14);
+      }
+
+      if (slice->pps->lists_modification_present_flag
+          && slice->NumPocTotalCurr > 1) {
+        if (!_h265_slice_bit_writer_ref_pic_list_modification (slice,
+                slice->NumPocTotalCurr, bw, &have_space))
+          goto error;
+      }
+
+      if (GST_H265_IS_B_SLICE (slice))
+        WRITE_BITS (bw, slice->mvd_l1_zero_flag, 1);
+
+      if (slice->pps->cabac_init_present_flag)
+        WRITE_BITS (bw, slice->cabac_init_flag, 1);
+
+      if (slice->temporal_mvp_enabled_flag) {
+        if (GST_H265_IS_B_SLICE (slice))
+          WRITE_BITS (bw, slice->collocated_from_l0_flag, 1);
+
+        if ((slice->collocated_from_l0_flag
+                && slice->num_ref_idx_l0_active_minus1 > 0)
+            || (!slice->collocated_from_l0_flag
+                && slice->num_ref_idx_l1_active_minus1 > 0)) {
+          if ((GST_H265_IS_P_SLICE (slice))
+              || ((GST_H265_IS_B_SLICE (slice))
+                  && (slice->collocated_from_l0_flag))) {
+            WRITE_UE_MAX (bw, slice->collocated_ref_idx,
+                slice->num_ref_idx_l0_active_minus1);
+          } else if ((GST_H265_IS_B_SLICE (slice))
+              && (!slice->collocated_from_l0_flag)) {
+            WRITE_UE_MAX (bw, slice->collocated_ref_idx,
+                slice->num_ref_idx_l1_active_minus1);
+          }
+        }
+      }
+
+      if ((slice->pps->weighted_pred_flag && GST_H265_IS_P_SLICE (slice)) ||
+          (slice->pps->weighted_bipred_flag && GST_H265_IS_B_SLICE (slice)))
+        if (!_h265_slice_bit_writer_pred_weight_table (slice, bw, &have_space))
+          goto error;
+
+      WRITE_UE_MAX (bw, slice->five_minus_max_num_merge_cand, 4);
+
+      if (sps->sps_scc_extension_params.motion_vector_resolution_control_idc
+          == 2)
+        WRITE_BITS (bw, slice->use_integer_mv_flag, 1);
+    }
+
+    WRITE_SE_RANGE (bw, slice->qp_delta, -87, 77);
+    if (slice->pps->slice_chroma_qp_offsets_present_flag) {
+      WRITE_SE_RANGE (bw, slice->cb_qp_offset, -12, 12);
+      WRITE_SE_RANGE (bw, slice->cr_qp_offset, -12, 12);
+    }
+
+    if (pps_scc_extension_params->pps_slice_act_qp_offsets_present_flag) {
+      WRITE_SE_RANGE (bw, slice->slice_act_y_qp_offset, -12, 12);
+      WRITE_SE_RANGE (bw, slice->slice_act_cb_qp_offset, -12, 12);
+      WRITE_SE_RANGE (bw, slice->slice_act_cr_qp_offset, -12, 12);
+    }
+
+    if (pps_extension_params->chroma_qp_offset_list_enabled_flag)
+      WRITE_BITS (bw, slice->cu_chroma_qp_offset_enabled_flag, 1);
+
+    if (slice->pps->deblocking_filter_override_enabled_flag)
+      WRITE_BITS (bw, slice->deblocking_filter_override_flag, 1);
+
+    if (slice->deblocking_filter_override_flag) {
+      WRITE_BITS (bw, slice->deblocking_filter_disabled_flag, 1);
+
+      if (!slice->deblocking_filter_disabled_flag) {
+        WRITE_SE_RANGE (bw, slice->beta_offset_div2, -6, 6);
+        WRITE_SE_RANGE (bw, slice->tc_offset_div2, -6, 6);
+      }
+    }
+
+    if (slice->pps->loop_filter_across_slices_enabled_flag &&
+        (slice->sao_luma_flag || slice->sao_chroma_flag ||
+            !slice->deblocking_filter_disabled_flag))
+      WRITE_BITS (bw, slice->loop_filter_across_slices_enabled_flag, 1);
+  }
+
+  if (slice->pps->tiles_enabled_flag
+      || slice->pps->entropy_coding_sync_enabled_flag) {
+    guint32 offset_max;
+
+    if (!slice->pps->tiles_enabled_flag
+        && slice->pps->entropy_coding_sync_enabled_flag) {
+      offset_max = slice->pps->PicHeightInCtbsY - 1;
+    } else if (slice->pps->tiles_enabled_flag
+        && !slice->pps->entropy_coding_sync_enabled_flag) {
+      offset_max =
+          (slice->pps->num_tile_columns_minus1 +
+          1) * (slice->pps->num_tile_rows_minus1 + 1) - 1;
+    } else {
+      offset_max =
+          (slice->pps->num_tile_columns_minus1 +
+          1) * slice->pps->PicHeightInCtbsY - 1;
+    }
+
+    WRITE_UE_MAX (bw, slice->num_entry_point_offsets, offset_max);
+    if (slice->num_entry_point_offsets > 0) {
+      WRITE_UE_MAX (bw, slice->offset_len_minus1, 31);
+      for (i = 0; i < slice->num_entry_point_offsets; i++)
+        WRITE_BITS (bw, slice->entry_point_offset_minus1[i],
+            (slice->offset_len_minus1 + 1));
+    }
+  }
+
+  /* TODO */
+  if (slice->pps->slice_segment_header_extension_present_flag) {
+    GST_WARNING
+        ("slice_segment_header_extension_present_flag is not supported");
+    goto error;
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write slice header");
+
+  *space = have_space;
+  return FALSE;
+}
+
+/**
+ * gst_h265_bit_writer_slice_hdr:
+ * @slice: the slice header of #GstH265SliceHdr to write
+ * @start_code: whether adding the nal start code
+ * @nal_type: the slice's nal type of #GstH265NalUnitType
+ * @data: (out): the bit stream generated by the slice header
+ * @size: (inout): the size in bytes of the input and output
+ *
+ * Generating the according h265 bit stream by providing the slice header.
+ *
+ * Returns: a #GstH265BitWriterResult
+ *
+ * Since: 1.22
+ **/
+GstH265BitWriterResult
+gst_h265_bit_writer_slice_hdr (const GstH265SliceHdr * slice,
+    gboolean start_code, guint32 nal_type, guint8 * data, guint * size)
+{
+  gboolean have_space = TRUE;
+  GstBitWriter bw;
+
+  g_return_val_if_fail (slice != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (slice->pps != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (slice->pps->sps != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (data != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (size != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (*size > 0, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (nal_type >= GST_H265_NAL_SLICE_TRAIL_N &&
+      nal_type <= GST_H265_NAL_SLICE_CRA_NUT, GST_H265_BIT_WRITER_ERROR);
+
+  gst_bit_writer_init_with_data (&bw, data, *size, FALSE);
+
+  if (start_code)
+    WRITE_BITS (&bw, 0x00000001, 32);
+
+  /* NAL unit header */
+  /* forbidden_zero_bit */
+  WRITE_BITS (&bw, 0, 1);
+  /* nal_unit_type */
+  WRITE_BITS (&bw, nal_type, 6);
+  /* nuh_layer_id, only support 0 now */
+  WRITE_BITS (&bw, 0, 6);
+  /* nuh_temporal_id_plus1, only support 1 now */
+  WRITE_BITS (&bw, 1, 3);
+
+  if (!_h265_bit_writer_slice_header (slice, nal_type, &bw, &have_space))
+    goto error;
+
+  /* Add trailings. */
+  WRITE_BITS (&bw, 1, 1);
+  if (!gst_bit_writer_align_bytes (&bw, 0)) {
+    have_space = FALSE;
+    goto error;
+  }
+
+  *size = gst_bit_writer_get_size (&bw) / 8;
+  gst_bit_writer_reset (&bw);
+  return GST_H265_BIT_WRITER_OK;
+
+error:
+  gst_bit_writer_reset (&bw);
+  *size = 0;
+
+  if (!have_space)
+    return GST_H265_BIT_WRITER_NO_MORE_SPACE;
+  return GST_H265_BIT_WRITER_INVALID_DATA;
+}
+
+
+static gboolean
+_h265_bit_writer_sei_registered_user_data (const GstH265RegisteredUserData *
+    rud, GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+
+  GST_DEBUG ("Writing \"Registered user data\"");
+
+  WRITE_BITS (bw, rud->country_code, 8);
+  if (rud->country_code == 0xff)
+    WRITE_BITS (bw, rud->country_code_extension, 8);
+
+  WRITE_BYTES (bw, rud->data, rud->size);
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_DEBUG ("Failed to write \"Registered user data\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h265_bit_writer_sei_time_code (const GstH265TimeCode * tc,
+    GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+  gint i;
+
+  GST_DEBUG ("Wrtiting \"Time code\"");
+
+  WRITE_BITS (bw, tc->num_clock_ts, 2);
+
+  for (i = 0; i < tc->num_clock_ts; i++) {
+    WRITE_BITS (bw, tc->clock_timestamp_flag[i], 1);
+    if (tc->clock_timestamp_flag[i]) {
+      WRITE_BITS (bw, tc->units_field_based_flag[i], 1);
+      WRITE_BITS (bw, tc->counting_type[i], 5);
+      WRITE_BITS (bw, tc->full_timestamp_flag[i], 1);
+      WRITE_BITS (bw, tc->discontinuity_flag[i], 1);
+      WRITE_BITS (bw, tc->cnt_dropped_flag[i], 1);
+      WRITE_BITS (bw, tc->n_frames[i], 9);
+
+      if (tc->full_timestamp_flag[i]) {
+        WRITE_BITS (bw, tc->seconds_value[i], 6);
+        WRITE_BITS (bw, tc->minutes_value[i], 6);
+        WRITE_BITS (bw, tc->hours_value[i], 5);
+      } else {
+        WRITE_BITS (bw, tc->seconds_flag[i], 1);
+        if (tc->seconds_flag[i]) {
+          WRITE_BITS (bw, tc->seconds_value[i], 6);
+          WRITE_BITS (bw, tc->minutes_flag[i], 1);
+          if (tc->minutes_flag[i]) {
+            WRITE_BITS (bw, tc->minutes_value[i], 6);
+            WRITE_BITS (bw, tc->hours_flag[i], 1);
+            if (tc->hours_flag[i]) {
+              WRITE_BITS (bw, tc->hours_value[i], 5);
+            }
+          }
+        }
+      }
+    }
+
+    WRITE_BITS (bw, tc->time_offset_length[i], 5);
+
+    if (tc->time_offset_length[i] > 0)
+      WRITE_BITS (bw, tc->time_offset_value[i], tc->time_offset_length[i]);
+  }
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("Failed to write \"Time code\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h265_bit_writer_sei_mastering_display_colour_volume (const
+    GstH265MasteringDisplayColourVolume * mdcv, GstBitWriter * bw,
+    gboolean * space)
+{
+  gboolean have_space = TRUE;
+  gint i;
+
+  GST_DEBUG ("Wrtiting \"Mastering display colour volume\"");
+
+  for (i = 0; i < 3; i++) {
+    WRITE_BITS (bw, mdcv->display_primaries_x[i], 16);
+    WRITE_BITS (bw, mdcv->display_primaries_y[i], 16);
+  }
+
+  WRITE_BITS (bw, mdcv->white_point_x, 16);
+  WRITE_BITS (bw, mdcv->white_point_y, 16);
+  WRITE_BITS (bw, mdcv->max_display_mastering_luminance, 32);
+  WRITE_BITS (bw, mdcv->min_display_mastering_luminance, 32);
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("Failed to write \"Mastering display colour volume\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h265_bit_writer_sei_content_light_level_info (const
+    GstH265ContentLightLevel * cll, GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+
+  GST_DEBUG ("Writing \"Content light level\"");
+
+  WRITE_BITS (bw, cll->max_content_light_level, 16);
+  WRITE_BITS (bw, cll->max_pic_average_light_level, 16);
+
+  *space = TRUE;
+  return TRUE;
+
+error:
+  GST_WARNING ("Failed to write \"Content light level\"");
+
+  *space = have_space;
+  return FALSE;
+}
+
+static gboolean
+_h265_bit_writer_sei_message (const GstH265SEIMessage * msg,
+    GstBitWriter * bw, gboolean * space)
+{
+  gboolean have_space = TRUE;
+
+  GST_DEBUG ("writing SEI message");
+
+  switch (msg->payloadType) {
+    case GST_H265_SEI_REGISTERED_USER_DATA:
+      if (!_h265_bit_writer_sei_registered_user_data
+          (&msg->payload.registered_user_data, bw, &have_space))
+        goto error;
+      break;
+    case GST_H265_SEI_TIME_CODE:
+      if (!_h265_bit_writer_sei_time_code
+          (&msg->payload.time_code, bw, &have_space))
+        goto error;
+      break;
+    case GST_H265_SEI_MASTERING_DISPLAY_COLOUR_VOLUME:
+      if (!_h265_bit_writer_sei_mastering_display_colour_volume
+          (&msg->payload.mastering_display_colour_volume, bw, &have_space))
+        goto error;
+      break;
+    case GST_H265_SEI_CONTENT_LIGHT_LEVEL:
+      if (!_h265_bit_writer_sei_content_light_level_info
+          (&msg->payload.content_light_level, bw, &have_space))
+        goto error;
+      break;
+    default:
+      break;
+  }
+
+  /* Add trailings. */
+  WRITE_BITS (bw, 1, 1);
+  gst_bit_writer_align_bytes_unchecked (bw, 0);
+
+  *space = TRUE;
+
+  return TRUE;
+
+error:
+  GST_WARNING ("error to write SEI message");
+
+  *space = have_space;
+  return FALSE;
+}
+
+/**
+ * gst_h265_bit_writer_sei:
+ * @sei_messages: An array of #GstH265SEIMessage to write
+ * @start_code: whether adding the nal start code
+ * @data: (out): the bit stream generated by the sei messages
+ * @size: (inout): the size in bytes of the input and output
+ *
+ * Generating the according h265 bit stream by providing sei messages.
+ *
+ * Returns: a #GstH265BitWriterResult
+ *
+ * Since: 1.22
+ **/
+GstH265BitWriterResult
+gst_h265_bit_writer_sei (GArray * sei_messages,
+    GstH265NalUnitType nal_type, gboolean start_code, guint8 * data,
+    guint * size)
+{
+  gboolean have_space = TRUE;
+  GstBitWriter bw;
+  GstH265SEIMessage *sei;
+  gboolean have_written_data = FALSE;
+  guint i;
+
+  g_return_val_if_fail (sei_messages != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (nal_type == GST_H265_NAL_PREFIX_SEI
+      || nal_type == GST_H265_NAL_SUFFIX_SEI, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (data != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (size != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (*size > 0, GST_H265_BIT_WRITER_ERROR);
+
+  if (nal_type == GST_H265_NAL_PREFIX_SEI) {
+    GST_WARNING ("prefix sei is not supported");
+    return GST_H265_BIT_WRITER_ERROR;
+  }
+
+  gst_bit_writer_init_with_data (&bw, data, *size, FALSE);
+
+  if (start_code)
+    WRITE_BITS (&bw, 0x00000001, 32);
+
+  /* NAL unit header */
+  /* forbidden_zero_bit */
+  WRITE_BITS (&bw, 0, 1);
+  /* nal_unit_type */
+  WRITE_BITS (&bw, nal_type, 6);
+  /* nuh_layer_id, only support 0 now */
+  WRITE_BITS (&bw, 0, 6);
+  /* nuh_temporal_id_plus1, only support 1 now */
+  WRITE_BITS (&bw, 1, 3);
+
+  for (i = 0; i < sei_messages->len; i++) {
+    guint32 payload_size_data;
+    guint32 payload_type_data;
+
+    gst_bit_writer_init (&bw);
+
+    sei = &g_array_index (sei_messages, GstH265SEIMessage, i);
+    if (!_h265_bit_writer_sei_message (sei, &bw, &have_space))
+      goto error;
+
+    if (gst_bit_writer_get_size (&bw) == 0) {
+      GST_FIXME ("Unsupported SEI type %d", sei->payloadType);
+      continue;
+    }
+
+    have_written_data = TRUE;
+
+    g_assert (gst_bit_writer_get_size (&bw) % 8 == 0);
+    payload_size_data = (gst_bit_writer_get_size (&bw) + 7) / 8;
+    payload_type_data = sei->payloadType;
+
+    /* write payload type bytes */
+    while (payload_type_data >= 0xff) {
+      WRITE_BITS (&bw, 0xff, 8);
+      payload_type_data -= -0xff;
+    }
+    WRITE_BITS (&bw, payload_type_data, 8);
+
+    /* write payload size bytes */
+    while (payload_size_data >= 0xff) {
+      WRITE_BITS (&bw, 0xff, 8);
+      payload_size_data -= -0xff;
+    }
+    WRITE_BITS (&bw, payload_size_data, 8);
+
+    if (gst_bit_writer_get_size (&bw) / 8)
+      WRITE_BYTES (&bw, gst_bit_writer_get_data (&bw),
+          gst_bit_writer_get_size (&bw) / 8);
+
+    gst_bit_writer_reset (&bw);
+  }
+
+  if (!have_written_data) {
+    GST_WARNING ("No written sei data");
+    goto error;
+  }
+
+  /* Add trailings. */
+  WRITE_BITS (&bw, 1, 1);
+  if (!gst_bit_writer_align_bytes (&bw, 0)) {
+    have_space = FALSE;
+    goto error;
+  }
+
+  *size = gst_bit_writer_get_size (&bw) / 8;
+  gst_bit_writer_reset (&bw);
+  return GST_H265_BIT_WRITER_OK;
+
+error:
+  gst_bit_writer_reset (&bw);
+  *size = 0;
+
+  if (!have_space)
+    return GST_H265_BIT_WRITER_NO_MORE_SPACE;
+  return GST_H265_BIT_WRITER_INVALID_DATA;
+}
+
+/**
+ * gst_h265_bit_writer_aud:
+ * @pic_type: indicate the possible slice types list just
+ *   as the H265 spec Table 7-2 defines
+ * @start_code: whether adding the nal start code
+ * @data: (out): the bit stream generated by the aud
+ * @size: (inout): the size in bytes of the input and output
+ *
+ * Generating the according h265 bit stream of an aud.
+ *
+ * Returns: a #GstH265BitWriterResult
+ *
+ * Since: 1.22
+ **/
+GstH265BitWriterResult
+gst_h265_bit_writer_aud (guint8 pic_type, gboolean start_code,
+    guint8 * data, guint * size)
+{
+  gboolean have_space = TRUE;
+  GstBitWriter bw;
+
+  g_return_val_if_fail (pic_type <= 2, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (data != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (size != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (*size > 0, GST_H265_BIT_WRITER_ERROR);
+
+  gst_bit_writer_init_with_data (&bw, data, *size, FALSE);
+
+  if (start_code)
+    WRITE_BITS (&bw, 0x00000001, 32);
+
+  /* NAL unit header */
+  /* forbidden_zero_bit */
+  WRITE_BITS (&bw, 0, 1);
+  /* nal_unit_type */
+  WRITE_BITS (&bw, GST_H265_NAL_AUD, 6);
+  /* nuh_layer_id, only support 0 now */
+  WRITE_BITS (&bw, 0, 6);
+  /* nuh_temporal_id_plus1, only support 1 now */
+  WRITE_BITS (&bw, 1, 3);
+
+  WRITE_BITS (&bw, pic_type, 3);
+
+  /* Add trailings. */
+  WRITE_BITS (&bw, 1, 1);
+  if (!gst_bit_writer_align_bytes (&bw, 0)) {
+    goto error;
+  }
+
+  *size = gst_bit_writer_get_size (&bw) / 8;
+  gst_bit_writer_reset (&bw);
+
+  return GST_H265_BIT_WRITER_OK;
+
+error:
+  gst_bit_writer_reset (&bw);
+  *size = 0;
+
+  if (!have_space)
+    return GST_H265_BIT_WRITER_NO_MORE_SPACE;
+  return GST_H265_BIT_WRITER_INVALID_DATA;
+}
+
+/**
+ * gst_h265_bit_writer_convert_to_nal:
+ * @nal_prefix_size: the size in bytes for the prefix of a nal, may
+ *   be 2, 3 or 4
+ * @packetized: whether to write the bit stream in packetized format,
+ *   which does not have the start code but has a @nal_prefix_size bytes'
+ *   size prepending to the real nal data
+ * @has_startcode: whether the input already has a start code
+ * @add_trailings: whether to add rbsp trailing bits to make the output
+ *   aligned to byte
+ * @raw_data: the input bit stream
+ * @raw_size: the size in bits of the input bit stream
+ * @nal_data: (out): the output bit stream converted to a real nal
+ * @nal_size: (inout): the size in bytes of the output
+ *
+ * Converting a bit stream into a real nal packet. If the bit stream already
+ * has a start code, it will be replaced by the new one specified by the
+ * @nal_prefix_size and @packetized. It is assured that the output aligns to
+ * the byte and the all the emulations are inserted.
+ *
+ * Returns: a #GstH265BitWriterResult
+ *
+ * Since: 1.22
+ **/
+GstH265BitWriterResult
+gst_h265_bit_writer_convert_to_nal (guint nal_prefix_size,
+    gboolean packetized, gboolean has_startcode, gboolean add_trailings,
+    const guint8 * raw_data, gsize raw_size, guint8 * nal_data,
+    guint * nal_size)
+{
+  NalWriter nw;
+  guint8 *data;
+  guint32 size = 0;
+  gboolean need_more_space = FALSE;
+
+  g_return_val_if_fail (
+      (packetized && nal_prefix_size > 1 && nal_prefix_size < 5) ||
+      (!packetized && (nal_prefix_size == 3 || nal_prefix_size == 4)),
+      GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (raw_data != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (raw_size > 0, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (nal_data != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (nal_size != NULL, GST_H265_BIT_WRITER_ERROR);
+  g_return_val_if_fail (*nal_size > 0, GST_H265_BIT_WRITER_ERROR);
+
+  if (has_startcode) {
+    /* Skip the start code, the NalWriter will add it automatically. */
+    if (raw_size >= 4 && raw_data[0] == 0
+        && raw_data[1] == 0 && raw_data[2] == 0 && raw_data[3] == 0x01) {
+      raw_data += 4;
+      raw_size -= 4 * 8;
+    } else if (raw_size >= 3 && raw_data[0] == 0 && raw_data[1] == 0
+        && raw_data[2] == 0x01) {
+      raw_data += 3;
+      raw_size -= 3 * 8;
+    } else {
+      /* Fail to find the start code. */
+      g_return_val_if_reached (GST_H265_BIT_WRITER_ERROR);
+    }
+  }
+
+  /* If no RBSP trailing needed, it must align to byte. We assume
+     that the rbsp trailing bits are already added. */
+  if (!add_trailings)
+    g_return_val_if_fail (raw_size % 8 == 0, GST_H265_BIT_WRITER_ERROR);
+
+  nal_writer_init (&nw, nal_prefix_size, packetized);
+
+  if (!nal_writer_put_bytes (&nw, raw_data, raw_size / 8))
+    goto error;
+
+  if (raw_size % 8) {
+    guint8 data = *(raw_data + raw_size / 8);
+
+    if (!nal_writer_put_bits_uint8 (&nw,
+            data >> (8 - raw_size % 8), raw_size % 8))
+      goto error;
+  }
+
+  if (add_trailings) {
+    if (!nal_writer_do_rbsp_trailing_bits (&nw))
+      goto error;
+  }
+
+  data = nal_writer_reset_and_get_data (&nw, &size);
+  if (!data)
+    goto error;
+
+  if (size > *nal_size) {
+    need_more_space = TRUE;
+    g_free (data);
+    goto error;
+  }
+
+  memcpy (nal_data, data, size);
+  *nal_size = size;
+  g_free (data);
+  nal_writer_reset (&nw);
+  return GST_H265_BIT_WRITER_OK;
+
+error:
+  nal_writer_reset (&nw);
+  *nal_size = 0;
+
+  GST_WARNING ("Failed to convert nal data");
+
+  if (need_more_space)
+    return GST_H265_BIT_WRITER_NO_MORE_SPACE;
+  return GST_H265_BIT_WRITER_INVALID_DATA;
+}
diff --git a/gst-libs/gst/codecparsers/gsth265bitwriter.h b/gst-libs/gst/codecparsers/gsth265bitwriter.h
new file mode 100644
index 000000000..88da8104c
--- /dev/null
+++ b/gst-libs/gst/codecparsers/gsth265bitwriter.h
@@ -0,0 +1,93 @@
+/* GStreamer
+ *  Copyright (C) 2021 Intel Corporation
+ *     Author: He Junyan <junyan.he@intel.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the0
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef __GST_H265_BIT_WRITER_H__
+#define __GST_H265_BIT_WRITER_H__
+
+#include <gst/codecparsers/gsth265parser.h>
+#include <gst/codecparsers/codecparsers-prelude.h>
+
+G_BEGIN_DECLS
+
+/**
+ * GstH265BitWriterResult:
+ * @GST_H265_BIT_WRITER_OK: The writing succeeded
+ * @GST_H265_BIT_WRITER_INVALID_DATA: The input data to write is invalid
+ * @GST_H265_BIT_WRITER_NO_MORE_SPACE: The output does not have enough size
+ * @GST_H265_BIT_WRITER_ERROR: An general error occurred when writing
+ *
+ * The result of writing H265 data into bit stream.
+ *
+ * Since: 1.22
+ */
+typedef enum
+{
+  GST_H265_BIT_WRITER_OK,
+  GST_H265_BIT_WRITER_INVALID_DATA,
+  GST_H265_BIT_WRITER_NO_MORE_SPACE,
+  GST_H265_BIT_WRITER_ERROR
+} GstH265BitWriterResult;
+
+GST_CODEC_PARSERS_API
+GstH265BitWriterResult    gst_h265_bit_writer_vps      (const GstH265VPS * vps,
+                                                        gboolean start_code,
+                                                        guint8 * data,
+                                                        guint * size);
+GST_CODEC_PARSERS_API
+GstH265BitWriterResult    gst_h265_bit_writer_sps      (const GstH265SPS * sps,
+                                                        gboolean start_code,
+                                                        guint8 * data,
+                                                        guint * size);
+GST_CODEC_PARSERS_API
+GstH265BitWriterResult    gst_h265_bit_writer_pps      (const GstH265PPS * pps,
+                                                        gboolean start_code,
+                                                        guint8 * data,
+                                                        guint * size);
+GST_CODEC_PARSERS_API
+GstH265BitWriterResult    gst_h265_bit_writer_slice_hdr (const GstH265SliceHdr * slice,
+                                                         gboolean start_code,
+                                                         guint32 nal_type,
+                                                         guint8 * data,
+                                                         guint * size);
+GST_CODEC_PARSERS_API
+GstH265BitWriterResult    gst_h265_bit_writer_sei       (GArray * sei_messages,
+                                                         GstH265NalUnitType nal_type,
+                                                         gboolean start_code,
+                                                         guint8 * data,
+                                                         guint * size);
+
+GST_CODEC_PARSERS_API
+GstH265BitWriterResult    gst_h265_bit_writer_aud       (guint8 pic_type,
+                                                         gboolean start_code,
+                                                         guint8 * data,
+                                                         guint * size);
+
+GST_CODEC_PARSERS_API
+GstH265BitWriterResult    gst_h265_bit_writer_convert_to_nal (guint nal_prefix_size,
+                                                              gboolean packetized,
+                                                              gboolean has_startcode,
+                                                              gboolean add_trailings,
+                                                              const guint8 * raw_data,
+                                                              gsize raw_size,
+                                                              guint8 * nal_data,
+                                                              guint * nal_size);
+G_END_DECLS
+
+#endif /* __GST_H265_BIT_WRITER_H__ */
diff --git a/gst-libs/gst/codecparsers/gsth265parser.c b/gst-libs/gst/codecparsers/gsth265parser.c
index dc7f27aa9..d232ba9f9 100644
--- a/gst-libs/gst/codecparsers/gsth265parser.c
+++ b/gst-libs/gst/codecparsers/gsth265parser.c
@@ -597,10 +597,12 @@ gst_h265_parse_vui_parameters (GstH265SPS * sps, NalReader * nr)
     READ_UE_MAX (nr, vui->log2_max_mv_length_vertical, 15);
   }
 
+  vui->parsed = TRUE;
   return TRUE;
 
 error:
   GST_WARNING ("error parsing \"VUI Parameters\"");
+  vui->parsed = FALSE;
   return FALSE;
 }
 
@@ -940,7 +942,7 @@ gst_h265_slice_parse_ref_pic_list_modification (GstH265SliceHdr * slice,
   return TRUE;
 
 error:
-  GST_WARNING ("error parsing \"Prediction weight table\"");
+  GST_WARNING ("error parsing \"Reference picture list modifications\"");
   return FALSE;
 }
 
@@ -1581,6 +1583,179 @@ gst_h265_parser_identify_nalu_hevc (GstH265Parser * parser,
   return GST_H265_PARSER_OK;
 }
 
+/**
+ * gst_h265_parser_identify_and_split_nalu_hevc:
+ * @parser: a #GstH265Parser
+ * @data: The data to parse, must be the beging of the Nal unit
+ * @offset: the offset from which to parse @data
+ * @size: the size of @data
+ * @nal_length_size: the size in bytes of the HEVC nal length prefix.
+ * @nalus: a caller allocated GArray of #GstH265NalUnit where to store parsed nal headers
+ * @consumed: the size of consumed bytes
+ *
+ * Parses @data for packetized (e.g., hvc1/hev1) bitstream and
+ * sets @nalus. In addition to nal identifying process,
+ * this method scans start-code prefix to split malformed packet into
+ * actual nal chunks.
+ *
+ * Returns: a #GstH265ParserResult
+ *
+ * Since: 1.22
+ */
+GstH265ParserResult
+gst_h265_parser_identify_and_split_nalu_hevc (GstH265Parser * parser,
+    const guint8 * data, guint offset, gsize size, guint8 nal_length_size,
+    GArray * nalus, gsize * consumed)
+{
+  GstBitReader br;
+  guint nalu_size;
+  guint remaining;
+  guint off;
+  guint sc_size;
+
+  g_return_val_if_fail (data != NULL, GST_H265_PARSER_ERROR);
+  g_return_val_if_fail (nalus != NULL, GST_H265_PARSER_ERROR);
+  g_return_val_if_fail (nal_length_size > 0 && nal_length_size < 5,
+      GST_H265_PARSER_ERROR);
+
+  g_array_set_size (nalus, 0);
+
+  if (consumed)
+    *consumed = 0;
+
+  /* Would overflow guint below otherwise: the callers needs to ensure that
+   * this never happens */
+  if (offset > G_MAXUINT32 - nal_length_size) {
+    GST_WARNING ("offset + nal_length_size overflow");
+    return GST_H265_PARSER_BROKEN_DATA;
+  }
+
+  if (size < offset + nal_length_size) {
+    GST_DEBUG ("Can't parse, buffer has too small size %" G_GSIZE_FORMAT
+        ", offset %u", size, offset);
+    return GST_H265_PARSER_ERROR;
+  }
+
+  /* Read nal unit size and unwrap the size field */
+  gst_bit_reader_init (&br, data + offset, size - offset);
+  nalu_size = gst_bit_reader_get_bits_uint32_unchecked (&br,
+      nal_length_size * 8);
+
+  if (nalu_size < 2) {
+    GST_WARNING ("too small nal size %d", nalu_size);
+    return GST_H265_PARSER_BROKEN_DATA;
+  }
+
+  if (size < (gsize) nalu_size + nal_length_size) {
+    GST_WARNING ("larger nalu size %d than data size %" G_GSIZE_FORMAT,
+        nalu_size + nal_length_size, size);
+    return GST_H265_PARSER_BROKEN_DATA;
+  }
+
+  if (consumed)
+    *consumed = nalu_size + nal_length_size;
+
+  off = offset + nal_length_size;
+  remaining = nalu_size;
+  sc_size = nal_length_size;
+
+  /* Drop trailing start-code since it will not be scanned */
+  if (remaining >= 3) {
+    if (data[off + remaining - 1] == 0x01 && data[off + remaining - 2] == 0x00
+        && data[off + remaining - 3] == 0x00) {
+      remaining -= 3;
+
+      /* 4 bytes start-code */
+      if (remaining > 0 && data[off + remaining - 1] == 0x00)
+        remaining--;
+    }
+  }
+
+  /* Looping to split malformed nal units. nal-length field was dropped above
+   * so expected bitstream structure are:
+   *
+   * <complete nalu>
+   * | nalu |
+   * sc scan result will be -1 and handled in CONDITION-A
+   *
+   * <nalu with startcode prefix>
+   * | SC | nalu |
+   * Hit CONDITION-C first then terminated in CONDITION-A
+   *
+   * <first nal has no startcode but others have>
+   * | nalu | SC | nalu | ...
+   * CONDITION-B handles those cases
+   */
+  do {
+    GstH265NalUnit nalu;
+    gint sc_offset = -1;
+    guint skip_size = 0;
+
+    memset (&nalu, 0, sizeof (GstH265NalUnit));
+
+    /* startcode 3 bytes + minimum nal size 2 */
+    if (remaining >= 5)
+      sc_offset = scan_for_start_codes (data + off, remaining);
+
+    if (sc_offset < 0) {
+      if (remaining >= 2) {
+        /* CONDITION-A */
+        /* Last chunk */
+        nalu.size = remaining;
+        nalu.sc_offset = off - sc_size;
+        nalu.offset = off;
+        nalu.data = (guint8 *) data;
+        nalu.valid = TRUE;
+
+        gst_h265_parse_nalu_header (&nalu);
+        g_array_append_val (nalus, nalu);
+      }
+      break;
+    } else if ((sc_offset == 2 && data[off + sc_offset - 1] != 0)
+        || sc_offset > 2) {
+      /* CONDITION-B */
+      /* Found trailing startcode prefix */
+
+      nalu.size = sc_offset;
+      if (data[off + sc_offset - 1] == 0) {
+        /* 4 bytes start code */
+        nalu.size--;
+      }
+
+      nalu.sc_offset = off - sc_size;
+      nalu.offset = off;
+      nalu.data = (guint8 *) data;
+      nalu.valid = TRUE;
+
+      gst_h265_parse_nalu_header (&nalu);
+      g_array_append_val (nalus, nalu);
+    } else {
+      /* CONDITION-C */
+      /* startcode located at beginning of this chunk without actual nal data.
+       * skip this start code */
+    }
+
+    skip_size = sc_offset + 3;
+    if (skip_size >= remaining)
+      break;
+
+    /* no more nal-length bytes but 3bytes startcode */
+    sc_size = 3;
+    if (sc_offset > 0 && data[off + sc_offset - 1] == 0)
+      sc_size++;
+
+    remaining -= skip_size;
+    off += skip_size;
+  } while (remaining >= 2);
+
+  if (nalus->len > 0)
+    return GST_H265_PARSER_OK;
+
+  GST_WARNING ("No nal found");
+
+  return GST_H265_PARSER_BROKEN_DATA;
+}
+
 /**
  * gst_h265_parser_parse_nal:
  * @parser: a #GstH265Parser
@@ -1825,12 +2000,9 @@ gst_h265_parse_sps (GstH265Parser * parser, GstH265NalUnit * nalu,
     GstH265SPS * sps, gboolean parse_vui_params)
 {
   NalReader nr;
-  GstH265VPS *vps;
-  guint8 vps_id;
   guint i;
   guint subwc[] = { 1, 2, 2, 1, 1 };
   guint subhc[] = { 1, 2, 1, 1, 1 };
-  GstH265VUIParams *vui = NULL;
 
   GST_DEBUG ("parsing SPS");
 
@@ -1839,13 +2011,7 @@ gst_h265_parse_sps (GstH265Parser * parser, GstH265NalUnit * nalu,
 
   memset (sps, 0, sizeof (*sps));
 
-  READ_UINT8 (&nr, vps_id, 4);
-  vps = gst_h265_parser_get_vps (parser, vps_id);
-  if (!vps) {
-    GST_DEBUG ("couldn't find associated video parameter set with id: %d",
-        vps_id);
-  }
-  sps->vps = vps;
+  READ_UINT8 (&nr, sps->vps_id, 4);
 
   READ_UINT8 (&nr, sps->max_sub_layers_minus1, 3);
   READ_UINT8 (&nr, sps->temporal_id_nesting_flag, 1);
@@ -1946,11 +2112,9 @@ gst_h265_parse_sps (GstH265Parser * parser, GstH265NalUnit * nalu,
   READ_UINT8 (&nr, sps->strong_intra_smoothing_enabled_flag, 1);
   READ_UINT8 (&nr, sps->vui_parameters_present_flag, 1);
 
-  if (sps->vui_parameters_present_flag && parse_vui_params) {
+  if (sps->vui_parameters_present_flag && parse_vui_params)
     if (!gst_h265_parse_vui_parameters (sps, &nr))
       goto error;
-    vui = &sps->vui_params;
-  }
 
   READ_UINT8 (&nr, sps->sps_extension_flag, 1);
 
@@ -1964,20 +2128,21 @@ gst_h265_parse_sps (GstH265Parser * parser, GstH265NalUnit * nalu,
 
   if (sps->sps_range_extension_flag) {
     READ_UINT8 (&nr,
-        sps->sps_extnsion_params.transform_skip_rotation_enabled_flag, 1);
+        sps->sps_extension_params.transform_skip_rotation_enabled_flag, 1);
     READ_UINT8 (&nr,
-        sps->sps_extnsion_params.transform_skip_context_enabled_flag, 1);
-    READ_UINT8 (&nr, sps->sps_extnsion_params.implicit_rdpcm_enabled_flag, 1);
-    READ_UINT8 (&nr, sps->sps_extnsion_params.explicit_rdpcm_enabled_flag, 1);
+        sps->sps_extension_params.transform_skip_context_enabled_flag, 1);
+    READ_UINT8 (&nr, sps->sps_extension_params.implicit_rdpcm_enabled_flag, 1);
+    READ_UINT8 (&nr, sps->sps_extension_params.explicit_rdpcm_enabled_flag, 1);
     READ_UINT8 (&nr,
-        sps->sps_extnsion_params.extended_precision_processing_flag, 1);
-    READ_UINT8 (&nr, sps->sps_extnsion_params.intra_smoothing_disabled_flag, 1);
+        sps->sps_extension_params.extended_precision_processing_flag, 1);
+    READ_UINT8 (&nr, sps->sps_extension_params.intra_smoothing_disabled_flag,
+        1);
     READ_UINT8 (&nr,
-        sps->sps_extnsion_params.high_precision_offsets_enabled_flag, 1);
+        sps->sps_extension_params.high_precision_offsets_enabled_flag, 1);
     READ_UINT8 (&nr,
-        sps->sps_extnsion_params.persistent_rice_adaptation_enabled_flag, 1);
+        sps->sps_extension_params.persistent_rice_adaptation_enabled_flag, 1);
     READ_UINT8 (&nr,
-        sps->sps_extnsion_params.cabac_bypass_alignment_enabled_flag, 1);
+        sps->sps_extension_params.cabac_bypass_alignment_enabled_flag, 1);
   }
 
   if (sps->sps_multilayer_extension_flag) {
@@ -2002,22 +2167,25 @@ gst_h265_parse_sps (GstH265Parser * parser, GstH265NalUnit * nalu,
           128 - sps->sps_scc_extension_params.palette_max_size);
 
       READ_UINT8 (&nr,
-          sps->sps_scc_extension_params.
-          sps_palette_predictor_initializers_present_flag, 1);
-      if (sps->sps_scc_extension_params.
-          sps_palette_predictor_initializers_present_flag) {
+          sps->
+          sps_scc_extension_params.sps_palette_predictor_initializers_present_flag,
+          1);
+      if (sps->
+          sps_scc_extension_params.sps_palette_predictor_initializers_present_flag)
+      {
         guint comp;
         READ_UE_MAX (&nr,
-            sps->sps_scc_extension_params.
-            sps_num_palette_predictor_initializer_minus1,
+            sps->
+            sps_scc_extension_params.sps_num_palette_predictor_initializer_minus1,
             sps->sps_scc_extension_params.palette_max_size +
             sps->sps_scc_extension_params.delta_palette_max_predictor_size - 1);
 
         for (comp = 0; comp < (sps->chroma_format_idc == 0 ? 1 : 3); comp++) {
           guint num_bits;
           guint num =
-              sps->sps_scc_extension_params.
-              sps_num_palette_predictor_initializer_minus1 + 1;
+              sps->
+              sps_scc_extension_params.sps_num_palette_predictor_initializer_minus1
+              + 1;
 
           num_bits = (comp == 0 ? sps->bit_depth_luma_minus8 + 8 :
               sps->bit_depth_chroma_minus8 + 8);
@@ -2068,24 +2236,6 @@ done:
   sps->fps_num = 0;
   sps->fps_den = 1;
 
-  if (vui && vui->timing_info_present_flag) {
-    /* derive framerate for progressive stream if the pic_struct
-     * syntax element is not present in picture timing SEI messages */
-    /* Fixme: handle other cases also */
-    if (parse_vui_params && vui->timing_info_present_flag
-        && !vui->field_seq_flag && !vui->frame_field_info_present_flag) {
-      sps->fps_num = vui->time_scale;
-      sps->fps_den = vui->num_units_in_tick;
-      GST_LOG ("framerate %d/%d in VUI", sps->fps_num, sps->fps_den);
-    }
-  } else if (vps && vps->timing_info_present_flag) {
-    sps->fps_num = vps->time_scale;
-    sps->fps_den = vps->num_units_in_tick;
-    GST_LOG ("framerate %d/%d in VPS", sps->fps_num, sps->fps_den);
-  } else {
-    GST_LOG ("No VUI, unknown framerate");
-  }
-
   sps->valid = TRUE;
 
   return GST_H265_PARSER_OK;
@@ -2110,11 +2260,8 @@ GstH265ParserResult
 gst_h265_parse_pps (GstH265Parser * parser, GstH265NalUnit * nalu,
     GstH265PPS * pps)
 {
+  guint32 MaxBitDepthY, MaxBitDepthC;
   NalReader nr;
-  GstH265SPS *sps;
-  gint sps_id;
-  gint qp_bd_offset;
-  guint32 CtbSizeY, MinCbLog2SizeY, CtbLog2SizeY, MaxBitDepthY, MaxBitDepthC;
   guint8 i;
 
   GST_DEBUG ("parsing PPS");
@@ -2125,24 +2272,7 @@ gst_h265_parse_pps (GstH265Parser * parser, GstH265NalUnit * nalu,
   memset (pps, 0, sizeof (*pps));
 
   READ_UE_MAX (&nr, pps->id, GST_H265_MAX_PPS_COUNT - 1);
-  READ_UE_MAX (&nr, sps_id, GST_H265_MAX_SPS_COUNT - 1);
-
-  sps = gst_h265_parser_get_sps (parser, sps_id);
-  if (!sps) {
-    GST_WARNING ("couldn't find associated sequence parameter set with id: %d",
-        sps_id);
-    return GST_H265_PARSER_BROKEN_LINK;
-  }
-  pps->sps = sps;
-  qp_bd_offset = 6 * sps->bit_depth_luma_minus8;
-
-  MinCbLog2SizeY = sps->log2_min_luma_coding_block_size_minus3 + 3;
-  CtbLog2SizeY = MinCbLog2SizeY + sps->log2_diff_max_min_luma_coding_block_size;
-  CtbSizeY = 1 << CtbLog2SizeY;
-  pps->PicHeightInCtbsY =
-      ceil ((gdouble) sps->pic_height_in_luma_samples / (gdouble) CtbSizeY);
-  pps->PicWidthInCtbsY =
-      ceil ((gdouble) sps->pic_width_in_luma_samples / (gdouble) CtbSizeY);
+  READ_UE_MAX (&nr, pps->sps_id, GST_H265_MAX_SPS_COUNT - 1);
 
   /* set default values for fields that might not be present in the bitstream
      and have valid defaults */
@@ -2157,15 +2287,21 @@ gst_h265_parse_pps (GstH265Parser * parser, GstH265NalUnit * nalu,
 
   READ_UE_MAX (&nr, pps->num_ref_idx_l0_default_active_minus1, 14);
   READ_UE_MAX (&nr, pps->num_ref_idx_l1_default_active_minus1, 14);
-  READ_SE_ALLOWED (&nr, pps->init_qp_minus26, -(26 + qp_bd_offset), 25);
+
+  /* The value of init_qp_minus26 shall be in the range of
+   * −( 26 + QpBdOffsetY ) to +25, inclusive.
+   * QpBdOffsetY = 6 * bit_depth_luma_minus8 (7-5)
+   * and bit_depth_luma_minus8 shall be in the range of 0 to 8, inclusive.
+   * so the minimum possible value of init_qp_minus26 is -(26 + 6*8) */
+  READ_SE_ALLOWED (&nr, pps->init_qp_minus26, -(26 + 6 * 8), 25);
 
   READ_UINT8 (&nr, pps->constrained_intra_pred_flag, 1);
   READ_UINT8 (&nr, pps->transform_skip_enabled_flag, 1);
 
   READ_UINT8 (&nr, pps->cu_qp_delta_enabled_flag, 1);
-  if (pps->cu_qp_delta_enabled_flag)
-    READ_UE_MAX (&nr, pps->diff_cu_qp_delta_depth,
-        sps->log2_diff_max_min_luma_coding_block_size);
+  if (pps->cu_qp_delta_enabled_flag) {
+    READ_UE_MAX (&nr, pps->diff_cu_qp_delta_depth, 6);
+  }
 
   READ_SE_ALLOWED (&nr, pps->cb_qp_offset, -12, 12);
   READ_SE_ALLOWED (&nr, pps->cr_qp_offset, -12, 12);
@@ -2178,6 +2314,26 @@ gst_h265_parse_pps (GstH265Parser * parser, GstH265NalUnit * nalu,
   READ_UINT8 (&nr, pps->entropy_coding_sync_enabled_flag, 1);
 
   if (pps->tiles_enabled_flag) {
+    GstH265SPS *sps;
+    guint32 CtbSizeY, MinCbLog2SizeY, CtbLog2SizeY;
+
+    sps = gst_h265_parser_get_sps (parser, pps->sps_id);
+    if (!sps) {
+      GST_WARNING
+          ("couldn't find associated sequence parameter set with id: %d",
+          pps->sps_id);
+      return GST_H265_PARSER_BROKEN_LINK;
+    }
+
+    MinCbLog2SizeY = sps->log2_min_luma_coding_block_size_minus3 + 3;
+    CtbLog2SizeY =
+        MinCbLog2SizeY + sps->log2_diff_max_min_luma_coding_block_size;
+    CtbSizeY = 1 << CtbLog2SizeY;
+    pps->PicHeightInCtbsY =
+        ceil ((gdouble) sps->pic_height_in_luma_samples / (gdouble) CtbSizeY);
+    pps->PicWidthInCtbsY =
+        ceil ((gdouble) sps->pic_width_in_luma_samples / (gdouble) CtbSizeY);
+
     READ_UE_ALLOWED (&nr,
         pps->num_tile_columns_minus1, 0, pps->PicWidthInCtbsY - 1);
     READ_UE_ALLOWED (&nr,
@@ -2248,10 +2404,6 @@ gst_h265_parse_pps (GstH265Parser * parser, GstH265NalUnit * nalu,
   if (pps->scaling_list_data_present_flag)
     if (!gst_h265_parser_parse_scaling_lists (&nr, &pps->scaling_list, FALSE))
       goto error;
-  if (sps->scaling_list_enabled_flag && !sps->scaling_list_data_present_flag
-      && !pps->scaling_list_data_present_flag)
-    if (!gst_h265_parser_parse_scaling_lists (&nr, &pps->scaling_list, TRUE))
-      goto error;
 
   READ_UINT8 (&nr, pps->lists_modification_present_flag, 1);
   READ_UE_MAX (&nr, pps->log2_parallel_merge_level_minus2, 4);
@@ -2267,6 +2419,16 @@ gst_h265_parse_pps (GstH265Parser * parser, GstH265NalUnit * nalu,
   }
 
   if (pps->pps_range_extension_flag) {
+    GstH265SPS *sps;
+
+    sps = gst_h265_parser_get_sps (parser, pps->sps_id);
+    if (!sps) {
+      GST_WARNING
+          ("couldn't find associated sequence parameter set with id: %d",
+          pps->sps_id);
+      return GST_H265_PARSER_BROKEN_LINK;
+    }
+
     if (pps->transform_skip_enabled_flag)
       READ_UE (&nr,
           pps->pps_extension_params.log2_max_transform_skip_block_size_minus2);
@@ -2311,13 +2473,25 @@ gst_h265_parse_pps (GstH265Parser * parser, GstH265NalUnit * nalu,
   }
 
   if (pps->pps_scc_extension_flag) {
+    GstH265SPS *sps;
+
+    sps = gst_h265_parser_get_sps (parser, pps->sps_id);
+    if (!sps) {
+      GST_WARNING
+          ("couldn't find associated sequence parameter set with id: %d",
+          pps->sps_id);
+      return GST_H265_PARSER_BROKEN_LINK;
+    }
+
     READ_UINT8 (&nr,
         pps->pps_scc_extension_params.pps_curr_pic_ref_enabled_flag, 1);
     READ_UINT8 (&nr,
-        pps->pps_scc_extension_params.
-        residual_adaptive_colour_transform_enabled_flag, 1);
-    if (pps->pps_scc_extension_params.
-        residual_adaptive_colour_transform_enabled_flag) {
+        pps->
+        pps_scc_extension_params.residual_adaptive_colour_transform_enabled_flag,
+        1);
+    if (pps->
+        pps_scc_extension_params.residual_adaptive_colour_transform_enabled_flag)
+    {
       READ_UINT8 (&nr,
           pps->pps_scc_extension_params.pps_slice_act_qp_offsets_present_flag,
           1);
@@ -2330,10 +2504,12 @@ gst_h265_parse_pps (GstH265Parser * parser, GstH265NalUnit * nalu,
     }
 
     READ_UINT8 (&nr,
-        pps->pps_scc_extension_params.
-        pps_palette_predictor_initializers_present_flag, 1);
-    if (pps->pps_scc_extension_params.
-        pps_palette_predictor_initializers_present_flag) {
+        pps->
+        pps_scc_extension_params.pps_palette_predictor_initializers_present_flag,
+        1);
+    if (pps->
+        pps_scc_extension_params.pps_palette_predictor_initializers_present_flag)
+    {
       READ_UE_MAX (&nr,
           pps->pps_scc_extension_params.pps_num_palette_predictor_initializer,
           sps->sps_scc_extension_params.palette_max_size +
@@ -2364,8 +2540,8 @@ gst_h265_parse_pps (GstH265Parser * parser, GstH265NalUnit * nalu,
             comp++) {
           guint num_bits;
           guint num =
-              pps->pps_scc_extension_params.
-              pps_num_palette_predictor_initializer;
+              pps->
+              pps_scc_extension_params.pps_num_palette_predictor_initializer;
 
           num_bits = (comp == 0 ?
               pps->pps_scc_extension_params.luma_bit_depth_entry_minus8 + 8 :
@@ -2414,6 +2590,90 @@ gst_h265_parser_parse_pps (GstH265Parser * parser,
   return res;
 }
 
+static GstH265ParserResult
+gst_h265_parser_fill_sps (GstH265Parser * parser, GstH265SPS * sps)
+{
+  GstH265VPS *vps;
+  GstH265VUIParams *vui = &sps->vui_params;
+  GstH265ParserResult ret = GST_H265_PARSER_OK;
+
+  vps = gst_h265_parser_get_vps (parser, sps->vps_id);
+  if (!vps) {
+    GST_DEBUG ("couldn't find associated video parameter set with id: %d",
+        sps->vps_id);
+    return GST_H265_PARSER_BROKEN_LINK;
+  }
+  sps->vps = vps;
+
+  if (vui && vui->timing_info_present_flag) {
+    /* derive framerate for progressive stream if the pic_struct
+     * syntax element is not present in picture timing SEI messages */
+    /* Fixme: handle other cases also */
+    if (vui->parsed && vui->timing_info_present_flag
+        && !vui->field_seq_flag && !vui->frame_field_info_present_flag) {
+      sps->fps_num = vui->time_scale;
+      sps->fps_den = vui->num_units_in_tick;
+      GST_LOG ("framerate %d/%d in VUI", sps->fps_num, sps->fps_den);
+    }
+  } else if (vps && vps->timing_info_present_flag) {
+    sps->fps_num = vps->time_scale;
+    sps->fps_den = vps->num_units_in_tick;
+    GST_LOG ("framerate %d/%d in VPS", sps->fps_num, sps->fps_den);
+  } else {
+    GST_LOG ("No VUI, unknown framerate");
+  }
+
+  return ret;
+}
+
+static GstH265ParserResult
+gst_h265_parser_fill_pps (GstH265Parser * parser, GstH265PPS * pps)
+{
+  GstH265SPS *sps;
+  gint qp_bd_offset;
+  guint32 CtbSizeY, MinCbLog2SizeY, CtbLog2SizeY;
+  GstH265ParserResult ret = GST_H265_PARSER_OK;
+
+  sps = gst_h265_parser_get_sps (parser, pps->sps_id);
+  if (!sps) {
+    GST_WARNING ("couldn't find associated sequence parameter set with id: %d",
+        pps->sps_id);
+    return GST_H265_PARSER_BROKEN_LINK;
+  }
+
+  ret = gst_h265_parser_fill_sps (parser, sps);
+  if (ret != GST_H265_PARSER_OK) {
+    GST_WARNING ("couldn't fill sps id: %d", pps->sps_id);
+    return ret;
+  }
+
+  pps->sps = sps;
+  qp_bd_offset = 6 * sps->bit_depth_luma_minus8;
+
+  MinCbLog2SizeY = sps->log2_min_luma_coding_block_size_minus3 + 3;
+  CtbLog2SizeY = MinCbLog2SizeY + sps->log2_diff_max_min_luma_coding_block_size;
+  CtbSizeY = 1 << CtbLog2SizeY;
+  pps->PicHeightInCtbsY =
+      ceil ((gdouble) sps->pic_height_in_luma_samples / (gdouble) CtbSizeY);
+  pps->PicWidthInCtbsY =
+      ceil ((gdouble) sps->pic_width_in_luma_samples / (gdouble) CtbSizeY);
+
+  if (pps->init_qp_minus26 < -(26 + qp_bd_offset))
+    return GST_H265_PARSER_BROKEN_LINK;
+
+  if (sps->scaling_list_enabled_flag && !sps->scaling_list_data_present_flag
+      && !pps->scaling_list_data_present_flag)
+    if (!gst_h265_parser_parse_scaling_lists (NULL, &pps->scaling_list, TRUE))
+      return GST_H265_PARSER_BROKEN_LINK;
+
+  if (pps->cu_qp_delta_enabled_flag)
+    if (pps->diff_cu_qp_delta_depth >
+        sps->log2_diff_max_min_luma_coding_block_size)
+      return GST_H265_PARSER_BROKEN_LINK;
+
+  return ret;
+}
+
 /**
  * gst_h265_parser_parse_slice_hdr:
  * @parser: a #GstH265Parser
@@ -2439,6 +2699,7 @@ gst_h265_parser_parse_slice_hdr (GstH265Parser * parser,
   guint32 UsedByCurrPicLt[16];
   guint32 PicSizeInCtbsY;
   gint NumPocTotalCurr = 0;
+  GstH265ParserResult err;
 
   memset (slice, 0, sizeof (*slice));
 
@@ -2465,6 +2726,12 @@ gst_h265_parser_parse_slice_hdr (GstH265Parser * parser,
     return GST_H265_PARSER_BROKEN_LINK;
   }
 
+  err = gst_h265_parser_fill_pps (parser, pps);
+  if (err != GST_H265_PARSER_OK) {
+    GST_WARNING ("couldn't fill pps id: %d", pps_id);
+    return err;
+  }
+
   slice->pps = pps;
   sps = pps->sps;
   if (!sps) {
@@ -2499,7 +2766,6 @@ gst_h265_parser_parse_slice_hdr (GstH265Parser * parser,
       nal_reader_skip (&nr, 1);
     READ_UE_MAX (&nr, slice->type, 63);
 
-
     if (pps->output_flag_present_flag)
       READ_UINT8 (&nr, slice->pic_output_flag, 1);
     if (sps->separate_colour_plane_flag == 1)
@@ -2512,12 +2778,16 @@ gst_h265_parser_parse_slice_hdr (GstH265Parser * parser,
       READ_UINT8 (&nr, slice->short_term_ref_pic_set_sps_flag, 1);
       if (!slice->short_term_ref_pic_set_sps_flag) {
         guint pos = nal_reader_get_pos (&nr);
+        guint epb_pos = nal_reader_get_epb_count (&nr);
+
         if (!gst_h265_parser_parse_short_term_ref_pic_sets
             (&slice->short_term_ref_pic_sets, &nr,
                 sps->num_short_term_ref_pic_sets, sps))
           goto error;
 
-        slice->short_term_ref_pic_set_size = nal_reader_get_pos (&nr) - pos;
+        slice->short_term_ref_pic_set_size =
+            (nal_reader_get_pos (&nr) - pos) -
+            (8 * (nal_reader_get_epb_count (&nr) - epb_pos));
       } else if (sps->num_short_term_ref_pic_sets > 1) {
         const guint n = ceil_log2 (sps->num_short_term_ref_pic_sets);
         READ_UINT8 (&nr, slice->short_term_ref_pic_set_idx, n);
@@ -2527,6 +2797,8 @@ gst_h265_parser_parse_slice_hdr (GstH265Parser * parser,
 
       if (sps->long_term_ref_pics_present_flag) {
         guint32 limit;
+        guint pos = nal_reader_get_pos (&nr);
+        guint epb_pos = nal_reader_get_epb_count (&nr);
 
         if (sps->num_long_term_ref_pics_sps > 0)
           READ_UE_MAX (&nr, slice->num_long_term_sps,
@@ -2556,6 +2828,10 @@ gst_h265_parser_parse_slice_hdr (GstH265Parser * parser,
           if (slice->delta_poc_msb_present_flag[i])
             READ_UE (&nr, slice->delta_poc_msb_cycle_lt[i]);
         }
+
+        slice->long_term_ref_pic_set_size =
+            (nal_reader_get_pos (&nr) - pos) -
+            (8 * (nal_reader_get_epb_count (&nr) - epb_pos));
       }
       if (sps->temporal_mvp_enabled_flag)
         READ_UINT8 (&nr, slice->temporal_mvp_enabled_flag, 1);
@@ -2563,7 +2839,8 @@ gst_h265_parser_parse_slice_hdr (GstH265Parser * parser,
 
     if (sps->sample_adaptive_offset_enabled_flag) {
       READ_UINT8 (&nr, slice->sao_luma_flag, 1);
-      READ_UINT8 (&nr, slice->sao_chroma_flag, 1);
+      if (sps->chroma_array_type)
+        READ_UINT8 (&nr, slice->sao_chroma_flag, 1);
     }
 
     if (GST_H265_IS_B_SLICE (slice) || GST_H265_IS_P_SLICE (slice)) {
@@ -3376,7 +3653,7 @@ sort_fre_profile_matches (H265ExtensionProfileMatch * a,
 
 static GstH265Profile
 get_extension_profile (H265ExtensionProfile * profiles, guint num,
-    GstH265ProfileTierLevel * ptl)
+    const GstH265ProfileTierLevel * ptl)
 {
   GstH265Profile result = GST_H265_PROFILE_INVALID;
   guint i;
@@ -3479,7 +3756,7 @@ get_extension_profile (H265ExtensionProfile * profiles, guint num,
 }
 
 static GstH265Profile
-get_format_range_extension_profile (GstH265ProfileTierLevel * ptl)
+get_format_range_extension_profile (const GstH265ProfileTierLevel * ptl)
 {
   /* Profile idc: GST_H265_PROFILE_IDC_FORMAT_RANGE_EXTENSION
      See Table A.2 for the definition of those formats */
@@ -3532,7 +3809,7 @@ get_format_range_extension_profile (GstH265ProfileTierLevel * ptl)
 }
 
 static GstH265Profile
-get_3d_profile (GstH265ProfileTierLevel * ptl)
+get_3d_profile (const GstH265ProfileTierLevel * ptl)
 {
   /* profile idc: GST_H265_PROFILE_IDC_3D_MAIN */
   static H265ExtensionProfile profiles[] = {
@@ -3544,7 +3821,7 @@ get_3d_profile (GstH265ProfileTierLevel * ptl)
 }
 
 static GstH265Profile
-get_multiview_profile (GstH265ProfileTierLevel * ptl)
+get_multiview_profile (const GstH265ProfileTierLevel * ptl)
 {
   static H265ExtensionProfile profiles[] = {
     {GST_H265_PROFILE_MULTIVIEW_MAIN,
@@ -3555,7 +3832,7 @@ get_multiview_profile (GstH265ProfileTierLevel * ptl)
 }
 
 static GstH265Profile
-get_scalable_profile (GstH265ProfileTierLevel * ptl)
+get_scalable_profile (const GstH265ProfileTierLevel * ptl)
 {
   static H265ExtensionProfile profiles[] = {
     {GST_H265_PROFILE_SCALABLE_MAIN,
@@ -3568,7 +3845,7 @@ get_scalable_profile (GstH265ProfileTierLevel * ptl)
 }
 
 static GstH265Profile
-get_high_throughput_profile (GstH265ProfileTierLevel * ptl)
+get_high_throughput_profile (const GstH265ProfileTierLevel * ptl)
 {
   static H265ExtensionProfile profiles[] = {
     {GST_H265_PROFILE_HIGH_THROUGHPUT_444,
@@ -3585,7 +3862,8 @@ get_high_throughput_profile (GstH265ProfileTierLevel * ptl)
 }
 
 static GstH265Profile
-get_screen_content_coding_extensions_profile (GstH265ProfileTierLevel * ptl)
+get_screen_content_coding_extensions_profile (const GstH265ProfileTierLevel *
+    ptl)
 {
   static H265ExtensionProfile profiles[] = {
     {GST_H265_PROFILE_SCREEN_EXTENDED_MAIN,
@@ -3596,21 +3874,14 @@ get_screen_content_coding_extensions_profile (GstH265ProfileTierLevel * ptl)
         1, 1, 1, 1, 0, 0, 0, 0, 0, TRUE, 2},
     {GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444_10,
         1, 1, 1, 0, 0, 0, 0, 0, 0, TRUE, 3},
-    /* identical to screen-extended-main-444 */
-    {GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444,
-        1, 1, 1, 1, 0, 0, 0, 0, 0, TRUE, 4},
-    /* identical to screen-extended-main-444-10 */
-    {GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_10,
-        1, 1, 1, 0, 0, 0, 0, 0, 0, TRUE, 5},
-    {GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_14,
-        1, 0, 0, 0, 0, 0, 0, 0, 0, TRUE, 6},
   };
 
   return get_extension_profile (profiles, G_N_ELEMENTS (profiles), ptl);
 }
 
 static GstH265Profile
-get_scalable_format_range_extensions_profile (GstH265ProfileTierLevel * ptl)
+get_scalable_format_range_extensions_profile (const GstH265ProfileTierLevel *
+    ptl)
 {
   static H265ExtensionProfile profiles[] = {
     {GST_H265_PROFILE_SCALABLE_MONOCHROME,
@@ -3626,6 +3897,99 @@ get_scalable_format_range_extensions_profile (GstH265ProfileTierLevel * ptl)
   return get_extension_profile (profiles, G_N_ELEMENTS (profiles), ptl);
 }
 
+static GstH265Profile
+    get_screen_content_coding_extensions_high_throughput_profile
+    (const GstH265ProfileTierLevel * ptl)
+{
+  static H265ExtensionProfile profiles[] = {
+    {GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444,
+        1, 1, 1, 1, 0, 0, 0, 0, 0, TRUE, 0},
+    {GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_10,
+        1, 1, 1, 0, 0, 0, 0, 0, 0, TRUE, 1},
+    {GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_14,
+        1, 0, 0, 0, 0, 0, 0, 0, 0, TRUE, 2},
+  };
+
+  return get_extension_profile (profiles, G_N_ELEMENTS (profiles), ptl);
+}
+
+static inline void
+append_profile (GstH265Profile profiles[GST_H265_PROFILE_MAX], guint * idx,
+    GstH265Profile profile)
+{
+  if (profile == GST_H265_PROFILE_INVALID)
+    return;
+  profiles[*idx] = profile;
+  (*idx)++;
+}
+
+/* *INDENT-OFF* */
+struct h265_profiles_map
+{
+  GstH265ProfileIDC profile_idc;
+  GstH265Profile (*get_profile) (const GstH265ProfileTierLevel *);
+  GstH265Profile profile;
+};
+/* *INDENT-ON* */
+
+static const struct h265_profiles_map profiles_map[] = {
+  /* keep profile check in asc order */
+  {GST_H265_PROFILE_IDC_MAIN, NULL, GST_H265_PROFILE_MAIN},
+  {GST_H265_PROFILE_IDC_MAIN_10, NULL, GST_H265_PROFILE_MAIN_10},
+  {GST_H265_PROFILE_IDC_MAIN_STILL_PICTURE, NULL,
+      GST_H265_PROFILE_MAIN_STILL_PICTURE},
+  {GST_H265_PROFILE_IDC_FORMAT_RANGE_EXTENSION,
+      get_format_range_extension_profile, GST_H265_PROFILE_INVALID},
+  {GST_H265_PROFILE_IDC_HIGH_THROUGHPUT, get_high_throughput_profile,
+      GST_H265_PROFILE_INVALID},
+  {GST_H265_PROFILE_IDC_MULTIVIEW_MAIN, get_multiview_profile,
+      GST_H265_PROFILE_INVALID},
+  {GST_H265_PROFILE_IDC_SCALABLE_MAIN, get_scalable_profile,
+      GST_H265_PROFILE_INVALID},
+  {GST_H265_PROFILE_IDC_3D_MAIN, get_3d_profile, GST_H265_PROFILE_INVALID},
+  {GST_H265_PROFILE_IDC_SCREEN_CONTENT_CODING,
+        get_screen_content_coding_extensions_profile,
+      GST_H265_PROFILE_INVALID},
+  {GST_H265_PROFILE_IDC_SCALABLE_FORMAT_RANGE_EXTENSION,
+        get_scalable_format_range_extensions_profile,
+      GST_H265_PROFILE_INVALID},
+  {GST_H265_PROFILE_IDC_HIGH_THROUGHPUT_SCREEN_CONTENT_CODING_EXTENSION,
+        get_screen_content_coding_extensions_high_throughput_profile,
+      GST_H265_PROFILE_INVALID},
+};
+
+static void
+gst_h265_profile_tier_level_get_profiles (const GstH265ProfileTierLevel * ptl,
+    GstH265Profile profiles[GST_H265_PROFILE_MAX], guint * len)
+{
+  guint i = 0, j;
+
+  /* First add profile idc */
+  for (j = 0; j < G_N_ELEMENTS (profiles_map); j++) {
+    if (ptl->profile_idc == profiles_map[j].profile_idc) {
+      if (profiles_map[j].get_profile)
+        append_profile (profiles, &i, profiles_map[j].get_profile (ptl));
+      else
+        profiles[i++] = profiles_map[j].profile;
+      break;
+    }
+  }
+
+  /* Later add compatibility flags */
+  for (j = 0; j < G_N_ELEMENTS (profiles_map); j++) {
+    if (i > 0 && ptl->profile_idc == profiles_map[j].profile_idc)
+      continue;
+    if (ptl->profile_compatibility_flag[profiles_map[j].profile_idc]) {
+      if (profiles_map[j].get_profile)
+        append_profile (profiles, &i, profiles_map[j].get_profile (ptl));
+      else
+        profiles[i++] = profiles_map[j].profile;
+    }
+  }
+
+  *len = i;
+}
+
 /**
  * gst_h265_profile_tier_level_get_profile:
  * @ptl: a #GstH265ProfileTierLevel
@@ -3636,50 +4000,15 @@ get_scalable_format_range_extensions_profile (GstH265ProfileTierLevel * ptl)
  * Since: 1.14
  */
 GstH265Profile
-gst_h265_profile_tier_level_get_profile (GstH265ProfileTierLevel * ptl)
+gst_h265_profile_tier_level_get_profile (const GstH265ProfileTierLevel * ptl)
 {
-  if (ptl->profile_idc == GST_H265_PROFILE_IDC_MAIN
-      || ptl->profile_compatibility_flag[1])
-    return GST_H265_PROFILE_MAIN;
-
-  if (ptl->profile_idc == GST_H265_PROFILE_IDC_MAIN_10
-      || ptl->profile_compatibility_flag[2])
-    return GST_H265_PROFILE_MAIN_10;
-
-  if (ptl->profile_idc == GST_H265_PROFILE_IDC_MAIN_STILL_PICTURE
-      || ptl->profile_compatibility_flag[3])
-    return GST_H265_PROFILE_MAIN_STILL_PICTURE;
-
-  if (ptl->profile_idc == GST_H265_PROFILE_IDC_FORMAT_RANGE_EXTENSION
-      || ptl->profile_compatibility_flag[4])
-    return get_format_range_extension_profile (ptl);
-
-  if (ptl->profile_idc == GST_H265_PROFILE_IDC_HIGH_THROUGHPUT
-      || ptl->profile_compatibility_flag[5])
-    return get_high_throughput_profile (ptl);
+  guint len = 0;
+  GstH265Profile profiles[GST_H265_PROFILE_MAX] = { GST_H265_PROFILE_INVALID, };
 
-  if (ptl->profile_idc == GST_H265_PROFILE_IDC_MULTIVIEW_MAIN
-      || ptl->profile_compatibility_flag[6])
-    return get_multiview_profile (ptl);
+  gst_h265_profile_tier_level_get_profiles (ptl, profiles, &len);
 
-  if (ptl->profile_idc == GST_H265_PROFILE_IDC_SCALABLE_MAIN
-      || ptl->profile_compatibility_flag[7])
-    return get_scalable_profile (ptl);
-
-  if (ptl->profile_idc == GST_H265_PROFILE_IDC_3D_MAIN
-      || ptl->profile_compatibility_flag[8])
-    return get_3d_profile (ptl);
-
-  if (ptl->profile_idc == GST_H265_PROFILE_IDC_SCREEN_CONTENT_CODING
-      || ptl->profile_compatibility_flag[9]
-      || ptl->profile_idc ==
-      GST_H265_PROFILE_IDC_HIGH_THROUGHPUT_SCREEN_CONTENT_CODING_EXTENSION
-      || ptl->profile_compatibility_flag[11])
-    return get_screen_content_coding_extensions_profile (ptl);
-
-  if (ptl->profile_idc == GST_H265_PROFILE_IDC_SCALABLE_FORMAT_RANGE_EXTENSION
-      || ptl->profile_compatibility_flag[10])
-    return get_scalable_format_range_extensions_profile (ptl);
+  if (len > 0)
+    return profiles[0];
 
   return GST_H265_PROFILE_INVALID;
 }
@@ -3975,14 +4304,14 @@ gst_h265_create_sei_memory_internal (guint8 layer_id, guint8 temporal_id_plus1,
     /* write payload type bytes */
     while (payload_type_data >= 0xff) {
       WRITE_UINT8 (&nw, 0xff, 8);
-      payload_type_data -= -0xff;
+      payload_type_data -= 0xff;
     }
     WRITE_UINT8 (&nw, payload_type_data, 8);
 
     /* write payload size bytes */
     while (payload_size_data >= 0xff) {
       WRITE_UINT8 (&nw, 0xff, 8);
-      payload_size_data -= -0xff;
+      payload_size_data -= 0xff;
     }
     WRITE_UINT8 (&nw, payload_size_data, 8);
 
@@ -4293,3 +4622,119 @@ gst_h265_parser_insert_sei_hevc (GstH265Parser * parser, guint8 nal_length_size,
   return gst_h265_parser_insert_sei_internal (parser, nal_length_size, TRUE,
       au, sei);
 }
+
+/**
+ * gst_h265_get_profile_from_sps:
+ * @sps: a #GstH265SPS
+ *
+ * Return the H265 profile from @sps.
+ *
+ * Returns: a #GstH265Profile
+ * Since: 1.20
+ */
+GstH265Profile
+gst_h265_get_profile_from_sps (GstH265SPS * sps)
+{
+  GstH265Profile profiles[GST_H265_PROFILE_MAX] = { GST_H265_PROFILE_INVALID, };
+  GstH265ProfileTierLevel tmp_ptl;
+  guint i, len = 0;
+  guint chroma_format_idc, bit_depth_luma, bit_depth_chroma;
+
+  g_return_val_if_fail (sps != NULL, GST_H265_PROFILE_INVALID);
+
+  tmp_ptl = sps->profile_tier_level;
+  chroma_format_idc = sps->chroma_format_idc;
+  bit_depth_luma = sps->bit_depth_luma_minus8 + 8;
+  bit_depth_chroma = sps->bit_depth_chroma_minus8 + 8;
+
+  gst_h265_profile_tier_level_get_profiles (&sps->profile_tier_level, profiles,
+      &len);
+
+  for (i = 0; i < len && i < G_N_ELEMENTS (profiles); i++) {
+    switch (profiles[i]) {
+      case GST_H265_PROFILE_INVALID:
+        break;
+      case GST_H265_PROFILE_MAIN:
+      case GST_H265_PROFILE_MAIN_STILL_PICTURE:
+        /* A.3.2 or A.3.5 */
+        if (chroma_format_idc == 1
+            && bit_depth_luma == 8 && bit_depth_chroma == 8)
+          return profiles[i];
+        break;
+      case GST_H265_PROFILE_MAIN_10:
+        /* A.3.3 */
+        if (chroma_format_idc == 1
+            && bit_depth_luma >= 8 && bit_depth_luma <= 10
+            && bit_depth_chroma >= 8 && bit_depth_chroma <= 10)
+          return profiles[i];
+        break;
+      default:
+        return profiles[i];
+    }
+  }
+
+  /* Invalid profile: */
+  /* Set the conformance indicators based on chroma_format_idc / bit_depth */
+  switch (chroma_format_idc) {
+    case 0:
+      tmp_ptl.max_monochrome_constraint_flag = 1;
+      tmp_ptl.max_420chroma_constraint_flag = 1;
+      tmp_ptl.max_422chroma_constraint_flag = 1;
+      break;
+
+    case 1:
+      tmp_ptl.max_monochrome_constraint_flag = 0;
+      tmp_ptl.max_420chroma_constraint_flag = 1;
+      tmp_ptl.max_422chroma_constraint_flag = 1;
+      break;
+
+    case 2:
+      tmp_ptl.max_monochrome_constraint_flag = 0;
+      tmp_ptl.max_420chroma_constraint_flag = 0;
+      tmp_ptl.max_422chroma_constraint_flag = 1;
+      break;
+
+    case 3:
+      tmp_ptl.max_monochrome_constraint_flag = 0;
+      tmp_ptl.max_420chroma_constraint_flag = 0;
+      tmp_ptl.max_422chroma_constraint_flag = 0;
+      break;
+
+    default:
+      g_assert_not_reached ();
+      break;
+  }
+
+  tmp_ptl.max_8bit_constraint_flag = 1;
+  tmp_ptl.max_10bit_constraint_flag = 1;
+  tmp_ptl.max_12bit_constraint_flag = 1;
+  tmp_ptl.max_14bit_constraint_flag = 1;
+
+  if (bit_depth_luma > 8 || bit_depth_chroma > 8)
+    tmp_ptl.max_8bit_constraint_flag = 0;
+
+  if (bit_depth_luma > 10 || bit_depth_chroma > 10)
+    tmp_ptl.max_10bit_constraint_flag = 0;
+
+  if (bit_depth_luma > 12 || bit_depth_chroma > 12)
+    tmp_ptl.max_12bit_constraint_flag = 0;
+
+  if (tmp_ptl.profile_idc == GST_H265_PROFILE_IDC_HIGH_THROUGHPUT
+      || tmp_ptl.profile_idc == GST_H265_PROFILE_IDC_SCREEN_CONTENT_CODING
+      || tmp_ptl.profile_idc ==
+      GST_H265_PROFILE_IDC_SCALABLE_FORMAT_RANGE_EXTENSION
+      || tmp_ptl.profile_idc ==
+      GST_H265_PROFILE_IDC_HIGH_THROUGHPUT_SCREEN_CONTENT_CODING_EXTENSION
+      || tmp_ptl.profile_compatibility_flag[5]
+      || tmp_ptl.profile_compatibility_flag[9]
+      || tmp_ptl.profile_compatibility_flag[10]
+      || tmp_ptl.profile_compatibility_flag[11]) {
+    if (bit_depth_luma > 14 || bit_depth_chroma > 14)
+      tmp_ptl.max_14bit_constraint_flag = 0;
+  } else {
+    tmp_ptl.max_14bit_constraint_flag = 0;
+  }
+
+  /* first profile of the synthetic ptl */
+  return gst_h265_profile_tier_level_get_profile (&tmp_ptl);
+}
diff --git a/gst-libs/gst/codecparsers/gsth265parser.h b/gst-libs/gst/codecparsers/gsth265parser.h
index 073123d7c..679d70c6d 100644
--- a/gst-libs/gst/codecparsers/gsth265parser.h
+++ b/gst-libs/gst/codecparsers/gsth265parser.h
@@ -788,6 +788,7 @@ struct _GstH265ShortTermRefPicSet
 
 /**
  * GstH265VUIParams:
+ * @parsed: %TRUE indicate that VUI parameters have been parsed (Since: 1.22)
  * @aspect_ratio_info_present_flag: %TRUE specifies that aspect_ratio_idc is present.
  *  %FALSE specifies that aspect_ratio_idc is not present
  * @aspect_ratio_idc specifies the value of the sample aspect ratio of the luma samples
@@ -856,6 +857,14 @@ struct _GstH265ShortTermRefPicSet
  */
 struct _GstH265VUIParams
 {
+  /**
+   * _GstH265VUIParams.parsed:
+   *
+   * %TRUE indicate that VUI parameters have been parsed.
+   *
+   * Since: 1.22
+   */
+  gboolean parsed;
   guint8 aspect_ratio_info_present_flag;
   guint8 aspect_ratio_idc;
   /* if aspect_ratio_idc == 255 */
@@ -1102,6 +1111,14 @@ struct _GstH265SPS
 {
   guint8 id;
 
+  /**
+   * _GstH265SPS.vps_id:
+   *
+   * The ID of the VPS. This is used to store the ID until the VPS is
+   * parsed in case its placed after the SPS.
+   * Since: 1.22
+   */
+  guint8 vps_id;
   GstH265VPS *vps;
 
   guint8 max_sub_layers_minus1;
@@ -1166,7 +1183,7 @@ struct _GstH265SPS
   guint8 strong_intra_smoothing_enabled_flag;
   guint8 vui_parameters_present_flag;
 
-  /* if vui_parameters_present_flat */
+  /* if vui_parameters_present_flag */
   GstH265VUIParams vui_params;
 
   guint8 sps_extension_flag;
@@ -1179,7 +1196,12 @@ struct _GstH265SPS
   guint8 sps_extension_4bits;
 
   /* if sps_range_extension_flag */
-  GstH265SPSExtensionParams sps_extnsion_params;
+  /**
+   * _GstH265SPS.sps_extension_params:
+   *
+   * Since: 1.22
+   */
+  GstH265SPSExtensionParams sps_extension_params;
   /* if sps_scc_extension_flag */
   GstH265SPSSccExtensionParams sps_scc_extension_params;
 
@@ -1201,6 +1223,15 @@ struct _GstH265PPS
 {
   guint id;
 
+  /**
+   * _GstH265PPS.sps_id:
+   *
+   * The ID of the SPS. This is used to store the ID until the SPS is
+   * parsed in case its placed after the PPS.
+   *
+   * Since: 1.22
+   */
+  guint sps_id;
   GstH265SPS *sps;
 
   guint8 dependent_slice_segments_enabled_flag;
@@ -1384,6 +1415,9 @@ struct _GstH265PredWeightTable
  *   in this slice_header\()
  * @short_term_ref_pic_set_size: the calculated size of short_term_ref_pic_set\()
  *   in bits. (Since: 1.18)
+ * @long_term_ref_pic_set_size: the calculated size of the branch
+ *   `if( long_term_ref_pics_present_flag )` `inside slice_segment_header()` syntax
+ *   in bits. (Since: 1.22)
  */
 struct _GstH265SliceHdr
 {
@@ -1460,8 +1494,19 @@ struct _GstH265SliceHdr
   /* Number of emulation prevention bytes (EPB) in this slice_header() */
   guint n_emulation_prevention_bytes;
 
-  /* Size of short_term_ref_pic_set() in bits */
+  /* Size of short_term_ref_pic_set() after emulation preventation bytes are
+   * removed, in bits */
   guint short_term_ref_pic_set_size;
+
+  /**
+   * _GstH265SliceHdr.long_term_ref_pic_set_size:
+   *
+   * The calculated size of the branch `if( long_term_ref_pics_present_flag )`
+   * inside `slice_segment_header()` syntax in bits.
+   *
+   * Since: 1.22
+   */
+  guint long_term_ref_pic_set_size;
 };
 
 struct _GstH265PicTiming
@@ -1652,6 +1697,15 @@ GstH265ParserResult gst_h265_parser_identify_nalu_hevc (GstH265Parser  * parser,
                                                         guint8           nal_length_size,
                                                         GstH265NalUnit * nalu);
 
+GST_CODEC_PARSERS_API
+GstH265ParserResult gst_h265_parser_identify_and_split_nalu_hevc (GstH265Parser * parser,
+                                                                  const guint8 * data,
+                                                                  guint offset,
+                                                                  gsize size,
+                                                                  guint8 nal_length_size,
+                                                                  GArray * nalus,
+                                                                  gsize * consumed);
+
 GST_CODEC_PARSERS_API
 GstH265ParserResult gst_h265_parser_parse_nal       (GstH265Parser   * parser,
                                                      GstH265NalUnit  * nalu);
@@ -1777,7 +1831,7 @@ void    gst_h265_quant_matrix_8x8_get_raster_from_uprightdiagonal (guint8 out_qu
         gst_h265_quant_matrix_8x8_get_raster_from_uprightdiagonal
 
 GST_CODEC_PARSERS_API
-GstH265Profile gst_h265_profile_tier_level_get_profile (GstH265ProfileTierLevel * ptl);
+GstH265Profile gst_h265_profile_tier_level_get_profile (const GstH265ProfileTierLevel * ptl);
 
 GST_CODEC_PARSERS_API
 const gchar * gst_h265_profile_to_string (GstH265Profile profile);
@@ -1808,5 +1862,8 @@ GstBuffer * gst_h265_parser_insert_sei_hevc (GstH265Parser * parser,
                                              GstBuffer * au,
                                              GstMemory * sei);
 
+GST_CODEC_PARSERS_API
+GstH265Profile gst_h265_get_profile_from_sps (GstH265SPS * sps);
+
 G_END_DECLS
 #endif
diff --git a/gst-libs/gst/codecparsers/gstjpeg2000sampling.c b/gst-libs/gst/codecparsers/gstjpeg2000sampling.c
index 526a7ecce..c1e76f0fc 100644
--- a/gst-libs/gst/codecparsers/gstjpeg2000sampling.c
+++ b/gst-libs/gst/codecparsers/gstjpeg2000sampling.c
@@ -42,6 +42,7 @@ static const gchar *gst_jpeg2000_sampling_strings[] = {
   "YCbCr-4:1:0",
   "GRAYSCALE",
   "YCbCrA-4:4:4:4",
+  "YCbCr-4:1:1",
 };
 
 /* convert string to GstJPEG2000Sampling enum */
@@ -86,8 +87,9 @@ gst_jpeg2000_sampling_is_yuv (GstJPEG2000Sampling sampling)
   return sampling == GST_JPEG2000_SAMPLING_YBRA4444_EXT ||
       sampling == GST_JPEG2000_SAMPLING_YBR444 ||
       sampling == GST_JPEG2000_SAMPLING_YBR422 ||
-      sampling == GST_JPEG2000_SAMPLING_YBR420
-      || sampling == GST_JPEG2000_SAMPLING_YBR410;
+      sampling == GST_JPEG2000_SAMPLING_YBR420 ||
+      sampling == GST_JPEG2000_SAMPLING_YBR411 ||
+      sampling == GST_JPEG2000_SAMPLING_YBR410;
 }
 
 /* check if @sampling is in GRAYSCALE color space */
diff --git a/gst-libs/gst/codecparsers/gstjpeg2000sampling.h b/gst-libs/gst/codecparsers/gstjpeg2000sampling.h
index 5fa081000..4b5bea5a3 100644
--- a/gst-libs/gst/codecparsers/gstjpeg2000sampling.h
+++ b/gst-libs/gst/codecparsers/gstjpeg2000sampling.h
@@ -30,17 +30,26 @@
  * Note: sampling extensions that are not listed in the RFC are signified by an _EXT at the end of the enum
  *
  * @GST_JPEG2000_SAMPLING_NONE: no sampling
- * @GST_JPEG2000_SAMPLING_RGB:  standard Red, Green, Blue color space.
- * @GST_JPEG2000_SAMPLING_BGR:  standard Blue, Green, Red color space.
- * @GST_JPEG2000_SAMPLING_RGBA:  standard Red, Green, Blue, Alpha color space.
- * @GST_JPEG2000_SAMPLING_BGRA:  standard Blue, Green, Red, Alpha color space.
- * @GST_JPEG2000_SAMPLING_YCbCr-4:4:4:  standard YCbCr color space; no subsampling.
- * @GST_JPEG2000_SAMPLING_YCbCr-4:2:2:  standard YCbCr color space; Cb and Cr are subsampled horizontally by 1/2.
- * @GST_JPEG2000_SAMPLING_YCbCr-4:2:0:  standard YCbCr color space; Cb and Cr are subsampled horizontally and vertically by 1/2.
- * @GST_JPEG2000_SAMPLING_YCbCr-4:1:1:  standard YCbCr color space; Cb and Cr are subsampled vertically by 1/4.
+ * @GST_JPEG2000_SAMPLING_RGB: standard Red, Green, Blue color space.
+ * @GST_JPEG2000_SAMPLING_BGR: standard Blue, Green, Red color space.
+ * @GST_JPEG2000_SAMPLING_RGBA: standard Red, Green, Blue, Alpha color space.
+ * @GST_JPEG2000_SAMPLING_BGRA: standard Blue, Green, Red, Alpha color space.
+ * @GST_JPEG2000_SAMPLING_YBR444: standard YCbCr color space; no subsampling.
+ * @GST_JPEG2000_SAMPLING_YBR422: standard YCbCr color space; Cb and Cr are subsampled horizontally by 1/2.
+ * @GST_JPEG2000_SAMPLING_YBR420: standard YCbCr color space; Cb and Cr are subsampled horizontally and vertically by 1/2.
+ * @GST_JPEG2000_SAMPLING_YBR411: standard YCbCr color space; Cb and Cr are subsampled vertically by 1/4 (Since: 1.20).
+ * @GST_JPEG2000_SAMPLING_YBR410: standard YCbCr color space; Cb and Cr are subsampled vertically by 1/4 alternating the Cb and Cr component.
  * @GST_JPEG2000_SAMPLING_GRAYSCALE:  basically, a single component image of just multilevels of grey.
  * @GST_JPEG2000_SAMPLING_YBRA4444_EXT: standard YCbCr color space, alpha channel, no subsampling,
  */
+
+/**
+ * GST_JPEG2000_SAMPLING_YBR411:
+ *
+ * standard YCbCr color space; Cb and Cr are subsampled vertically by 1/4
+ *
+ * Since: 1.20
+ */
 typedef enum
 {
   GST_JPEG2000_SAMPLING_NONE,
@@ -53,11 +62,12 @@ typedef enum
   GST_JPEG2000_SAMPLING_YBR420,
   GST_JPEG2000_SAMPLING_YBR410,
   GST_JPEG2000_SAMPLING_GRAYSCALE,
-  GST_JPEG2000_SAMPLING_YBRA4444_EXT
+  GST_JPEG2000_SAMPLING_YBRA4444_EXT,
+  GST_JPEG2000_SAMPLING_YBR411
 } GstJPEG2000Sampling;
 
 /* GST_JPEG2000_SAMPLING_LIST: sampling strings in list form, for use in caps */
-#define GST_JPEG2000_SAMPLING_LIST "sampling = (string) {\"RGB\", \"BGR\", \"RGBA\", \"BGRA\", \"YCbCr-4:4:4\", \"YCbCr-4:2:2\", \"YCbCr-4:2:0\", \"YCbCr-4:1:1\", \"GRAYSCALE\" , \"YCbCrA-4:4:4:4\"}"
+#define GST_JPEG2000_SAMPLING_LIST "sampling = (string) {\"RGB\", \"BGR\", \"RGBA\", \"BGRA\", \"YCbCr-4:4:4\", \"YCbCr-4:2:2\", \"YCbCr-4:2:0\", \"YCbCr-4:1:1\", \"YCbCr-4:1:0\", \"GRAYSCALE\" , \"YCbCrA-4:4:4:4\"}"
 
 GST_CODEC_PARSERS_API
 const gchar *gst_jpeg2000_sampling_to_string (GstJPEG2000Sampling sampling);
diff --git a/gst-libs/gst/codecparsers/gstvp8parser.c b/gst-libs/gst/codecparsers/gstvp8parser.c
index 717647661..2de34f0b9 100644
--- a/gst-libs/gst/codecparsers/gstvp8parser.c
+++ b/gst-libs/gst/codecparsers/gstvp8parser.c
@@ -535,6 +535,8 @@ gst_vp8_parser_parse_frame_header (GstVp8Parser * parser,
   g_return_val_if_fail (frame_hdr != NULL, GST_VP8_PARSER_ERROR);
   g_return_val_if_fail (parser != NULL, GST_VP8_PARSER_ERROR);
 
+  memset (frame_hdr, 0, sizeof (GstVp8FrameHdr));
+
   /* Uncompressed Data Chunk */
   gst_byte_reader_init (&br, data, size);
 
diff --git a/gst-libs/gst/codecparsers/gstvp9parser.c b/gst-libs/gst/codecparsers/gstvp9parser.c
index 33e1f0ebd..cb82a0816 100644
--- a/gst-libs/gst/codecparsers/gstvp9parser.c
+++ b/gst-libs/gst/codecparsers/gstvp9parser.c
@@ -646,6 +646,7 @@ gst_vp9_parser_new (void)
     return NULL;
 
   parser->priv = priv;
+  parser->subsampling_x = parser->subsampling_y = -1;
 
   return parser;
 }
diff --git a/gst-libs/gst/codecparsers/gstvp9parser.h b/gst-libs/gst/codecparsers/gstvp9parser.h
index 20417d9c6..3a0d67c08 100644
--- a/gst-libs/gst/codecparsers/gstvp9parser.h
+++ b/gst-libs/gst/codecparsers/gstvp9parser.h
@@ -48,7 +48,6 @@ G_BEGIN_DECLS
 
 #define GST_VP9_FRAME_CONTEXTS_LOG2 2
 
-#define GST_VP9_MAX_LOOP_FILTER    63
 #define GST_VP9_MAX_SHARPNESS      7
 
 #define GST_VP9_MAX_REF_LF_DELTAS  4
@@ -461,7 +460,7 @@ struct _GstVp9SuperframeInfo {
  */
 struct _GstVp9Segmentation
 {
-  guint8 filter_level[4][2];
+  guint8 filter_level[GST_VP9_MAX_REF_LF_DELTAS][GST_VP9_MAX_MODE_LF_DELTAS];
   gint16 luma_ac_quant_scale;
   gint16 luma_dc_quant_scale;
   gint16 chroma_ac_quant_scale;
diff --git a/gst-libs/gst/codecparsers/meson.build b/gst-libs/gst/codecparsers/meson.build
index 7b76f4001..7d621f6a9 100644
--- a/gst-libs/gst/codecparsers/meson.build
+++ b/gst-libs/gst/codecparsers/meson.build
@@ -15,7 +15,9 @@ codecparser_sources = files([
   'dboolhuff.c',
   'vp8utils.c',
   'gstmpegvideometa.c',
-  'gstav1parser.c'
+  'gstav1parser.c',
+  'gsth264bitwriter.c',
+  'gsth265bitwriter.c',
 ])
 codecparser_headers = [
   'codecparsers-prelude.h',
@@ -30,13 +32,14 @@ codecparser_headers = [
   'gstjpegparser.h',
   'gstmpegvideometa.h',
   'gstvp9parser.h',
-  'gstav1parser.h'
+  'gstav1parser.h',
 ]
 install_headers(codecparser_headers, subdir : 'gstreamer-1.0/gst/codecparsers')
 
 cp_args = [
   '-DGST_USE_UNSTABLE_API',
   '-DBUILDING_GST_CODEC_PARSERS',
+  '-DG_LOG_DOMAIN="GStreamer-CodecParsers"',
   '-Dvp8_norm=gst_codecparsers_vp8_norm',
   '-Dvp8dx_start_decode=gst_codecparsers_vp8dx_start_decode',
   '-Dvp8dx_bool_decoder_fill=gst_codecparsers_vp8dx_bool_decoder_fill',
diff --git a/gst-libs/gst/codecparsers/nalutils.c b/gst-libs/gst/codecparsers/nalutils.c
index cd63d8ae2..af802d7d8 100644
--- a/gst-libs/gst/codecparsers/nalutils.c
+++ b/gst-libs/gst/codecparsers/nalutils.c
@@ -345,29 +345,15 @@ nal_writer_do_rbsp_trailing_bits (NalWriter * nw)
   return TRUE;
 }
 
-GstMemory *
-nal_writer_reset_and_get_memory (NalWriter * nw)
+static gpointer
+nal_writer_create_nal_data (NalWriter * nw, guint32 * ret_size)
 {
   GstBitWriter bw;
   gint i;
   guint8 *src, *dst;
   gsize size;
-  GstMemory *ret = NULL;
   gpointer data;
 
-  g_return_val_if_fail (nw != NULL, NULL);
-
-  if ((GST_BIT_WRITER_BIT_SIZE (&nw->bw) >> 3) == 0) {
-    GST_WARNING ("No written byte");
-    goto done;
-  }
-
-  if ((GST_BIT_WRITER_BIT_SIZE (&nw->bw) & 0x7) != 0) {
-    GST_WARNING ("Written stream is not byte aligned");
-    if (!nal_writer_do_rbsp_trailing_bits (nw))
-      goto done;
-  }
-
   /* scan to put emulation_prevention_three_byte */
   size = GST_BIT_WRITER_BIT_SIZE (&nw->bw) >> 3;
   src = GST_BIT_WRITER_DATA (&nw->bw);
@@ -388,44 +374,104 @@ nal_writer_reset_and_get_memory (NalWriter * nw)
     gst_bit_writer_put_bits_uint8 (&bw, src[i], 8);
   }
 
-  size = bw.bit_size >> 3;
+  *ret_size = bw.bit_size >> 3;
   data = gst_bit_writer_reset_and_get_data (&bw);
-  ret = gst_memory_new_wrapped (0, data, size, 0, size, data, g_free);
 
   if (nw->packetized) {
-    GstMapInfo info;
-
-    gst_memory_map (ret, &info, GST_MAP_WRITE);
-
-    size = info.size - nw->nal_prefix_size;
+    size = *ret_size - nw->nal_prefix_size;
 
     switch (nw->nal_prefix_size) {
       case 1:
-        GST_WRITE_UINT8 (info.data, size);
+        GST_WRITE_UINT8 (data, size);
         break;
       case 2:
-        GST_WRITE_UINT16_BE (info.data, size);
+        GST_WRITE_UINT16_BE (data, size);
         break;
       case 3:
-        GST_WRITE_UINT24_BE (info.data, size);
+        GST_WRITE_UINT24_BE (data, size);
         break;
       case 4:
-        GST_WRITE_UINT32_BE (info.data, size);
+        GST_WRITE_UINT32_BE (data, size);
         break;
       default:
         g_assert_not_reached ();
         break;
     }
+  }
 
-    gst_memory_unmap (ret, &info);
+  return data;
+}
+
+GstMemory *
+nal_writer_reset_and_get_memory (NalWriter * nw)
+{
+  guint32 size = 0;
+  GstMemory *ret = NULL;
+  gpointer data;
+
+  g_return_val_if_fail (nw != NULL, NULL);
+
+  if ((GST_BIT_WRITER_BIT_SIZE (&nw->bw) >> 3) == 0) {
+    GST_WARNING ("No written byte");
+    goto done;
   }
 
+  if ((GST_BIT_WRITER_BIT_SIZE (&nw->bw) & 0x7) != 0) {
+    GST_WARNING ("Written stream is not byte aligned");
+    if (!nal_writer_do_rbsp_trailing_bits (nw))
+      goto done;
+  }
+
+  data = nal_writer_create_nal_data (nw, &size);
+  if (!data) {
+    GST_WARNING ("Failed to create nal data");
+    goto done;
+  }
+
+  ret = gst_memory_new_wrapped (0, data, size, 0, size, data, g_free);
+
 done:
   gst_bit_writer_reset (&nw->bw);
 
   return ret;
 }
 
+guint8 *
+nal_writer_reset_and_get_data (NalWriter * nw, guint32 * ret_size)
+{
+  guint32 size = 0;
+  guint8 *data = NULL;
+
+  g_return_val_if_fail (nw != NULL, NULL);
+  g_return_val_if_fail (ret_size != NULL, NULL);
+
+  *ret_size = 0;
+
+  if ((GST_BIT_WRITER_BIT_SIZE (&nw->bw) >> 3) == 0) {
+    GST_WARNING ("No written byte");
+    goto done;
+  }
+
+  if ((GST_BIT_WRITER_BIT_SIZE (&nw->bw) & 0x7) != 0) {
+    GST_WARNING ("Written stream is not byte aligned");
+    if (!nal_writer_do_rbsp_trailing_bits (nw))
+      goto done;
+  }
+
+  data = nal_writer_create_nal_data (nw, &size);
+  if (!data) {
+    GST_WARNING ("Failed to create nal data");
+    goto done;
+  }
+
+  *ret_size = size;
+
+done:
+  gst_bit_writer_reset (&nw->bw);
+
+  return data;
+}
+
 gboolean
 nal_writer_put_bits_uint8 (NalWriter * nw, guint8 value, guint nbits)
 {
diff --git a/gst-libs/gst/codecparsers/nalutils.h b/gst-libs/gst/codecparsers/nalutils.h
index fdfc57556..d8c0fbb7b 100644
--- a/gst-libs/gst/codecparsers/nalutils.h
+++ b/gst-libs/gst/codecparsers/nalutils.h
@@ -208,6 +208,9 @@ gboolean nal_writer_do_rbsp_trailing_bits (NalWriter * nw);
 G_GNUC_INTERNAL
 GstMemory * nal_writer_reset_and_get_memory (NalWriter * nw);
 
+G_GNUC_INTERNAL
+guint8 * nal_writer_reset_and_get_data (NalWriter * nw, guint32 * ret_size);
+
 G_GNUC_INTERNAL
 gboolean nal_writer_put_bits_uint8 (NalWriter * nw, guint8 value, guint nbits);
 
diff --git a/gst-libs/gst/webrtc/datachannel.c b/gst-libs/gst/webrtc/datachannel.c
index ee0be6030..38cd3ce03 100644
--- a/gst-libs/gst/webrtc/datachannel.c
+++ b/gst-libs/gst/webrtc/datachannel.c
@@ -22,6 +22,8 @@
  * SECTION:gstwebrtc-datachannel
  * @short_description: RTCDataChannel object
  * @title: GstWebRTCDataChannel
+ * @symbols:
+ * - GstWebRTCDataChannel
  *
  * <https://www.w3.org/TR/webrtc/#rtcdatachannel>
  *
@@ -33,6 +35,7 @@
 #endif
 
 #include "datachannel.h"
+#include "webrtc-priv.h"
 
 #define GST_CAT_DEFAULT gst_webrtc_data_channel_debug
 GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
@@ -178,6 +181,8 @@ gst_webrtc_data_channel_finalize (GObject * object)
   g_free (channel->protocol);
   channel->protocol = NULL;
 
+  g_mutex_clear (&channel->lock);
+
   G_OBJECT_CLASS (parent_class)->finalize (object);
 }
 
@@ -258,7 +263,7 @@ gst_webrtc_data_channel_class_init (GstWebRTCDataChannelClass * klass)
           "Ready State",
           "The Ready state of this data channel",
           GST_TYPE_WEBRTC_DATA_CHANNEL_STATE,
-          GST_WEBRTC_DATA_CHANNEL_STATE_NEW,
+          GST_WEBRTC_DATA_CHANNEL_STATE_CONNECTING,
           G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
 
   g_object_class_install_property (gobject_class,
@@ -334,7 +339,7 @@ gst_webrtc_data_channel_class_init (GstWebRTCDataChannelClass * klass)
    */
   gst_webrtc_data_channel_signals[SIGNAL_SEND_DATA] =
       g_signal_new_class_handler ("send-data", G_TYPE_FROM_CLASS (klass),
-      G_SIGNAL_RUN_LAST | G_SIGNAL_ACTION,
+      G_SIGNAL_RUN_LAST | G_SIGNAL_ACTION | G_SIGNAL_DEPRECATED,
       G_CALLBACK (gst_webrtc_data_channel_send_data), NULL, NULL, NULL,
       G_TYPE_NONE, 1, G_TYPE_BYTES);
 
@@ -519,7 +524,31 @@ gst_webrtc_data_channel_send_data (GstWebRTCDataChannel * channel,
   g_return_if_fail (GST_IS_WEBRTC_DATA_CHANNEL (channel));
 
   klass = GST_WEBRTC_DATA_CHANNEL_GET_CLASS (channel);
-  klass->send_data (channel, data);
+  (void) klass->send_data (channel, data, NULL);
+}
+
+/**
+ * gst_webrtc_data_channel_send_data_full:
+ * @channel: a #GstWebRTCDataChannel
+ * @data: (nullable): a #GBytes or %NULL
+ * @error: (nullable): location to a #GError or %NULL
+ *
+ * Send @data as a data message over @channel.
+ *
+ * Returns: TRUE if @channel is open and data could be queued
+ *
+ * Since: 1.22
+ */
+gboolean
+gst_webrtc_data_channel_send_data_full (GstWebRTCDataChannel * channel,
+    GBytes * data, GError ** error)
+{
+  GstWebRTCDataChannelClass *klass;
+
+  g_return_val_if_fail (GST_IS_WEBRTC_DATA_CHANNEL (channel), FALSE);
+
+  klass = GST_WEBRTC_DATA_CHANNEL_GET_CLASS (channel);
+  return klass->send_data (channel, data, error);
 }
 
 /**
@@ -538,7 +567,30 @@ gst_webrtc_data_channel_send_string (GstWebRTCDataChannel * channel,
   g_return_if_fail (GST_IS_WEBRTC_DATA_CHANNEL (channel));
 
   klass = GST_WEBRTC_DATA_CHANNEL_GET_CLASS (channel);
-  klass->send_string (channel, str);
+  (void) klass->send_string (channel, str, NULL);
+}
+
+/**
+ * gst_webrtc_data_channel_send_string_full:
+ * @channel: a #GstWebRTCDataChannel
+ * @str: (nullable): a string or %NULL
+ *
+ * Send @str as a string message over @channel.
+ *
+ * Returns: TRUE if @channel is open and data could be queued
+ *
+ * Since: 1.22
+ */
+gboolean
+gst_webrtc_data_channel_send_string_full (GstWebRTCDataChannel * channel,
+    const gchar * str, GError ** error)
+{
+  GstWebRTCDataChannelClass *klass;
+
+  g_return_val_if_fail (GST_IS_WEBRTC_DATA_CHANNEL (channel), FALSE);
+
+  klass = GST_WEBRTC_DATA_CHANNEL_GET_CLASS (channel);
+  return klass->send_string (channel, str, error);
 }
 
 /**
diff --git a/gst-libs/gst/webrtc/datachannel.h b/gst-libs/gst/webrtc/datachannel.h
index 79b536f5b..408872aec 100644
--- a/gst-libs/gst/webrtc/datachannel.h
+++ b/gst-libs/gst/webrtc/datachannel.h
@@ -36,77 +36,22 @@ GType gst_webrtc_data_channel_get_type(void);
 #define GST_IS_WEBRTC_DATA_CHANNEL_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE((klass) ,GST_TYPE_WEBRTC_DATA_CHANNEL))
 #define GST_WEBRTC_DATA_CHANNEL_GET_CLASS(obj)  (G_TYPE_INSTANCE_GET_CLASS((obj) ,GST_TYPE_WEBRTC_DATA_CHANNEL,GstWebRTCDataChannelClass))
 
-#define GST_WEBRTC_DATA_CHANNEL_LOCK(channel) g_mutex_lock(&((GstWebRTCDataChannel *)(channel))->lock)
-#define GST_WEBRTC_DATA_CHANNEL_UNLOCK(channel) g_mutex_unlock(&((GstWebRTCDataChannel *)(channel))->lock)
-
-/**
- * GstWebRTCDataChannel:
- *
- * Since: 1.18
- */
-struct _GstWebRTCDataChannel
-{
-  GObject                           parent;
-
-  GMutex                            lock;
-
-  gchar                            *label;
-  gboolean                          ordered;
-  guint                             max_packet_lifetime;
-  guint                             max_retransmits;
-  gchar                            *protocol;
-  gboolean                          negotiated;
-  gint                              id;
-  GstWebRTCPriorityType             priority;
-  GstWebRTCDataChannelState         ready_state;
-  guint64                           buffered_amount;
-  guint64                           buffered_amount_low_threshold;
-
-  gpointer                         _padding[GST_PADDING];
-};
-
-/**
- * GstWebRTCDataChannelClass:
- *
- * Since: 1.18
- */
-struct _GstWebRTCDataChannelClass
-{
-  GObjectClass        parent_class;
-
-  void              (*send_data)   (GstWebRTCDataChannel * channel, GBytes *data);
-  void              (*send_string) (GstWebRTCDataChannel * channel, const gchar *str);
-  void              (*close)       (GstWebRTCDataChannel * channel);
-
-  gpointer           _padding[GST_PADDING];
-};
-
 GST_WEBRTC_API
-void gst_webrtc_data_channel_on_open (GstWebRTCDataChannel * channel);
+gboolean gst_webrtc_data_channel_send_data_full (GstWebRTCDataChannel * channel, GBytes * data, GError ** error);
 
 GST_WEBRTC_API
-void gst_webrtc_data_channel_on_close (GstWebRTCDataChannel * channel);
+gboolean gst_webrtc_data_channel_send_string_full (GstWebRTCDataChannel * channel, const gchar * str, GError ** error);
 
 GST_WEBRTC_API
-void gst_webrtc_data_channel_on_error (GstWebRTCDataChannel * channel, GError * error);
-
-GST_WEBRTC_API
-void gst_webrtc_data_channel_on_message_data (GstWebRTCDataChannel * channel, GBytes * data);
-
-GST_WEBRTC_API
-void gst_webrtc_data_channel_on_message_string (GstWebRTCDataChannel * channel, const gchar * str);
-
-GST_WEBRTC_API
-void gst_webrtc_data_channel_on_buffered_amount_low (GstWebRTCDataChannel * channel);
+void gst_webrtc_data_channel_close (GstWebRTCDataChannel * channel);
 
-GST_WEBRTC_API
+#ifndef GST_REMOVE_DEPRECATED
+GST_WEBRTC_DEPRECATED_FOR(gst_webrtc_data_channel_send_data_full)
 void gst_webrtc_data_channel_send_data (GstWebRTCDataChannel * channel, GBytes * data);
 
-GST_WEBRTC_API
+GST_WEBRTC_DEPRECATED_FOR(gst_webrtc_data_channel_send_string_full)
 void gst_webrtc_data_channel_send_string (GstWebRTCDataChannel * channel, const gchar * str);
-
-GST_WEBRTC_API
-void gst_webrtc_data_channel_close (GstWebRTCDataChannel * channel);
+#endif
 
 G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstWebRTCDataChannel, g_object_unref)
 
diff --git a/gst-libs/gst/webrtc/dtlstransport.c b/gst-libs/gst/webrtc/dtlstransport.c
index 2c7135b1d..bd1a553e7 100644
--- a/gst-libs/gst/webrtc/dtlstransport.c
+++ b/gst-libs/gst/webrtc/dtlstransport.c
@@ -22,6 +22,8 @@
  * @short_description: RTCDtlsTransport object
  * @title: GstWebRTCDTLSTransport
  * @see_also: #GstWebRTCRTPSender, #GstWebRTCRTPReceiver, #GstWebRTCICETransport
+ * @symbols:
+ * - GstWebRTCDTLSTransport
  *
  * <https://www.w3.org/TR/webrtc/#rtcdtlstransport>
  */
@@ -32,6 +34,8 @@
 
 #include "dtlstransport.h"
 
+#include "webrtc-priv.h"
+
 #define GST_CAT_DEFAULT gst_webrtc_dtls_transport_debug
 GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
 
@@ -55,20 +59,26 @@ enum
   PROP_STATE,
   PROP_CLIENT,
   PROP_CERTIFICATE,
-  PROP_REMOTE_CERTIFICATE,
-  PROP_RTCP,
+  PROP_REMOTE_CERTIFICATE
 };
 
 void
 gst_webrtc_dtls_transport_set_transport (GstWebRTCDTLSTransport * transport,
     GstWebRTCICETransport * ice)
 {
+  gboolean notify = FALSE;
+
   g_return_if_fail (GST_IS_WEBRTC_DTLS_TRANSPORT (transport));
   g_return_if_fail (GST_IS_WEBRTC_ICE_TRANSPORT (ice));
 
   GST_OBJECT_LOCK (transport);
-  gst_object_replace ((GstObject **) & transport->transport, GST_OBJECT (ice));
+  notify =
+      gst_object_replace ((GstObject **) & transport->transport,
+      GST_OBJECT (ice));
   GST_OBJECT_UNLOCK (transport);
+
+  if (notify)
+    g_object_notify (G_OBJECT (transport), "transport");
 }
 
 static void
@@ -88,9 +98,6 @@ gst_webrtc_dtls_transport_set_property (GObject * object, guint prop_id,
     case PROP_CERTIFICATE:
       g_object_set_property (G_OBJECT (webrtc->dtlssrtpdec), "pem", value);
       break;
-    case PROP_RTCP:
-      webrtc->is_rtcp = g_value_get_boolean (value);
-      break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
       break;
@@ -123,9 +130,6 @@ gst_webrtc_dtls_transport_get_property (GObject * object, guint prop_id,
     case PROP_REMOTE_CERTIFICATE:
       g_object_get_property (G_OBJECT (webrtc->dtlssrtpdec), "peer-pem", value);
       break;
-    case PROP_RTCP:
-      g_value_set_boolean (value, webrtc->is_rtcp);
-      break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
       break;
@@ -184,12 +188,12 @@ gst_webrtc_dtls_transport_constructed (GObject * object)
   /* XXX: this may collide with another connection_id however this is only a
    * problem if multiple dtls element sets are being used within the same
    * process */
-  connection_id = g_strdup_printf ("%s_%u_%u", webrtc->is_rtcp ? "rtcp" : "rtp",
-      webrtc->session_id, g_random_int ());
+  connection_id = g_strdup_printf ("rtp_%u_%u", webrtc->session_id,
+      g_random_int ());
 
   webrtc->dtlssrtpenc = gst_element_factory_make ("dtlssrtpenc", NULL);
   g_object_set (webrtc->dtlssrtpenc, "connection-id", connection_id,
-      "is-client", webrtc->client, "rtp-sync", TRUE, NULL);
+      "is-client", webrtc->client, "rtp-sync", FALSE, NULL);
 
   webrtc->dtlssrtpdec = gst_element_factory_make ("dtlssrtpdec", NULL);
   g_object_set (webrtc->dtlssrtpdec, "connection-id", connection_id, NULL);
@@ -249,12 +253,6 @@ gst_webrtc_dtls_transport_class_init (GstWebRTCDTLSTransportClass * klass)
       g_param_spec_string ("remote-certificate", "Remote DTLS certificate",
           "Remote DTLS certificate", NULL,
           G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
-
-  g_object_class_install_property (gobject_class,
-      PROP_RTCP,
-      g_param_spec_boolean ("rtcp", "RTCP",
-          "The transport is being used solely for RTCP", FALSE,
-          G_PARAM_READWRITE | G_PARAM_CONSTRUCT_ONLY | G_PARAM_STATIC_STRINGS));
 }
 
 static void
@@ -263,8 +261,8 @@ gst_webrtc_dtls_transport_init (GstWebRTCDTLSTransport * webrtc)
 }
 
 GstWebRTCDTLSTransport *
-gst_webrtc_dtls_transport_new (guint session_id, gboolean is_rtcp)
+gst_webrtc_dtls_transport_new (guint session_id)
 {
   return g_object_new (GST_TYPE_WEBRTC_DTLS_TRANSPORT, "session-id", session_id,
-      "rtcp", is_rtcp, NULL);
+      NULL);
 }
diff --git a/gst-libs/gst/webrtc/dtlstransport.h b/gst-libs/gst/webrtc/dtlstransport.h
index feb3944bb..019861956 100644
--- a/gst-libs/gst/webrtc/dtlstransport.h
+++ b/gst-libs/gst/webrtc/dtlstransport.h
@@ -35,39 +35,6 @@ GType gst_webrtc_dtls_transport_get_type(void);
 #define GST_IS_WEBRTC_DTLS_TRANSPORT_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE((klass) ,GST_TYPE_WEBRTC_DTLS_TRANSPORT))
 #define GST_WEBRTC_DTLS_TRANSPORT_GET_CLASS(obj)  (G_TYPE_INSTANCE_GET_CLASS((obj) ,GST_TYPE_WEBRTC_DTLS_TRANSPORT,GstWebRTCDTLSTransportClass))
 
-/**
- * GstWebRTCDTLSTransport:
- */
-struct _GstWebRTCDTLSTransport
-{
-  GstObject                          parent;
-
-  GstWebRTCICETransport             *transport;
-  GstWebRTCDTLSTransportState        state;
-
-  gboolean                           is_rtcp;
-  gboolean                           client;
-  guint                              session_id;
-  GstElement                        *dtlssrtpenc;
-  GstElement                        *dtlssrtpdec;
-
-  gpointer                          _padding[GST_PADDING];
-};
-
-struct _GstWebRTCDTLSTransportClass
-{
-  GstObjectClass               parent_class;
-
-  gpointer                  _padding[GST_PADDING];
-};
-
-GST_WEBRTC_API
-GstWebRTCDTLSTransport *    gst_webrtc_dtls_transport_new               (guint session_id, gboolean rtcp);
-
-GST_WEBRTC_API
-void                        gst_webrtc_dtls_transport_set_transport     (GstWebRTCDTLSTransport * transport,
-                                                                         GstWebRTCICETransport * ice);
-
 G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstWebRTCDTLSTransport, gst_object_unref)
 
 G_END_DECLS
diff --git a/gst-libs/gst/webrtc/ice.c b/gst-libs/gst/webrtc/ice.c
new file mode 100644
index 000000000..2328d0b82
--- /dev/null
+++ b/gst-libs/gst/webrtc/ice.c
@@ -0,0 +1,622 @@
+/* GStreamer
+ * Copyright (C) 2017 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+/**
+ * SECTION:gstwebrtcice
+ * @title: GstWebRTCICE
+ * @short_description: Base class WebRTC ICE handling
+ * @symbols:
+ * - GstWebRTCICE
+ */
+
+#ifdef HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "ice.h"
+#include "icestream.h"
+
+#include "webrtc-priv.h"
+
+#define GST_CAT_DEFAULT gst_webrtc_ice_debug
+GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
+
+enum
+{
+  SIGNAL_0,
+  ADD_LOCAL_IP_ADDRESS_SIGNAL,
+  LAST_SIGNAL,
+};
+
+enum
+{
+  PROP_0,
+  PROP_MIN_RTP_PORT,
+  PROP_MAX_RTP_PORT,
+};
+
+static guint gst_webrtc_ice_signals[LAST_SIGNAL] = { 0 };
+
+#define gst_webrtc_ice_parent_class parent_class
+G_DEFINE_ABSTRACT_TYPE_WITH_CODE (GstWebRTCICE, gst_webrtc_ice,
+    GST_TYPE_OBJECT, GST_DEBUG_CATEGORY_INIT (gst_webrtc_ice_debug,
+        "webrtcice", 0, "webrtcice"););
+
+/**
+ * gst_webrtc_ice_add_stream:
+ * @ice: The #GstWebRTCICE
+ * @session_id: The session id
+ *
+ * Returns: (transfer full) (nullable): The #GstWebRTCICEStream, or %NULL
+ *
+ * Since: 1.22
+ */
+GstWebRTCICEStream *
+gst_webrtc_ice_add_stream (GstWebRTCICE * ice, guint session_id)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE (ice), NULL);
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->add_stream);
+
+  return GST_WEBRTC_ICE_GET_CLASS (ice)->add_stream (ice, session_id);
+}
+
+/**
+ * gst_webrtc_ice_find_transport:
+ * @ice: The #GstWebRTCICE
+ * @stream: The #GstWebRTCICEStream
+ * @component: The #GstWebRTCICEComponent
+ *
+ * Returns: (transfer full) (nullable): The #GstWebRTCICETransport, or %NULL
+ *
+ * Since: 1.22
+ */
+GstWebRTCICETransport *
+gst_webrtc_ice_find_transport (GstWebRTCICE * ice,
+    GstWebRTCICEStream * stream, GstWebRTCICEComponent component)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE (ice), NULL);
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->find_transport);
+
+  return GST_WEBRTC_ICE_GET_CLASS (ice)->find_transport (ice, stream,
+      component);
+}
+
+/**
+ * gst_webrtc_ice_add_candidate:
+ * @ice: The #GstWebRTCICE
+ * @stream: The #GstWebRTCICEStream
+ * @candidate: The ICE candidate
+ *
+ * Since: 1.22
+ */
+void
+gst_webrtc_ice_add_candidate (GstWebRTCICE * ice,
+    GstWebRTCICEStream * stream, const gchar * candidate)
+{
+  g_return_if_fail (GST_IS_WEBRTC_ICE (ice));
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->add_candidate);
+
+  GST_WEBRTC_ICE_GET_CLASS (ice)->add_candidate (ice, stream, candidate);
+}
+
+/**
+ * gst_webrtc_ice_set_remote_credentials:
+ * @ice: The #GstWebRTCICE
+ * @stream: The #GstWebRTCICEStream
+ * @ufrag: ICE username
+ * @pwd: ICE password
+ *
+ * Returns: FALSE on error, TRUE otherwise
+ *
+ * Since: 1.22
+ */
+gboolean
+gst_webrtc_ice_set_remote_credentials (GstWebRTCICE * ice,
+    GstWebRTCICEStream * stream, const gchar * ufrag, const gchar * pwd)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE (ice), FALSE);
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->set_remote_credentials);
+
+  return GST_WEBRTC_ICE_GET_CLASS (ice)->set_remote_credentials (ice, stream,
+      ufrag, pwd);
+}
+
+/**
+ * gst_webrtc_ice_add_turn_server:
+ * @ice: The #GstWebRTCICE
+ * @uri: URI of the TURN server
+ *
+ * Returns: FALSE on error, TRUE otherwise
+ *
+ * Since: 1.22
+ */
+gboolean
+gst_webrtc_ice_add_turn_server (GstWebRTCICE * ice, const gchar * uri)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE (ice), FALSE);
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->add_turn_server);
+
+  return GST_WEBRTC_ICE_GET_CLASS (ice)->add_turn_server (ice, uri);
+}
+
+/**
+ * gst_webrtc_ice_set_local_credentials:
+ * @ice: The #GstWebRTCICE
+ * @stream: The #GstWebRTCICEStream
+ * @ufrag: ICE username
+ * @pwd: ICE password
+ *
+ * Returns: FALSE on error, TRUE otherwise
+ *
+ * Since: 1.22
+ */
+gboolean
+gst_webrtc_ice_set_local_credentials (GstWebRTCICE * ice,
+    GstWebRTCICEStream * stream, const gchar * ufrag, const gchar * pwd)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE (ice), FALSE);
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->set_local_credentials);
+
+  return GST_WEBRTC_ICE_GET_CLASS (ice)->set_local_credentials (ice, stream,
+      ufrag, pwd);
+}
+
+/**
+ * gst_webrtc_ice_gather_candidates:
+ * @ice: The #GstWebRTCICE
+ * @stream: The #GstWebRTCICEStream
+ * Returns: FALSE on error, TRUE otherwise
+ *
+ * Since: 1.22
+ */
+gboolean
+gst_webrtc_ice_gather_candidates (GstWebRTCICE * ice,
+    GstWebRTCICEStream * stream)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE (ice), FALSE);
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->gather_candidates);
+
+  return GST_WEBRTC_ICE_GET_CLASS (ice)->gather_candidates (ice, stream);
+}
+
+/**
+ * gst_webrtc_ice_set_is_controller:
+ * @ice: The #GstWebRTCICE
+ * @controller: TRUE to set as controller
+ *
+ * Since: 1.22
+ */
+void
+gst_webrtc_ice_set_is_controller (GstWebRTCICE * ice, gboolean controller)
+{
+  g_return_if_fail (GST_IS_WEBRTC_ICE (ice));
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->set_is_controller);
+
+  GST_WEBRTC_ICE_GET_CLASS (ice)->set_is_controller (ice, controller);
+}
+
+/**
+ * gst_webrtc_ice_get_is_controller:
+ * @ice: The #GstWebRTCICE
+ * Returns: TRUE if set as controller, FALSE otherwise
+ *
+ * Since: 1.22
+ */
+gboolean
+gst_webrtc_ice_get_is_controller (GstWebRTCICE * ice)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE (ice), FALSE);
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->get_is_controller);
+
+  return GST_WEBRTC_ICE_GET_CLASS (ice)->get_is_controller (ice);
+}
+
+/**
+ * gst_webrtc_ice_set_force_relay:
+ * @ice: The #GstWebRTCICE
+ * @force_relay: TRUE to enable force relay
+ *
+ * Since: 1.22
+ */
+void
+gst_webrtc_ice_set_force_relay (GstWebRTCICE * ice, gboolean force_relay)
+{
+  g_return_if_fail (GST_IS_WEBRTC_ICE (ice));
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->set_force_relay);
+
+  GST_WEBRTC_ICE_GET_CLASS (ice)->set_force_relay (ice, force_relay);
+}
+
+/**
+ * gst_webrtc_ice_set_tos:
+ * @ice: The #GstWebRTCICE
+ * @stream: The #GstWebRTCICEStream
+ * @tos: ToS to be set
+ *
+ * Since: 1.22
+ */
+void
+gst_webrtc_ice_set_tos (GstWebRTCICE * ice, GstWebRTCICEStream * stream,
+    guint tos)
+{
+  g_return_if_fail (GST_IS_WEBRTC_ICE (ice));
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->set_tos);
+
+  GST_WEBRTC_ICE_GET_CLASS (ice)->set_tos (ice, stream, tos);
+}
+
+
+/**
+ * gst_webrtc_ice_get_local_candidates:
+ * @ice: The #GstWebRTCICE
+ * @stream: The #GstWebRTCICEStream
+ * Returns: (transfer full)(array zero-terminated=1): List of local candidates
+ *
+ * Since: 1.22
+ */
+GstWebRTCICECandidateStats **
+gst_webrtc_ice_get_local_candidates (GstWebRTCICE * ice,
+    GstWebRTCICEStream * stream)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE (ice), NULL);
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->get_local_candidates);
+
+  return GST_WEBRTC_ICE_GET_CLASS (ice)->get_local_candidates (ice, stream);
+}
+
+
+/**
+ * gst_webrtc_ice_get_remote_candidates:
+ * @ice: The #GstWebRTCICE
+ * @stream: The #GstWebRTCICEStream
+ * Returns: (transfer full) (array zero-terminated=1): List of remote candidates
+ *
+ * Since: 1.22
+ */
+GstWebRTCICECandidateStats **
+gst_webrtc_ice_get_remote_candidates (GstWebRTCICE * ice,
+    GstWebRTCICEStream * stream)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE (ice), NULL);
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->get_remote_candidates);
+
+  return GST_WEBRTC_ICE_GET_CLASS (ice)->get_remote_candidates (ice, stream);
+}
+
+/**
+ * gst_webrtc_ice_get_selected_pair:
+ * @ice: The #GstWebRTCICE
+ * @stream: The #GstWebRTCICEStream
+ * @local_stats: (out) (transfer full): A pointer to #GstWebRTCICECandidateStats for local candidate
+ * @remote_stats: (out) (transfer full): pointer to #GstWebRTCICECandidateStats for remote candidate
+ *
+ * Returns: FALSE on failure, otherwise @local_stats @remote_stats will be set
+ *
+ * Since: 1.22
+ */
+gboolean
+gst_webrtc_ice_get_selected_pair (GstWebRTCICE * ice,
+    GstWebRTCICEStream * stream, GstWebRTCICECandidateStats ** local_stats,
+    GstWebRTCICECandidateStats ** remote_stats)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE (ice), FALSE);
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->get_selected_pair);
+
+  return GST_WEBRTC_ICE_GET_CLASS (ice)->get_selected_pair (ice, stream,
+      local_stats, remote_stats);
+}
+
+/**
+ * gst_webrtc_ice_candidate_stats_free:
+ * @stats: The #GstWebRTCICECandidateStats to be free'd
+ *
+ * Helper function to free #GstWebRTCICECandidateStats
+ *
+ * Since: 1.22
+ */
+void
+gst_webrtc_ice_candidate_stats_free (GstWebRTCICECandidateStats * stats)
+{
+  if (stats) {
+    g_free (stats->ipaddr);
+    g_free (stats->url);
+  }
+
+  g_free (stats);
+}
+
+/**
+ * gst_webrtc_ice_candidate_stats_copy:
+ * @stats: The #GstWebRTCICE
+ *
+ * Returns: (transfer full): A copy of @stats
+ *
+ * Since: 1.22
+ */
+GstWebRTCICECandidateStats *
+gst_webrtc_ice_candidate_stats_copy (GstWebRTCICECandidateStats * stats)
+{
+  GstWebRTCICECandidateStats *copy =
+      g_malloc (sizeof (GstWebRTCICECandidateStats));
+
+  *copy = *stats;
+
+  copy->ipaddr = g_strdup (stats->ipaddr);
+  copy->url = g_strdup (stats->url);
+
+  return copy;
+}
+
+G_DEFINE_BOXED_TYPE (GstWebRTCICECandidateStats, gst_webrtc_ice_candidate_stats,
+    (GBoxedCopyFunc) gst_webrtc_ice_candidate_stats_copy,
+    (GBoxedFreeFunc) gst_webrtc_ice_candidate_stats_free);
+
+/**
+ * gst_webrtc_ice_set_on_ice_candidate:
+ * @ice: The #GstWebRTCICE
+ * @func: The #GstWebRTCICEOnCandidateFunc callback function
+ * @user_data: User data passed to the callback function
+ * @notify: a #GDestroyNotify when the candidate is no longer needed
+ *
+ * Since: 1.22
+ */
+void
+gst_webrtc_ice_set_on_ice_candidate (GstWebRTCICE * ice,
+    GstWebRTCICEOnCandidateFunc func, gpointer user_data, GDestroyNotify notify)
+{
+  g_return_if_fail (GST_IS_WEBRTC_ICE (ice));
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->set_on_ice_candidate);
+
+  GST_WEBRTC_ICE_GET_CLASS (ice)->set_on_ice_candidate (ice, func, user_data,
+      notify);
+}
+
+/**
+ * gst_webrtc_ice_set_stun_server:
+ * @ice: The #GstWebRTCICE
+ * @uri: (nullable): URI of the STUN server
+ *
+ * Since: 1.22
+ */
+void
+gst_webrtc_ice_set_stun_server (GstWebRTCICE * ice, const gchar * uri_s)
+{
+  g_return_if_fail (GST_IS_WEBRTC_ICE (ice));
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->set_stun_server);
+
+  GST_WEBRTC_ICE_GET_CLASS (ice)->set_stun_server (ice, uri_s);
+}
+
+/**
+ * gst_webrtc_ice_get_stun_server:
+ * @ice: The #GstWebRTCICE
+ *
+ * Returns: (nullable): URI of the STUN sever
+ *
+ * Since: 1.22
+ */
+gchar *
+gst_webrtc_ice_get_stun_server (GstWebRTCICE * ice)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE (ice), NULL);
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->get_stun_server);
+
+  return GST_WEBRTC_ICE_GET_CLASS (ice)->get_stun_server (ice);
+}
+
+/**
+ * gst_webrtc_ice_set_turn_server:
+ * @ice: The #GstWebRTCICE
+ * @uri: (nullable): URI of the TURN sever
+ *
+ * Since: 1.22
+ */
+void
+gst_webrtc_ice_set_turn_server (GstWebRTCICE * ice, const gchar * uri_s)
+{
+  g_return_if_fail (GST_IS_WEBRTC_ICE (ice));
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->set_turn_server);
+
+  GST_WEBRTC_ICE_GET_CLASS (ice)->set_turn_server (ice, uri_s);
+}
+
+/**
+ * gst_webrtc_ice_get_turn_server:
+ * @ice: The #GstWebRTCICE
+ *
+ * Returns: (nullable): URI of the TURN sever
+ *
+ * Since: 1.22
+ */
+gchar *
+gst_webrtc_ice_get_turn_server (GstWebRTCICE * ice)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE (ice), NULL);
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->get_turn_server);
+
+  return GST_WEBRTC_ICE_GET_CLASS (ice)->get_turn_server (ice);
+}
+
+/**
+ * gst_webrtc_ice_set_http_proxy:
+ * @ice: The #GstWebRTCICE
+ * @uri: (transfer none): URI of the HTTP proxy of the form
+ *   http://[username:password@]hostname[:port]
+ *
+ * Set HTTP Proxy to be used when connecting to TURN server.
+ *
+ * Since: 1.22
+ */
+void
+gst_webrtc_ice_set_http_proxy (GstWebRTCICE * ice, const gchar * uri_s)
+{
+  g_return_if_fail (GST_IS_WEBRTC_ICE (ice));
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->set_http_proxy);
+
+  GST_WEBRTC_ICE_GET_CLASS (ice)->set_http_proxy (ice, uri_s);
+}
+
+/**
+ * gst_webrtc_ice_get_http_proxy:
+ * @ice: The #GstWebRTCICE
+ *
+ * Returns: (transfer full): URI of the HTTP proxy of the form
+ *   http://[username:password@]hostname[:port]
+ *
+ * Get HTTP Proxy to be used when connecting to TURN server.
+ *
+ * Since: 1.22
+ */
+gchar *
+gst_webrtc_ice_get_http_proxy (GstWebRTCICE * ice)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE (ice), NULL);
+  g_assert (GST_WEBRTC_ICE_GET_CLASS (ice)->get_http_proxy);
+
+  return GST_WEBRTC_ICE_GET_CLASS (ice)->get_http_proxy (ice);
+}
+
+
+static void
+gst_webrtc_ice_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  GstWebRTCICE *ice = GST_WEBRTC_ICE (object);
+
+  switch (prop_id) {
+    case PROP_MIN_RTP_PORT:
+      ice->min_rtp_port = g_value_get_uint (value);
+      if (ice->min_rtp_port > ice->max_rtp_port)
+        g_warning ("Set min-rtp-port to %u which is larger than"
+            " max-rtp-port %u", ice->min_rtp_port, ice->max_rtp_port);
+      break;
+    case PROP_MAX_RTP_PORT:
+      ice->max_rtp_port = g_value_get_uint (value);
+      if (ice->min_rtp_port > ice->max_rtp_port)
+        g_warning ("Set max-rtp-port to %u which is smaller than"
+            " min-rtp-port %u", ice->max_rtp_port, ice->min_rtp_port);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_webrtc_ice_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  GstWebRTCICE *ice = GST_WEBRTC_ICE (object);
+
+  switch (prop_id) {
+    case PROP_MIN_RTP_PORT:
+      g_value_set_uint (value, ice->min_rtp_port);
+      break;
+    case PROP_MAX_RTP_PORT:
+      g_value_set_uint (value, ice->max_rtp_port);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_webrtc_ice_class_init (GstWebRTCICEClass * klass)
+{
+  GObjectClass *gobject_class = (GObjectClass *) klass;
+
+  klass->add_stream = NULL;
+  klass->find_transport = NULL;
+  klass->gather_candidates = NULL;
+  klass->add_candidate = NULL;
+  klass->set_local_credentials = NULL;
+  klass->set_remote_credentials = NULL;
+  klass->add_turn_server = NULL;
+  klass->set_is_controller = NULL;
+  klass->get_is_controller = NULL;
+  klass->set_force_relay = NULL;
+  klass->set_stun_server = NULL;
+  klass->get_stun_server = NULL;
+  klass->set_turn_server = NULL;
+  klass->get_turn_server = NULL;
+  klass->get_http_proxy = NULL;
+  klass->set_http_proxy = NULL;
+  klass->set_tos = NULL;
+  klass->set_on_ice_candidate = NULL;
+  klass->get_local_candidates = NULL;
+  klass->get_remote_candidates = NULL;
+  klass->get_selected_pair = NULL;
+
+  gobject_class->get_property = gst_webrtc_ice_get_property;
+  gobject_class->set_property = gst_webrtc_ice_set_property;
+
+  /**
+   * GstWebRTCICE:min-rtp-port:
+   *
+   * Minimum port for local rtp port range.
+   * min-rtp-port must be <= max-rtp-port
+   *
+   * Since: 1.20
+   */
+  g_object_class_install_property (gobject_class,
+      PROP_MIN_RTP_PORT,
+      g_param_spec_uint ("min-rtp-port", "ICE RTP candidate min port",
+          "Minimum port for local rtp port range. "
+          "min-rtp-port must be <= max-rtp-port",
+          0, 65535, 0,
+          G_PARAM_READWRITE | G_PARAM_CONSTRUCT | G_PARAM_STATIC_STRINGS));
+
+  /**
+   * GstWebRTCICE:max-rtp-port:
+   *
+   * Maximum port for local rtp port range.
+   * min-rtp-port must be <= max-rtp-port
+   *
+   * Since: 1.20
+   */
+  g_object_class_install_property (gobject_class,
+      PROP_MAX_RTP_PORT,
+      g_param_spec_uint ("max-rtp-port", "ICE RTP candidate max port",
+          "Maximum port for local rtp port range. "
+          "max-rtp-port must be >= min-rtp-port",
+          0, 65535, 65535,
+          G_PARAM_READWRITE | G_PARAM_CONSTRUCT | G_PARAM_STATIC_STRINGS));
+
+  /**
+   * GstWebRTCICE::add-local-ip-address:
+   * @object: the #GstWebRTCICE
+   * @address: The local IP address
+   *
+   * Add a local IP address to use for ICE candidate gathering.  If none
+   * are supplied, they will be discovered automatically. Calling this signal
+   * stops automatic ICE gathering.
+   *
+   * Returns: whether the address could be added.
+   */
+  gst_webrtc_ice_signals[ADD_LOCAL_IP_ADDRESS_SIGNAL] =
+      g_signal_new_class_handler ("add-local-ip-address",
+      G_TYPE_FROM_CLASS (klass), G_SIGNAL_RUN_LAST | G_SIGNAL_ACTION,
+      NULL, NULL, NULL,
+      g_cclosure_marshal_generic, G_TYPE_BOOLEAN, 1, G_TYPE_STRING);
+}
+
+static void
+gst_webrtc_ice_init (GstWebRTCICE * ice)
+{
+}
diff --git a/gst-libs/gst/webrtc/ice.h b/gst-libs/gst/webrtc/ice.h
new file mode 100644
index 000000000..f67889b1f
--- /dev/null
+++ b/gst-libs/gst/webrtc/ice.h
@@ -0,0 +1,261 @@
+/* GStreamer
+ * Copyright (C) 2017 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef __GST_WEBRTC_ICE_H__
+#define __GST_WEBRTC_ICE_H__
+
+#include <gst/webrtc/webrtc_fwd.h>
+
+G_BEGIN_DECLS
+
+GST_WEBRTC_API
+GType gst_webrtc_ice_get_type(void);
+#define GST_TYPE_WEBRTC_ICE            (gst_webrtc_ice_get_type())
+#define GST_WEBRTC_ICE(obj)            (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_WEBRTC_ICE,GstWebRTCICE))
+#define GST_IS_WEBRTC_ICE(obj)         (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_WEBRTC_ICE))
+#define GST_WEBRTC_ICE_CLASS(klass)    (G_TYPE_CHECK_CLASS_CAST((klass) ,GST_TYPE_WEBRTC_ICE,GstWebRTCICEClass))
+#define GST_IS_WEBRTC_ICE_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE((klass) ,GST_TYPE_WEBRTC_ICE))
+#define GST_WEBRTC_ICE_GET_CLASS(obj)  (G_TYPE_INSTANCE_GET_CLASS((obj) ,GST_TYPE_WEBRTC_ICE,GstWebRTCICEClass))
+
+struct _GstWebRTCICE
+{
+  GstObject                          parent;
+
+  GstWebRTCICEGatheringState         ice_gathering_state;
+  GstWebRTCICEConnectionState        ice_connection_state;
+
+  /*< protected >*/
+  guint                              min_rtp_port;
+  guint                              max_rtp_port;
+
+  gpointer _gst_reserved[GST_PADDING];
+};
+
+struct _GstWebRTCICECandidateStats
+{
+  gchar                            *ipaddr;
+  guint                             port;
+  guint                             stream_id;
+  const gchar                      *type;
+  const gchar                      *proto;
+  const gchar                      *relay_proto;
+  guint                             prio;
+  gchar                            *url;
+
+  gpointer _gst_reserved[GST_PADDING_LARGE];
+};
+
+/**
+ * GstWebRTCICEOnCandidateFunc:
+ * @ice: The #GstWebRTCICE
+ * @stream_id: The stream id
+ * @candidate: The discovered candidate
+ * @user_data: User data that was set by #gst_webrtc_ice_set_on_ice_candidate
+ *
+ * Callback function to be triggered on discovery of a new candidate
+ * Since: 1.22
+ */
+typedef void (*GstWebRTCICEOnCandidateFunc) (GstWebRTCICE * ice, guint stream_id, const gchar * candidate, gpointer user_data);
+
+struct _GstWebRTCICEClass {
+  GstObjectClass parent_class;
+  GstWebRTCICEStream * (*add_stream)                   (GstWebRTCICE * ice,
+                                                        guint session_id);
+  GstWebRTCICETransport * (*find_transport)            (GstWebRTCICE * ice,
+                                                        GstWebRTCICEStream * stream,
+                                                        GstWebRTCICEComponent component);
+  gboolean (*gather_candidates)                        (GstWebRTCICE * ice,
+                                                        GstWebRTCICEStream * stream);
+  void (*add_candidate)                                (GstWebRTCICE * ice,
+                                                        GstWebRTCICEStream * stream,
+                                                        const gchar * candidate);
+  gboolean (*set_local_credentials)                    (GstWebRTCICE * ice,
+                                                        GstWebRTCICEStream * stream,
+                                                        const gchar * ufrag,
+                                                        const gchar * pwd);
+  gboolean (*set_remote_credentials)                   (GstWebRTCICE * ice,
+                                                        GstWebRTCICEStream * stream,
+                                                        const gchar * ufrag,
+                                                        const gchar * pwd);
+  gboolean (*add_turn_server)                          (GstWebRTCICE * ice,
+                                                        const gchar * uri);
+  void (*set_is_controller)                            (GstWebRTCICE * ice,
+                                                        gboolean controller);
+  gboolean (*get_is_controller)                        (GstWebRTCICE * ice);
+  void (*set_force_relay)                              (GstWebRTCICE * ice,
+                                                        gboolean force_relay);
+  void (*set_stun_server)                              (GstWebRTCICE * ice,
+                                                        const gchar * uri);
+  gchar * (*get_stun_server)                           (GstWebRTCICE * ice);
+  void (*set_turn_server)                              (GstWebRTCICE * ice,
+                                                        const gchar * uri);
+  gchar * (*get_turn_server)                           (GstWebRTCICE * ice);
+
+  /**
+   * GstWebRTCICEClass::set_http_proxy:
+   * @ice: a #GstWebRTCICE
+   * @uri: (transfer none): URI of the HTTP proxy of the form
+   *   http://[username:password@]hostname[:port]
+   *
+   * Set HTTP Proxy to be used when connecting to TURN server.
+   *
+   * Since: 1.22
+   */
+  void (*set_http_proxy)                               (GstWebRTCICE * ice,
+                                                        const gchar * uri);
+
+  /**
+   * GstWebRTCICEClass::get_http_proxy:
+   * @ice: a #GstWebRTCICE
+   *
+   * Get HTTP Proxy to be used when connecting to TURN server.
+   *
+   * Returns: (transfer full): URI of the HTTP proxy of the form
+   *   http://[username:password@]hostname[:port]
+   *
+   * Since: 1.22
+   */
+  gchar * (*get_http_proxy)                            (GstWebRTCICE * ice);
+
+  void (*set_tos)                                      (GstWebRTCICE * ice,
+                                                        GstWebRTCICEStream * stream,
+                                                        guint tos);
+  void (*set_on_ice_candidate)                         (GstWebRTCICE * ice,
+                                                        GstWebRTCICEOnCandidateFunc func,
+                                                        gpointer user_data,
+                                                        GDestroyNotify notify);
+  GstWebRTCICECandidateStats** (*get_local_candidates)(GstWebRTCICE * ice,
+                                                       GstWebRTCICEStream * stream);
+  GstWebRTCICECandidateStats**(*get_remote_candidates)(GstWebRTCICE * ice,
+                                                       GstWebRTCICEStream * stream);
+  gboolean (*get_selected_pair)                       (GstWebRTCICE * ice,
+                                                       GstWebRTCICEStream * stream,
+                                                       GstWebRTCICECandidateStats ** local_stats,
+                                                       GstWebRTCICECandidateStats ** remote_stats);
+  gpointer _gst_reserved[GST_PADDING];
+};
+
+GST_WEBRTC_API
+GstWebRTCICEStream *        gst_webrtc_ice_add_stream               (GstWebRTCICE * ice,
+                                                                     guint session_id);
+
+GST_WEBRTC_API
+GstWebRTCICETransport *     gst_webrtc_ice_find_transport           (GstWebRTCICE * ice,
+                                                                     GstWebRTCICEStream * stream,
+                                                                     GstWebRTCICEComponent component);
+
+
+GST_WEBRTC_API
+gboolean                    gst_webrtc_ice_gather_candidates        (GstWebRTCICE * ice,
+                                                                     GstWebRTCICEStream * stream);
+
+/* FIXME: GstStructure-ize the candidate */
+GST_WEBRTC_API
+void                        gst_webrtc_ice_add_candidate            (GstWebRTCICE * ice,
+                                                                     GstWebRTCICEStream * stream,
+                                                                     const gchar * candidate);
+
+GST_WEBRTC_API
+gboolean                    gst_webrtc_ice_set_local_credentials    (GstWebRTCICE * ice,
+                                                                     GstWebRTCICEStream * stream,
+                                                                     const gchar * ufrag,
+                                                                     const gchar * pwd);
+
+GST_WEBRTC_API
+gboolean                    gst_webrtc_ice_set_remote_credentials   (GstWebRTCICE * ice,
+                                                                     GstWebRTCICEStream * stream,
+                                                                     const gchar * ufrag,
+                                                                     const gchar * pwd);
+
+GST_WEBRTC_API
+gboolean                    gst_webrtc_ice_add_turn_server          (GstWebRTCICE * ice,
+                                                                     const gchar * uri);
+
+
+GST_WEBRTC_API
+void                        gst_webrtc_ice_set_is_controller        (GstWebRTCICE * ice,
+                                                                     gboolean controller);
+
+GST_WEBRTC_API
+gboolean                    gst_webrtc_ice_get_is_controller        (GstWebRTCICE * ice);
+
+GST_WEBRTC_API
+void                        gst_webrtc_ice_set_force_relay          (GstWebRTCICE * ice,
+                                                                     gboolean force_relay);
+
+GST_WEBRTC_API
+void                        gst_webrtc_ice_set_stun_server          (GstWebRTCICE * ice,
+                                                                     const gchar * uri);
+
+GST_WEBRTC_API
+gchar *                     gst_webrtc_ice_get_stun_server          (GstWebRTCICE * ice);
+
+GST_WEBRTC_API
+void                        gst_webrtc_ice_set_turn_server          (GstWebRTCICE * ice,
+                                                                     const gchar * uri);
+
+GST_WEBRTC_API
+gchar *                     gst_webrtc_ice_get_turn_server          (GstWebRTCICE * ice);
+
+GST_WEBRTC_API
+void                        gst_webrtc_ice_set_http_proxy           (GstWebRTCICE * ice,
+                                                                     const gchar * uri);
+
+GST_WEBRTC_API
+gchar *                     gst_webrtc_ice_get_http_proxy           (GstWebRTCICE * ice);
+
+GST_WEBRTC_API
+void                        gst_webrtc_ice_set_on_ice_candidate     (GstWebRTCICE * ice,
+                                                                     GstWebRTCICEOnCandidateFunc func,
+                                                                     gpointer user_data,
+                                                                     GDestroyNotify notify);
+
+GST_WEBRTC_API
+void                        gst_webrtc_ice_set_tos                  (GstWebRTCICE * ice,
+                                                                     GstWebRTCICEStream * stream,
+                                                                     guint tos);
+
+GST_WEBRTC_API
+GstWebRTCICECandidateStats** gst_webrtc_ice_get_local_candidates    (GstWebRTCICE * ice,
+                                                                     GstWebRTCICEStream * stream);
+
+GST_WEBRTC_API
+GstWebRTCICECandidateStats** gst_webrtc_ice_get_remote_candidates   (GstWebRTCICE * ice,
+                                                                     GstWebRTCICEStream * stream);
+
+GST_WEBRTC_API
+gboolean                    gst_webrtc_ice_get_selected_pair        (GstWebRTCICE * ice,
+                                                                     GstWebRTCICEStream * stream,
+                                                                     GstWebRTCICECandidateStats ** local_stats,
+                                                                     GstWebRTCICECandidateStats ** remote_stats);
+
+GST_WEBRTC_API
+void                        gst_webrtc_ice_candidate_stats_free     (GstWebRTCICECandidateStats * stats);
+
+GST_WEBRTC_API
+GType                       gst_webrtc_ice_candidate_stats_get_type (void);
+
+G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstWebRTCICE, gst_object_unref)
+
+GST_WEBRTC_API
+GstWebRTCICECandidateStats * gst_webrtc_ice_candidate_stats_copy   (GstWebRTCICECandidateStats *stats);
+
+G_END_DECLS
+
+#endif /* __GST_WEBRTC_ICE_H__ */
diff --git a/gst-libs/gst/webrtc/icestream.c b/gst-libs/gst/webrtc/icestream.c
new file mode 100644
index 000000000..4d0055f52
--- /dev/null
+++ b/gst-libs/gst/webrtc/icestream.c
@@ -0,0 +1,137 @@
+/* GStreamer
+ * Copyright (C) 2017 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+/**
+ * SECTION: icestream
+ * @short_description: IceStream object
+ * @title: GstIceStream
+ * @symbols:
+ * - GstWebRTCICEStream
+ */
+
+#ifdef HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "icestream.h"
+
+#include "webrtc-priv.h"
+
+#define GST_CAT_DEFAULT gst_webrtc_ice_stream_debug
+GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
+
+enum
+{
+  PROP_0,
+  PROP_STREAM_ID,
+};
+
+#define gst_webrtc_ice_stream_parent_class parent_class
+G_DEFINE_ABSTRACT_TYPE_WITH_CODE (GstWebRTCICEStream, gst_webrtc_ice_stream,
+    GST_TYPE_OBJECT, GST_DEBUG_CATEGORY_INIT (gst_webrtc_ice_stream_debug,
+        "webrtcicestream", 0, "webrtcicestream"););
+
+static void
+gst_webrtc_ice_stream_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  GstWebRTCICEStream *stream = GST_WEBRTC_ICE_STREAM (object);
+
+  switch (prop_id) {
+    case PROP_STREAM_ID:
+      stream->stream_id = g_value_get_uint (value);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_webrtc_ice_stream_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  GstWebRTCICEStream *stream = GST_WEBRTC_ICE_STREAM (object);
+
+  switch (prop_id) {
+    case PROP_STREAM_ID:
+      g_value_set_uint (value, stream->stream_id);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+/**
+ * gst_webrtc_ice_stream_find_transport:
+ * @stream: the #GstWebRTCICEStream
+ * @component: The #GstWebRTCICEComponent
+ *
+ * Returns: (transfer full) (nullable): the #GstWebRTCICETransport, or %NULL
+ * Since: 1.22
+ */
+GstWebRTCICETransport *
+gst_webrtc_ice_stream_find_transport (GstWebRTCICEStream * stream,
+    GstWebRTCICEComponent component)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE_STREAM (stream), NULL);
+  g_assert (GST_WEBRTC_ICE_STREAM_GET_CLASS (stream)->find_transport);
+
+  return GST_WEBRTC_ICE_STREAM_GET_CLASS (stream)->find_transport (stream,
+      component);
+}
+
+/**
+ * gst_webrtc_ice_stream_gather_candidates:
+ * @ice: the #GstWebRTCICEStream
+ * Returns: FALSE on error, TRUE otherwise
+ * Since: 1.22
+ */
+gboolean
+gst_webrtc_ice_stream_gather_candidates (GstWebRTCICEStream * stream)
+{
+  g_return_val_if_fail (GST_IS_WEBRTC_ICE_STREAM (stream), FALSE);
+  g_assert (GST_WEBRTC_ICE_STREAM_GET_CLASS (stream)->gather_candidates);
+
+  return GST_WEBRTC_ICE_STREAM_GET_CLASS (stream)->gather_candidates (stream);
+}
+
+static void
+gst_webrtc_ice_stream_class_init (GstWebRTCICEStreamClass * klass)
+{
+  GObjectClass *gobject_class = (GObjectClass *) klass;
+
+  klass->find_transport = NULL;
+  klass->gather_candidates = NULL;
+
+  gobject_class->get_property = gst_webrtc_ice_stream_get_property;
+  gobject_class->set_property = gst_webrtc_ice_stream_set_property;
+
+  g_object_class_install_property (gobject_class,
+      PROP_STREAM_ID,
+      g_param_spec_uint ("stream-id",
+          "ICE stream id", "ICE stream id associated with this stream",
+          0, G_MAXUINT, 0,
+          G_PARAM_READWRITE | G_PARAM_CONSTRUCT_ONLY | G_PARAM_STATIC_STRINGS));
+}
+
+static void
+gst_webrtc_ice_stream_init (GstWebRTCICEStream * stream)
+{
+}
diff --git a/gst-libs/gst/webrtc/icestream.h b/gst-libs/gst/webrtc/icestream.h
new file mode 100644
index 000000000..361d0b76c
--- /dev/null
+++ b/gst-libs/gst/webrtc/icestream.h
@@ -0,0 +1,61 @@
+/* GStreamer
+ * Copyright (C) 2017 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef __GST_WEBRTC_ICE_STREAM_H__
+#define __GST_WEBRTC_ICE_STREAM_H__
+
+#include "ice.h"
+
+G_BEGIN_DECLS
+
+GST_WEBRTC_API
+GType gst_webrtc_ice_stream_get_type(void);
+#define GST_TYPE_WEBRTC_ICE_STREAM            (gst_webrtc_ice_stream_get_type())
+#define GST_WEBRTC_ICE_STREAM(obj)            (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_WEBRTC_ICE_STREAM,GstWebRTCICEStream))
+#define GST_IS_WEBRTC_ICE_STREAM(obj)         (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_WEBRTC_ICE_STREAM))
+#define GST_WEBRTC_ICE_STREAM_CLASS(klass)    (G_TYPE_CHECK_CLASS_CAST((klass) ,GST_TYPE_WEBRTC_ICE_STREAM,GstWebRTCICEStreamClass))
+#define GST_IS_WEBRTC_ICE_STREAM_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE((klass) ,GST_TYPE_WEBRTC_ICE_STREAM))
+#define GST_WEBRTC_ICE_STREAM_GET_CLASS(obj)  (G_TYPE_INSTANCE_GET_CLASS((obj) ,GST_TYPE_WEBRTC_ICE_STREAM,GstWebRTCICEStreamClass))
+
+struct _GstWebRTCICEStream
+{
+  GstObject                 parent;
+  guint                     stream_id;
+};
+
+struct _GstWebRTCICEStreamClass
+{
+  GstObjectClass            parent_class;
+  GstWebRTCICETransport * (*find_transport)      (GstWebRTCICEStream * stream,
+                                                 GstWebRTCICEComponent component);
+  gboolean                (*gather_candidates)   (GstWebRTCICEStream * ice);
+};
+
+
+GST_WEBRTC_API
+GstWebRTCICETransport *     gst_webrtc_ice_stream_find_transport        (GstWebRTCICEStream * stream,
+                                                                         GstWebRTCICEComponent component);
+GST_WEBRTC_API
+gboolean                    gst_webrtc_ice_stream_gather_candidates     (GstWebRTCICEStream * ice);
+
+G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstWebRTCICEStream, gst_object_unref)
+
+G_END_DECLS
+
+#endif /* __GST_WEBRTC_ICE_STREAM_H__ */
diff --git a/gst-libs/gst/webrtc/icetransport.c b/gst-libs/gst/webrtc/icetransport.c
index 21e2cbe9b..30040c6ac 100644
--- a/gst-libs/gst/webrtc/icetransport.c
+++ b/gst-libs/gst/webrtc/icetransport.c
@@ -22,8 +22,10 @@
  * @short_description: RTCIceTransport object
  * @title: GstWebRTCICETransport
  * @see_also: #GstWebRTCRTPSender, #GstWebRTCRTPReceiver, #GstWebRTCDTLSTransport
+ * @symbols:
+ * - GstWebRTCICETransport
  *
- * <https://www.w3.org/TR/webrtc/#rtcicetransport>
+ * See the [specification](https://www.w3.org/TR/webrtc/#rtcicetransport)
  */
 
 #ifdef HAVE_CONFIG_H
@@ -33,6 +35,8 @@
 #include "icetransport.h"
 #include "webrtc-enumtypes.h"
 
+#include "webrtc-priv.h"
+
 #define GST_CAT_DEFAULT gst_webrtc_ice_transport_debug
 GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
 
@@ -92,7 +96,7 @@ gst_webrtc_ice_transport_selected_pair_change (GstWebRTCICETransport * ice)
 
 void
 gst_webrtc_ice_transport_new_candidate (GstWebRTCICETransport * ice,
-    guint stream_id, GstWebRTCICEComponent component, gchar * attr)
+    guint stream_id, GstWebRTCICEComponent component, const gchar * attr)
 {
   g_signal_emit (ice, gst_webrtc_ice_transport_signals[ON_NEW_CANDIDATE_SIGNAL],
       stream_id, component, attr);
diff --git a/gst-libs/gst/webrtc/icetransport.h b/gst-libs/gst/webrtc/icetransport.h
index c1e56d41e..d605d63ff 100644
--- a/gst-libs/gst/webrtc/icetransport.h
+++ b/gst-libs/gst/webrtc/icetransport.h
@@ -20,7 +20,6 @@
 #ifndef __GST_WEBRTC_ICE_TRANSPORT_H__
 #define __GST_WEBRTC_ICE_TRANSPORT_H__
 
-#include <gst/gst.h>
 #include <gst/webrtc/webrtc_fwd.h>
 
 G_BEGIN_DECLS
@@ -33,14 +32,10 @@ GType gst_webrtc_ice_transport_get_type(void);
 #define GST_WEBRTC_ICE_TRANSPORT_CLASS(klass)    (G_TYPE_CHECK_CLASS_CAST((klass) ,GST_TYPE_WEBRTC_ICE_TRANSPORT,GstWebRTCICETransportClass))
 #define GST_IS_WEBRTC_ICE_TRANSPORT_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE((klass) ,GST_TYPE_WEBRTC_ICE_TRANSPORT))
 #define GST_WEBRTC_ICE_TRANSPORT_GET_CLASS(obj)  (G_TYPE_INSTANCE_GET_CLASS((obj) ,GST_TYPE_WEBRTC_ICE_TRANSPORT,GstWebRTCICETransportClass))
-
-/**
- * GstWebRTCICETransport:
- */
 struct _GstWebRTCICETransport
 {
   GstObject                          parent;
-
+  /* <protected> */
   GstWebRTCICERole                   role;
   GstWebRTCICEComponent              component;
 
@@ -72,7 +67,7 @@ void            gst_webrtc_ice_transport_gathering_state_change     (GstWebRTCIC
 GST_WEBRTC_API
 void            gst_webrtc_ice_transport_selected_pair_change       (GstWebRTCICETransport * ice);
 GST_WEBRTC_API
-void            gst_webrtc_ice_transport_new_candidate              (GstWebRTCICETransport * ice, guint stream_id, GstWebRTCICEComponent component, gchar * attr);
+void            gst_webrtc_ice_transport_new_candidate              (GstWebRTCICETransport * ice, guint stream_id, GstWebRTCICEComponent component, const gchar * attr);
 
 G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstWebRTCICETransport, gst_object_unref)
 
diff --git a/gst-libs/gst/webrtc/meson.build b/gst-libs/gst/webrtc/meson.build
index 981083c2e..5614d4cf4 100644
--- a/gst-libs/gst/webrtc/meson.build
+++ b/gst-libs/gst/webrtc/meson.build
@@ -1,15 +1,21 @@
-webrtc_sources = [
+webrtc_sources = files([
   'dtlstransport.c',
+  'ice.c',
+  'icestream.c',
   'icetransport.c',
   'rtcsessiondescription.c',
   'rtpreceiver.c',
   'rtpsender.c',
   'rtptransceiver.c',
   'datachannel.c',
-]
+  'sctptransport.c',
+  'webrtc.c',
+])
 
-webrtc_headers = [
+webrtc_headers = files([
   'dtlstransport.h',
+  'ice.h',
+  'icestream.h',
   'icetransport.h',
   'rtcsessiondescription.h',
   'rtpreceiver.h',
@@ -18,14 +24,17 @@ webrtc_headers = [
   'datachannel.h',
   'webrtc_fwd.h',
   'webrtc.h',
-]
+  'sctptransport.h',
+])
 
-webrtc_enumtypes_headers = [
+webrtc_enumtypes_headers = files([
   'dtlstransport.h',
+  'ice.h',
+  'icestream.h',
   'icetransport.h',
   'rtptransceiver.h',
   'webrtc_fwd.h',
-]
+])
 
 webrtc_enums = gnome.mkenums_simple('webrtc-enumtypes',
   sources : webrtc_enumtypes_headers,
@@ -44,7 +53,7 @@ gstwebrtc_dependencies = [gstbase_dep, gstsdp_dep]
 
 gstwebrtc = library('gstwebrtc-' + api_version,
   webrtc_sources, gstwebrtc_c, gstwebrtc_h,
-  c_args : gst_plugins_bad_args + ['-DGST_USE_UNSTABLE_API', '-DBUILDING_GST_WEBRTC'],
+  c_args : gst_plugins_bad_args + ['-DGST_USE_UNSTABLE_API', '-DBUILDING_GST_WEBRTC', '-DG_LOG_DOMAIN="GStreamer-WebRTC"'],
   include_directories : [configinc, libsinc],
   version : libversion,
   soversion : soversion,
@@ -75,3 +84,6 @@ gstwebrtc_dep = declare_dependency(link_with: gstwebrtc,
   include_directories : libsinc,
   sources: webrtc_gen_sources,
   dependencies: gstwebrtc_dependencies)
+
+
+subdir('nice')
\ No newline at end of file
diff --git a/gst-libs/gst/webrtc/nice/meson.build b/gst-libs/gst/webrtc/nice/meson.build
new file mode 100644
index 000000000..007e7b23b
--- /dev/null
+++ b/gst-libs/gst/webrtc/nice/meson.build
@@ -0,0 +1,48 @@
+libgstwebrtcnice_sources = files([
+    'nice.c',
+    'nicestream.c',
+    'nicetransport.c',
+])
+
+libgstwebrtcnice_headers = files([
+    'nice_fwd.h',
+    'nice.h',
+    'nicestream.h',
+    'nicetransport.h',
+])
+
+libgstwebrtcnice_dep = dependency('', required : false)
+
+libnice_dep = dependency('nice', version : '>=0.1.20', required : get_option('webrtc'),
+                         fallback : ['libnice', 'libnice_dep'],
+                         default_options: ['tests=disabled'])
+
+deps = [gstwebrtc_dep, libnice_dep]
+
+if libnice_dep.found()
+  libnice_version = libnice_dep.version()
+  libnice_c_args = []
+  libgstwebrtcnice = library('gstwebrtcnice-' + api_version,
+    libgstwebrtcnice_sources, libgstwebrtcnice_headers,
+    c_args : gst_plugins_bad_args + ['-DGST_USE_UNSTABLE_API', '-DBUILDING_GST_WEBRTCNICE', '-DG_LOG_DOMAIN="GStreamer-webrtcnice"'] + libnice_c_args,
+    include_directories: [configinc],
+    version : libversion,
+    soversion : soversion,
+    darwin_versions : osxversion,
+    dependencies: deps,
+    install: true,
+  )
+
+  pkg_name = 'gstreamer-webrtc-nice-1.0'
+  pkgconfig.generate(libgstwebrtcnice,
+    libraries : [deps],
+    name : pkg_name,
+    description : 'libnice based implementaion for GstWebRTCICE',
+  )
+
+  libgstwebrtcnice_dep = declare_dependency(link_with: libgstwebrtcnice,
+    dependencies: [deps])
+
+  install_headers(libgstwebrtcnice_headers, subdir : 'gstreamer-1.0/gst/webrtc/nice')
+  meson.override_dependency(pkg_name, libgstwebrtcnice_dep)
+endif
diff --git a/gst-libs/gst/webrtc/nice/nice.c b/gst-libs/gst/webrtc/nice/nice.c
new file mode 100644
index 000000000..d7feae194
--- /dev/null
+++ b/gst-libs/gst/webrtc/nice/nice.c
@@ -0,0 +1,1677 @@
+/* GStreamer
+ * Copyright (C) 2017 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "nice.h"
+#include "nicestream.h"
+/* libnice */
+#include <agent.h>
+
+#define HTTP_PROXY_PORT_DEFAULT 3128
+
+/* XXX:
+ *
+ * - are locally generated remote candidates meant to be readded to libnice?
+ */
+
+static GstUri *_validate_turn_server (GstWebRTCNice * ice, const gchar * s);
+
+#define GST_CAT_DEFAULT gst_webrtc_nice_debug
+GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
+
+enum
+{
+  PROP_0,
+  PROP_AGENT,
+  PROP_ICE_TCP,
+  PROP_ICE_UDP,
+  PROP_MIN_RTP_PORT,
+  PROP_MAX_RTP_PORT,
+};
+
+struct _GstWebRTCNicePrivate
+{
+  NiceAgent *nice_agent;
+
+  GArray *nice_stream_map;
+
+  GThread *thread;
+  GMainContext *main_context;
+  GMainLoop *loop;
+  GMutex lock;
+  GCond cond;
+
+  GstWebRTCICEOnCandidateFunc on_candidate;
+  gpointer on_candidate_data;
+  GDestroyNotify on_candidate_notify;
+
+  GstUri *stun_server;
+  GstUri *turn_server;
+
+  GHashTable *turn_servers;
+
+  GstUri *http_proxy;
+};
+
+#define gst_webrtc_nice_parent_class parent_class
+G_DEFINE_TYPE_WITH_CODE (GstWebRTCNice, gst_webrtc_nice,
+    GST_TYPE_WEBRTC_ICE, G_ADD_PRIVATE (GstWebRTCNice)
+    GST_DEBUG_CATEGORY_INIT (gst_webrtc_nice_debug, "webrtcnice", 0,
+        "webrtcnice"););
+
+static gboolean
+_unlock_pc_thread (GMutex * lock)
+{
+  g_mutex_unlock (lock);
+  return G_SOURCE_REMOVE;
+}
+
+static gpointer
+_gst_nice_thread (GstWebRTCNice * ice)
+{
+  g_mutex_lock (&ice->priv->lock);
+  ice->priv->main_context = g_main_context_new ();
+  ice->priv->loop = g_main_loop_new (ice->priv->main_context, FALSE);
+
+  g_cond_broadcast (&ice->priv->cond);
+  g_main_context_invoke (ice->priv->main_context,
+      (GSourceFunc) _unlock_pc_thread, &ice->priv->lock);
+
+  g_main_loop_run (ice->priv->loop);
+
+  g_mutex_lock (&ice->priv->lock);
+  g_main_context_unref (ice->priv->main_context);
+  ice->priv->main_context = NULL;
+  g_main_loop_unref (ice->priv->loop);
+  ice->priv->loop = NULL;
+  g_cond_broadcast (&ice->priv->cond);
+  g_mutex_unlock (&ice->priv->lock);
+
+  return NULL;
+}
+
+static void
+_start_thread (GstWebRTCNice * ice)
+{
+  g_mutex_lock (&ice->priv->lock);
+  ice->priv->thread = g_thread_new (GST_OBJECT_NAME (ice),
+      (GThreadFunc) _gst_nice_thread, ice);
+
+  while (!ice->priv->loop)
+    g_cond_wait (&ice->priv->cond, &ice->priv->lock);
+  g_mutex_unlock (&ice->priv->lock);
+}
+
+static void
+_stop_thread (GstWebRTCNice * ice)
+{
+  g_mutex_lock (&ice->priv->lock);
+  g_main_loop_quit (ice->priv->loop);
+  while (ice->priv->loop)
+    g_cond_wait (&ice->priv->cond, &ice->priv->lock);
+  g_mutex_unlock (&ice->priv->lock);
+
+  g_thread_unref (ice->priv->thread);
+}
+
+struct NiceStreamItem
+{
+  guint session_id;
+  guint nice_stream_id;
+  GstWebRTCICEStream *stream;
+};
+
+/* TRUE to continue, FALSE to stop */
+typedef gboolean (*NiceStreamItemForeachFunc) (struct NiceStreamItem * item,
+    gpointer user_data);
+
+static void
+_nice_stream_item_foreach (GstWebRTCNice * ice, NiceStreamItemForeachFunc func,
+    gpointer data)
+{
+  int i, len;
+
+  len = ice->priv->nice_stream_map->len;
+  for (i = 0; i < len; i++) {
+    struct NiceStreamItem *item =
+        &g_array_index (ice->priv->nice_stream_map, struct NiceStreamItem,
+        i);
+
+    if (!func (item, data))
+      break;
+  }
+}
+
+/* TRUE for match, FALSE otherwise */
+typedef gboolean (*NiceStreamItemFindFunc) (struct NiceStreamItem * item,
+    gpointer user_data);
+
+struct nice_find
+{
+  NiceStreamItemFindFunc func;
+  gpointer data;
+  struct NiceStreamItem *ret;
+};
+
+static gboolean
+_find_nice_item (struct NiceStreamItem *item, gpointer user_data)
+{
+  struct nice_find *f = user_data;
+  if (f->func (item, f->data)) {
+    f->ret = item;
+    return FALSE;
+  }
+  return TRUE;
+}
+
+static struct NiceStreamItem *
+_nice_stream_item_find (GstWebRTCNice * ice, NiceStreamItemFindFunc func,
+    gpointer data)
+{
+  struct nice_find f;
+
+  f.func = func;
+  f.data = data;
+  f.ret = NULL;
+
+  _nice_stream_item_foreach (ice, _find_nice_item, &f);
+
+  return f.ret;
+}
+
+#define NICE_MATCH_INIT { -1, -1, NULL }
+
+static gboolean
+_match (struct NiceStreamItem *item, struct NiceStreamItem *m)
+{
+  if (m->session_id != -1 && m->session_id != item->session_id)
+    return FALSE;
+  if (m->nice_stream_id != -1 && m->nice_stream_id != item->nice_stream_id)
+    return FALSE;
+  if (m->stream != NULL && m->stream != item->stream)
+    return FALSE;
+
+  return TRUE;
+}
+
+static struct NiceStreamItem *
+_find_item (GstWebRTCNice * ice, guint session_id, guint nice_stream_id,
+    GstWebRTCICEStream * stream)
+{
+  struct NiceStreamItem m = NICE_MATCH_INIT;
+
+  m.session_id = session_id;
+  m.nice_stream_id = nice_stream_id;
+  m.stream = stream;
+
+  return _nice_stream_item_find (ice, (NiceStreamItemFindFunc) _match, &m);
+}
+
+static struct NiceStreamItem *
+_create_nice_stream_item (GstWebRTCNice * ice, guint session_id)
+{
+  struct NiceStreamItem item;
+
+  item.session_id = session_id;
+  item.nice_stream_id = nice_agent_add_stream (ice->priv->nice_agent, 1);
+  item.stream =
+      GST_WEBRTC_ICE_STREAM (gst_webrtc_nice_stream_new (GST_WEBRTC_ICE (ice),
+          item.nice_stream_id)
+      );
+
+  g_array_append_val (ice->priv->nice_stream_map, item);
+
+  return _find_item (ice, item.session_id, item.nice_stream_id, item.stream);
+}
+
+static void
+_parse_userinfo (const gchar * userinfo, gchar ** user, gchar ** pass)
+{
+  const gchar *colon;
+
+  if (!userinfo) {
+    *user = NULL;
+    *pass = NULL;
+    return;
+  }
+
+  colon = g_strstr_len (userinfo, -1, ":");
+  if (!colon) {
+    *user = g_uri_unescape_string (userinfo, NULL);
+    *pass = NULL;
+    return;
+  }
+
+  /* Check that the first occurence is also the last occurence */
+  if (colon != g_strrstr (userinfo, ":"))
+    GST_WARNING ("userinfo %s contains more than one ':', will assume that the "
+        "first ':' delineates user:pass. You should escape the user and pass "
+        "before adding to the URI.", userinfo);
+
+  *user = g_uri_unescape_segment (userinfo, colon, NULL);
+  *pass = g_uri_unescape_string (&colon[1], NULL);
+}
+
+struct resolve_host_data
+{
+  GstWebRTCNice *ice;
+  char *host;
+  gboolean main_context_handled;
+  gpointer user_data;
+  GDestroyNotify notify;
+};
+
+static void
+on_resolve_host (GResolver * resolver, GAsyncResult * res, gpointer user_data)
+{
+  GTask *task = user_data;
+  struct resolve_host_data *rh;
+  GError *error = NULL;
+  GList *addresses;
+
+  rh = g_task_get_task_data (task);
+
+  if (!(addresses = g_resolver_lookup_by_name_finish (resolver, res, &error))) {
+    GST_ERROR ("failed to resolve: %s", error->message);
+    g_task_return_error (task, error);
+    g_object_unref (task);
+    return;
+  }
+
+  GST_DEBUG_OBJECT (rh->ice, "Resolved %d addresses for host %s with data %p",
+      g_list_length (addresses), rh->host, rh);
+
+  g_task_return_pointer (task, addresses,
+      (GDestroyNotify) g_resolver_free_addresses);
+  g_object_unref (task);
+}
+
+static void
+free_resolve_host_data (struct resolve_host_data *rh)
+{
+  GST_TRACE_OBJECT (rh->ice, "Freeing data %p for resolving host %s", rh,
+      rh->host);
+
+  if (rh->notify)
+    rh->notify (rh->user_data);
+
+  g_free (rh->host);
+  g_free (rh);
+}
+
+static struct resolve_host_data *
+resolve_host_data_new (GstWebRTCNice * ice, const char *host)
+{
+  struct resolve_host_data *rh = g_new0 (struct resolve_host_data, 1);
+
+  rh->ice = ice;
+  rh->host = g_strdup (host);
+
+  return rh;
+}
+
+static gboolean
+resolve_host_main_cb (gpointer user_data)
+{
+  GResolver *resolver = g_resolver_get_default ();
+  GTask *task = user_data;
+  struct resolve_host_data *rh;
+
+  rh = g_task_get_task_data (task);
+  /* no need to error anymore if the main context disappears and this task is
+   * not run */
+  rh->main_context_handled = TRUE;
+
+  GST_DEBUG_OBJECT (rh->ice, "Resolving host %s", rh->host);
+  g_resolver_lookup_by_name_async (resolver, rh->host, NULL,
+      (GAsyncReadyCallback) on_resolve_host, g_object_ref (task));
+
+  return G_SOURCE_REMOVE;
+}
+
+static void
+error_task_if_unhandled (GTask * task)
+{
+  struct resolve_host_data *rh;
+
+  rh = g_task_get_task_data (task);
+
+  if (!rh->main_context_handled) {
+    GST_DEBUG_OBJECT (rh->ice, "host resolve for %s with data %p was never "
+        "executed, main context quit?", rh->host, rh);
+    g_task_return_new_error (task, G_IO_ERROR, G_IO_ERROR_CANCELLED, "%s",
+        "Cancelled");
+  }
+
+  g_object_unref (task);
+}
+
+static void
+resolve_host_async (GstWebRTCNice * ice, const gchar * host,
+    GAsyncReadyCallback cb, gpointer user_data, GDestroyNotify notify)
+{
+  struct resolve_host_data *rh = resolve_host_data_new (ice, host);
+  GTask *task;
+
+  rh->user_data = user_data;
+  rh->notify = notify;
+  task = g_task_new (rh->ice, NULL, cb, user_data);
+
+  g_task_set_task_data (task, rh, (GDestroyNotify) free_resolve_host_data);
+
+  GST_TRACE_OBJECT (rh->ice, "invoking main context for resolving host %s "
+      "with data %p", host, rh);
+  g_main_context_invoke_full (ice->priv->main_context, G_PRIORITY_DEFAULT,
+      resolve_host_main_cb, task, (GDestroyNotify) error_task_if_unhandled);
+}
+
+static GList *
+resolve_host_finish (GstWebRTCNice * ice, GAsyncResult * res, GError ** error)
+{
+  g_return_val_if_fail (g_task_is_valid (res, ice), NULL);
+
+  return g_task_propagate_pointer (G_TASK (res), error);
+}
+
+static void
+_add_turn_server (GstWebRTCNice * ice, struct NiceStreamItem *item,
+    GstUri * turn_server)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  const gchar *host;
+  NiceRelayType relays[4] = { 0, };
+  gchar *user, *pass;
+  const gchar *userinfo, *transport, *scheme;
+  int i, relay_n = 0;
+
+  host = gst_uri_get_host (turn_server);
+  if (!host) {
+    GST_ERROR_OBJECT (ice, "Turn server has no host");
+    return;
+  }
+
+  scheme = gst_uri_get_scheme (turn_server);
+  transport = gst_uri_get_query_value (turn_server, "transport");
+  userinfo = gst_uri_get_userinfo (turn_server);
+  _parse_userinfo (userinfo, &user, &pass);
+
+  if (g_strcmp0 (scheme, "turns") == 0) {
+    relays[relay_n++] = NICE_RELAY_TYPE_TURN_TLS;
+  } else if (g_strcmp0 (scheme, "turn") == 0) {
+    if (!transport || g_strcmp0 (transport, "udp") == 0)
+      relays[relay_n++] = NICE_RELAY_TYPE_TURN_UDP;
+    if (!transport || g_strcmp0 (transport, "tcp") == 0)
+      relays[relay_n++] = NICE_RELAY_TYPE_TURN_TCP;
+  }
+  g_assert (relay_n < G_N_ELEMENTS (relays));
+
+  for (i = 0; i < relay_n; i++) {
+    if (!nice_agent_set_relay_info (nice->priv->nice_agent,
+            item->nice_stream_id, NICE_COMPONENT_TYPE_RTP,
+            gst_uri_get_host (turn_server), gst_uri_get_port (turn_server),
+            user, pass, relays[i])) {
+      gchar *uri_str = gst_uri_to_string (turn_server);
+      GST_ERROR_OBJECT (ice, "Could not set TURN server %s on libnice",
+          uri_str);
+      g_free (uri_str);
+    }
+  }
+
+  g_free (user);
+  g_free (pass);
+
+}
+
+typedef struct
+{
+  GstWebRTCNice *ice;
+  struct NiceStreamItem *item;
+} AddTurnServerData;
+
+static void
+_add_turn_server_func (const gchar * uri, GstUri * turn_server,
+    AddTurnServerData * data)
+{
+  _add_turn_server (data->ice, data->item, turn_server);
+}
+
+static void
+_add_stun_server (GstWebRTCNice * ice, GstUri * stun_server)
+{
+  const gchar *msg = "must be of the form stun://<host>:<port>";
+  const gchar *host;
+  gchar *s = NULL;
+  guint port;
+
+  s = gst_uri_to_string (stun_server);
+  GST_DEBUG_OBJECT (ice, "adding stun server, %s", s);
+
+  host = gst_uri_get_host (stun_server);
+  if (!host) {
+    GST_ERROR_OBJECT (ice, "Stun server '%s' has no host, %s", s, msg);
+    goto out;
+  }
+
+  port = gst_uri_get_port (stun_server);
+  if (port == GST_URI_NO_PORT) {
+    GST_INFO_OBJECT (ice, "Stun server '%s' has no port, assuming 3478", s);
+    port = 3478;
+    gst_uri_set_port (stun_server, port);
+  }
+
+  g_object_set (ice->priv->nice_agent, "stun-server", host,
+      "stun-server-port", port, NULL);
+
+out:
+  g_free (s);
+}
+
+static GstWebRTCICEStream *
+gst_webrtc_nice_add_stream (GstWebRTCICE * ice, guint session_id)
+{
+  struct NiceStreamItem m = NICE_MATCH_INIT;
+  struct NiceStreamItem *item;
+  AddTurnServerData add_data;
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+
+  m.session_id = session_id;
+  item = _nice_stream_item_find (nice, (NiceStreamItemFindFunc) _match, &m);
+  if (item) {
+    GST_ERROR_OBJECT (nice, "stream already added with session_id=%u",
+        session_id);
+    return 0;
+  }
+
+  if (nice->priv->stun_server) {
+    _add_stun_server (nice, nice->priv->stun_server);
+  }
+
+  item = _create_nice_stream_item (nice, session_id);
+
+  if (nice->priv->turn_server) {
+    _add_turn_server (nice, item, nice->priv->turn_server);
+  }
+
+  add_data.ice = nice;
+  add_data.item = item;
+
+  g_hash_table_foreach (nice->priv->turn_servers,
+      (GHFunc) _add_turn_server_func, &add_data);
+
+  return item->stream;
+}
+
+static void
+_on_new_candidate (NiceAgent * agent, NiceCandidate * candidate,
+    GstWebRTCNice * ice)
+{
+  struct NiceStreamItem *item;
+  gchar *attr;
+
+  item = _find_item (ice, -1, candidate->stream_id, NULL);
+  if (!item) {
+    GST_WARNING_OBJECT (ice, "received signal for non-existent stream %u",
+        candidate->stream_id);
+    return;
+  }
+
+  if (!candidate->username || !candidate->password) {
+    gboolean got_credentials;
+    gchar *ufrag, *password;
+
+    got_credentials = nice_agent_get_local_credentials (ice->priv->nice_agent,
+        candidate->stream_id, &ufrag, &password);
+    g_warn_if_fail (got_credentials);
+
+    if (!candidate->username)
+      candidate->username = ufrag;
+    else
+      g_free (ufrag);
+
+    if (!candidate->password)
+      candidate->password = password;
+    else
+      g_free (password);
+  }
+
+  attr = nice_agent_generate_local_candidate_sdp (agent, candidate);
+
+  if (ice->priv->on_candidate)
+    ice->priv->on_candidate (GST_WEBRTC_ICE (ice), item->session_id, attr,
+        ice->priv->on_candidate_data);
+
+  g_free (attr);
+}
+
+static GstWebRTCICETransport *
+gst_webrtc_nice_find_transport (GstWebRTCICE * ice, GstWebRTCICEStream * stream,
+    GstWebRTCICEComponent component)
+{
+  struct NiceStreamItem *item;
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+
+  item = _find_item (nice, -1, -1, stream);
+  g_return_val_if_fail (item != NULL, NULL);
+
+  return gst_webrtc_ice_stream_find_transport (item->stream, component);
+}
+
+#if 0
+/* TODO don't rely on libnice to (de)serialize candidates */
+static NiceCandidateType
+_candidate_type_from_string (const gchar * s)
+{
+  if (g_strcmp0 (s, "host") == 0) {
+    return NICE_CANDIDATE_TYPE_HOST;
+  } else if (g_strcmp0 (s, "srflx") == 0) {
+    return NICE_CANDIDATE_TYPE_SERVER_REFLEXIVE;
+  } else if (g_strcmp0 (s, "prflx") == 0) {     /* FIXME: is the right string? */
+    return NICE_CANDIDATE_TYPE_PEER_REFLEXIVE;
+  } else if (g_strcmp0 (s, "relay") == 0) {
+    return NICE_CANDIDATE_TYPE_RELAY;
+  } else {
+    g_assert_not_reached ();
+    return 0;
+  }
+}
+
+static const gchar *
+_candidate_type_to_string (NiceCandidateType type)
+{
+  switch (type) {
+    case NICE_CANDIDATE_TYPE_HOST:
+      return "host";
+    case NICE_CANDIDATE_TYPE_SERVER_REFLEXIVE:
+      return "srflx";
+    case NICE_CANDIDATE_TYPE_PEER_REFLEXIVE:
+      return "prflx";
+    case NICE_CANDIDATE_TYPE_RELAY:
+      return "relay";
+    default:
+      g_assert_not_reached ();
+      return NULL;
+  }
+}
+
+static NiceCandidateTransport
+_candidate_transport_from_string (const gchar * s)
+{
+  if (g_strcmp0 (s, "UDP") == 0) {
+    return NICE_CANDIDATE_TRANSPORT_UDP;
+  } else if (g_strcmp0 (s, "TCP tcptype") == 0) {
+    return NICE_CANDIDATE_TRANSPORT_TCP_ACTIVE;
+  } else if (g_strcmp0 (s, "tcp-passive") == 0) {       /* FIXME: is the right string? */
+    return NICE_CANDIDATE_TRANSPORT_TCP_PASSIVE;
+  } else if (g_strcmp0 (s, "tcp-so") == 0) {
+    return NICE_CANDIDATE_TRANSPORT_TCP_SO;
+  } else {
+    g_assert_not_reached ();
+    return 0;
+  }
+}
+
+static const gchar *
+_candidate_type_to_string (NiceCandidateType type)
+{
+  switch (type) {
+    case NICE_CANDIDATE_TYPE_HOST:
+      return "host";
+    case NICE_CANDIDATE_TYPE_SERVER_REFLEXIVE:
+      return "srflx";
+    case NICE_CANDIDATE_TYPE_PEER_REFLEXIVE:
+      return "prflx";
+    case NICE_CANDIDATE_TYPE_RELAY:
+      return "relay";
+    default:
+      g_assert_not_reached ();
+      return NULL;
+  }
+}
+#endif
+
+/* parse the address for possible resolution */
+static gboolean
+get_candidate_address (const gchar * candidate, gchar ** prefix,
+    gchar ** address, gchar ** postfix)
+{
+  char **tokens = NULL;
+  char *tmp_address = NULL;
+
+  if (!g_str_has_prefix (candidate, "a=candidate:")) {
+    GST_ERROR ("candidate \"%s\" does not start with \"a=candidate:\"",
+        candidate);
+    goto failure;
+  }
+
+  if (!(tokens = g_strsplit (candidate, " ", 6))) {
+    GST_ERROR ("candidate \"%s\" could not be tokenized", candidate);
+    goto failure;
+  }
+
+  if (g_strv_length (tokens) < 6) {
+    GST_ERROR ("candidate \"%s\" tokenization resulted in not enough tokens",
+        candidate);
+    goto failure;
+  }
+
+  tmp_address = tokens[4];
+  if (address)
+    *address = g_strdup (tmp_address);
+  tokens[4] = NULL;
+
+  if (prefix)
+    *prefix = g_strjoinv (" ", tokens);
+  if (postfix)
+    *postfix = g_strdup (tokens[5]);
+
+  tokens[4] = tmp_address;
+
+  g_strfreev (tokens);
+  return TRUE;
+
+failure:
+  if (tokens)
+    g_strfreev (tokens);
+  return FALSE;
+}
+
+struct resolve_candidate_data
+{
+  guint nice_stream_id;
+  char *prefix;
+  char *postfix;
+};
+
+static void
+free_resolve_candidate_data (struct resolve_candidate_data *rc)
+{
+  g_free (rc->prefix);
+  g_free (rc->postfix);
+  g_free (rc);
+}
+
+static void
+add_ice_candidate_to_libnice (GstWebRTCICE * ice, guint nice_stream_id,
+    NiceCandidate * cand)
+{
+  GSList *candidates = NULL;
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+
+  if (cand->component_id == 2) {
+    /* we only support rtcp-mux so rtcp candidates are useless for us */
+    GST_INFO_OBJECT (ice, "Dropping RTCP candidate");
+    return;
+  }
+
+  candidates = g_slist_append (candidates, cand);
+
+  nice_agent_set_remote_candidates (nice->priv->nice_agent, nice_stream_id,
+      cand->component_id, candidates);
+
+  g_slist_free (candidates);
+}
+
+static void
+on_candidate_resolved (GstWebRTCICE * ice, GAsyncResult * res,
+    gpointer user_data)
+{
+  struct resolve_candidate_data *rc = user_data;
+  GError *error = NULL;
+  GList *addresses;
+  char *new_candv[4] = { NULL, };
+  char *new_addr, *new_candidate;
+  NiceCandidate *cand;
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+
+  if (!(addresses = resolve_host_finish (nice, res, &error))) {
+    GST_WARNING_OBJECT (ice, "Could not resolve candidate address: %s",
+        error->message);
+    g_clear_error (&error);
+    return;
+  }
+
+  new_addr = g_inet_address_to_string (addresses->data);
+
+  new_candv[0] = rc->prefix;
+  new_candv[1] = new_addr;
+  new_candv[2] = rc->postfix;
+  new_candv[3] = NULL;
+  new_candidate = g_strjoinv (" ", new_candv);
+
+  GST_DEBUG_OBJECT (ice, "resolved to candidate %s", new_candidate);
+
+  cand =
+      nice_agent_parse_remote_candidate_sdp (nice->priv->nice_agent,
+      rc->nice_stream_id, new_candidate);
+  g_free (new_candidate);
+  if (!cand) {
+    GST_WARNING_OBJECT (ice, "Could not parse candidate \'%s\'", new_candidate);
+    return;
+  }
+
+  g_free (new_addr);
+
+  add_ice_candidate_to_libnice (ice, rc->nice_stream_id, cand);
+  nice_candidate_free (cand);
+}
+
+/* candidate must start with "a=candidate:" or be NULL*/
+static void
+gst_webrtc_nice_add_candidate (GstWebRTCICE * ice, GstWebRTCICEStream * stream,
+    const gchar * candidate)
+{
+  struct NiceStreamItem *item;
+  NiceCandidate *cand;
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+
+  item = _find_item (nice, -1, -1, stream);
+  g_return_if_fail (item != NULL);
+
+  if (candidate == NULL) {
+    nice_agent_peer_candidate_gathering_done (nice->priv->nice_agent,
+        item->nice_stream_id);
+    return;
+  }
+
+  cand =
+      nice_agent_parse_remote_candidate_sdp (nice->priv->nice_agent,
+      item->nice_stream_id, candidate);
+  if (!cand) {
+    /* might be a .local candidate */
+    char *prefix = NULL, *address = NULL, *postfix = NULL;
+    struct resolve_candidate_data *rc;
+
+    if (!get_candidate_address (candidate, &prefix, &address, &postfix)) {
+      GST_WARNING_OBJECT (nice, "Failed to retrieve address from candidate %s",
+          candidate);
+      goto done;
+    }
+
+    if (!g_str_has_suffix (address, ".local")) {
+      GST_WARNING_OBJECT (nice, "candidate address \'%s\' does not end "
+          "with \'.local\'", address);
+      goto done;
+    }
+
+    rc = g_new0 (struct resolve_candidate_data, 1);
+    rc->nice_stream_id = item->nice_stream_id;
+    rc->prefix = prefix;
+    rc->postfix = postfix;
+    resolve_host_async (nice, address,
+        (GAsyncReadyCallback) on_candidate_resolved, rc,
+        (GDestroyNotify) free_resolve_candidate_data);
+
+    prefix = NULL;
+    postfix = NULL;
+
+  done:
+    g_clear_pointer (&address, g_free);
+    g_clear_pointer (&prefix, g_free);
+    g_clear_pointer (&postfix, g_free);
+
+    return;
+  }
+
+  add_ice_candidate_to_libnice (ice, item->nice_stream_id, cand);
+  nice_candidate_free (cand);
+}
+
+static gboolean
+gst_webrtc_nice_set_remote_credentials (GstWebRTCICE * ice,
+    GstWebRTCICEStream * stream, const gchar * ufrag, const gchar * pwd)
+{
+  struct NiceStreamItem *item;
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+
+  g_return_val_if_fail (ufrag != NULL, FALSE);
+  g_return_val_if_fail (pwd != NULL, FALSE);
+  item = _find_item (nice, -1, -1, stream);
+  g_return_val_if_fail (item != NULL, FALSE);
+
+  GST_DEBUG_OBJECT (nice, "Setting remote ICE credentials on "
+      "ICE stream %u ufrag:%s pwd:%s", item->nice_stream_id, ufrag, pwd);
+
+  nice_agent_set_remote_credentials (nice->priv->nice_agent,
+      item->nice_stream_id, ufrag, pwd);
+
+  return TRUE;
+}
+
+typedef struct
+{
+  GstWebRTCNice *ice;
+  GstUri *turn_server;
+} AddTurnServerToStreamData;
+
+static gboolean
+_add_turn_server_foreach_stream_func (struct NiceStreamItem *item,
+    gpointer data)
+{
+  AddTurnServerToStreamData *add_data = (AddTurnServerToStreamData *) data;
+  _add_turn_server (add_data->ice, item, add_data->turn_server);
+  return TRUE;
+}
+
+static gboolean
+gst_webrtc_nice_add_turn_server (GstWebRTCICE * ice, const gchar * uri)
+{
+  gboolean ret = FALSE;
+  GstUri *valid_uri;
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  gboolean inserted;
+  AddTurnServerToStreamData add_data;
+
+  if (!(valid_uri = _validate_turn_server (nice, uri)))
+    goto done;
+
+  inserted =
+      g_hash_table_insert (nice->priv->turn_servers, g_strdup (uri), valid_uri);
+
+  /* add the turn server to any streams that were already created */
+  if (inserted) {
+    add_data.ice = nice;
+    add_data.turn_server = valid_uri;
+    _nice_stream_item_foreach (nice, _add_turn_server_foreach_stream_func,
+        &add_data);
+  }
+
+  ret = TRUE;
+
+done:
+  return ret;
+}
+
+static gboolean
+gst_webrtc_nice_add_local_ip_address (GstWebRTCNice * ice,
+    const gchar * address)
+{
+  gboolean ret = FALSE;
+  NiceAddress nice_addr;
+
+  nice_address_init (&nice_addr);
+
+  ret = nice_address_set_from_string (&nice_addr, address);
+
+  if (ret) {
+    ret = nice_agent_add_local_address (ice->priv->nice_agent, &nice_addr);
+    if (!ret) {
+      GST_ERROR_OBJECT (ice, "Failed to add local address to NiceAgent");
+    }
+  } else {
+    GST_ERROR_OBJECT (ice, "Failed to initialize NiceAddress [%s]", address);
+  }
+
+  return ret;
+}
+
+static gboolean
+gst_webrtc_nice_set_local_credentials (GstWebRTCICE * ice,
+    GstWebRTCICEStream * stream, const gchar * ufrag, const gchar * pwd)
+{
+  struct NiceStreamItem *item;
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+
+  g_return_val_if_fail (ufrag != NULL, FALSE);
+  g_return_val_if_fail (pwd != NULL, FALSE);
+  item = _find_item (nice, -1, -1, stream);
+  g_return_val_if_fail (item != NULL, FALSE);
+
+  GST_DEBUG_OBJECT (nice, "Setting local ICE credentials on "
+      "ICE stream %u ufrag:%s pwd:%s", item->nice_stream_id, ufrag, pwd);
+
+  nice_agent_set_local_credentials (nice->priv->nice_agent,
+      item->nice_stream_id, ufrag, pwd);
+
+  return TRUE;
+}
+
+static gboolean
+gst_webrtc_nice_gather_candidates (GstWebRTCICE * ice,
+    GstWebRTCICEStream * stream)
+{
+  struct NiceStreamItem *item;
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+
+  item = _find_item (nice, -1, -1, stream);
+  g_return_val_if_fail (item != NULL, FALSE);
+
+  GST_DEBUG_OBJECT (nice, "gather candidates for stream %u",
+      item->nice_stream_id);
+
+  return gst_webrtc_ice_stream_gather_candidates (stream);
+}
+
+static void
+gst_webrtc_nice_set_is_controller (GstWebRTCICE * ice, gboolean controller)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  g_object_set (G_OBJECT (nice->priv->nice_agent), "controlling-mode",
+      controller, NULL);
+}
+
+static gboolean
+gst_webrtc_nice_get_is_controller (GstWebRTCICE * ice)
+{
+  gboolean ret;
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  g_object_get (G_OBJECT (nice->priv->nice_agent), "controlling-mode",
+      &ret, NULL);
+  return ret;
+}
+
+static void
+gst_webrtc_nice_set_force_relay (GstWebRTCICE * ice, gboolean force_relay)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  g_object_set (G_OBJECT (nice->priv->nice_agent), "force-relay", force_relay,
+      NULL);
+}
+
+static void
+gst_webrtc_nice_set_on_ice_candidate (GstWebRTCICE * ice,
+    GstWebRTCICEOnCandidateFunc func, gpointer user_data, GDestroyNotify notify)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  if (nice->priv->on_candidate_notify)
+    nice->priv->on_candidate_notify (nice->priv->on_candidate_data);
+  nice->priv->on_candidate = NULL;
+
+  nice->priv->on_candidate = func;
+  nice->priv->on_candidate_data = user_data;
+  nice->priv->on_candidate_notify = notify;
+}
+
+static void
+gst_webrtc_nice_set_tos (GstWebRTCICE * ice, GstWebRTCICEStream * stream,
+    guint tos)
+{
+  struct NiceStreamItem *item;
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+
+  item = _find_item (nice, -1, -1, stream);
+  g_return_if_fail (item != NULL);
+
+  nice_agent_set_stream_tos (nice->priv->nice_agent, item->nice_stream_id, tos);
+}
+
+static const gchar *
+_relay_type_to_string (GstUri * turn_server)
+{
+  const gchar *scheme;
+  const gchar *transport;
+
+  if (!turn_server)
+    return "none";
+
+  scheme = gst_uri_get_scheme (turn_server);
+  transport = gst_uri_get_query_value (turn_server, "transport");
+
+  if (g_strcmp0 (scheme, "turns") == 0) {
+    return "tls";
+  } else if (g_strcmp0 (scheme, "turn") == 0) {
+    if (!transport || g_strcmp0 (transport, "udp") == 0)
+      return "udp";
+    if (!transport || g_strcmp0 (transport, "tcp") == 0)
+      return "tcp";
+  }
+
+  return "none";
+}
+
+static gchar *
+_get_server_url (GstWebRTCNice * ice, NiceCandidate * cand)
+{
+  switch (cand->type) {
+    case NICE_CANDIDATE_TYPE_RELAYED:{
+      NiceAddress addr;
+      gchar ipaddr[NICE_ADDRESS_STRING_LEN];
+      nice_candidate_relay_address (cand, &addr);
+      nice_address_to_string (&addr, ipaddr);
+      return g_strdup (ipaddr);
+    }
+    case NICE_CANDIDATE_TYPE_SERVER_REFLEXIVE:{
+      NiceAddress addr;
+      gchar ipaddr[NICE_ADDRESS_STRING_LEN];
+      if (nice_candidate_stun_server_address (cand, &addr)) {
+        nice_address_to_string (&addr, ipaddr);
+        return g_strdup (ipaddr);
+      } else {
+        return g_strdup (gst_uri_get_host (ice->priv->stun_server));
+      }
+      return g_strdup (gst_uri_get_host (ice->priv->stun_server));
+    }
+    default:
+      return g_strdup ("");
+  }
+}
+
+/* TODO: replace it with nice_candidate_type_to_string()
+ * when it's ready for use
+ * https://libnice.freedesktop.org/libnice/NiceCandidate.html#nice-candidate-type-to-string
+ */
+static const gchar *
+_candidate_type_to_string (NiceCandidateType type)
+{
+  switch (type) {
+    case NICE_CANDIDATE_TYPE_HOST:
+      return "host";
+    case NICE_CANDIDATE_TYPE_SERVER_REFLEXIVE:
+      return "srflx";
+    case NICE_CANDIDATE_TYPE_PEER_REFLEXIVE:
+      return "prflx";
+    case NICE_CANDIDATE_TYPE_RELAYED:
+      return "relay";
+    default:
+      g_assert_not_reached ();
+      return NULL;
+  }
+}
+
+static void
+_populate_candidate_stats (GstWebRTCNice * ice, NiceCandidate * cand,
+    GstWebRTCICEStream * stream, GstWebRTCICECandidateStats * stats,
+    gboolean is_local)
+{
+  gchar ipaddr[INET6_ADDRSTRLEN];
+
+  g_assert (cand != NULL);
+
+  nice_address_to_string (&cand->addr, ipaddr);
+  stats->port = nice_address_get_port (&cand->addr);
+  stats->ipaddr = g_strdup (ipaddr);
+  stats->stream_id = stream->stream_id;
+  stats->type = _candidate_type_to_string (cand->type);
+  stats->prio = cand->priority;
+  stats->proto =
+      cand->transport == NICE_CANDIDATE_TRANSPORT_UDP ? "udp" : "tcp";
+  if (is_local) {
+    if (cand->type == NICE_CANDIDATE_TYPE_RELAYED)
+      stats->relay_proto = _relay_type_to_string (ice->priv->turn_server);
+    stats->url = _get_server_url (ice, cand);
+  }
+}
+
+static void
+_populate_candidate_list_stats (GstWebRTCNice * ice, GSList * cands,
+    GstWebRTCICEStream * stream, GPtrArray * result, gboolean is_local)
+{
+  GSList *item;
+
+  for (item = cands; item != NULL; item = item->next) {
+    GstWebRTCICECandidateStats *stats =
+        g_malloc0 (sizeof (GstWebRTCICECandidateStats));
+    NiceCandidate *c = item->data;
+    _populate_candidate_stats (ice, c, stream, stats, is_local);
+    g_ptr_array_add (result, stats);
+  }
+
+  g_ptr_array_add (result, NULL);
+}
+
+static GstWebRTCICECandidateStats **
+gst_webrtc_nice_get_local_candidates (GstWebRTCICE * ice,
+    GstWebRTCICEStream * stream)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  GSList *cands = NULL;
+
+  /* TODO: Use a g_ptr_array_new_null_terminated once when we depend on GLib 2.74 */
+  GPtrArray *result = g_ptr_array_new ();
+
+  cands = nice_agent_get_local_candidates (nice->priv->nice_agent,
+      stream->stream_id, NICE_COMPONENT_TYPE_RTP);
+
+  _populate_candidate_list_stats (nice, cands, stream, result, TRUE);
+  g_slist_free_full (cands, (GDestroyNotify) nice_candidate_free);
+
+  return (GstWebRTCICECandidateStats **) g_ptr_array_free (result, FALSE);
+}
+
+static GstWebRTCICECandidateStats **
+gst_webrtc_nice_get_remote_candidates (GstWebRTCICE * ice,
+    GstWebRTCICEStream * stream)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  GSList *cands = NULL;
+
+  /* TODO: Use a g_ptr_array_new_null_terminated once when we depend on GLib 2.74 */
+  GPtrArray *result = g_ptr_array_new ();
+
+  cands = nice_agent_get_remote_candidates (nice->priv->nice_agent,
+      stream->stream_id, NICE_COMPONENT_TYPE_RTP);
+
+  _populate_candidate_list_stats (nice, cands, stream, result, FALSE);
+  g_slist_free_full (cands, (GDestroyNotify) nice_candidate_free);
+
+  return (GstWebRTCICECandidateStats **) g_ptr_array_free (result, FALSE);
+}
+
+static gboolean
+gst_webrtc_nice_get_selected_pair (GstWebRTCICE * ice,
+    GstWebRTCICEStream * stream, GstWebRTCICECandidateStats ** local_stats,
+    GstWebRTCICECandidateStats ** remote_stats)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  NiceCandidate *local_cand = NULL;
+  NiceCandidate *remote_cand = NULL;
+
+
+  if (stream) {
+    if (nice_agent_get_selected_pair (nice->priv->nice_agent, stream->stream_id,
+            NICE_COMPONENT_TYPE_RTP, &local_cand, &remote_cand)) {
+      *local_stats = g_new0 (GstWebRTCICECandidateStats, 1);
+      _populate_candidate_stats (nice, local_cand, stream, *local_stats, TRUE);
+
+      *remote_stats = g_new0 (GstWebRTCICECandidateStats, 1);
+      _populate_candidate_stats (nice, remote_cand, stream, *remote_stats,
+          FALSE);
+
+      return TRUE;
+    }
+  }
+
+  return FALSE;
+}
+
+static void
+_clear_ice_stream (struct NiceStreamItem *item)
+{
+  GstWebRTCNice *ice = NULL;
+
+  if (!item)
+    return;
+
+  if (item->stream) {
+    g_object_get (item->stream, "ice", &ice, NULL);
+
+    if (ice != NULL) {
+      g_signal_handlers_disconnect_by_data (ice->priv->nice_agent,
+          item->stream);
+      gst_object_unref (ice);
+    }
+    gst_object_unref (item->stream);
+  }
+}
+
+static GstUri *
+_validate_turn_server (GstWebRTCNice * ice, const gchar * s)
+{
+  GstUri *uri = gst_uri_from_string_escaped (s);
+  const gchar *userinfo, *scheme;
+  GList *keys = NULL, *l;
+  gchar *user = NULL, *pass = NULL;
+  gboolean turn_tls = FALSE;
+  guint port;
+
+  GST_DEBUG_OBJECT (ice, "validating turn server, %s", s);
+
+  if (!uri) {
+    GST_ERROR_OBJECT (ice, "Could not parse turn server '%s'", s);
+    return NULL;
+  }
+
+  scheme = gst_uri_get_scheme (uri);
+  if (g_strcmp0 (scheme, "turn") == 0) {
+  } else if (g_strcmp0 (scheme, "turns") == 0) {
+    turn_tls = TRUE;
+  } else {
+    GST_ERROR_OBJECT (ice, "unknown scheme '%s'", scheme);
+    goto out;
+  }
+
+  keys = gst_uri_get_query_keys (uri);
+  for (l = keys; l; l = l->next) {
+    gchar *key = l->data;
+
+    if (g_strcmp0 (key, "transport") == 0) {
+      const gchar *transport = gst_uri_get_query_value (uri, "transport");
+      if (!transport) {
+      } else if (g_strcmp0 (transport, "udp") == 0) {
+      } else if (g_strcmp0 (transport, "tcp") == 0) {
+      } else {
+        GST_ERROR_OBJECT (ice, "unknown transport value, '%s'", transport);
+        goto out;
+      }
+    } else {
+      GST_ERROR_OBJECT (ice, "unknown query key, '%s'", key);
+      goto out;
+    }
+  }
+
+  /* TODO: Implement error checking similar to the stun server below */
+  userinfo = gst_uri_get_userinfo (uri);
+  _parse_userinfo (userinfo, &user, &pass);
+  if (!user) {
+    GST_ERROR_OBJECT (ice, "No username specified in '%s'", s);
+    goto out;
+  }
+  if (!pass) {
+    GST_ERROR_OBJECT (ice, "No password specified in '%s'", s);
+    goto out;
+  }
+
+  port = gst_uri_get_port (uri);
+
+  if (port == GST_URI_NO_PORT) {
+    if (turn_tls) {
+      gst_uri_set_port (uri, 5349);
+    } else {
+      gst_uri_set_port (uri, 3478);
+    }
+  }
+
+  g_list_free (keys);
+  g_free (user);
+  g_free (pass);
+
+  return uri;
+
+out:
+  g_list_free (keys);
+  g_free (user);
+  g_free (pass);
+  gst_uri_unref (uri);
+
+  return NULL;
+}
+
+static void
+on_http_proxy_resolved (GstWebRTCICE * ice, GAsyncResult * res,
+    gpointer user_data)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  GstUri *uri = user_data;
+  GList *addresses;
+  GError *error = NULL;
+  const gchar *userinfo;
+  gchar *user = NULL;
+  gchar *pass = NULL;
+  gchar *ip = NULL;
+  guint port = GST_URI_NO_PORT;
+
+  if (!(addresses = resolve_host_finish (nice, res, &error))) {
+    GST_WARNING_OBJECT (ice, "Failed to resolve http proxy: %s",
+        error->message);
+    g_clear_error (&error);
+    return;
+  }
+
+  /* XXX: only the first IP is used */
+  ip = g_inet_address_to_string (addresses->data);
+
+  if (!ip) {
+    GST_ERROR_OBJECT (ice, "failed to resolve host for proxy");
+    gst_uri_unref (uri);
+    return;
+  }
+
+  port = gst_uri_get_port (uri);
+  if (port == GST_URI_NO_PORT) {
+    port = HTTP_PROXY_PORT_DEFAULT;
+    GST_DEBUG_OBJECT (ice, "Proxy server has no port, assuming %u",
+        HTTP_PROXY_PORT_DEFAULT);
+  }
+
+  userinfo = gst_uri_get_userinfo (uri);
+  _parse_userinfo (userinfo, &user, &pass);
+
+  g_object_set (nice->priv->nice_agent,
+      "proxy-ip", ip, "proxy-port", port, "proxy-type", NICE_PROXY_TYPE_HTTP,
+      "proxy-username", user, "proxy-password", pass, NULL);
+
+  g_free (ip);
+  g_free (user);
+  g_free (pass);
+}
+
+static GstUri *
+_set_http_proxy (GstWebRTCICE * ice, const gchar * s)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  GstUri *uri = gst_uri_from_string_escaped (s);
+  const gchar *msg =
+      "must be of the form http://[username:password@]<host>[:<port>]";
+  const gchar *host = NULL;
+  const gchar *userinfo;
+  gchar *user = NULL, *pass = NULL;
+
+  GST_DEBUG_OBJECT (ice, "setting http proxy %s", s);
+
+  if (!uri) {
+    GST_ERROR_OBJECT (ice, "Couldn't parse http proxy uri '%s', %s", s, msg);
+    return NULL;
+  }
+
+  if (g_strcmp0 (gst_uri_get_scheme (uri), "http") != 0) {
+    GST_ERROR_OBJECT (ice,
+        "Couldn't parse uri scheme for http proxy server '%s', %s", s, msg);
+    gst_uri_unref (uri);
+    return NULL;
+  }
+
+  host = gst_uri_get_host (uri);
+  if (!host) {
+    GST_ERROR_OBJECT (ice, "http proxy server '%s' has no host, %s", s, msg);
+    gst_uri_unref (uri);
+    return NULL;
+  }
+
+  userinfo = gst_uri_get_userinfo (uri);
+  _parse_userinfo (userinfo, &user, &pass);
+  if ((pass && pass[0] != '\0') && (!user || user[0] == '\0')) {
+    GST_ERROR_OBJECT (ice,
+        "Password specified without user for http proxy '%s', %s", s, msg);
+    uri = NULL;
+    goto out;
+  }
+
+  resolve_host_async (nice, host, (GAsyncReadyCallback) on_http_proxy_resolved,
+      gst_uri_ref (uri), (GDestroyNotify) gst_uri_unref);
+
+out:
+  g_free (user);
+  g_free (pass);
+
+  return uri;
+}
+
+static void
+gst_webrtc_nice_set_stun_server (GstWebRTCICE * ice, const gchar * uri_s)
+{
+  GstUri *uri = gst_uri_from_string_escaped (uri_s);
+  const gchar *msg = "must be of the form stun://<host>:<port>";
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+
+  GST_DEBUG_OBJECT (nice, "setting stun server, %s", uri_s);
+
+  if (!uri) {
+    GST_ERROR_OBJECT (nice, "Couldn't parse stun server '%s', %s", uri_s, msg);
+    return;
+  }
+
+  if (nice->priv->stun_server)
+    gst_uri_unref (nice->priv->stun_server);
+  nice->priv->stun_server = uri;
+}
+
+static gchar *
+gst_webrtc_nice_get_stun_server (GstWebRTCICE * ice)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  if (nice->priv->stun_server)
+    return gst_uri_to_string (nice->priv->stun_server);
+  else
+    return NULL;
+}
+
+static void
+gst_webrtc_nice_set_turn_server (GstWebRTCICE * ice, const gchar * uri_s)
+{
+  GstUri *uri;
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  uri = _validate_turn_server (nice, uri_s);
+
+  if (uri) {
+    if (nice->priv->turn_server)
+      gst_uri_unref (nice->priv->turn_server);
+    nice->priv->turn_server = uri;
+  }
+}
+
+static gchar *
+gst_webrtc_nice_get_turn_server (GstWebRTCICE * ice)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  if (nice->priv->turn_server)
+    return gst_uri_to_string (nice->priv->turn_server);
+  else
+    return NULL;
+}
+
+static void
+gst_webrtc_nice_set_http_proxy (GstWebRTCICE * ice, const gchar * http_proxy)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+  GstUri *uri = _set_http_proxy (ice, http_proxy);
+
+  if (uri) {
+    if (nice->priv->http_proxy)
+      gst_uri_unref (nice->priv->http_proxy);
+    nice->priv->http_proxy = uri;
+  }
+}
+
+static gchar *
+gst_webrtc_nice_get_http_proxy (GstWebRTCICE * ice)
+{
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (ice);
+
+  if (nice->priv->http_proxy)
+    return gst_uri_to_string (nice->priv->http_proxy);
+  else
+    return NULL;
+}
+
+static void
+gst_webrtc_nice_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  GstWebRTCICE *ice = GST_WEBRTC_ICE (object);
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (object);
+
+  switch (prop_id) {
+    case PROP_ICE_TCP:
+      g_object_set_property (G_OBJECT (nice->priv->nice_agent),
+          "ice-tcp", value);
+      break;
+    case PROP_ICE_UDP:
+      g_object_set_property (G_OBJECT (nice->priv->nice_agent),
+          "ice-udp", value);
+      break;
+    case PROP_MIN_RTP_PORT:
+      ice->min_rtp_port = g_value_get_uint (value);
+      if (ice->min_rtp_port > ice->max_rtp_port)
+        g_warning ("Set min-rtp-port to %u which is larger than"
+            " max-rtp-port %u", ice->min_rtp_port, ice->max_rtp_port);
+      break;
+    case PROP_MAX_RTP_PORT:
+      ice->max_rtp_port = g_value_get_uint (value);
+      if (ice->min_rtp_port > ice->max_rtp_port)
+        g_warning ("Set max-rtp-port to %u which is smaller than"
+            " min-rtp-port %u", ice->max_rtp_port, ice->min_rtp_port);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_webrtc_nice_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  GstWebRTCICE *ice = GST_WEBRTC_ICE (object);
+  GstWebRTCNice *nice = GST_WEBRTC_NICE (object);
+
+  switch (prop_id) {
+    case PROP_AGENT:
+      g_value_set_object (value, nice->priv->nice_agent);
+      break;
+    case PROP_ICE_TCP:
+      g_object_get_property (G_OBJECT (nice->priv->nice_agent),
+          "ice-tcp", value);
+      break;
+    case PROP_ICE_UDP:
+      g_object_get_property (G_OBJECT (nice->priv->nice_agent),
+          "ice-udp", value);
+      break;
+    case PROP_MIN_RTP_PORT:
+      g_value_set_uint (value, ice->min_rtp_port);
+      break;
+    case PROP_MAX_RTP_PORT:
+      g_value_set_uint (value, ice->max_rtp_port);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_webrtc_nice_finalize (GObject * object)
+{
+  GstWebRTCNice *ice = GST_WEBRTC_NICE (object);
+
+  g_signal_handlers_disconnect_by_data (ice->priv->nice_agent, ice);
+
+  _stop_thread (ice);
+
+  if (ice->priv->on_candidate_notify)
+    ice->priv->on_candidate_notify (ice->priv->on_candidate_data);
+  ice->priv->on_candidate = NULL;
+  ice->priv->on_candidate_notify = NULL;
+
+  if (ice->priv->turn_server)
+    gst_uri_unref (ice->priv->turn_server);
+  if (ice->priv->stun_server)
+    gst_uri_unref (ice->priv->stun_server);
+  if (ice->priv->http_proxy)
+    gst_uri_unref (ice->priv->http_proxy);
+
+  g_mutex_clear (&ice->priv->lock);
+  g_cond_clear (&ice->priv->cond);
+
+  g_array_free (ice->priv->nice_stream_map, TRUE);
+
+  g_object_unref (ice->priv->nice_agent);
+
+  g_hash_table_unref (ice->priv->turn_servers);
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
+static void
+gst_webrtc_nice_constructed (GObject * object)
+{
+  GstWebRTCNice *ice = GST_WEBRTC_NICE (object);
+  NiceAgentOption options = 0;
+
+  _start_thread (ice);
+
+  options |= NICE_AGENT_OPTION_ICE_TRICKLE;
+  options |= NICE_AGENT_OPTION_REGULAR_NOMINATION;
+
+  ice->priv->nice_agent = nice_agent_new_full (ice->priv->main_context,
+      NICE_COMPATIBILITY_RFC5245, options);
+  g_signal_connect (ice->priv->nice_agent, "new-candidate-full",
+      G_CALLBACK (_on_new_candidate), ice);
+
+  G_OBJECT_CLASS (parent_class)->constructed (object);
+}
+
+static void
+gst_webrtc_nice_class_init (GstWebRTCNiceClass * klass)
+{
+  GstWebRTCICEClass *gst_webrtc_ice_class = GST_WEBRTC_ICE_CLASS (klass);
+  GObjectClass *gobject_class = (GObjectClass *) klass;
+
+  // override virtual functions
+  gst_webrtc_ice_class->add_candidate = gst_webrtc_nice_add_candidate;
+  gst_webrtc_ice_class->add_stream = gst_webrtc_nice_add_stream;
+  gst_webrtc_ice_class->add_turn_server = gst_webrtc_nice_add_turn_server;
+  gst_webrtc_ice_class->find_transport = gst_webrtc_nice_find_transport;
+  gst_webrtc_ice_class->gather_candidates = gst_webrtc_nice_gather_candidates;
+  gst_webrtc_ice_class->get_is_controller = gst_webrtc_nice_get_is_controller;
+  gst_webrtc_ice_class->get_stun_server = gst_webrtc_nice_get_stun_server;
+  gst_webrtc_ice_class->get_turn_server = gst_webrtc_nice_get_turn_server;
+  gst_webrtc_ice_class->get_http_proxy = gst_webrtc_nice_get_http_proxy;
+  gst_webrtc_ice_class->set_force_relay = gst_webrtc_nice_set_force_relay;
+  gst_webrtc_ice_class->set_is_controller = gst_webrtc_nice_set_is_controller;
+  gst_webrtc_ice_class->set_local_credentials =
+      gst_webrtc_nice_set_local_credentials;
+  gst_webrtc_ice_class->set_remote_credentials =
+      gst_webrtc_nice_set_remote_credentials;
+  gst_webrtc_ice_class->set_stun_server = gst_webrtc_nice_set_stun_server;
+  gst_webrtc_ice_class->set_tos = gst_webrtc_nice_set_tos;
+  gst_webrtc_ice_class->set_turn_server = gst_webrtc_nice_set_turn_server;
+  gst_webrtc_ice_class->set_http_proxy = gst_webrtc_nice_set_http_proxy;
+  gst_webrtc_ice_class->set_on_ice_candidate =
+      gst_webrtc_nice_set_on_ice_candidate;
+  gst_webrtc_ice_class->get_local_candidates =
+      gst_webrtc_nice_get_local_candidates;
+  gst_webrtc_ice_class->get_remote_candidates =
+      gst_webrtc_nice_get_remote_candidates;
+  gst_webrtc_ice_class->get_selected_pair = gst_webrtc_nice_get_selected_pair;
+
+  gobject_class->constructed = gst_webrtc_nice_constructed;
+  gobject_class->get_property = gst_webrtc_nice_get_property;
+  gobject_class->set_property = gst_webrtc_nice_set_property;
+  gobject_class->finalize = gst_webrtc_nice_finalize;
+
+  g_object_class_install_property (gobject_class,
+      PROP_AGENT,
+      g_param_spec_object ("agent", "ICE agent",
+          "ICE agent in use by this object. WARNING! Accessing this property "
+          "may have disastrous consequences for the operation of webrtcbin. "
+          "Other ICE implementations may not have the same interface.",
+          NICE_TYPE_AGENT, G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
+
+  g_object_class_install_property (gobject_class,
+      PROP_ICE_TCP,
+      g_param_spec_boolean ("ice-tcp", "ICE TCP",
+          "Whether the agent should use ICE-TCP when gathering candidates",
+          TRUE, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+  g_object_class_install_property (gobject_class,
+      PROP_ICE_UDP,
+      g_param_spec_boolean ("ice-udp", "ICE UDP",
+          "Whether the agent should use ICE-UDP when gathering candidates",
+          TRUE, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+  g_signal_override_class_handler ("add-local-ip-address",
+      G_TYPE_FROM_CLASS (klass),
+      G_CALLBACK (gst_webrtc_nice_add_local_ip_address));
+}
+
+static void
+gst_webrtc_nice_init (GstWebRTCNice * ice)
+{
+  ice->priv = gst_webrtc_nice_get_instance_private (ice);
+
+  g_mutex_init (&ice->priv->lock);
+  g_cond_init (&ice->priv->cond);
+
+  ice->priv->turn_servers =
+      g_hash_table_new_full (g_str_hash, g_str_equal, g_free,
+      (GDestroyNotify) gst_uri_unref);
+
+  ice->priv->nice_stream_map =
+      g_array_new (FALSE, TRUE, sizeof (struct NiceStreamItem));
+  g_array_set_clear_func (ice->priv->nice_stream_map,
+      (GDestroyNotify) _clear_ice_stream);
+}
+
+GstWebRTCNice *
+gst_webrtc_nice_new (const gchar * name)
+{
+  return g_object_new (GST_TYPE_WEBRTC_NICE, "name", name, NULL);
+}
diff --git a/gst-libs/gst/webrtc/nice/nice.h b/gst-libs/gst/webrtc/nice/nice.h
new file mode 100644
index 000000000..a4d8a94a5
--- /dev/null
+++ b/gst-libs/gst/webrtc/nice/nice.h
@@ -0,0 +1,67 @@
+/* GStreamer
+ * Copyright (C) 2017 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef __GST_WEBRTC_NICE_H__
+#define __GST_WEBRTC_NICE_H__
+
+#include "gst/webrtc/ice.h"
+
+#include "nicestream.h"
+#include "nicetransport.h"
+
+#include "nice_fwd.h"
+
+G_BEGIN_DECLS
+
+GST_WEBRTCNICE_API
+GType gst_webrtc_nice_get_type(void);
+#define GST_TYPE_WEBRTC_NICE            (gst_webrtc_nice_get_type())
+#define GST_WEBRTC_NICE(obj)            (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_WEBRTC_NICE,GstWebRTCNice))
+#define GST_IS_WEBRTC_NICE(obj)         (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_WEBRTC_NICE))
+#define GST_WEBRTC_NICE_CLASS(klass)    (G_TYPE_CHECK_CLASS_CAST((klass) ,GST_TYPE_WEBRTC_NICE,GstWebRTCNiceClass))
+#define GST_IS_WEBRTC_NICE_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE((klass) ,GST_TYPE_WEBRTC_NICE))
+#define GST_WEBRTC_NICE_GET_CLASS(obj)  (G_TYPE_INSTANCE_GET_CLASS((obj) ,GST_TYPE_WEBRTC_NICE,GstWebRTCNiceClass))
+
+/**
+ * GstWebRTCNice:
+ */
+typedef struct _GstWebRTCNice GstWebRTCNice;
+typedef struct _GstWebRTCNiceClass GstWebRTCNiceClass;
+typedef struct _GstWebRTCNicePrivate GstWebRTCNicePrivate;
+
+struct _GstWebRTCNice
+{
+  GstWebRTCICE                      parent;
+  GstWebRTCNicePrivate             *priv;
+
+};
+
+struct _GstWebRTCNiceClass
+{
+  GstWebRTCICEClass     parent_class;
+};
+
+GST_WEBRTCNICE_API
+GstWebRTCNice *             gst_webrtc_nice_new                      (const gchar * name);
+
+G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstWebRTCNice, gst_object_unref)
+
+G_END_DECLS
+
+#endif /* __GST_WEBRTC_NICE_H__ */
\ No newline at end of file
diff --git a/gst-libs/gst/webrtc/nice/nice_fwd.h b/gst-libs/gst/webrtc/nice/nice_fwd.h
new file mode 100644
index 000000000..4d51c36c5
--- /dev/null
+++ b/gst-libs/gst/webrtc/nice/nice_fwd.h
@@ -0,0 +1,17 @@
+#ifndef __GST_WEBRTCNICE_FWD_H__
+#define __GST_WEBRTCNICE_FWD_H__
+
+#ifndef GST_USE_UNSTABLE_API
+#warning "The GstWebRTCNice library from gst-plugins-bad is unstable API and may change in future."
+#warning "You can define GST_USE_UNSTABLE_API to avoid this warning."
+#endif
+
+#ifndef GST_WEBRTCNICE_API
+# ifdef BUILDING_GST_WEBRTCNICE
+#  define GST_WEBRTCNICE_API GST_API_EXPORT         /* from config.h */
+# else
+#  define GST_WEBRTCNICE_API GST_API_IMPORT
+# endif
+#endif
+
+#endif /* __GST_WEBRTCNICE_FWD_H__ */
\ No newline at end of file
diff --git a/gst-libs/gst/webrtc/nice/nicestream.c b/gst-libs/gst/webrtc/nice/nicestream.c
new file mode 100644
index 000000000..cda1c133f
--- /dev/null
+++ b/gst-libs/gst/webrtc/nice/nicestream.c
@@ -0,0 +1,334 @@
+/* GStreamer
+ * Copyright (C) 2017 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "nicestream.h"
+#include "nicetransport.h"
+
+#define GST_CAT_DEFAULT gst_webrtc_nice_stream_debug
+GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
+
+enum
+{
+  PROP_0,
+  PROP_ICE,
+};
+
+struct _GstWebRTCNiceStreamPrivate
+{
+  gboolean gathered;
+  GList *transports;
+  gboolean gathering_started;
+  gulong candidate_gathering_done_id;
+  GWeakRef ice_weak;
+};
+
+#define gst_webrtc_nice_stream_parent_class parent_class
+G_DEFINE_TYPE_WITH_CODE (GstWebRTCNiceStream, gst_webrtc_nice_stream,
+    GST_TYPE_WEBRTC_ICE_STREAM, G_ADD_PRIVATE (GstWebRTCNiceStream)
+    GST_DEBUG_CATEGORY_INIT (gst_webrtc_nice_stream_debug,
+        "webrtcnicestream", 0, "webrtcnicestream"););
+
+static void
+gst_webrtc_nice_stream_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  GstWebRTCNiceStream *stream = GST_WEBRTC_NICE_STREAM (object);
+
+  switch (prop_id) {
+    case PROP_ICE:
+      g_weak_ref_set (&stream->priv->ice_weak, g_value_get_object (value));
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_webrtc_nice_stream_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  GstWebRTCNiceStream *stream = GST_WEBRTC_NICE_STREAM (object);
+
+  switch (prop_id) {
+    case PROP_ICE:
+      g_value_take_object (value, g_weak_ref_get (&stream->priv->ice_weak));
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static GWeakRef *
+weak_new (gpointer object)
+{
+  GWeakRef *weak = g_new0 (GWeakRef, 1);
+  g_weak_ref_init (weak, object);
+  return weak;
+}
+
+static void
+weak_free (GWeakRef * weak)
+{
+  g_weak_ref_clear (weak);
+  g_free (weak);
+}
+
+static void
+gst_webrtc_nice_stream_finalize (GObject * object)
+{
+  GstWebRTCNiceStream *stream = GST_WEBRTC_NICE_STREAM (object);
+  GstWebRTCNice *ice = g_weak_ref_get (&stream->priv->ice_weak);
+
+  if (ice) {
+    NiceAgent *agent;
+    g_object_get (ice, "agent", &agent, NULL);
+
+    if (stream->priv->candidate_gathering_done_id != 0) {
+      g_signal_handler_disconnect (agent,
+          stream->priv->candidate_gathering_done_id);
+    }
+
+    g_object_unref (agent);
+    gst_object_unref (ice);
+  }
+
+  g_list_foreach (stream->priv->transports, (GFunc) weak_free, NULL);
+  g_list_free (stream->priv->transports);
+  stream->priv->transports = NULL;
+
+  g_weak_ref_clear (&stream->priv->ice_weak);
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
+static GList *
+_delete_transport (GList ** transports, GList * link)
+{
+  GList *next = link->next;
+  weak_free (link->data);
+  *transports = g_list_delete_link (*transports, link);
+  return next;
+}
+
+static void
+_on_candidate_gathering_done (NiceAgent * agent, guint stream_id,
+    GWeakRef * ice_weak)
+{
+  GstWebRTCNiceStream *ice = g_weak_ref_get (ice_weak);
+  GList *l;
+
+  if (!ice)
+    return;
+
+  if (stream_id != GST_WEBRTC_ICE_STREAM (ice)->stream_id)
+    goto cleanup;
+
+  GST_DEBUG_OBJECT (ice, "%u gathering done", stream_id);
+
+  ice->priv->gathered = TRUE;
+
+  for (l = ice->priv->transports; l; l = l->next) {
+    GstWebRTCICETransport *trans = g_weak_ref_get (l->data);
+
+    if (trans) {
+      gst_webrtc_ice_transport_gathering_state_change (trans,
+          GST_WEBRTC_ICE_GATHERING_STATE_COMPLETE);
+      g_object_unref (trans);
+    } else {
+      l = _delete_transport (&ice->priv->transports, l);
+    }
+  }
+
+cleanup:
+  gst_object_unref (ice);
+}
+
+static GstWebRTCICETransport *
+gst_webrtc_nice_stream_find_transport (GstWebRTCICEStream * stream,
+    GstWebRTCICEComponent component)
+{
+  GstWebRTCICEComponent trans_comp;
+  GstWebRTCICETransport *ret;
+  GList *l;
+  GstWebRTCNiceStream *nice_stream = GST_WEBRTC_NICE_STREAM (stream);
+
+  for (l = nice_stream->priv->transports; l; l = l->next) {
+    GstWebRTCICETransport *trans = g_weak_ref_get (l->data);
+    if (trans) {
+      g_object_get (trans, "component", &trans_comp, NULL);
+
+      if (component == trans_comp)
+        return trans;
+      else
+        gst_object_unref (trans);
+    } else {
+      l = _delete_transport (&nice_stream->priv->transports, l);
+    }
+  }
+
+  ret =
+      GST_WEBRTC_ICE_TRANSPORT (gst_webrtc_nice_transport_new (nice_stream,
+          component));
+  nice_stream->priv->transports =
+      g_list_prepend (nice_stream->priv->transports, weak_new (ret));
+
+  return ret;
+}
+
+static void
+gst_webrtc_nice_stream_constructed (GObject * object)
+{
+  GstWebRTCNiceStream *stream;
+  NiceAgent *agent;
+  GstWebRTCNice *ice;
+
+  G_OBJECT_CLASS (parent_class)->constructed (object);
+
+  stream = GST_WEBRTC_NICE_STREAM (object);
+  ice = g_weak_ref_get (&stream->priv->ice_weak);
+
+
+  g_assert (ice != NULL);
+  g_object_get (ice, "agent", &agent, NULL);
+  stream->priv->candidate_gathering_done_id = g_signal_connect_data (agent,
+      "candidate-gathering-done", G_CALLBACK (_on_candidate_gathering_done),
+      weak_new (stream), (GClosureNotify) weak_free, (GConnectFlags) 0);
+
+  g_object_unref (agent);
+  gst_object_unref (ice);
+}
+
+static gboolean
+gst_webrtc_nice_stream_gather_candidates (GstWebRTCICEStream * stream)
+{
+  NiceAgent *agent;
+  GList *l;
+  GstWebRTCICE *ice;
+  gboolean ret = TRUE;
+  GstWebRTCNiceStream *nice_stream = GST_WEBRTC_NICE_STREAM (stream);
+
+  GST_DEBUG_OBJECT (nice_stream, "start gathering candidates");
+
+  if (nice_stream->priv->gathered)
+    return TRUE;
+
+  for (l = nice_stream->priv->transports; l; l = l->next) {
+    GstWebRTCICETransport *trans = g_weak_ref_get (l->data);
+
+    if (trans) {
+      gst_webrtc_ice_transport_gathering_state_change (trans,
+          GST_WEBRTC_ICE_GATHERING_STATE_GATHERING);
+      g_object_unref (trans);
+    } else {
+      l = _delete_transport (&nice_stream->priv->transports, l);
+    }
+  }
+
+  ice = GST_WEBRTC_ICE (g_weak_ref_get (&nice_stream->priv->ice_weak));
+  g_assert (ice != NULL);
+
+  g_object_get (ice, "agent", &agent, NULL);
+
+  if (!nice_stream->priv->gathering_started) {
+    if (ice->min_rtp_port != 0 || ice->max_rtp_port != 65535) {
+      if (ice->min_rtp_port > ice->max_rtp_port) {
+        GST_ERROR_OBJECT (ice,
+            "invalid port range: min-rtp-port %d must be <= max-rtp-port %d",
+            ice->min_rtp_port, ice->max_rtp_port);
+        ret = FALSE;
+        goto cleanup;
+      }
+
+      nice_agent_set_port_range (agent, stream->stream_id,
+          NICE_COMPONENT_TYPE_RTP, ice->min_rtp_port, ice->max_rtp_port);
+    }
+    /* mark as gathering started to prevent changing ports again */
+    nice_stream->priv->gathering_started = TRUE;
+  }
+
+  if (!nice_agent_gather_candidates (agent, stream->stream_id)) {
+    ret = FALSE;
+    goto cleanup;
+  }
+
+  for (l = nice_stream->priv->transports; l; l = l->next) {
+    GstWebRTCNiceTransport *trans = g_weak_ref_get (l->data);
+
+    if (trans) {
+      gst_webrtc_nice_transport_update_buffer_size (trans);
+      g_object_unref (trans);
+    } else {
+      l = _delete_transport (&nice_stream->priv->transports, l);
+    }
+  }
+
+cleanup:
+  if (agent)
+    g_object_unref (agent);
+  if (ice)
+    gst_object_unref (ice);
+
+  return ret;
+}
+
+static void
+gst_webrtc_nice_stream_class_init (GstWebRTCNiceStreamClass * klass)
+{
+  GObjectClass *gobject_class = (GObjectClass *) klass;
+  GstWebRTCICEStreamClass *gst_webrtc_ice_stream_class =
+      GST_WEBRTC_ICE_STREAM_CLASS (klass);
+
+  gst_webrtc_ice_stream_class->find_transport =
+      gst_webrtc_nice_stream_find_transport;
+  gst_webrtc_ice_stream_class->gather_candidates =
+      gst_webrtc_nice_stream_gather_candidates;
+
+  gobject_class->constructed = gst_webrtc_nice_stream_constructed;
+  gobject_class->get_property = gst_webrtc_nice_stream_get_property;
+  gobject_class->set_property = gst_webrtc_nice_stream_set_property;
+  gobject_class->finalize = gst_webrtc_nice_stream_finalize;
+
+  g_object_class_install_property (gobject_class,
+      PROP_ICE,
+      g_param_spec_object ("ice",
+          "ICE", "ICE agent associated with this stream",
+          GST_TYPE_WEBRTC_ICE,
+          G_PARAM_READWRITE | G_PARAM_CONSTRUCT_ONLY | G_PARAM_STATIC_STRINGS));
+}
+
+static void
+gst_webrtc_nice_stream_init (GstWebRTCNiceStream * stream)
+{
+  stream->priv = gst_webrtc_nice_stream_get_instance_private (stream);
+
+  g_weak_ref_init (&stream->priv->ice_weak, NULL);
+}
+
+GstWebRTCNiceStream *
+gst_webrtc_nice_stream_new (GstWebRTCICE * ice, guint stream_id)
+{
+  return g_object_new (GST_TYPE_WEBRTC_NICE_STREAM, "ice", ice,
+      "stream-id", stream_id, NULL);
+}
diff --git a/gst-libs/gst/webrtc/nice/nicestream.h b/gst-libs/gst/webrtc/nice/nicestream.h
new file mode 100644
index 000000000..ef68153c6
--- /dev/null
+++ b/gst-libs/gst/webrtc/nice/nicestream.h
@@ -0,0 +1,63 @@
+/* GStreamer
+ * Copyright (C) 2017 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef __GST_WEBRTC_NICE_STREAM_H__
+#define __GST_WEBRTC_NICE_STREAM_H__
+
+#include "gst/webrtc/icestream.h"
+
+#include "nice_fwd.h"
+
+G_BEGIN_DECLS
+
+GST_WEBRTCNICE_API
+GType gst_webrtc_nice_stream_get_type(void);
+#define GST_TYPE_WEBRTC_NICE_STREAM            (gst_webrtc_nice_stream_get_type())
+#define GST_WEBRTC_NICE_STREAM(obj)            (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_WEBRTC_NICE_STREAM,GstWebRTCNiceStream))
+#define GST_IS_WEBRTC_NICE_STREAM(obj)         (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_WEBRTC_NICE_STREAM))
+#define GST_WEBRTC_NICE_STREAM_CLASS(klass)    (G_TYPE_CHECK_CLASS_CAST((klass) ,GST_TYPE_WEBRTC_NICE_STREAM,GstWebRTCNiceStreamClass))
+#define GST_IS_WEBRTC_NICE_STREAM_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE((klass) ,GST_TYPE_WEBRTC_NICE_STREAM))
+#define GST_WEBRTC_NICE_STREAM_GET_CLASS(obj)  (G_TYPE_INSTANCE_GET_CLASS((obj) ,GST_TYPE_WEBRTC_NICE_STREAM,GstWebRTCNiceStreamClass))
+
+/**
+ * GstWebRTCNiceStream:
+ */
+typedef struct _GstWebRTCNiceStream GstWebRTCNiceStream;
+typedef struct _GstWebRTCNiceStreamClass GstWebRTCNiceStreamClass;
+typedef struct _GstWebRTCNiceStreamPrivate GstWebRTCNiceStreamPrivate;
+
+struct _GstWebRTCNiceStream
+{
+  GstWebRTCICEStream    parent;
+  GstWebRTCNiceStreamPrivate *priv;
+};
+
+struct _GstWebRTCNiceStreamClass
+{
+  GstWebRTCICEStreamClass     parent_class;
+};
+
+GstWebRTCNiceStream *       gst_webrtc_nice_stream_new                   (GstWebRTCICE * ice,
+                                                                         guint stream_id);
+
+G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstWebRTCNiceStream, gst_object_unref)
+
+G_END_DECLS
+
+#endif /* __GST_WEBRTC_NICE_STREAM_H__ */
diff --git a/gst-libs/gst/webrtc/nice/nicetransport.c b/gst-libs/gst/webrtc/nice/nicetransport.c
new file mode 100644
index 000000000..13030d0fb
--- /dev/null
+++ b/gst-libs/gst/webrtc/nice/nicetransport.c
@@ -0,0 +1,426 @@
+/* GStreamer
+ * Copyright (C) 2017 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "nicestream.h"
+#include "nicetransport.h"
+
+#define GST_CAT_DEFAULT gst_webrtc_nice_transport_debug
+GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
+
+enum
+{
+  SIGNAL_0,
+  LAST_SIGNAL,
+};
+
+enum
+{
+  PROP_0,
+  PROP_STREAM,
+  PROP_SEND_BUFFER_SIZE,
+  PROP_RECEIVE_BUFFER_SIZE
+};
+
+//static guint gst_webrtc_nice_transport_signals[LAST_SIGNAL] = { 0 };
+
+struct _GstWebRTCNiceTransportPrivate
+{
+  gboolean running;
+
+  gint send_buffer_size;
+  gint receive_buffer_size;
+  gulong on_new_selected_pair_id;
+  gulong on_component_state_changed_id;
+};
+
+#define gst_webrtc_nice_transport_parent_class parent_class
+G_DEFINE_TYPE_WITH_CODE (GstWebRTCNiceTransport, gst_webrtc_nice_transport,
+    GST_TYPE_WEBRTC_ICE_TRANSPORT, G_ADD_PRIVATE (GstWebRTCNiceTransport)
+    GST_DEBUG_CATEGORY_INIT (gst_webrtc_nice_transport_debug,
+        "webrtcnicetransport", 0, "webrtcnicetransport");
+    );
+
+static NiceComponentType
+_gst_component_to_nice (GstWebRTCICEComponent component)
+{
+  switch (component) {
+    case GST_WEBRTC_ICE_COMPONENT_RTP:
+      return NICE_COMPONENT_TYPE_RTP;
+    case GST_WEBRTC_ICE_COMPONENT_RTCP:
+      return NICE_COMPONENT_TYPE_RTCP;
+    default:
+      g_assert_not_reached ();
+      return 0;
+  }
+}
+
+static GstWebRTCICEComponent
+_nice_component_to_gst (NiceComponentType component)
+{
+  switch (component) {
+    case NICE_COMPONENT_TYPE_RTP:
+      return GST_WEBRTC_ICE_COMPONENT_RTP;
+    case NICE_COMPONENT_TYPE_RTCP:
+      return GST_WEBRTC_ICE_COMPONENT_RTCP;
+    default:
+      g_assert_not_reached ();
+      return 0;
+  }
+}
+
+static GstWebRTCICEConnectionState
+_nice_component_state_to_gst (NiceComponentState state)
+{
+  switch (state) {
+    case NICE_COMPONENT_STATE_DISCONNECTED:
+      return GST_WEBRTC_ICE_CONNECTION_STATE_DISCONNECTED;
+    case NICE_COMPONENT_STATE_GATHERING:
+      return GST_WEBRTC_ICE_CONNECTION_STATE_NEW;
+    case NICE_COMPONENT_STATE_CONNECTING:
+      return GST_WEBRTC_ICE_CONNECTION_STATE_CHECKING;
+    case NICE_COMPONENT_STATE_CONNECTED:
+      return GST_WEBRTC_ICE_CONNECTION_STATE_CONNECTED;
+    case NICE_COMPONENT_STATE_READY:
+      return GST_WEBRTC_ICE_CONNECTION_STATE_COMPLETED;
+    case NICE_COMPONENT_STATE_FAILED:
+      return GST_WEBRTC_ICE_CONNECTION_STATE_FAILED;
+    default:
+      g_assert_not_reached ();
+      return 0;
+  }
+}
+
+static void
+gst_webrtc_nice_transport_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  GstWebRTCNiceTransport *nice = GST_WEBRTC_NICE_TRANSPORT (object);
+
+  switch (prop_id) {
+    case PROP_STREAM:
+      if (nice->stream)
+        gst_object_unref (nice->stream);
+      nice->stream = g_value_dup_object (value);
+      break;
+    case PROP_SEND_BUFFER_SIZE:
+      nice->priv->send_buffer_size = g_value_get_int (value);
+      gst_webrtc_nice_transport_update_buffer_size (nice);
+      break;
+    case PROP_RECEIVE_BUFFER_SIZE:
+      nice->priv->receive_buffer_size = g_value_get_int (value);
+      gst_webrtc_nice_transport_update_buffer_size (nice);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_webrtc_nice_transport_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  GstWebRTCNiceTransport *nice = GST_WEBRTC_NICE_TRANSPORT (object);
+
+  switch (prop_id) {
+    case PROP_STREAM:
+      g_value_set_object (value, nice->stream);
+      break;
+    case PROP_SEND_BUFFER_SIZE:
+      g_value_set_int (value, nice->priv->send_buffer_size);
+      break;
+    case PROP_RECEIVE_BUFFER_SIZE:
+      g_value_set_int (value, nice->priv->receive_buffer_size);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_webrtc_nice_transport_finalize (GObject * object)
+{
+  GstWebRTCNiceTransport *nice = GST_WEBRTC_NICE_TRANSPORT (object);
+  NiceAgent *agent;
+  GstWebRTCNice *webrtc_ice = NULL;
+
+  g_object_get (nice->stream, "ice", &webrtc_ice, NULL);
+
+  if (webrtc_ice) {
+    g_object_get (webrtc_ice, "agent", &agent, NULL);
+
+    if (nice->priv->on_component_state_changed_id != 0) {
+      g_signal_handler_disconnect (agent,
+          nice->priv->on_component_state_changed_id);
+    }
+
+    if (nice->priv->on_new_selected_pair_id != 0) {
+      g_signal_handler_disconnect (agent, nice->priv->on_new_selected_pair_id);
+    }
+
+    g_object_unref (agent);
+    gst_object_unref (webrtc_ice);
+  }
+
+  gst_object_unref (nice->stream);
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
+void
+gst_webrtc_nice_transport_update_buffer_size (GstWebRTCNiceTransport * nice)
+{
+  NiceAgent *agent = NULL;
+  GPtrArray *sockets;
+  guint i;
+  GstWebRTCNice *webrtc_ice = NULL;
+
+  g_object_get (nice->stream, "ice", &webrtc_ice, NULL);
+
+  g_assert (webrtc_ice != NULL);
+
+  g_object_get (webrtc_ice, "agent", &agent, NULL);
+  g_assert (agent != NULL);
+
+  sockets =
+      nice_agent_get_sockets (agent,
+      GST_WEBRTC_ICE_STREAM (nice->stream)->stream_id, 1);
+  if (sockets == NULL) {
+    g_object_unref (agent);
+    gst_object_unref (webrtc_ice);
+    return;
+  }
+
+  for (i = 0; i < sockets->len; i++) {
+    GSocket *gsocket = g_ptr_array_index (sockets, i);
+#ifdef SO_SNDBUF
+    if (nice->priv->send_buffer_size != 0) {
+      GError *gerror = NULL;
+      if (!g_socket_set_option (gsocket, SOL_SOCKET, SO_SNDBUF,
+              nice->priv->send_buffer_size, &gerror))
+        GST_WARNING_OBJECT (nice, "Could not set send buffer size : %s",
+            gerror->message);
+      g_clear_error (&gerror);
+    }
+#endif
+#ifdef SO_RCVBUF
+    if (nice->priv->receive_buffer_size != 0) {
+      GError *gerror = NULL;
+      if (!g_socket_set_option (gsocket, SOL_SOCKET, SO_RCVBUF,
+              nice->priv->receive_buffer_size, &gerror))
+        GST_WARNING_OBJECT (nice, "Could not set send receive size : %s",
+            gerror->message);
+      g_clear_error (&gerror);
+    }
+#endif
+  }
+  g_ptr_array_unref (sockets);
+  g_object_unref (agent);
+  gst_object_unref (webrtc_ice);
+}
+
+
+static void
+_on_new_selected_pair (NiceAgent * agent, guint stream_id,
+    NiceComponentType component, NiceCandidate * lcandidate,
+    NiceCandidate * rcandidate, GWeakRef * nice_weak)
+{
+  GstWebRTCNiceTransport *nice = g_weak_ref_get (nice_weak);
+  GstWebRTCICETransport *ice;
+  GstWebRTCICEComponent comp = _nice_component_to_gst (component);
+  guint our_stream_id;
+
+  if (!nice)
+    return;
+
+  ice = GST_WEBRTC_ICE_TRANSPORT (nice);
+
+  g_object_get (nice->stream, "stream-id", &our_stream_id, NULL);
+
+  if (stream_id != our_stream_id)
+    goto cleanup;
+  if (comp != ice->component)
+    goto cleanup;
+
+  gst_webrtc_ice_transport_selected_pair_change (ice);
+
+cleanup:
+  gst_object_unref (nice);
+}
+
+static void
+_on_component_state_changed (NiceAgent * agent, guint stream_id,
+    NiceComponentType component, NiceComponentState state, GWeakRef * nice_weak)
+{
+  GstWebRTCNiceTransport *nice = g_weak_ref_get (nice_weak);
+  GstWebRTCICETransport *ice;
+  GstWebRTCICEComponent comp = _nice_component_to_gst (component);
+  guint our_stream_id;
+
+  if (!nice)
+    return;
+
+  ice = GST_WEBRTC_ICE_TRANSPORT (nice);
+
+  g_object_get (nice->stream, "stream-id", &our_stream_id, NULL);
+
+  if (stream_id != our_stream_id)
+    goto cleanup;
+  if (comp != ice->component)
+    goto cleanup;
+
+  GST_DEBUG_OBJECT (ice, "%u %u %s", stream_id, component,
+      nice_component_state_to_string (state));
+
+  gst_webrtc_ice_transport_connection_state_change (ice,
+      _nice_component_state_to_gst (state));
+
+cleanup:
+  gst_object_unref (nice);
+}
+
+static GWeakRef *
+weak_new (GstWebRTCNiceTransport * nice)
+{
+  GWeakRef *weak = g_new0 (GWeakRef, 1);
+  g_weak_ref_init (weak, nice);
+  return weak;
+}
+
+static void
+weak_free (GWeakRef * weak)
+{
+  g_weak_ref_clear (weak);
+  g_free (weak);
+}
+
+static void
+gst_webrtc_nice_transport_constructed (GObject * object)
+{
+  GstWebRTCNiceTransport *nice;
+  GstWebRTCICETransport *ice;
+  NiceComponentType component;
+  gboolean controlling_mode;
+  guint our_stream_id;
+  NiceAgent *agent;
+  GstWebRTCNice *webrtc_ice = NULL;
+
+  G_OBJECT_CLASS (parent_class)->constructed (object);
+
+  nice = GST_WEBRTC_NICE_TRANSPORT (object);
+  ice = GST_WEBRTC_ICE_TRANSPORT (object);
+  component = _gst_component_to_nice (ice->component);
+
+  g_object_get (nice->stream, "ice", &webrtc_ice, "stream-id", &our_stream_id,
+      NULL);
+  g_assert (webrtc_ice != NULL);
+  g_object_get (webrtc_ice, "agent", &agent, NULL);
+
+  g_object_get (agent, "controlling-mode", &controlling_mode, NULL);
+  ice->role =
+      controlling_mode ? GST_WEBRTC_ICE_ROLE_CONTROLLING :
+      GST_WEBRTC_ICE_ROLE_CONTROLLED;
+
+  nice->priv->on_component_state_changed_id = g_signal_connect_data (agent,
+      "component-state-changed", G_CALLBACK (_on_component_state_changed),
+      weak_new (nice), (GClosureNotify) weak_free, (GConnectFlags) 0);
+  nice->priv->on_new_selected_pair_id = g_signal_connect_data (agent,
+      "new-selected-pair-full", G_CALLBACK (_on_new_selected_pair),
+      weak_new (nice), (GClosureNotify) weak_free, (GConnectFlags) 0);
+
+  ice->src = gst_element_factory_make ("nicesrc", NULL);
+  if (ice->src) {
+    g_object_set (ice->src, "agent", agent, "stream", our_stream_id,
+        "component", component, NULL);
+  }
+  ice->sink = gst_element_factory_make ("nicesink", NULL);
+  if (ice->sink) {
+    g_object_set (ice->sink, "agent", agent, "stream", our_stream_id,
+        "component", component, "async", FALSE, "enable-last-sample", FALSE,
+        "sync", FALSE, NULL);
+  }
+
+  g_object_unref (agent);
+  gst_object_unref (webrtc_ice);
+}
+
+static void
+gst_webrtc_nice_transport_class_init (GstWebRTCNiceTransportClass * klass)
+{
+  GObjectClass *gobject_class = (GObjectClass *) klass;
+
+  gobject_class->constructed = gst_webrtc_nice_transport_constructed;
+  gobject_class->get_property = gst_webrtc_nice_transport_get_property;
+  gobject_class->set_property = gst_webrtc_nice_transport_set_property;
+  gobject_class->finalize = gst_webrtc_nice_transport_finalize;
+
+  g_object_class_install_property (gobject_class,
+      PROP_STREAM,
+      g_param_spec_object ("stream",
+          "WebRTC ICE Stream", "ICE stream associated with this transport",
+          GST_TYPE_WEBRTC_NICE_STREAM,
+          G_PARAM_READWRITE | G_PARAM_CONSTRUCT_ONLY | G_PARAM_STATIC_STRINGS));
+
+  /**
+   * GstWebRTCNiceTransport:send-buffer-size:
+   *
+   * Size of the kernel send buffer in bytes, 0=default
+   *
+   * Since: 1.20
+   */
+
+  g_object_class_install_property (G_OBJECT_CLASS (klass),
+      PROP_SEND_BUFFER_SIZE, g_param_spec_int ("send-buffer-size",
+          "Send Buffer Size",
+          "Size of the kernel send buffer in bytes, 0=default", 0, G_MAXINT, 0,
+          G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+  /**
+   * GstWebRTCNiceTransport:receive-buffer-size:
+   *
+   * Size of the kernel receive buffer in bytes, 0=default
+   *
+   * Since: 1.20
+   */
+
+  g_object_class_install_property (G_OBJECT_CLASS (klass),
+      PROP_RECEIVE_BUFFER_SIZE, g_param_spec_int ("receive-buffer-size",
+          "Receive Buffer Size",
+          "Size of the kernel receive buffer in bytes, 0=default", 0, G_MAXINT,
+          0, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+}
+
+static void
+gst_webrtc_nice_transport_init (GstWebRTCNiceTransport * nice)
+{
+  nice->priv = gst_webrtc_nice_transport_get_instance_private (nice);
+}
+
+GstWebRTCNiceTransport *
+gst_webrtc_nice_transport_new (GstWebRTCNiceStream * stream,
+    GstWebRTCICEComponent component)
+{
+  return g_object_new (GST_TYPE_WEBRTC_NICE_TRANSPORT, "stream", stream,
+      "component", component, NULL);
+}
diff --git a/gst-libs/gst/webrtc/nice/nicetransport.h b/gst-libs/gst/webrtc/nice/nicetransport.h
new file mode 100644
index 000000000..93263a033
--- /dev/null
+++ b/gst-libs/gst/webrtc/nice/nicetransport.h
@@ -0,0 +1,71 @@
+/* GStreamer
+ * Copyright (C) 2017 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef __GST_WEBRTC_NICE_TRANSPORT_H__
+#define __GST_WEBRTC_NICE_TRANSPORT_H__
+
+#include "nice.h"
+#include "gst/webrtc/icetransport.h"
+/* libnice */
+#include <agent.h>
+
+#include "nice_fwd.h"
+
+G_BEGIN_DECLS
+
+GST_WEBRTCNICE_API
+GType gst_webrtc_nice_transport_get_type(void);
+#define GST_TYPE_WEBRTC_NICE_TRANSPORT            (gst_webrtc_nice_transport_get_type())
+#define GST_WEBRTC_NICE_TRANSPORT(obj)            (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_WEBRTC_NICE_TRANSPORT,GstWebRTCNiceTransport))
+#define GST_IS_WEBRTC_NICE_TRANSPORT(obj)         (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_WEBRTC_NICE_TRANSPORT))
+#define GST_WEBRTC_NICE_TRANSPORT_CLASS(klass)    (G_TYPE_CHECK_CLASS_CAST((klass) ,GST_TYPE_WEBRTC_NICE_TRANSPORT,GstWebRTCNiceTransportClass))
+#define GST_IS_WEBRTC_NICE_TRANSPORT_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE((klass) ,GST_TYPE_WEBRTC_NICE_TRANSPORT))
+#define GST_WEBRTC_NICE_TRANSPORT_GET_CLASS(obj)  (G_TYPE_INSTANCE_GET_CLASS((obj) ,GST_TYPE_WEBRTC_NICE_TRANSPORT,GstWebRTCNiceTransportClass))
+
+/**
+ * GstWebRTCNiceTransport:
+ */
+typedef struct _GstWebRTCNiceTransport GstWebRTCNiceTransport;
+typedef struct _GstWebRTCNiceTransportClass GstWebRTCNiceTransportClass;
+typedef struct _GstWebRTCNiceTransportPrivate GstWebRTCNiceTransportPrivate;
+
+struct _GstWebRTCNiceTransport
+{
+  GstWebRTCICETransport     parent;
+
+  GstWebRTCNiceStream      *stream;
+
+  GstWebRTCNiceTransportPrivate *priv;
+};
+
+struct _GstWebRTCNiceTransportClass
+{
+  GstWebRTCICETransportClass               parent_class;
+};
+
+GstWebRTCNiceTransport * gst_webrtc_nice_transport_new                (GstWebRTCNiceStream * stream,
+                                                                       GstWebRTCICEComponent component);
+
+void                     gst_webrtc_nice_transport_update_buffer_size (GstWebRTCNiceTransport * nice);
+
+G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstWebRTCNiceTransport, gst_object_unref)
+
+G_END_DECLS
+
+#endif /* __GST_WEBRTC_NICE_TRANSPORT_H__ */
diff --git a/gst-libs/gst/webrtc/rtpreceiver.c b/gst-libs/gst/webrtc/rtpreceiver.c
index 768e9876d..4a397ff37 100644
--- a/gst-libs/gst/webrtc/rtpreceiver.c
+++ b/gst-libs/gst/webrtc/rtpreceiver.c
@@ -22,6 +22,8 @@
  * @short_description: RTCRtpReceiver object
  * @title: GstWebRTCRTPReceiver
  * @see_also: #GstWebRTCRTPSender, #GstWebRTCRTPTransceiver
+ * @symbols:
+ * - GstWebRTCRTPReceiver
  *
  * <https://www.w3.org/TR/webrtc/#rtcrtpreceiver-interface>
  */
@@ -31,6 +33,7 @@
 #endif
 
 #include "rtpreceiver.h"
+#include "webrtc-priv.h"
 
 #define GST_CAT_DEFAULT gst_webrtc_rtp_receiver_debug
 GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
@@ -49,36 +52,11 @@ enum
 enum
 {
   PROP_0,
+  PROP_TRANSPORT,
 };
 
 //static guint gst_webrtc_rtp_receiver_signals[LAST_SIGNAL] = { 0 };
 
-void
-gst_webrtc_rtp_receiver_set_transport (GstWebRTCRTPReceiver * receiver,
-    GstWebRTCDTLSTransport * transport)
-{
-  g_return_if_fail (GST_IS_WEBRTC_RTP_RECEIVER (receiver));
-  g_return_if_fail (GST_IS_WEBRTC_DTLS_TRANSPORT (transport));
-
-  GST_OBJECT_LOCK (receiver);
-  gst_object_replace ((GstObject **) & receiver->transport,
-      GST_OBJECT (transport));
-  GST_OBJECT_UNLOCK (receiver);
-}
-
-void
-gst_webrtc_rtp_receiver_set_rtcp_transport (GstWebRTCRTPReceiver * receiver,
-    GstWebRTCDTLSTransport * transport)
-{
-  g_return_if_fail (GST_IS_WEBRTC_RTP_RECEIVER (receiver));
-  g_return_if_fail (GST_IS_WEBRTC_DTLS_TRANSPORT (transport));
-
-  GST_OBJECT_LOCK (receiver);
-  gst_object_replace ((GstObject **) & receiver->rtcp_transport,
-      GST_OBJECT (transport));
-  GST_OBJECT_UNLOCK (receiver);
-}
-
 static void
 gst_webrtc_rtp_receiver_set_property (GObject * object, guint prop_id,
     const GValue * value, GParamSpec * pspec)
@@ -94,7 +72,13 @@ static void
 gst_webrtc_rtp_receiver_get_property (GObject * object, guint prop_id,
     GValue * value, GParamSpec * pspec)
 {
+  GstWebRTCRTPReceiver *receiver = GST_WEBRTC_RTP_RECEIVER (object);
   switch (prop_id) {
+    case PROP_TRANSPORT:
+      GST_OBJECT_LOCK (receiver);
+      g_value_set_object (value, receiver->transport);
+      GST_OBJECT_UNLOCK (receiver);
+      break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
       break;
@@ -110,10 +94,6 @@ gst_webrtc_rtp_receiver_finalize (GObject * object)
     gst_object_unref (webrtc->transport);
   webrtc->transport = NULL;
 
-  if (webrtc->rtcp_transport)
-    gst_object_unref (webrtc->rtcp_transport);
-  webrtc->rtcp_transport = NULL;
-
   G_OBJECT_CLASS (parent_class)->finalize (object);
 }
 
@@ -125,6 +105,20 @@ gst_webrtc_rtp_receiver_class_init (GstWebRTCRTPReceiverClass * klass)
   gobject_class->get_property = gst_webrtc_rtp_receiver_get_property;
   gobject_class->set_property = gst_webrtc_rtp_receiver_set_property;
   gobject_class->finalize = gst_webrtc_rtp_receiver_finalize;
+
+  /**
+   * GstWebRTCRTPReceiver:transport:
+   *
+   * The DTLS transport for this receiver
+   *
+   * Since: 1.20
+   */
+  g_object_class_install_property (gobject_class,
+      PROP_TRANSPORT,
+      g_param_spec_object ("transport", "Transport",
+          "The DTLS transport for this receiver",
+          GST_TYPE_WEBRTC_DTLS_TRANSPORT,
+          G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
 }
 
 static void
diff --git a/gst-libs/gst/webrtc/rtpreceiver.h b/gst-libs/gst/webrtc/rtpreceiver.h
index 55a9a86fd..5f02fda81 100644
--- a/gst-libs/gst/webrtc/rtpreceiver.h
+++ b/gst-libs/gst/webrtc/rtpreceiver.h
@@ -35,36 +35,6 @@ GType gst_webrtc_rtp_receiver_get_type(void);
 #define GST_IS_WEBRTC_RTP_RECEIVER_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE((klass) ,GST_TYPE_WEBRTC_RTP_RECEIVER))
 #define GST_WEBRTC_RTP_RECEIVER_GET_CLASS(obj)  (G_TYPE_INSTANCE_GET_CLASS((obj) ,GST_TYPE_WEBRTC_RTP_RECEIVER,GstWebRTCRTPReceiverClass))
 
-/**
- * GstWebRTCRTPReceiver:
- */
-struct _GstWebRTCRTPReceiver
-{
-  GstObject                          parent;
-
-  /* The MediStreamTrack is represented by the stream and is output into @transport/@rtcp_transport as necessary */
-  GstWebRTCDTLSTransport            *transport;
-  GstWebRTCDTLSTransport            *rtcp_transport;
-
-  gpointer                          _padding[GST_PADDING];
-};
-
-struct _GstWebRTCRTPReceiverClass
-{
-  GstObjectClass            parent_class;
-
-  gpointer                  _padding[GST_PADDING];
-};
-
-GST_WEBRTC_API
-GstWebRTCRTPReceiver *      gst_webrtc_rtp_receiver_new                 (void);
-GST_WEBRTC_API
-void                        gst_webrtc_rtp_receiver_set_transport       (GstWebRTCRTPReceiver * receiver,
-                                                                         GstWebRTCDTLSTransport * transport);
-GST_WEBRTC_API
-void                        gst_webrtc_rtp_receiver_set_rtcp_transport  (GstWebRTCRTPReceiver * receiver,
-                                                                         GstWebRTCDTLSTransport * transport);
-
 G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstWebRTCRTPReceiver, gst_object_unref)
 
 G_END_DECLS
diff --git a/gst-libs/gst/webrtc/rtpsender.c b/gst-libs/gst/webrtc/rtpsender.c
index 3a8a9044f..2a3a96969 100644
--- a/gst-libs/gst/webrtc/rtpsender.c
+++ b/gst-libs/gst/webrtc/rtpsender.c
@@ -22,6 +22,8 @@
  * @short_description: RTCRtpSender object
  * @title: GstWebRTCRTPSender
  * @see_also: #GstWebRTCRTPReceiver, #GstWebRTCRTPTransceiver
+ * @symbols:
+ * - GstWebRTCRTPSender
  *
  * <https://www.w3.org/TR/webrtc/#rtcrtpsender-interface>
  */
@@ -32,6 +34,7 @@
 
 #include "rtpsender.h"
 #include "rtptransceiver.h"
+#include "webrtc-priv.h"
 
 #define GST_CAT_DEFAULT gst_webrtc_rtp_sender_debug
 GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
@@ -51,45 +54,44 @@ enum
 enum
 {
   PROP_0,
-  PROP_MID,
-  PROP_SENDER,
-  PROP_STOPPED,
-  PROP_DIRECTION,
+  PROP_PRIORITY,
+  PROP_TRANSPORT,
 };
 
 //static guint gst_webrtc_rtp_sender_signals[LAST_SIGNAL] = { 0 };
 
-void
-gst_webrtc_rtp_sender_set_transport (GstWebRTCRTPSender * sender,
-    GstWebRTCDTLSTransport * transport)
-{
-  g_return_if_fail (GST_IS_WEBRTC_RTP_SENDER (sender));
-  g_return_if_fail (GST_IS_WEBRTC_DTLS_TRANSPORT (transport));
-
-  GST_OBJECT_LOCK (sender);
-  gst_object_replace ((GstObject **) & sender->transport,
-      GST_OBJECT (transport));
-  GST_OBJECT_UNLOCK (sender);
-}
+/**
+ * gst_webrtc_rtp_sender_set_priority:
+ * @sender: a #GstWebRTCRTPSender
+ * @priority: The priority of this sender
+ *
+ * Sets the content of the IPv4 Type of Service (ToS), also known as DSCP
+ * (Differentiated Services Code Point).
+ * This also sets the Traffic Class field of IPv6.
+ *
+ * Since: 1.20
+ */
 
 void
-gst_webrtc_rtp_sender_set_rtcp_transport (GstWebRTCRTPSender * sender,
-    GstWebRTCDTLSTransport * transport)
+gst_webrtc_rtp_sender_set_priority (GstWebRTCRTPSender * sender,
+    GstWebRTCPriorityType priority)
 {
-  g_return_if_fail (GST_IS_WEBRTC_RTP_SENDER (sender));
-  g_return_if_fail (GST_IS_WEBRTC_DTLS_TRANSPORT (transport));
-
   GST_OBJECT_LOCK (sender);
-  gst_object_replace ((GstObject **) & sender->rtcp_transport,
-      GST_OBJECT (transport));
+  sender->priority = priority;
   GST_OBJECT_UNLOCK (sender);
+  g_object_notify (G_OBJECT (sender), "priority");
 }
 
 static void
 gst_webrtc_rtp_sender_set_property (GObject * object, guint prop_id,
     const GValue * value, GParamSpec * pspec)
 {
+  GstWebRTCRTPSender *sender = GST_WEBRTC_RTP_SENDER (object);
+
   switch (prop_id) {
+    case PROP_PRIORITY:
+      gst_webrtc_rtp_sender_set_priority (sender, g_value_get_uint (value));
+      break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
       break;
@@ -100,7 +102,19 @@ static void
 gst_webrtc_rtp_sender_get_property (GObject * object, guint prop_id,
     GValue * value, GParamSpec * pspec)
 {
+  GstWebRTCRTPSender *sender = GST_WEBRTC_RTP_SENDER (object);
+
   switch (prop_id) {
+    case PROP_PRIORITY:
+      GST_OBJECT_LOCK (sender);
+      g_value_set_uint (value, sender->priority);
+      GST_OBJECT_UNLOCK (sender);
+      break;
+    case PROP_TRANSPORT:
+      GST_OBJECT_LOCK (sender);
+      g_value_set_object (value, sender->transport);
+      GST_OBJECT_UNLOCK (sender);
+      break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
       break;
@@ -110,15 +124,11 @@ gst_webrtc_rtp_sender_get_property (GObject * object, guint prop_id,
 static void
 gst_webrtc_rtp_sender_finalize (GObject * object)
 {
-  GstWebRTCRTPSender *webrtc = GST_WEBRTC_RTP_SENDER (object);
+  GstWebRTCRTPSender *sender = GST_WEBRTC_RTP_SENDER (object);
 
-  if (webrtc->transport)
-    gst_object_unref (webrtc->transport);
-  webrtc->transport = NULL;
-
-  if (webrtc->rtcp_transport)
-    gst_object_unref (webrtc->rtcp_transport);
-  webrtc->rtcp_transport = NULL;
+  if (sender->transport)
+    gst_object_unref (sender->transport);
+  sender->transport = NULL;
 
   G_OBJECT_CLASS (parent_class)->finalize (object);
 }
@@ -131,6 +141,35 @@ gst_webrtc_rtp_sender_class_init (GstWebRTCRTPSenderClass * klass)
   gobject_class->get_property = gst_webrtc_rtp_sender_get_property;
   gobject_class->set_property = gst_webrtc_rtp_sender_set_property;
   gobject_class->finalize = gst_webrtc_rtp_sender_finalize;
+
+  /**
+   * GstWebRTCRTPSender:priority:
+   *
+   * The priority from which to set the DSCP field on packets
+   *
+   * Since: 1.20
+   */
+  g_object_class_install_property (gobject_class,
+      PROP_PRIORITY,
+      g_param_spec_enum ("priority",
+          "Priority",
+          "The priority from which to set the DSCP field on packets",
+          GST_TYPE_WEBRTC_PRIORITY_TYPE, GST_WEBRTC_PRIORITY_TYPE_LOW,
+          G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+  /**
+   * GstWebRTCRTPSender:transport:
+   *
+   * The DTLS transport for this sender
+   *
+   * Since: 1.20
+   */
+  g_object_class_install_property (gobject_class,
+      PROP_TRANSPORT,
+      g_param_spec_object ("transport", "Transport",
+          "The DTLS transport for this sender",
+          GST_TYPE_WEBRTC_DTLS_TRANSPORT,
+          G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
 }
 
 static void
diff --git a/gst-libs/gst/webrtc/rtpsender.h b/gst-libs/gst/webrtc/rtpsender.h
index bcaf93c60..b3ca9a010 100644
--- a/gst-libs/gst/webrtc/rtpsender.h
+++ b/gst-libs/gst/webrtc/rtpsender.h
@@ -35,39 +35,9 @@ GType gst_webrtc_rtp_sender_get_type(void);
 #define GST_IS_WEBRTC_RTP_SENDER_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE((klass) ,GST_TYPE_WEBRTC_RTP_SENDER))
 #define GST_WEBRTC_RTP_SENDER_GET_CLASS(obj)  (G_TYPE_INSTANCE_GET_CLASS((obj) ,GST_TYPE_WEBRTC_RTP_SENDER,GstWebRTCRTPSenderClass))
 
-/**
- * GstWebRTCRTPSender:
- */
-struct _GstWebRTCRTPSender
-{
-  GstObject                          parent;
-
-  /* The MediStreamTrack is represented by the stream and is output into @transport/@rtcp_transport as necessary */
-  GstWebRTCDTLSTransport            *transport;
-  GstWebRTCDTLSTransport            *rtcp_transport;
-
-  GArray                            *send_encodings;
-
-  gpointer                          _padding[GST_PADDING];
-};
-
-struct _GstWebRTCRTPSenderClass
-{
-  GstObjectClass        parent_class;
-
-  gpointer              _padding[GST_PADDING];
-};
-
-GST_WEBRTC_API
-GstWebRTCRTPSender *        gst_webrtc_rtp_sender_new                   (void);
-
 GST_WEBRTC_API
-void                        gst_webrtc_rtp_sender_set_transport         (GstWebRTCRTPSender * sender,
-                                                                         GstWebRTCDTLSTransport * transport);
-GST_WEBRTC_API
-void                        gst_webrtc_rtp_sender_set_rtcp_transport    (GstWebRTCRTPSender * sender,
-                                                                         GstWebRTCDTLSTransport * transport);
-
+void                        gst_webrtc_rtp_sender_set_priority          (GstWebRTCRTPSender *sender,
+                                                                         GstWebRTCPriorityType priority);
 
 G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstWebRTCRTPSender, gst_object_unref)
 
diff --git a/gst-libs/gst/webrtc/rtptransceiver.c b/gst-libs/gst/webrtc/rtptransceiver.c
index 08019462a..2db2abd4d 100644
--- a/gst-libs/gst/webrtc/rtptransceiver.c
+++ b/gst-libs/gst/webrtc/rtptransceiver.c
@@ -22,6 +22,8 @@
  * @short_description: RTCRtpTransceiver object
  * @title: GstWebRTCRTPTransceiver
  * @see_also: #GstWebRTCRTPSender, #GstWebRTCRTPReceiver
+ * @symbols:
+ * - GstWebRTCRTPTransceiver
  *
  * <https://www.w3.org/TR/webrtc/#rtcrtptransceiver-interface>
  */
@@ -32,6 +34,8 @@
 
 #include "rtptransceiver.h"
 
+#include "webrtc-priv.h"
+
 #define GST_CAT_DEFAULT gst_webrtc_rtp_transceiver_debug
 GST_DEBUG_CATEGORY_STATIC (GST_CAT_DEFAULT);
 
@@ -51,11 +55,14 @@ enum
 enum
 {
   PROP_0,
-  PROP_MID,
   PROP_SENDER,
   PROP_RECEIVER,
   PROP_DIRECTION,
   PROP_MLINE,
+  PROP_MID,
+  PROP_CURRENT_DIRECTION,
+  PROP_KIND,
+  PROP_CODEC_PREFERENCES,
   PROP_STOPPED,                 // FIXME
 };
 
@@ -78,7 +85,14 @@ gst_webrtc_rtp_transceiver_set_property (GObject * object, guint prop_id,
       webrtc->mline = g_value_get_uint (value);
       break;
     case PROP_DIRECTION:
+      GST_OBJECT_LOCK (webrtc);
       webrtc->direction = g_value_get_enum (value);
+      GST_OBJECT_UNLOCK (webrtc);
+      break;
+    case PROP_CODEC_PREFERENCES:
+      GST_OBJECT_LOCK (webrtc);
+      gst_caps_replace (&webrtc->codec_preferences, g_value_get_boxed (value));
+      GST_OBJECT_UNLOCK (webrtc);
       break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
@@ -93,6 +107,9 @@ gst_webrtc_rtp_transceiver_get_property (GObject * object, guint prop_id,
   GstWebRTCRTPTransceiver *webrtc = GST_WEBRTC_RTP_TRANSCEIVER (object);
 
   switch (prop_id) {
+    case PROP_MID:
+      g_value_set_string (value, webrtc->mid);
+      break;
     case PROP_SENDER:
       g_value_set_object (value, webrtc->sender);
       break;
@@ -103,7 +120,20 @@ gst_webrtc_rtp_transceiver_get_property (GObject * object, guint prop_id,
       g_value_set_uint (value, webrtc->mline);
       break;
     case PROP_DIRECTION:
+      GST_OBJECT_LOCK (webrtc);
       g_value_set_enum (value, webrtc->direction);
+      GST_OBJECT_UNLOCK (webrtc);
+      break;
+    case PROP_CURRENT_DIRECTION:
+      g_value_set_enum (value, webrtc->current_direction);
+      break;
+    case PROP_KIND:
+      g_value_set_enum (value, webrtc->kind);
+      break;
+    case PROP_CODEC_PREFERENCES:
+      GST_OBJECT_LOCK (webrtc);
+      gst_value_set_caps (value, webrtc->codec_preferences);
+      GST_OBJECT_UNLOCK (webrtc);
       break;
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
@@ -199,6 +229,73 @@ gst_webrtc_rtp_transceiver_class_init (GstWebRTCRTPTransceiverClass * klass)
           GST_TYPE_WEBRTC_RTP_TRANSCEIVER_DIRECTION,
           GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_NONE,
           G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+  /**
+   * GstWebRTCRTPTransceiver:mid:
+   *
+   * The media ID of the m-line associated with this transceiver. This
+   * association is established, when possible, whenever either a
+   * local or remote description is applied. This field is null if
+   * neither a local or remote description has been applied, or if its
+   * associated m-line is rejected by either a remote offer or any
+   * answer.
+   *
+   * Since: 1.20
+   */
+  g_object_class_install_property (gobject_class,
+      PROP_MID,
+      g_param_spec_string ("mid", "Media ID",
+          "The media ID of the m-line associated with this transceiver. This "
+          " association is established, when possible, whenever either a local"
+          " or remote description is applied. This field is null if neither a"
+          " local or remote description has been applied, or if its associated"
+          " m-line is rejected by either a remote offer or any answer.",
+          NULL, G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
+
+  /**
+   * GstWebRTCRTPTransceiver:current-direction:
+   *
+   * The transceiver's current directionality, or none if the
+   * transceiver is stopped or has never participated in an exchange
+   * of offers and answers. To change the transceiver's
+   * directionality, set the value of the direction property.
+   *
+   * Since: 1.20
+   **/
+  g_object_class_install_property (gobject_class,
+      PROP_DIRECTION,
+      g_param_spec_enum ("current-direction", "Current Direction",
+          "Transceiver current direction",
+          GST_TYPE_WEBRTC_RTP_TRANSCEIVER_DIRECTION,
+          GST_WEBRTC_RTP_TRANSCEIVER_DIRECTION_NONE,
+          G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
+
+  /**
+   * GstWebRTCRTPTransceiver:kind:
+   *
+   * The kind of media this transceiver transports
+   *
+   * Since: 1.20
+   **/
+  g_object_class_install_property (gobject_class,
+      PROP_KIND,
+      g_param_spec_enum ("kind", "Media Kind",
+          "Kind of media this transceiver transports",
+          GST_TYPE_WEBRTC_KIND, GST_WEBRTC_KIND_UNKNOWN,
+          G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
+
+  /**
+   * GstWebRTCRTPTransceiver:codec-preferences:
+   *
+   * Caps representing the codec preferences.
+   *
+   * Since: 1.20
+   **/
+  g_object_class_install_property (gobject_class,
+      PROP_CODEC_PREFERENCES,
+      g_param_spec_boxed ("codec-preferences", "Codec Preferences",
+          "Caps representing the codec preferences.",
+          GST_TYPE_CAPS, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
 }
 
 static void
diff --git a/gst-libs/gst/webrtc/rtptransceiver.h b/gst-libs/gst/webrtc/rtptransceiver.h
index 4b2e6e30c..569a39a46 100644
--- a/gst-libs/gst/webrtc/rtptransceiver.h
+++ b/gst-libs/gst/webrtc/rtptransceiver.h
@@ -22,8 +22,6 @@
 
 #include <gst/gst.h>
 #include <gst/webrtc/webrtc_fwd.h>
-#include <gst/webrtc/rtpsender.h>
-#include <gst/webrtc/rtpreceiver.h>
 
 G_BEGIN_DECLS
 
@@ -36,35 +34,6 @@ GType gst_webrtc_rtp_transceiver_get_type(void);
 #define GST_IS_WEBRTC_RTP_TRANSCEIVER_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE((klass) ,GST_TYPE_WEBRTC_RTP_TRANSCEIVER))
 #define GST_WEBRTC_RTP_TRANSCEIVER_GET_CLASS(obj)  (G_TYPE_INSTANCE_GET_CLASS((obj) ,GST_TYPE_WEBRTC_RTP_TRANSCEIVER,GstWebRTCRTPTransceiverClass))
 
-/**
- * GstWebRTCRTPTransceiver:
- */
-struct _GstWebRTCRTPTransceiver
-{
-  GstObject                         parent;
-  guint                             mline;
-  gchar                            *mid;
-  gboolean                          stopped;
-
-  GstWebRTCRTPSender               *sender;
-  GstWebRTCRTPReceiver             *receiver;
-
-  GstWebRTCRTPTransceiverDirection  direction;
-  GstWebRTCRTPTransceiverDirection  current_direction;
-
-  GstCaps                          *codec_preferences;
-
-  gpointer                          _padding[GST_PADDING];
-};
-
-struct _GstWebRTCRTPTransceiverClass
-{
-  GstObjectClass        parent_class;
-
-  /* FIXME; reset */
-  gpointer              _padding[GST_PADDING];
-};
-
 G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstWebRTCRTPTransceiver, gst_object_unref)
 
 G_END_DECLS
diff --git a/gst-libs/gst/webrtc/sctptransport.c b/gst-libs/gst/webrtc/sctptransport.c
new file mode 100644
index 000000000..4d0495a46
--- /dev/null
+++ b/gst-libs/gst/webrtc/sctptransport.c
@@ -0,0 +1,79 @@
+/* GStreamer
+ * Copyright (C) 2018 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "sctptransport.h"
+#include "webrtc-priv.h"
+
+G_DEFINE_ABSTRACT_TYPE (GstWebRTCSCTPTransport, gst_webrtc_sctp_transport,
+    GST_TYPE_OBJECT);
+
+static void
+gst_webrtc_sctp_transport_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  /* all properties should by handled by the plugin class */
+  g_assert_not_reached ();
+}
+
+static void
+gst_webrtc_sctp_transport_class_init (GstWebRTCSCTPTransportClass * klass)
+{
+  GObjectClass *gobject_class = (GObjectClass *) klass;
+  guint property_id_dummy = 0;
+
+  gobject_class->get_property = gst_webrtc_sctp_transport_get_property;
+
+  g_object_class_install_property (gobject_class,
+      ++property_id_dummy,
+      g_param_spec_object ("transport",
+          "WebRTC DTLS Transport",
+          "DTLS transport used for this SCTP transport",
+          GST_TYPE_WEBRTC_DTLS_TRANSPORT,
+          G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
+
+  g_object_class_install_property (gobject_class,
+      ++property_id_dummy,
+      g_param_spec_enum ("state",
+          "WebRTC SCTP Transport state", "WebRTC SCTP Transport state",
+          GST_TYPE_WEBRTC_SCTP_TRANSPORT_STATE,
+          GST_WEBRTC_SCTP_TRANSPORT_STATE_NEW,
+          G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
+
+  g_object_class_install_property (gobject_class,
+      ++property_id_dummy,
+      g_param_spec_uint64 ("max-message-size",
+          "Maximum message size",
+          "Maximum message size as reported by the transport", 0, G_MAXUINT64,
+          0, G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
+
+  g_object_class_install_property (gobject_class,
+      ++property_id_dummy,
+      g_param_spec_uint ("max-channels",
+          "Maximum number of channels", "Maximum number of channels",
+          0, G_MAXUINT16, 0, G_PARAM_READABLE | G_PARAM_STATIC_STRINGS));
+}
+
+static void
+gst_webrtc_sctp_transport_init (GstWebRTCSCTPTransport * nice)
+{
+}
diff --git a/gst-libs/gst/webrtc/sctptransport.h b/gst-libs/gst/webrtc/sctptransport.h
new file mode 100644
index 000000000..99a46eede
--- /dev/null
+++ b/gst-libs/gst/webrtc/sctptransport.h
@@ -0,0 +1,42 @@
+/* GStreamer
+ * Copyright (C) 2018 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef __GST_WEBRTC_SCTP_TRANSPORT_H__
+#define __GST_WEBRTC_SCTP_TRANSPORT_H__
+
+#include <gst/gst.h>
+#include <gst/webrtc/webrtc_fwd.h>
+
+G_BEGIN_DECLS
+
+GST_WEBRTC_API
+GType gst_webrtc_sctp_transport_get_type(void);
+
+#define GST_TYPE_WEBRTC_SCTP_TRANSPORT            (gst_webrtc_sctp_transport_get_type())
+#define GST_WEBRTC_SCTP_TRANSPORT(obj)            (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_WEBRTC_SCTP_TRANSPORT,GstWebRTCSCTPTransport))
+#define GST_IS_WEBRTC_SCTP_TRANSPORT(obj)         (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_WEBRTC_SCTP_TRANSPORT))
+#define GST_WEBRTC_SCTP_TRANSPORT_CLASS(klass)    (G_TYPE_CHECK_CLASS_CAST((klass) ,GST_TYPE_WEBRTC_SCTP_TRANSPORT,GstWebRTCSCTPTransportClass))
+#define GST_IS_WEBRTC_SCTP_TRANSPORT_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE((klass) ,GST_TYPE_WEBRTC_SCTP_TRANSPORT))
+#define GST_WEBRTC_SCTP_TRANSPORT_GET_CLASS(obj)  (G_TYPE_INSTANCE_GET_CLASS((obj) ,GST_TYPE_WEBRTC_SCTP_TRANSPORT,GstWebRTCSCTPTransportClass))
+
+G_DEFINE_AUTOPTR_CLEANUP_FUNC(GstWebRTCSCTPTransport, gst_object_unref)
+
+G_END_DECLS
+
+#endif /* __GST_WEBRTC_SCTP_TRANSPORT_H__ */
diff --git a/gst-libs/gst/webrtc/webrtc-priv.h b/gst-libs/gst/webrtc/webrtc-priv.h
new file mode 100644
index 000000000..67676a38e
--- /dev/null
+++ b/gst-libs/gst/webrtc/webrtc-priv.h
@@ -0,0 +1,274 @@
+/* GStreamer
+ * Copyright (C) 2017 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef __GST_WEBRTC_PRIV_H__
+#define __GST_WEBRTC_PRIV_H__
+
+#include <gst/gst.h>
+#include <gst/webrtc/webrtc_fwd.h>
+#include <gst/webrtc/rtpsender.h>
+#include <gst/webrtc/rtpreceiver.h>
+
+G_BEGIN_DECLS
+
+/**
+ * GstWebRTCRTPTransceiver:
+ * @mline: the mline number this transceiver corresponds to
+ * @mid: The media ID of the m-line associated with this
+ * transceiver. This association is established, when possible,
+ * whenever either a local or remote description is applied. This
+ * field is NULL if neither a local or remote description has been
+ * applied, or if its associated m-line is rejected by either a remote
+ * offer or any answer.
+ * @stopped: Indicates whether or not sending and receiving using the paired
+ * #GstWebRTCRTPSender and #GstWebRTCRTPReceiver has been permanently disabled,
+ * either due to SDP offer/answer
+ * @sender: The #GstWebRTCRTPSender object responsible sending  data to the
+ * remote peer
+ * @receiver: The #GstWebRTCRTPReceiver object responsible for receiver data from
+ * the remote peer.
+ * @direction: The transceiver's desired direction.
+ * @current_direction: The transceiver's current direction (read-only)
+ * @codec_preferences: A caps representing the codec preferences (read-only)
+ * @kind: Type of media (Since: 1.20)
+ *
+ * Mostly matches the WebRTC RTCRtpTransceiver interface.
+ */
+/**
+ * GstWebRTCRTPTransceiver.kind:
+ *
+ * Type of media
+ *
+ * Since: 1.20
+ */
+struct _GstWebRTCRTPTransceiver
+{
+  GstObject                         parent;
+  guint                             mline;
+  gchar                            *mid;
+  gboolean                          stopped;
+
+  GstWebRTCRTPSender               *sender;
+  GstWebRTCRTPReceiver             *receiver;
+
+  GstWebRTCRTPTransceiverDirection  direction;
+  GstWebRTCRTPTransceiverDirection  current_direction;
+
+  GstCaps                          *codec_preferences;
+  GstWebRTCKind                     kind;
+
+  gpointer                          _padding[GST_PADDING];
+};
+
+struct _GstWebRTCRTPTransceiverClass
+{
+  GstObjectClass        parent_class;
+
+  /* FIXME; reset */
+  gpointer              _padding[GST_PADDING];
+};
+
+/**
+ * GstWebRTCRTPSender:
+ * @transport: The transport for RTP packets
+ * @send_encodings: Unused
+ * @priority: The priority of the stream (Since: 1.20)
+ *
+ * An object to track the sending aspect of the stream
+ *
+ * Mostly matches the WebRTC RTCRtpSender interface.
+ */
+/**
+ * GstWebRTCRTPSender.priority:
+ *
+ * The priority of the stream
+ *
+ * Since: 1.20
+ */
+struct _GstWebRTCRTPSender
+{
+  GstObject                          parent;
+
+  /* The MediStreamTrack is represented by the stream and is output into @transport as necessary */
+  GstWebRTCDTLSTransport            *transport;
+
+  GArray                            *send_encodings;
+  GstWebRTCPriorityType              priority;
+
+  gpointer                          _padding[GST_PADDING];
+};
+
+struct _GstWebRTCRTPSenderClass
+{
+  GstObjectClass        parent_class;
+
+  gpointer              _padding[GST_PADDING];
+};
+
+GST_WEBRTC_API
+GstWebRTCRTPSender *        gst_webrtc_rtp_sender_new                   (void);
+
+/**
+ * GstWebRTCRTPReceiver:
+ * @transport: The transport for RTP packets
+ *
+ * An object to track the receiving aspect of the stream
+ *
+ * Mostly matches the WebRTC RTCRtpReceiver interface.
+ */
+struct _GstWebRTCRTPReceiver
+{
+  GstObject                          parent;
+
+  /* The MediStreamTrack is represented by the stream and is output into @transport as necessary */
+  GstWebRTCDTLSTransport            *transport;
+
+  gpointer                          _padding[GST_PADDING];
+};
+
+struct _GstWebRTCRTPReceiverClass
+{
+  GstObjectClass            parent_class;
+
+  gpointer                  _padding[GST_PADDING];
+};
+
+GST_WEBRTC_API
+GstWebRTCRTPReceiver *      gst_webrtc_rtp_receiver_new                 (void);
+
+/**
+ * GstWebRTCDTLSTransport:
+ */
+struct _GstWebRTCDTLSTransport
+{
+  GstObject                          parent;
+
+  GstWebRTCICETransport             *transport;
+  GstWebRTCDTLSTransportState        state;
+
+  gboolean                           client;
+  guint                              session_id;
+  GstElement                        *dtlssrtpenc;
+  GstElement                        *dtlssrtpdec;
+
+  gpointer                          _padding[GST_PADDING];
+};
+
+struct _GstWebRTCDTLSTransportClass
+{
+  GstObjectClass               parent_class;
+
+  gpointer                  _padding[GST_PADDING];
+};
+
+GST_WEBRTC_API
+GstWebRTCDTLSTransport *    gst_webrtc_dtls_transport_new               (guint session_id);
+
+GST_WEBRTC_API
+void                        gst_webrtc_dtls_transport_set_transport     (GstWebRTCDTLSTransport * transport,
+                                                                         GstWebRTCICETransport * ice);
+
+#define GST_WEBRTC_DATA_CHANNEL_LOCK(channel) g_mutex_lock(&((GstWebRTCDataChannel *)(channel))->lock)
+#define GST_WEBRTC_DATA_CHANNEL_UNLOCK(channel) g_mutex_unlock(&((GstWebRTCDataChannel *)(channel))->lock)
+
+/**
+ * GstWebRTCDataChannel:
+ *
+ * Since: 1.18
+ */
+struct _GstWebRTCDataChannel
+{
+  GObject                           parent;
+
+  GMutex                            lock;
+
+  gchar                            *label;
+  gboolean                          ordered;
+  guint                             max_packet_lifetime;
+  guint                             max_retransmits;
+  gchar                            *protocol;
+  gboolean                          negotiated;
+  gint                              id;
+  GstWebRTCPriorityType             priority;
+  GstWebRTCDataChannelState         ready_state;
+  guint64                           buffered_amount;
+  guint64                           buffered_amount_low_threshold;
+
+  gpointer                         _padding[GST_PADDING];
+};
+
+/**
+ * GstWebRTCDataChannelClass:
+ *
+ * Since: 1.18
+ */
+struct _GstWebRTCDataChannelClass
+{
+  GObjectClass        parent_class;
+
+  gboolean          (*send_data)   (GstWebRTCDataChannel * channel, GBytes *data, GError ** error);
+  gboolean          (*send_string) (GstWebRTCDataChannel * channel, const gchar *str, GError ** error);
+  void              (*close)       (GstWebRTCDataChannel * channel);
+
+  gpointer           _padding[GST_PADDING];
+};
+
+GST_WEBRTC_API
+void gst_webrtc_data_channel_on_open (GstWebRTCDataChannel * channel);
+
+GST_WEBRTC_API
+void gst_webrtc_data_channel_on_close (GstWebRTCDataChannel * channel);
+
+GST_WEBRTC_API
+void gst_webrtc_data_channel_on_error (GstWebRTCDataChannel * channel, GError * error);
+
+GST_WEBRTC_API
+void gst_webrtc_data_channel_on_message_data (GstWebRTCDataChannel * channel, GBytes * data);
+
+GST_WEBRTC_API
+void gst_webrtc_data_channel_on_message_string (GstWebRTCDataChannel * channel, const gchar * str);
+
+GST_WEBRTC_API
+void gst_webrtc_data_channel_on_buffered_amount_low (GstWebRTCDataChannel * channel);
+
+
+/**
+ * GstWebRTCSCTPTransport:
+ *
+ * Since: 1.20
+ */
+struct _GstWebRTCSCTPTransport
+{
+  GstObject                     parent;
+};
+
+/**
+ * GstWebRTCSCTPTransportClass:
+ *
+ * Since: 1.20
+ */
+struct _GstWebRTCSCTPTransportClass
+{
+  GstObjectClass                parent_class;
+};
+
+
+G_END_DECLS
+
+#endif /* __GST_WEBRTC_PRIV_H__ */
diff --git a/gst-libs/gst/webrtc/webrtc.c b/gst-libs/gst/webrtc/webrtc.c
new file mode 100644
index 000000000..8040e3832
--- /dev/null
+++ b/gst-libs/gst/webrtc/webrtc.c
@@ -0,0 +1,35 @@
+/* GStreamer
+ * Copyright (C) 2017 Matthew Waters <matthew@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include <gst/webrtc/webrtc_fwd.h>
+
+/**
+ * gst_webrtc_error_quark:
+ *
+ * Since: 1.20
+ */
+GQuark
+gst_webrtc_error_quark (void)
+{
+  return g_quark_from_static_string ("gst-webrtc-error-quark");
+}
diff --git a/gst-libs/gst/webrtc/webrtc.h b/gst-libs/gst/webrtc/webrtc.h
index e68a9dba8..a467bdb92 100644
--- a/gst-libs/gst/webrtc/webrtc.h
+++ b/gst-libs/gst/webrtc/webrtc.h
@@ -24,6 +24,8 @@
 #include <gst/webrtc/webrtc_fwd.h>
 #include <gst/webrtc/webrtc-enumtypes.h>
 #include <gst/webrtc/dtlstransport.h>
+#include <gst/webrtc/ice.h>
+#include <gst/webrtc/icestream.h>
 #include <gst/webrtc/icetransport.h>
 #include <gst/webrtc/rtcsessiondescription.h>
 #include <gst/webrtc/rtpreceiver.h>
diff --git a/gst-libs/gst/webrtc/webrtc_fwd.h b/gst-libs/gst/webrtc/webrtc_fwd.h
index 5c727d234..d3556400a 100644
--- a/gst-libs/gst/webrtc/webrtc_fwd.h
+++ b/gst-libs/gst/webrtc/webrtc_fwd.h
@@ -40,28 +40,98 @@
 # endif
 #endif
 
+/**
+ * GST_WEBRTC_DEPRECATED: (attributes doc.skip=true)
+ */
+/**
+ * GST_WEBRTC_DEPRECATED_FOR: (attributes doc.skip=true)
+ */
+#ifndef GST_DISABLE_DEPRECATED
+#define GST_WEBRTC_DEPRECATED GST_WEBRTC_API
+#define GST_WEBRTC_DEPRECATED_FOR(f) GST_WEBRTC_API
+#else
+#define GST_WEBRTC_DEPRECATED G_DEPRECATED GST_WEBRTC_API
+#define GST_WEBRTC_DEPRECATED_FOR(f) G_DEPRECATED_FOR(f) GST_WEBRTC_API
+#endif
+
 #include <gst/webrtc/webrtc-enumtypes.h>
 
+/**
+ * GstWebRTCDTLSTransport:
+ */
 typedef struct _GstWebRTCDTLSTransport GstWebRTCDTLSTransport;
 typedef struct _GstWebRTCDTLSTransportClass GstWebRTCDTLSTransportClass;
 
+/**
+ * GstWebRTCICE:
+ *
+ * Since: 1.22
+ */
+typedef struct _GstWebRTCICE GstWebRTCICE;
+typedef struct _GstWebRTCICEClass GstWebRTCICEClass;
+
+/**
+ * GstWebRTCICECandidateStats:
+ *
+ * Since: 1.22
+ */
+typedef struct _GstWebRTCICECandidateStats GstWebRTCICECandidateStats;
+
+/**
+ * GstWebRTCICEStream:
+ *
+ * Since: 1.22
+ */
+typedef struct _GstWebRTCICEStream GstWebRTCICEStream;
+typedef struct _GstWebRTCICEStreamClass GstWebRTCICEStreamClass;
+
+/**
+ * GstWebRTCICETransport:
+ */
 typedef struct _GstWebRTCICETransport GstWebRTCICETransport;
 typedef struct _GstWebRTCICETransportClass GstWebRTCICETransportClass;
 
+/**
+ * GstWebRTCRTPReceiver:
+ *
+ * An object to track the receiving aspect of the stream
+ *
+ * Mostly matches the WebRTC RTCRtpReceiver interface.
+ */
 typedef struct _GstWebRTCRTPReceiver GstWebRTCRTPReceiver;
 typedef struct _GstWebRTCRTPReceiverClass GstWebRTCRTPReceiverClass;
 
+/**
+ * GstWebRTCRTPSender:
+ *
+ * An object to track the sending aspect of the stream
+ *
+ * Mostly matches the WebRTC RTCRtpSender interface.
+ */
 typedef struct _GstWebRTCRTPSender GstWebRTCRTPSender;
 typedef struct _GstWebRTCRTPSenderClass GstWebRTCRTPSenderClass;
 
 typedef struct _GstWebRTCSessionDescription GstWebRTCSessionDescription;
 
+/**
+ * GstWebRTCRTPTransceiver:
+ *
+ * Mostly matches the WebRTC RTCRtpTransceiver interface.
+ */
 typedef struct _GstWebRTCRTPTransceiver GstWebRTCRTPTransceiver;
 typedef struct _GstWebRTCRTPTransceiverClass GstWebRTCRTPTransceiverClass;
 
+/**
+ * GstWebRTCDataChannel:
+ *
+ * Since: 1.18
+ */
 typedef struct _GstWebRTCDataChannel GstWebRTCDataChannel;
 typedef struct _GstWebRTCDataChannelClass GstWebRTCDataChannelClass;
 
+typedef struct _GstWebRTCSCTPTransport GstWebRTCSCTPTransport;
+typedef struct _GstWebRTCSCTPTransportClass GstWebRTCSCTPTransportClass;
+
 /**
  * GstWebRTCDTLSTransportState:
  * @GST_WEBRTC_DTLS_TRANSPORT_STATE_NEW: new
@@ -238,7 +308,7 @@ typedef enum /*< underscore_name=gst_webrtc_dtls_setup >*/
  * @GST_WEBRTC_STATS_REMOTE_INBOUND_RTP: remote-inbound-rtp
  * @GST_WEBRTC_STATS_REMOTE_OUTBOUND_RTP: remote-outbound-rtp
  * @GST_WEBRTC_STATS_CSRC: csrc
- * @GST_WEBRTC_STATS_PEER_CONNECTION: peer-connectiion
+ * @GST_WEBRTC_STATS_PEER_CONNECTION: peer-connection
  * @GST_WEBRTC_STATS_DATA_CHANNEL: data-channel
  * @GST_WEBRTC_STATS_STREAM: stream
  * @GST_WEBRTC_STATS_TRANSPORT: transport
@@ -246,6 +316,8 @@ typedef enum /*< underscore_name=gst_webrtc_dtls_setup >*/
  * @GST_WEBRTC_STATS_LOCAL_CANDIDATE: local-candidate
  * @GST_WEBRTC_STATS_REMOTE_CANDIDATE: remote-candidate
  * @GST_WEBRTC_STATS_CERTIFICATE: certificate
+ *
+ * See <https://w3c.github.io/webrtc-stats/#dom-rtcstatstype>
  */
 typedef enum /*< underscore_name=gst_webrtc_stats_type >*/
 {
@@ -280,10 +352,10 @@ typedef enum /*< underscore_name=gst_webrtc_fec_type >*/
 
 /**
  * GstWebRTCSCTPTransportState:
- * GST_WEBRTC_SCTP_TRANSPORT_STATE_NEW: new
- * GST_WEBRTC_SCTP_TRANSPORT_STATE_CONNECTING: connecting
- * GST_WEBRTC_SCTP_TRANSPORT_STATE_CONNECTED: connected
- * GST_WEBRTC_SCTP_TRANSPORT_STATE_CLOSED: closed
+ * @GST_WEBRTC_SCTP_TRANSPORT_STATE_NEW: new
+ * @GST_WEBRTC_SCTP_TRANSPORT_STATE_CONNECTING: connecting
+ * @GST_WEBRTC_SCTP_TRANSPORT_STATE_CONNECTED: connected
+ * @GST_WEBRTC_SCTP_TRANSPORT_STATE_CLOSED: closed
  *
  * See <http://w3c.github.io/webrtc-pc/#dom-rtcsctptransportstate>
  *
@@ -299,10 +371,10 @@ typedef enum /*< underscore_name=gst_webrtc_sctp_transport_state >*/
 
 /**
  * GstWebRTCPriorityType:
- * GST_WEBRTC_PRIORITY_TYPE_VERY_LOW: very-low
- * GST_WEBRTC_PRIORITY_TYPE_LOW: low
- * GST_WEBRTC_PRIORITY_TYPE_MEDIUM: medium
- * GST_WEBRTC_PRIORITY_TYPE_HIGH: high
+ * @GST_WEBRTC_PRIORITY_TYPE_VERY_LOW: very-low
+ * @GST_WEBRTC_PRIORITY_TYPE_LOW: low
+ * @GST_WEBRTC_PRIORITY_TYPE_MEDIUM: medium
+ * @GST_WEBRTC_PRIORITY_TYPE_HIGH: high
  *
  * See <http://w3c.github.io/webrtc-pc/#dom-rtcprioritytype>
  *
@@ -318,11 +390,10 @@ typedef enum /*< underscore_name=gst_webrtc_priority_type >*/
 
 /**
  * GstWebRTCDataChannelState:
- * GST_WEBRTC_DATA_CHANNEL_STATE_NEW: new
- * GST_WEBRTC_DATA_CHANNEL_STATE_CONNECTING: connection
- * GST_WEBRTC_DATA_CHANNEL_STATE_OPEN: open
- * GST_WEBRTC_DATA_CHANNEL_STATE_CLOSING: closing
- * GST_WEBRTC_DATA_CHANNEL_STATE_CLOSED: closed
+ * @GST_WEBRTC_DATA_CHANNEL_STATE_CONNECTING: connecting
+ * @GST_WEBRTC_DATA_CHANNEL_STATE_OPEN: open
+ * @GST_WEBRTC_DATA_CHANNEL_STATE_CLOSING: closing
+ * @GST_WEBRTC_DATA_CHANNEL_STATE_CLOSED: closed
  *
  * See <http://w3c.github.io/webrtc-pc/#dom-rtcdatachannelstate>
  *
@@ -330,8 +401,7 @@ typedef enum /*< underscore_name=gst_webrtc_priority_type >*/
  */
 typedef enum /*< underscore_name=gst_webrtc_data_channel_state >*/
 {
-  GST_WEBRTC_DATA_CHANNEL_STATE_NEW,
-  GST_WEBRTC_DATA_CHANNEL_STATE_CONNECTING,
+  GST_WEBRTC_DATA_CHANNEL_STATE_CONNECTING = 1,
   GST_WEBRTC_DATA_CHANNEL_STATE_OPEN,
   GST_WEBRTC_DATA_CHANNEL_STATE_CLOSING,
   GST_WEBRTC_DATA_CHANNEL_STATE_CLOSED,
@@ -339,10 +409,10 @@ typedef enum /*< underscore_name=gst_webrtc_data_channel_state >*/
 
 /**
  * GstWebRTCBundlePolicy:
- * GST_WEBRTC_BUNDLE_POLICY_NONE: none
- * GST_WEBRTC_BUNDLE_POLICY_BALANCED: balanced
- * GST_WEBRTC_BUNDLE_POLICY_MAX_COMPAT: max-compat
- * GST_WEBRTC_BUNDLE_POLICY_MAX_BUNDLE: max-bundle
+ * @GST_WEBRTC_BUNDLE_POLICY_NONE: none
+ * @GST_WEBRTC_BUNDLE_POLICY_BALANCED: balanced
+ * @GST_WEBRTC_BUNDLE_POLICY_MAX_COMPAT: max-compat
+ * @GST_WEBRTC_BUNDLE_POLICY_MAX_BUNDLE: max-bundle
  *
  * See https://tools.ietf.org/html/draft-ietf-rtcweb-jsep-24#section-4.1.1
  * for more information.
@@ -359,8 +429,8 @@ typedef enum /*<underscore_name=gst_webrtc_bundle_policy>*/
 
 /**
  * GstWebRTCICETransportPolicy:
- * GST_WEBRTC_ICE_TRANSPORT_POLICY_ALL: all
- * GST_WEBRTC_ICE_TRANSPORT_POLICY_RELAY: relay
+ * @GST_WEBRTC_ICE_TRANSPORT_POLICY_ALL: all
+ * @GST_WEBRTC_ICE_TRANSPORT_POLICY_RELAY: relay
  *
  * See https://tools.ietf.org/html/draft-ietf-rtcweb-jsep-24#section-4.1.1
  * for more information.
@@ -373,4 +443,77 @@ typedef enum /*<underscore_name=gst_webrtc_ice_transport_policy>*/
   GST_WEBRTC_ICE_TRANSPORT_POLICY_RELAY,
 } GstWebRTCICETransportPolicy;
 
+/**
+ * GstWebRTCKind:
+ * @GST_WEBRTC_KIND_UNKNOWN: Kind has not yet been set
+ * @GST_WEBRTC_KIND_AUDIO: Kind is audio
+ * @GST_WEBRTC_KIND_VIDEO: Kind is audio
+ *
+ * https://w3c.github.io/mediacapture-main/#dom-mediastreamtrack-kind
+ *
+ * Since: 1.20
+ */
+typedef enum /*<underscore_name=gst_webrtc_kind>*/
+{
+  GST_WEBRTC_KIND_UNKNOWN,
+  GST_WEBRTC_KIND_AUDIO,
+  GST_WEBRTC_KIND_VIDEO,
+} GstWebRTCKind;
+
+
+GST_WEBRTC_API
+GQuark gst_webrtc_error_quark (void);
+
+/**
+ * GST_WEBRTC_ERROR:
+ *
+ * Since: 1.20
+ */
+#define GST_WEBRTC_ERROR gst_webrtc_error_quark ()
+
+/**
+ * GstWebRTCError:
+ * @GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE: data-channel-failure
+ * @GST_WEBRTC_ERROR_DTLS_FAILURE: dtls-failure
+ * @GST_WEBRTC_ERROR_FINGERPRINT_FAILURE: fingerprint-failure
+ * @GST_WEBRTC_ERROR_SCTP_FAILURE: sctp-failure
+ * @GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR: sdp-syntax-error
+ * @GST_WEBRTC_ERROR_HARDWARE_ENCODER_NOT_AVAILABLE: hardware-encoder-not-available
+ * @GST_WEBRTC_ERROR_ENCODER_ERROR: encoder-error
+ * @GST_WEBRTC_ERROR_INVALID_STATE: invalid-state (part of WebIDL specification)
+ * @GST_WEBRTC_ERROR_INTERNAL_FAILURE: GStreamer-specific failure, not matching any other value from the specification
+ *
+ * See <https://www.w3.org/TR/webrtc/#dom-rtcerrordetailtype> for more information.
+ *
+ * Since: 1.20
+ */
+/**
+ * GST_WEBRTC_ERROR_INVALID_MODIFICATION:
+ *
+ * invalid-modification (part of WebIDL specification)
+ *
+ * Since: 1.22
+ */
+/**
+ * GST_WEBRTC_ERROR_TYPE_ERROR:
+ *
+ * type-error (maps to JavaScript TypeError)
+ *
+ * Since: 1.22
+ */
+typedef enum /*<underscore_name=gst_webrtc_error>*/
+{
+  GST_WEBRTC_ERROR_DATA_CHANNEL_FAILURE,
+  GST_WEBRTC_ERROR_DTLS_FAILURE,
+  GST_WEBRTC_ERROR_FINGERPRINT_FAILURE,
+  GST_WEBRTC_ERROR_SCTP_FAILURE,
+  GST_WEBRTC_ERROR_SDP_SYNTAX_ERROR,
+  GST_WEBRTC_ERROR_HARDWARE_ENCODER_NOT_AVAILABLE,
+  GST_WEBRTC_ERROR_ENCODER_ERROR,
+  GST_WEBRTC_ERROR_INVALID_STATE,
+  GST_WEBRTC_ERROR_INTERNAL_FAILURE,
+  GST_WEBRTC_ERROR_INVALID_MODIFICATION,
+  GST_WEBRTC_ERROR_TYPE_ERROR,
+} GstWebRTCError;
+
 #endif /* __GST_WEBRTC_FWD_H__ */
diff --git a/gst/videoparsers/gstav1parse.c b/gst/videoparsers/gstav1parse.c
new file mode 100644
index 000000000..923bc5d70
--- /dev/null
+++ b/gst/videoparsers/gstav1parse.c
@@ -0,0 +1,2135 @@
+/* GStreamer
+ * Copyright (C) 2020 He Junyan <junyan.he@intel.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+/*
+ * SECTION:element-av1parse
+ * @title: av1parse
+ * @short_description: An AV1 stream parse.
+ *
+ * The minimal unit should be the BYTE.
+ * There are four types of AV1 alignment in the AV1 stream.
+ *
+ * alignment: byte, obu, frame, tu
+ *
+ * 1. Aligned to byte. The basic and default one for input.
+ * 2. Aligned to obu(Open Bitstream Units).
+ * 3. Aligned to frame. The default one for output. This ensures that
+ *    each buffer contains only one frame or frame header with the
+ *    show_existing flag for the base or sub layer. It is useful for
+ *    the decoder.
+ * 4. Aligned to tu(Temporal Unit). A temporal unit consists of all the
+ *    OBUs that are associated with a specific, distinct time instant.
+ *    When scalability is disabled, it contains just exact one showing
+ *    frame(may contain several unshowing frames). When scalability is
+ *    enabled, it contains frames depending on the layer number. It should
+ *    begin with a temporal delimiter obu. It may be useful for mux/demux
+ *    to index the data of some timestamp.
+ *
+ * The annex B define a special format for the temporal unit. The size of
+ * each temporal unit is extract out to the header of the buffer, and no
+ * size field inside the each obu. There are two stream formats:
+ *
+ * stream-format: obu-stream, annexb
+ *
+ * 1. obu-stream. The basic and default one.
+ * 2. annexb. A special stream of temporal unit. It also implies that the
+ *    alignment should be TU.
+ *
+ * This AV1 parse implements the conversion between the alignments and the
+ * stream-formats. If the input and output have the same alignment and the
+ * same stream-format, it will check and bypass the data.
+ *
+ * ## Example launch line to generate annex B format AV1 stream:
+ * ```
+ * gst-launch-1.0 filesrc location=sample.av1 ! ivfparse ! av1parse !  \
+ *   video/x-av1,alignment=\(string\)tu,stream-format=\(string\)annexb ! \
+ *   filesink location=matroskamux ! filesink location=trans.mkv
+ * ```
+ *
+ * Since: 1.20
+ */
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include <gst/base/gstbitreader.h>
+#include <gst/base/gstbitwriter.h>
+#include <gst/codecparsers/gstav1parser.h>
+#include <gst/video/video.h>
+#include "gstvideoparserselements.h"
+#include "gstav1parse.h"
+
+#include <string.h>
+
+#define GST_AV1_MAX_LEB_128_SIZE 8
+
+GST_DEBUG_CATEGORY (av1_parse_debug);
+#define GST_CAT_DEFAULT av1_parse_debug
+
+/* We combine the stream format and the alignment
+   together. When stream format is annexb, the
+   alignment must be TU. */
+typedef enum
+{
+  GST_AV1_PARSE_ALIGN_ERROR = -1,
+  GST_AV1_PARSE_ALIGN_NONE = 0,
+  GST_AV1_PARSE_ALIGN_BYTE,
+  GST_AV1_PARSE_ALIGN_OBU,
+  GST_AV1_PARSE_ALIGN_FRAME,
+  GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT,
+  GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B,
+} GstAV1ParseAligment;
+
+struct _GstAV1Parse
+{
+  GstBaseParse parent;
+
+  gint width;
+  gint height;
+  gint subsampling_x;
+  gint subsampling_y;
+  gboolean mono_chrome;
+  guint8 bit_depth;
+  gchar *colorimetry;
+  GstAV1Profile profile;
+
+  GstAV1ParseAligment in_align;
+  gboolean detect_annex_b;
+  GstAV1ParseAligment align;
+
+  GstAV1Parser *parser;
+  GstAdapter *cache_out;
+  guint last_parsed_offset;
+  GstAdapter *frame_cache;
+  guint highest_spatial_id;
+  gint last_shown_frame_temporal_id;
+  gint last_shown_frame_spatial_id;
+  gboolean within_one_frame;
+  gboolean update_caps;
+  gboolean discont;
+  gboolean header;
+  gboolean keyframe;
+  gboolean show_frame;
+
+  GstClockTime buffer_pts;
+  GstClockTime buffer_dts;
+  GstClockTime buffer_duration;
+};
+
+static GstStaticPadTemplate sinktemplate = GST_STATIC_PAD_TEMPLATE ("sink",
+    GST_PAD_SINK,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS ("video/x-av1"));
+
+static GstStaticPadTemplate srctemplate = GST_STATIC_PAD_TEMPLATE ("src",
+    GST_PAD_SRC,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS ("video/x-av1, parsed = (boolean) true, "
+        "stream-format=(string) { obu-stream, annexb }, "
+        "alignment=(string) { obu, tu, frame }"));
+
+#define parent_class gst_av1_parse_parent_class
+G_DEFINE_TYPE (GstAV1Parse, gst_av1_parse, GST_TYPE_BASE_PARSE);
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (av1parse, "av1parse", GST_RANK_SECONDARY,
+    GST_TYPE_AV1_PARSE, videoparsers_element_init (plugin));
+
+static void
+remove_fields (GstCaps * caps, gboolean all)
+{
+  guint i, n;
+
+  n = gst_caps_get_size (caps);
+  for (i = 0; i < n; i++) {
+    GstStructure *s = gst_caps_get_structure (caps, i);
+
+    if (all) {
+      gst_structure_remove_field (s, "alignment");
+      gst_structure_remove_field (s, "stream-format");
+    }
+    gst_structure_remove_field (s, "parsed");
+  }
+}
+
+static const gchar *
+_obu_name (GstAV1OBUType type)
+{
+  switch (type) {
+    case GST_AV1_OBU_SEQUENCE_HEADER:
+      return "sequence header";
+    case GST_AV1_OBU_TEMPORAL_DELIMITER:
+      return "temporal delimiter";
+    case GST_AV1_OBU_FRAME_HEADER:
+      return "frame header";
+    case GST_AV1_OBU_TILE_GROUP:
+      return "tile group";
+    case GST_AV1_OBU_METADATA:
+      return "metadata";
+    case GST_AV1_OBU_FRAME:
+      return "frame";
+    case GST_AV1_OBU_REDUNDANT_FRAME_HEADER:
+      return "redundant frame header";
+    case GST_AV1_OBU_TILE_LIST:
+      return "tile list";
+    case GST_AV1_OBU_PADDING:
+      return "padding";
+    default:
+      return "unknown";
+  }
+
+  return NULL;
+}
+
+static guint32
+_read_leb128 (guint8 * data, GstAV1ParserResult * retval, guint32 * comsumed)
+{
+  guint8 leb128_byte = 0;
+  guint64 value = 0;
+  gint i;
+  gboolean result;
+  GstBitReader br;
+  guint32 cur_pos;
+
+  gst_bit_reader_init (&br, data, 8);
+
+  cur_pos = gst_bit_reader_get_pos (&br);
+  for (i = 0; i < 8; i++) {
+    leb128_byte = 0;
+    result = gst_bit_reader_get_bits_uint8 (&br, &leb128_byte, 8);
+    if (result == FALSE) {
+      *retval = GST_AV1_PARSER_BITSTREAM_ERROR;
+      return 0;
+    }
+
+    value |= (((gint) leb128_byte & 0x7f) << (i * 7));
+    if (!(leb128_byte & 0x80))
+      break;
+  }
+
+  *comsumed = (gst_bit_reader_get_pos (&br) - cur_pos) / 8;
+  /* check for bitstream conformance see chapter4.10.5 */
+  if (value < G_MAXUINT32) {
+    *retval = GST_AV1_PARSER_OK;
+    return (guint32) value;
+  } else {
+    GST_WARNING ("invalid leb128");
+    *retval = GST_AV1_PARSER_BITSTREAM_ERROR;
+    return 0;
+  }
+}
+
+static gsize
+_leb_size_in_bytes (guint64 value)
+{
+  gsize size = 0;
+  do {
+    ++size;
+  } while ((value >>= 7) != 0);
+
+  return size;
+}
+
+static gboolean
+_write_leb128 (guint8 * data, guint * len, guint64 value)
+{
+  guint leb_size = _leb_size_in_bytes (value);
+  guint i;
+
+  if (value > G_MAXUINT32 || leb_size > GST_AV1_MAX_LEB_128_SIZE)
+    return FALSE;
+
+  for (i = 0; i < leb_size; ++i) {
+    guint8 byte = value & 0x7f;
+    value >>= 7;
+
+    /* Signal that more bytes follow. */
+    if (value != 0)
+      byte |= 0x80;
+
+    *(data + i) = byte;
+  }
+
+  *len = leb_size;
+  return TRUE;
+}
+
+static gboolean gst_av1_parse_start (GstBaseParse * parse);
+static gboolean gst_av1_parse_stop (GstBaseParse * parse);
+static GstFlowReturn gst_av1_parse_handle_frame (GstBaseParse * parse,
+    GstBaseParseFrame * frame, gint * skipsize);
+static gboolean gst_av1_parse_set_sink_caps (GstBaseParse * parse,
+    GstCaps * caps);
+static GstCaps *gst_av1_parse_get_sink_caps (GstBaseParse * parse,
+    GstCaps * filter);
+static GstFlowReturn gst_av1_parse_pre_push_frame (GstBaseParse * parse,
+    GstBaseParseFrame * frame);
+
+/* Clear the parse state related to data kind OBUs. */
+static void
+gst_av1_parse_reset_obu_data_state (GstAV1Parse * self)
+{
+  self->last_shown_frame_temporal_id = -1;
+  self->last_shown_frame_spatial_id = -1;
+  self->within_one_frame = FALSE;
+}
+
+static void
+gst_av1_parse_reset_tu_timestamp (GstAV1Parse * self)
+{
+  self->buffer_pts = GST_CLOCK_TIME_NONE;
+  self->buffer_dts = GST_CLOCK_TIME_NONE;
+  self->buffer_duration = GST_CLOCK_TIME_NONE;
+}
+
+static void
+gst_av1_parse_reset (GstAV1Parse * self)
+{
+  self->width = 0;
+  self->height = 0;
+  self->subsampling_x = -1;
+  self->subsampling_y = -1;
+  self->mono_chrome = FALSE;
+  self->profile = GST_AV1_PROFILE_UNDEFINED;
+  self->bit_depth = 0;
+  self->align = GST_AV1_PARSE_ALIGN_NONE;
+  self->in_align = GST_AV1_PARSE_ALIGN_NONE;
+  self->detect_annex_b = FALSE;
+  self->discont = TRUE;
+  self->header = FALSE;
+  self->keyframe = FALSE;
+  self->show_frame = FALSE;
+  self->last_parsed_offset = 0;
+  self->highest_spatial_id = 0;
+  gst_av1_parse_reset_obu_data_state (self);
+  g_clear_pointer (&self->colorimetry, g_free);
+  g_clear_pointer (&self->parser, gst_av1_parser_free);
+  gst_adapter_clear (self->cache_out);
+  gst_adapter_clear (self->frame_cache);
+  gst_av1_parse_reset_tu_timestamp (self);
+}
+
+static void
+gst_av1_parse_init (GstAV1Parse * self)
+{
+  gst_base_parse_set_pts_interpolation (GST_BASE_PARSE (self), FALSE);
+  gst_base_parse_set_infer_ts (GST_BASE_PARSE (self), FALSE);
+
+  GST_PAD_SET_ACCEPT_INTERSECT (GST_BASE_PARSE_SINK_PAD (self));
+  GST_PAD_SET_ACCEPT_TEMPLATE (GST_BASE_PARSE_SINK_PAD (self));
+
+  self->cache_out = gst_adapter_new ();
+  self->frame_cache = gst_adapter_new ();
+}
+
+static void
+gst_av1_parse_finalize (GObject * object)
+{
+  GstAV1Parse *self = GST_AV1_PARSE (object);
+
+  gst_av1_parse_reset (self);
+  g_object_unref (self->cache_out);
+  g_object_unref (self->frame_cache);
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
+static void
+gst_av1_parse_class_init (GstAV1ParseClass * klass)
+{
+  GObjectClass *gobject_class = (GObjectClass *) klass;
+  GstBaseParseClass *parse_class = GST_BASE_PARSE_CLASS (klass);
+  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);
+
+  gobject_class->finalize = gst_av1_parse_finalize;
+  parse_class->start = GST_DEBUG_FUNCPTR (gst_av1_parse_start);
+  parse_class->stop = GST_DEBUG_FUNCPTR (gst_av1_parse_stop);
+  parse_class->handle_frame = GST_DEBUG_FUNCPTR (gst_av1_parse_handle_frame);
+  parse_class->pre_push_frame =
+      GST_DEBUG_FUNCPTR (gst_av1_parse_pre_push_frame);
+  parse_class->set_sink_caps = GST_DEBUG_FUNCPTR (gst_av1_parse_set_sink_caps);
+  parse_class->get_sink_caps = GST_DEBUG_FUNCPTR (gst_av1_parse_get_sink_caps);
+
+  gst_element_class_add_static_pad_template (element_class, &srctemplate);
+  gst_element_class_add_static_pad_template (element_class, &sinktemplate);
+
+  gst_element_class_set_static_metadata (element_class, "AV1 parser",
+      "Codec/Parser/Converter/Video",
+      "Parses AV1 streams", "He Junyan <junyan.he@intel.com>");
+
+  GST_DEBUG_CATEGORY_INIT (av1_parse_debug, "av1parse", 0, "av1 parser");
+}
+
+static gboolean
+gst_av1_parse_start (GstBaseParse * parse)
+{
+  GstAV1Parse *self = GST_AV1_PARSE (parse);
+
+  GST_DEBUG_OBJECT (self, "start");
+
+  gst_av1_parse_reset (self);
+  self->parser = gst_av1_parser_new ();
+
+  /* At least the OBU header. */
+  gst_base_parse_set_min_frame_size (parse, 1);
+
+  return TRUE;
+}
+
+static gboolean
+gst_av1_parse_stop (GstBaseParse * parse)
+{
+  GstAV1Parse *self = GST_AV1_PARSE (parse);
+
+  GST_DEBUG_OBJECT (self, "stop");
+  g_clear_pointer (&self->parser, gst_av1_parser_free);
+
+  return TRUE;
+}
+
+static const gchar *
+gst_av1_parse_profile_to_string (GstAV1Profile profile)
+{
+  switch (profile) {
+    case GST_AV1_PROFILE_0:
+      return "main";
+    case GST_AV1_PROFILE_1:
+      return "high";
+    case GST_AV1_PROFILE_2:
+      return "professional";
+    default:
+      break;
+  }
+
+  return NULL;
+}
+
+static GstAV1Profile
+gst_av1_parse_profile_from_string (const gchar * profile)
+{
+  if (!profile)
+    return GST_AV1_PROFILE_UNDEFINED;
+
+  if (g_strcmp0 (profile, "main") == 0)
+    return GST_AV1_PROFILE_0;
+  else if (g_strcmp0 (profile, "high") == 0)
+    return GST_AV1_PROFILE_1;
+  else if (g_strcmp0 (profile, "professional") == 0)
+    return GST_AV1_PROFILE_2;
+
+  return GST_AV1_PROFILE_UNDEFINED;
+}
+
+static const gchar *
+gst_av1_parse_alignment_to_steam_format_string (GstAV1ParseAligment align)
+{
+  switch (align) {
+    case GST_AV1_PARSE_ALIGN_BYTE:
+      return "obu-stream";
+    case GST_AV1_PARSE_ALIGN_OBU:
+    case GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT:
+    case GST_AV1_PARSE_ALIGN_FRAME:
+      return "obu-stream";
+    case GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B:
+      return "annexb";
+    default:
+      GST_WARNING ("Unrecognized steam format");
+      break;
+  }
+
+  return NULL;
+}
+
+static const gchar *
+gst_av1_parse_alignment_to_string (GstAV1ParseAligment align)
+{
+  switch (align) {
+    case GST_AV1_PARSE_ALIGN_BYTE:
+      return "byte";
+    case GST_AV1_PARSE_ALIGN_OBU:
+      return "obu";
+    case GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT:
+    case GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B:
+      return "tu";
+    case GST_AV1_PARSE_ALIGN_FRAME:
+      return "frame";
+    default:
+      GST_WARNING ("Unrecognized alignment");
+      break;
+  }
+
+  return NULL;
+}
+
+static GstAV1ParseAligment
+gst_av1_parse_alignment_from_string (const gchar * align,
+    const gchar * stream_format)
+{
+  if (!align && !stream_format)
+    return GST_AV1_PARSE_ALIGN_NONE;
+
+  if (stream_format) {
+    if (g_strcmp0 (stream_format, "annexb") == 0) {
+      if (align && g_strcmp0 (align, "tu") != 0) {
+        /* annex b stream must align to TU. */
+        return GST_AV1_PARSE_ALIGN_ERROR;
+      } else {
+        return GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B;
+      }
+    } else if (g_strcmp0 (stream_format, "obu-stream") != 0) {
+      /* unrecognized */
+      return GST_AV1_PARSE_ALIGN_NONE;
+    }
+
+    /* stream-format is obu-stream, depends on align */
+  }
+
+  if (align) {
+    if (g_strcmp0 (align, "byte") == 0) {
+      return GST_AV1_PARSE_ALIGN_BYTE;
+    } else if (g_strcmp0 (align, "obu") == 0) {
+      return GST_AV1_PARSE_ALIGN_OBU;
+    } else if (g_strcmp0 (align, "tu") == 0) {
+      return GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT;
+    } else if (g_strcmp0 (align, "frame") == 0) {
+      return GST_AV1_PARSE_ALIGN_FRAME;
+    } else {
+      /* unrecognized */
+      return GST_AV1_PARSE_ALIGN_NONE;
+    }
+  }
+
+  return GST_AV1_PARSE_ALIGN_NONE;
+}
+
+static gboolean
+gst_av1_parse_caps_has_alignment (GstCaps * caps, GstAV1ParseAligment alignment)
+{
+  guint i, j, caps_size;
+  const gchar *cmp_align_str = NULL;
+  const gchar *cmp_stream_str = NULL;
+
+  GST_DEBUG ("Try to find alignment %d in caps: %" GST_PTR_FORMAT,
+      alignment, caps);
+
+  caps_size = gst_caps_get_size (caps);
+  if (caps_size == 0)
+    return FALSE;
+
+  switch (alignment) {
+    case GST_AV1_PARSE_ALIGN_BYTE:
+      cmp_align_str = "byte";
+      cmp_stream_str = "obu-stream";
+      break;
+    case GST_AV1_PARSE_ALIGN_OBU:
+      cmp_align_str = "obu";
+      cmp_stream_str = "obu-stream";
+      break;
+    case GST_AV1_PARSE_ALIGN_FRAME:
+      cmp_align_str = "frame";
+      cmp_stream_str = "obu-stream";
+      break;
+    case GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT:
+      cmp_align_str = "tu";
+      cmp_stream_str = "obu-stream";
+      break;
+    case GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B:
+      cmp_align_str = "tu";
+      cmp_stream_str = "annexb";
+      break;
+    default:
+      return FALSE;
+  }
+
+  for (i = 0; i < caps_size; i++) {
+    GstStructure *s = gst_caps_get_structure (caps, i);
+    const GValue *alignment_value = gst_structure_get_value (s, "alignment");
+    const GValue *stream_value = gst_structure_get_value (s, "stream-format");
+
+    if (!alignment_value || !stream_value)
+      continue;
+
+    if (G_VALUE_HOLDS_STRING (alignment_value)) {
+      const gchar *align_str = g_value_get_string (alignment_value);
+
+      if (g_strcmp0 (align_str, cmp_align_str) != 0)
+        continue;
+    } else if (GST_VALUE_HOLDS_LIST (alignment_value)) {
+      guint num_values = gst_value_list_get_size (alignment_value);
+
+      for (j = 0; j < num_values; j++) {
+        const GValue *v = gst_value_list_get_value (alignment_value, j);
+        const gchar *align_str = g_value_get_string (v);
+
+        if (g_strcmp0 (align_str, cmp_align_str) == 0)
+          break;
+      }
+
+      if (j == num_values)
+        continue;
+    }
+
+    if (G_VALUE_HOLDS_STRING (stream_value)) {
+      const gchar *stream_str = g_value_get_string (stream_value);
+
+      if (g_strcmp0 (stream_str, cmp_stream_str) != 0)
+        continue;
+    } else if (GST_VALUE_HOLDS_LIST (stream_value)) {
+      guint num_values = gst_value_list_get_size (stream_value);
+
+      for (j = 0; j < num_values; j++) {
+        const GValue *v = gst_value_list_get_value (stream_value, j);
+        const gchar *stream_str = g_value_get_string (v);
+
+        if (g_strcmp0 (stream_str, cmp_stream_str) == 0)
+          break;
+      }
+
+      if (j == num_values)
+        continue;
+    }
+
+    return TRUE;
+  }
+
+  return FALSE;
+}
+
+static GstAV1ParseAligment
+gst_av1_parse_alignment_from_caps (GstCaps * caps)
+{
+  GstAV1ParseAligment align;
+
+  align = GST_AV1_PARSE_ALIGN_NONE;
+
+  GST_DEBUG ("parsing caps: %" GST_PTR_FORMAT, caps);
+
+  if (caps && gst_caps_get_size (caps) > 0) {
+    GstStructure *s = gst_caps_get_structure (caps, 0);
+    const gchar *str_align = NULL;
+    const gchar *str_stream = NULL;
+
+    str_align = gst_structure_get_string (s, "alignment");
+    str_stream = gst_structure_get_string (s, "stream-format");
+
+    align = gst_av1_parse_alignment_from_string (str_align, str_stream);
+  }
+
+  return align;
+}
+
+static void
+gst_av1_parse_update_src_caps (GstAV1Parse * self, GstCaps * caps)
+{
+  GstCaps *sink_caps, *src_caps;
+  GstCaps *final_caps = NULL;
+  GstStructure *s = NULL;
+  gint width, height;
+  gint par_n = 0, par_d = 0;
+  gint fps_n = 0, fps_d = 0;
+  const gchar *profile = NULL;
+
+  if (G_UNLIKELY (!gst_pad_has_current_caps (GST_BASE_PARSE_SRC_PAD (self))))
+    self->update_caps = TRUE;
+
+  if (!self->update_caps)
+    return;
+
+  /* if this is being called from the first _setcaps call, caps on the sinkpad
+   * aren't set yet and so they need to be passed as an argument */
+  if (caps)
+    sink_caps = gst_caps_ref (caps);
+  else
+    sink_caps = gst_pad_get_current_caps (GST_BASE_PARSE_SINK_PAD (self));
+
+  /* carry over input caps as much as possible; override with our own stuff */
+  if (!sink_caps)
+    sink_caps = gst_caps_new_empty_simple ("video/x-av1");
+  else
+    s = gst_caps_get_structure (sink_caps, 0);
+
+  final_caps = gst_caps_copy (sink_caps);
+
+  if (s && gst_structure_has_field (s, "width") &&
+      gst_structure_has_field (s, "height")) {
+    gst_structure_get_int (s, "width", &width);
+    gst_structure_get_int (s, "height", &height);
+  } else {
+    width = self->width;
+    height = self->height;
+  }
+
+  if (width > 0 && height > 0)
+    gst_caps_set_simple (final_caps, "width", G_TYPE_INT, width,
+        "height", G_TYPE_INT, height, NULL);
+
+  if (s && gst_structure_get_fraction (s, "pixel-aspect-ratio", &par_n, &par_d)) {
+    if (par_n != 0 && par_d != 0) {
+      gst_caps_set_simple (final_caps, "pixel-aspect-ratio",
+          GST_TYPE_FRACTION, par_n, par_d, NULL);
+    }
+  }
+
+  if (s && gst_structure_has_field (s, "framerate")) {
+    gst_structure_get_fraction (s, "framerate", &fps_n, &fps_d);
+  }
+
+  if (fps_n > 0 && fps_d > 0) {
+    gst_caps_set_simple (final_caps, "framerate",
+        GST_TYPE_FRACTION, fps_n, fps_d, NULL);
+    gst_base_parse_set_frame_rate (GST_BASE_PARSE (self), fps_n, fps_d, 0, 0);
+  }
+
+  /* When not RGB, the chroma format is needed. */
+  if (self->colorimetry == NULL ||
+      (g_strcmp0 (self->colorimetry, GST_VIDEO_COLORIMETRY_SRGB) != 0)) {
+    const gchar *chroma_format = NULL;
+
+    if (self->subsampling_x == 1 && self->subsampling_y == 1) {
+      if (!self->mono_chrome) {
+        chroma_format = "4:2:0";
+      } else {
+        chroma_format = "4:0:0";
+      }
+    } else if (self->subsampling_x == 1 && self->subsampling_y == 0) {
+      chroma_format = "4:2:2";
+    } else if (self->subsampling_x == 0 && self->subsampling_y == 0) {
+      chroma_format = "4:4:4";
+    }
+
+    if (chroma_format)
+      gst_caps_set_simple (final_caps,
+          "chroma-format", G_TYPE_STRING, chroma_format, NULL);
+  }
+
+  if (self->bit_depth)
+    gst_caps_set_simple (final_caps,
+        "bit-depth-luma", G_TYPE_UINT, self->bit_depth,
+        "bit-depth-chroma", G_TYPE_UINT, self->bit_depth, NULL);
+
+  if (self->colorimetry && (!s || !gst_structure_has_field (s, "colorimetry")))
+    gst_caps_set_simple (final_caps,
+        "colorimetry", G_TYPE_STRING, self->colorimetry, NULL);
+
+  g_assert (self->align > GST_AV1_PARSE_ALIGN_NONE);
+  gst_caps_set_simple (final_caps, "parsed", G_TYPE_BOOLEAN, TRUE,
+      "stream-format", G_TYPE_STRING,
+      gst_av1_parse_alignment_to_steam_format_string (self->align),
+      "alignment", G_TYPE_STRING,
+      gst_av1_parse_alignment_to_string (self->align), NULL);
+
+  profile = gst_av1_parse_profile_to_string (self->profile);
+  if (profile)
+    gst_caps_set_simple (final_caps, "profile", G_TYPE_STRING, profile, NULL);
+
+  src_caps = gst_pad_get_current_caps (GST_BASE_PARSE_SRC_PAD (self));
+
+  if (!(src_caps && gst_caps_is_strictly_equal (src_caps, final_caps))) {
+    GST_DEBUG_OBJECT (self, "Update src caps %" GST_PTR_FORMAT, final_caps);
+    gst_pad_set_caps (GST_BASE_PARSE_SRC_PAD (self), final_caps);
+  }
+
+  gst_clear_caps (&src_caps);
+  gst_caps_unref (final_caps);
+  gst_caps_unref (sink_caps);
+
+  self->update_caps = FALSE;
+}
+
+/* check downstream caps to configure format and alignment */
+static void
+gst_av1_parse_negotiate (GstAV1Parse * self, GstCaps * in_caps)
+{
+  GstCaps *caps;
+  GstAV1ParseAligment align;
+
+  caps = gst_pad_get_allowed_caps (GST_BASE_PARSE_SRC_PAD (self));
+  GST_DEBUG_OBJECT (self, "allowed caps: %" GST_PTR_FORMAT, caps);
+
+  /* concentrate on leading structure, since decodebin parser
+   * capsfilter always includes parser template caps */
+  if (caps) {
+    caps = gst_caps_truncate (caps);
+    GST_DEBUG_OBJECT (self, "negotiating with caps: %" GST_PTR_FORMAT, caps);
+  }
+
+  /* prefer TU as default */
+  if (gst_av1_parse_caps_has_alignment (caps,
+          GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT)) {
+    self->align = GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT;
+    goto done;
+  }
+
+  /* Both upsteam and downstream support, best */
+  if (in_caps && caps) {
+    if (gst_caps_can_intersect (in_caps, caps)) {
+      GstCaps *common_caps = NULL;
+
+      common_caps = gst_caps_intersect (in_caps, caps);
+      align = gst_av1_parse_alignment_from_caps (common_caps);
+      gst_clear_caps (&common_caps);
+
+      if (align != GST_AV1_PARSE_ALIGN_NONE
+          && align != GST_AV1_PARSE_ALIGN_ERROR) {
+        self->align = align;
+        goto done;
+      }
+    }
+  }
+
+  /* Select first one of downstream support */
+  if (caps && !gst_caps_is_empty (caps)) {
+    /* fixate to avoid ambiguity with lists when parsing */
+    caps = gst_caps_fixate (caps);
+    align = gst_av1_parse_alignment_from_caps (caps);
+
+    if (align != GST_AV1_PARSE_ALIGN_NONE && align != GST_AV1_PARSE_ALIGN_ERROR) {
+      self->align = align;
+      goto done;
+    }
+  }
+
+  /* default */
+  self->align = GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT;
+
+done:
+  GST_INFO_OBJECT (self, "selected alignment %s",
+      gst_av1_parse_alignment_to_string (self->align));
+
+  gst_clear_caps (&caps);
+}
+
+static GstCaps *
+gst_av1_parse_get_sink_caps (GstBaseParse * parse, GstCaps * filter)
+{
+  GstCaps *peercaps, *templ;
+  GstCaps *res, *tmp, *pcopy;
+
+  templ = gst_pad_get_pad_template_caps (GST_BASE_PARSE_SINK_PAD (parse));
+  if (filter) {
+    GstCaps *fcopy = gst_caps_copy (filter);
+    /* Remove the fields we convert */
+    remove_fields (fcopy, TRUE);
+    peercaps = gst_pad_peer_query_caps (GST_BASE_PARSE_SRC_PAD (parse), fcopy);
+    gst_caps_unref (fcopy);
+  } else {
+    peercaps = gst_pad_peer_query_caps (GST_BASE_PARSE_SRC_PAD (parse), NULL);
+  }
+
+  pcopy = gst_caps_copy (peercaps);
+  remove_fields (pcopy, TRUE);
+
+  res = gst_caps_intersect_full (pcopy, templ, GST_CAPS_INTERSECT_FIRST);
+  gst_caps_unref (pcopy);
+  gst_caps_unref (templ);
+
+  if (filter) {
+    GstCaps *tmp = gst_caps_intersect_full (res, filter,
+        GST_CAPS_INTERSECT_FIRST);
+    gst_caps_unref (res);
+    res = tmp;
+  }
+
+  /* Try if we can put the downstream caps first */
+  pcopy = gst_caps_copy (peercaps);
+  remove_fields (pcopy, FALSE);
+  tmp = gst_caps_intersect_full (pcopy, res, GST_CAPS_INTERSECT_FIRST);
+  gst_caps_unref (pcopy);
+  if (!gst_caps_is_empty (tmp))
+    res = gst_caps_merge (tmp, res);
+  else
+    gst_caps_unref (tmp);
+
+  gst_caps_unref (peercaps);
+
+  return res;
+}
+
+static gboolean
+gst_av1_parse_set_sink_caps (GstBaseParse * parse, GstCaps * caps)
+{
+  GstAV1Parse *self = GST_AV1_PARSE (parse);
+  GstStructure *str;
+  GstAV1ParseAligment align;
+  GstCaps *in_caps = NULL;
+  const gchar *profile;
+
+  str = gst_caps_get_structure (caps, 0);
+
+  /* accept upstream info if provided */
+  gst_structure_get_int (str, "width", &self->width);
+  gst_structure_get_int (str, "height", &self->height);
+  profile = gst_structure_get_string (str, "profile");
+  if (profile)
+    self->profile = gst_av1_parse_profile_from_string (profile);
+
+  /* get upstream align from caps */
+  align = gst_av1_parse_alignment_from_caps (caps);
+  if (align == GST_AV1_PARSE_ALIGN_ERROR) {
+    GST_ERROR_OBJECT (self, "Sink caps %" GST_PTR_FORMAT " set stream-format"
+        " and alignment conflict.", caps);
+    return FALSE;
+  }
+
+  in_caps = gst_caps_copy (caps);
+  /* default */
+  if (align == GST_AV1_PARSE_ALIGN_NONE) {
+    align = GST_AV1_PARSE_ALIGN_BYTE;
+    gst_caps_set_simple (in_caps, "alignment", G_TYPE_STRING,
+        gst_av1_parse_alignment_to_string (align),
+        "stream-format", G_TYPE_STRING, "obu-stream", NULL);
+  }
+
+  /* negotiate with downstream, set output align */
+  gst_av1_parse_negotiate (self, in_caps);
+
+  self->update_caps = TRUE;
+
+  /* if all of decoder's capability related values are provided
+   * by upstream, update src caps now */
+  if (self->width > 0 && self->height > 0 && profile)
+    gst_av1_parse_update_src_caps (self, in_caps);
+
+  gst_caps_unref (in_caps);
+
+  self->in_align = align;
+
+  if (self->in_align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT)
+    self->detect_annex_b = TRUE;
+
+  if (self->in_align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B) {
+    gst_av1_parser_reset (self->parser, TRUE);
+  } else {
+    gst_av1_parser_reset (self->parser, FALSE);
+  }
+
+  return TRUE;
+}
+
+static GstFlowReturn
+gst_av1_parse_push_data (GstAV1Parse * self, GstBaseParseFrame * frame,
+    guint32 finish_sz, gboolean frame_finished)
+{
+  gsize sz;
+  GstBuffer *buf, *header_buf;
+  GstBuffer *buffer = frame->buffer;
+  GstFlowReturn ret = GST_FLOW_OK;
+
+  /* Need to generate the final TU annex-b format */
+  if (self->align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B) {
+    guint8 size_data[GST_AV1_MAX_LEB_128_SIZE];
+    guint size_len = 0;
+    guint len;
+
+    /* When push a TU, it must also be a frame end. */
+    g_assert (frame_finished);
+
+    /* Still some left in the frame cache */
+    len = gst_adapter_available (self->frame_cache);
+    if (len) {
+      buf = gst_adapter_take_buffer (self->frame_cache, len);
+
+      /* frame_unit_size */
+      _write_leb128 (size_data, &size_len, len);
+      header_buf = gst_buffer_new_memdup (size_data, size_len);
+      GST_BUFFER_PTS (header_buf) = GST_BUFFER_PTS (buf);
+      GST_BUFFER_DTS (header_buf) = GST_BUFFER_DTS (buf);
+      GST_BUFFER_DURATION (header_buf) = GST_BUFFER_DURATION (buf);
+
+      gst_adapter_push (self->cache_out, header_buf);
+      gst_adapter_push (self->cache_out, buf);
+    }
+
+    len = gst_adapter_available (self->cache_out);
+    if (len) {
+      buf = gst_adapter_take_buffer (self->cache_out, len);
+
+      /* temporal_unit_size */
+      _write_leb128 (size_data, &size_len, len);
+      header_buf = gst_buffer_new_memdup (size_data, size_len);
+      GST_BUFFER_PTS (header_buf) = GST_BUFFER_PTS (buf);
+      GST_BUFFER_DTS (header_buf) = GST_BUFFER_DTS (buf);
+      GST_BUFFER_DURATION (header_buf) = GST_BUFFER_DURATION (buf);
+
+      gst_adapter_push (self->cache_out, header_buf);
+      gst_adapter_push (self->cache_out, buf);
+    }
+  }
+
+  sz = gst_adapter_available (self->cache_out);
+  if (sz) {
+    buf = gst_adapter_take_buffer (self->cache_out, sz);
+    gst_buffer_copy_into (buf, buffer, GST_BUFFER_COPY_METADATA, 0, -1);
+    if (self->discont) {
+      GST_BUFFER_FLAG_SET (buf, GST_BUFFER_FLAG_DISCONT);
+      self->discont = FALSE;
+    } else {
+      GST_BUFFER_FLAG_UNSET (buf, GST_BUFFER_FLAG_DISCONT);
+    }
+
+    if (self->header) {
+      GST_BUFFER_FLAG_SET (buf, GST_BUFFER_FLAG_HEADER);
+      self->header = FALSE;
+    } else {
+      GST_BUFFER_FLAG_UNSET (buf, GST_BUFFER_FLAG_HEADER);
+    }
+
+    if (self->keyframe) {
+      GST_BUFFER_FLAG_UNSET (buf, GST_BUFFER_FLAG_DELTA_UNIT);
+      self->keyframe = FALSE;
+    } else {
+      GST_BUFFER_FLAG_SET (buf, GST_BUFFER_FLAG_DELTA_UNIT);
+    }
+
+    if (frame_finished) {
+      GST_BUFFER_FLAG_SET (buf, GST_BUFFER_FLAG_MARKER);
+    } else {
+      GST_BUFFER_FLAG_UNSET (buf, GST_BUFFER_FLAG_MARKER);
+    }
+
+    if (self->align == GST_AV1_PARSE_ALIGN_FRAME) {
+      if (!self->show_frame) {
+        GST_BUFFER_FLAG_SET (buf, GST_BUFFER_FLAG_DECODE_ONLY);
+      } else {
+        GST_BUFFER_FLAG_UNSET (buf, GST_BUFFER_FLAG_DECODE_ONLY);
+      }
+    } else {
+      GST_BUFFER_FLAG_UNSET (buf, GST_BUFFER_FLAG_DECODE_ONLY);
+    }
+
+    gst_buffer_replace (&frame->out_buffer, buf);
+    gst_buffer_unref (buf);
+
+    gst_av1_parse_update_src_caps (self, NULL);
+    GST_LOG_OBJECT (self, "comsumed %d, output one buffer with size %"
+        G_GSSIZE_FORMAT, finish_sz, sz);
+    ret = gst_base_parse_finish_frame (GST_BASE_PARSE (self), frame, finish_sz);
+  }
+
+  return ret;
+}
+
+static void
+gst_av1_parse_convert_to_annexb (GstAV1Parse * self, GstBuffer * buffer,
+    GstAV1OBU * obu, gboolean frame_complete)
+{
+  guint8 size_data[GST_AV1_MAX_LEB_128_SIZE];
+  guint size_len = 0;
+  GstBitWriter bs;
+  GstBuffer *buf, *buf2;
+  guint8 *data;
+  guint len, len2, offset;
+
+  /* obu_length */
+  _write_leb128 (size_data, &size_len,
+      obu->obu_size + 1 + obu->header.obu_extention_flag);
+
+  gst_bit_writer_init_with_size (&bs, 128, FALSE);
+  /* obu_forbidden_bit */
+  gst_bit_writer_put_bits_uint8 (&bs, 0, 1);
+  /* obu_type */
+  gst_bit_writer_put_bits_uint8 (&bs, obu->obu_type, 4);
+  /* obu_extension_flag */
+  gst_bit_writer_put_bits_uint8 (&bs, obu->header.obu_extention_flag, 1);
+  /* obu_has_size_field */
+  gst_bit_writer_put_bits_uint8 (&bs, 0, 1);
+  /* obu_reserved_1bit */
+  gst_bit_writer_put_bits_uint8 (&bs, 0, 1);
+  if (obu->header.obu_extention_flag) {
+    /* temporal_id */
+    gst_bit_writer_put_bits_uint8 (&bs, obu->header.obu_temporal_id, 3);
+    /* spatial_id */
+    gst_bit_writer_put_bits_uint8 (&bs, obu->header.obu_spatial_id, 2);
+    /* extension_header_reserved_3bits */
+    gst_bit_writer_put_bits_uint8 (&bs, 0, 3);
+  }
+  g_assert (GST_BIT_WRITER_BIT_SIZE (&bs) % 8 == 0);
+
+  len = size_len;
+  len += GST_BIT_WRITER_BIT_SIZE (&bs) / 8;
+  len += obu->obu_size;
+
+  data = g_malloc (len);
+  offset = 0;
+
+  memcpy (data + offset, size_data, size_len);
+  offset += size_len;
+
+  memcpy (data + offset, GST_BIT_WRITER_DATA (&bs),
+      GST_BIT_WRITER_BIT_SIZE (&bs) / 8);
+  offset += GST_BIT_WRITER_BIT_SIZE (&bs) / 8;
+
+  memcpy (data + offset, obu->data, obu->obu_size);
+
+  /* The buf of this OBU */
+  buf = gst_buffer_new_wrapped (data, len);
+  GST_BUFFER_PTS (buf) = GST_BUFFER_PTS (buffer);
+  GST_BUFFER_DTS (buf) = GST_BUFFER_DTS (buffer);
+  GST_BUFFER_DURATION (buf) = GST_BUFFER_DURATION (buffer);
+
+  gst_adapter_push (self->frame_cache, buf);
+
+  if (frame_complete) {
+    len2 = gst_adapter_available (self->frame_cache);
+    buf2 = gst_adapter_take_buffer (self->frame_cache, len2);
+
+    /* frame_unit_size */
+    _write_leb128 (size_data, &size_len, len2);
+    buf = gst_buffer_new_memdup (size_data, size_len);
+    GST_BUFFER_PTS (buf) = GST_BUFFER_PTS (buf2);
+    GST_BUFFER_DTS (buf) = GST_BUFFER_DTS (buf2);
+    GST_BUFFER_DURATION (buf) = GST_BUFFER_DURATION (buf2);
+
+    gst_adapter_push (self->cache_out, buf);
+    gst_adapter_push (self->cache_out, buf2);
+  }
+
+  gst_bit_writer_reset (&bs);
+}
+
+static void
+gst_av1_parse_convert_from_annexb (GstAV1Parse * self, GstBuffer * buffer,
+    GstAV1OBU * obu)
+{
+  guint8 size_data[GST_AV1_MAX_LEB_128_SIZE];
+  guint size_len = 0;
+  GstBuffer *buf;
+  guint len, offset;
+  guint8 *data;
+  GstBitWriter bs;
+
+  _write_leb128 (size_data, &size_len, obu->obu_size);
+
+  /* obu_header */
+  len = 1;
+  if (obu->header.obu_extention_flag)
+    len += 1;
+  len += size_len;
+  len += obu->obu_size;
+
+  gst_bit_writer_init_with_size (&bs, 128, FALSE);
+  /* obu_forbidden_bit */
+  gst_bit_writer_put_bits_uint8 (&bs, 0, 1);
+  /* obu_type */
+  gst_bit_writer_put_bits_uint8 (&bs, obu->obu_type, 4);
+  /* obu_extension_flag */
+  gst_bit_writer_put_bits_uint8 (&bs, obu->header.obu_extention_flag, 1);
+  /* obu_has_size_field */
+  gst_bit_writer_put_bits_uint8 (&bs, 1, 1);
+  /* obu_reserved_1bit */
+  gst_bit_writer_put_bits_uint8 (&bs, 0, 1);
+  if (obu->header.obu_extention_flag) {
+    /* temporal_id */
+    gst_bit_writer_put_bits_uint8 (&bs, obu->header.obu_temporal_id, 3);
+    /* spatial_id */
+    gst_bit_writer_put_bits_uint8 (&bs, obu->header.obu_spatial_id, 2);
+    /* extension_header_reserved_3bits */
+    gst_bit_writer_put_bits_uint8 (&bs, 0, 3);
+  }
+  g_assert (GST_BIT_WRITER_BIT_SIZE (&bs) % 8 == 0);
+
+  data = g_malloc (len);
+  offset = 0;
+  memcpy (data + offset, GST_BIT_WRITER_DATA (&bs),
+      GST_BIT_WRITER_BIT_SIZE (&bs) / 8);
+  offset += GST_BIT_WRITER_BIT_SIZE (&bs) / 8;
+
+  memcpy (data + offset, size_data, size_len);
+  offset += size_len;
+
+  memcpy (data + offset, obu->data, obu->obu_size);
+
+  buf = gst_buffer_new_wrapped (data, len);
+  GST_BUFFER_PTS (buf) = GST_BUFFER_PTS (buffer);
+  GST_BUFFER_DTS (buf) = GST_BUFFER_DTS (buffer);
+  GST_BUFFER_DURATION (buf) = GST_BUFFER_DURATION (buffer);
+
+  gst_adapter_push (self->cache_out, buf);
+
+  gst_bit_writer_reset (&bs);
+}
+
+static void
+gst_av1_parse_cache_one_obu (GstAV1Parse * self, GstBuffer * buffer,
+    GstAV1OBU * obu, guint8 * data, guint32 size, gboolean frame_complete)
+{
+  gboolean need_convert = FALSE;
+  GstBuffer *buf;
+
+  if (self->in_align != self->align
+      && (self->in_align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B
+          || self->align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B))
+    need_convert = TRUE;
+
+  if (need_convert) {
+    if (self->in_align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B) {
+      gst_av1_parse_convert_from_annexb (self, buffer, obu);
+    } else {
+      gst_av1_parse_convert_to_annexb (self, buffer, obu, frame_complete);
+    }
+  } else if (self->align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B) {
+    g_assert (self->in_align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B);
+    gst_av1_parse_convert_to_annexb (self, buffer, obu, frame_complete);
+  } else {
+    buf = gst_buffer_new_memdup (data, size);
+    GST_BUFFER_PTS (buf) = GST_BUFFER_PTS (buffer);
+    GST_BUFFER_DTS (buf) = GST_BUFFER_DTS (buffer);
+    GST_BUFFER_DURATION (buf) = GST_BUFFER_DURATION (buffer);
+
+    gst_adapter_push (self->cache_out, buf);
+  }
+}
+
+static GstAV1ParserResult
+gst_av1_parse_handle_sequence_obu (GstAV1Parse * self, GstAV1OBU * obu)
+{
+  GstAV1SequenceHeaderOBU seq_header;
+  GstAV1ParserResult res;
+  guint i;
+  guint val;
+
+  res = gst_av1_parser_parse_sequence_header_obu (self->parser,
+      obu, &seq_header);
+  if (res != GST_AV1_PARSER_OK)
+    return res;
+
+  if (self->width != seq_header.max_frame_width_minus_1 + 1) {
+    self->width = seq_header.max_frame_width_minus_1 + 1;
+    self->update_caps = TRUE;
+  }
+  if (self->height != seq_header.max_frame_height_minus_1 + 1) {
+    self->height = seq_header.max_frame_height_minus_1 + 1;
+    self->update_caps = TRUE;
+  }
+
+  if (seq_header.color_config.color_description_present_flag) {
+    GstVideoColorimetry cinfo;
+    gchar *colorimetry = NULL;
+
+    if (seq_header.color_config.color_range)
+      cinfo.range = GST_VIDEO_COLOR_RANGE_0_255;
+    else
+      cinfo.range = GST_VIDEO_COLOR_RANGE_16_235;
+
+    cinfo.matrix = gst_video_color_matrix_from_iso
+        (seq_header.color_config.matrix_coefficients);
+    cinfo.transfer = gst_video_transfer_function_from_iso
+        (seq_header.color_config.transfer_characteristics);
+    cinfo.primaries = gst_video_color_primaries_from_iso
+        (seq_header.color_config.color_primaries);
+
+    colorimetry = gst_video_colorimetry_to_string (&cinfo);
+
+    if (g_strcmp0 (colorimetry, self->colorimetry) != 0) {
+      g_free (self->colorimetry);
+      self->colorimetry = colorimetry;
+      colorimetry = NULL;
+      self->update_caps = TRUE;
+    }
+
+    g_clear_pointer (&colorimetry, g_free);
+  }
+
+  if (self->subsampling_x != seq_header.color_config.subsampling_x) {
+    self->subsampling_x = seq_header.color_config.subsampling_x;
+    self->update_caps = TRUE;
+  }
+
+  if (self->subsampling_y != seq_header.color_config.subsampling_y) {
+    self->subsampling_y = seq_header.color_config.subsampling_y;
+    self->update_caps = TRUE;
+  }
+
+  if (self->mono_chrome != seq_header.color_config.mono_chrome) {
+    self->mono_chrome = seq_header.color_config.mono_chrome;
+    self->update_caps = TRUE;
+  }
+
+  if (self->bit_depth != seq_header.bit_depth) {
+    self->bit_depth = seq_header.bit_depth;
+    self->update_caps = TRUE;
+  }
+
+  if (self->profile != seq_header.seq_profile) {
+    self->profile = seq_header.seq_profile;
+    self->update_caps = TRUE;
+  }
+
+  val = (self->parser->state.operating_point_idc >> 8) & 0x0f;
+  for (i = 0; i < (1 << GST_AV1_MAX_SPATIAL_LAYERS); i++) {
+    if (val & (1 << i))
+      self->highest_spatial_id = i;
+  }
+
+  return GST_AV1_PARSER_OK;
+}
+
+/* Check whether the frame start a new TU.
+   The obu here should be a shown frame/frame header. */
+static gboolean
+gst_av1_parse_frame_start_new_temporal_unit (GstAV1Parse * self,
+    GstAV1OBU * obu)
+{
+  gboolean ret = FALSE;
+
+  g_assert (obu->obu_type == GST_AV1_OBU_FRAME_HEADER
+      || obu->obu_type == GST_AV1_OBU_FRAME);
+
+  /* 7.5.Ordering of OBUs: The value of temporal_id must be the same in all
+     OBU extension headers that are contained in the same temporal unit. */
+  if (self->last_shown_frame_temporal_id >= 0 &&
+      obu->header.obu_temporal_id != self->last_shown_frame_temporal_id) {
+    ret = TRUE;
+    goto new_tu;
+  }
+
+  /* If scalability is not being used, only one shown frame for each
+     temporal unit. So the new frame belongs to a new temporal unit. */
+  if (!self->within_one_frame && self->last_shown_frame_temporal_id >= 0 &&
+      self->parser->state.operating_point_idc == 0) {
+    ret = TRUE;
+    goto new_tu;
+  }
+
+  /* The new frame has the same layer IDs with the last shown frame,
+     it should belong to a new temporal unit. */
+  if (!self->within_one_frame &&
+      obu->header.obu_temporal_id == self->last_shown_frame_temporal_id &&
+      obu->header.obu_spatial_id == self->last_shown_frame_spatial_id) {
+    ret = TRUE;
+    goto new_tu;
+  }
+
+new_tu:
+  if (ret) {
+    if (self->within_one_frame)
+      GST_WARNING_OBJECT (self,
+          "Start a new temporal unit with incompleted frame.");
+
+    gst_av1_parse_reset_obu_data_state (self);
+  }
+
+  return ret;
+}
+
+/* frame_complete will be set true if it is the frame edge. */
+static GstAV1ParserResult
+gst_av1_parse_handle_one_obu (GstAV1Parse * self, GstAV1OBU * obu,
+    gboolean * frame_complete, gboolean * check_new_tu)
+{
+  GstAV1ParserResult res = GST_AV1_PARSER_OK;
+  GstAV1MetadataOBU metadata;
+  GstAV1FrameHeaderOBU frame_header;
+  GstAV1TileListOBU tile_list;
+  GstAV1TileGroupOBU tile_group;
+  GstAV1FrameOBU frame;
+
+  *frame_complete = FALSE;
+
+  switch (obu->obu_type) {
+    case GST_AV1_OBU_TEMPORAL_DELIMITER:
+      res = gst_av1_parser_parse_temporal_delimiter_obu (self->parser, obu);
+      break;
+    case GST_AV1_OBU_SEQUENCE_HEADER:
+      res = gst_av1_parse_handle_sequence_obu (self, obu);
+      break;
+    case GST_AV1_OBU_REDUNDANT_FRAME_HEADER:
+      res = gst_av1_parser_parse_frame_header_obu (self->parser, obu,
+          &frame_header);
+      break;
+    case GST_AV1_OBU_FRAME_HEADER:
+      res = gst_av1_parser_parse_frame_header_obu (self->parser, obu,
+          &frame_header);
+      break;
+    case GST_AV1_OBU_FRAME:
+      res = gst_av1_parser_parse_frame_obu (self->parser, obu, &frame);
+      break;
+    case GST_AV1_OBU_METADATA:
+      res = gst_av1_parser_parse_metadata_obu (self->parser, obu, &metadata);
+      break;
+    case GST_AV1_OBU_TILE_GROUP:
+      res =
+          gst_av1_parser_parse_tile_group_obu (self->parser, obu, &tile_group);
+      break;
+    case GST_AV1_OBU_TILE_LIST:
+      res = gst_av1_parser_parse_tile_list_obu (self->parser, obu, &tile_list);
+      break;
+    case GST_AV1_OBU_PADDING:
+      break;
+    default:
+      GST_WARNING_OBJECT (self, "an unrecognized obu type %d", obu->obu_type);
+      res = GST_AV1_PARSER_BITSTREAM_ERROR;
+      break;
+  }
+
+  GST_LOG_OBJECT (self, "parsing the obu %s, result is %d",
+      _obu_name (obu->obu_type), res);
+  if (res != GST_AV1_PARSER_OK)
+    goto out;
+
+  /* 7.5:
+     All OBU extension headers that are contained in the same temporal
+     unit and have the same spatial_id value must have the same temporal_id
+     value.
+     And
+     OBUs with spatial level IDs (spatial_id) greater than 0 must
+     appear within a temporal unit in increasing order of the spatial
+     level ID values. */
+  if (obu->header.obu_spatial_id > self->highest_spatial_id) {
+    GST_WARNING_OBJECT (self,
+        "spatial_id %d is bigger than highest_spatial_id %d",
+        obu->header.obu_spatial_id, self->highest_spatial_id);
+    res = GST_AV1_PARSER_BITSTREAM_ERROR;
+    goto out;
+  }
+
+  /* If to check a new temporal starts, return early.
+     In 7.5.Ordering of OBUs: Sequence header OBUs may appear in any order
+     within a coded video sequence. So it is allowed to repeat the sequence
+     header within one temporal unit, and sequence header does not definitely
+     start a TU. We only check TD here. */
+  if (obu->obu_type == GST_AV1_OBU_TEMPORAL_DELIMITER) {
+    gst_av1_parse_reset_obu_data_state (self);
+
+    if (check_new_tu) {
+      *check_new_tu = TRUE;
+      res = GST_AV1_PARSER_OK;
+      goto out;
+    }
+  }
+
+  if (obu->obu_type == GST_AV1_OBU_SEQUENCE_HEADER)
+    self->header = TRUE;
+
+  if (obu->obu_type == GST_AV1_OBU_FRAME_HEADER
+      || obu->obu_type == GST_AV1_OBU_FRAME
+      || obu->obu_type == GST_AV1_OBU_REDUNDANT_FRAME_HEADER) {
+    GstAV1FrameHeaderOBU *fh = &frame_header;
+
+    if (obu->obu_type == GST_AV1_OBU_FRAME)
+      fh = &frame.frame_header;
+
+    self->show_frame = fh->show_frame || fh->show_existing_frame;
+    if (self->show_frame) {
+      /* Check whether a new temporal starts, and return early. */
+      if (check_new_tu && obu->obu_type != GST_AV1_OBU_REDUNDANT_FRAME_HEADER
+          && gst_av1_parse_frame_start_new_temporal_unit (self, obu)) {
+        *check_new_tu = TRUE;
+        res = GST_AV1_PARSER_OK;
+        goto out;
+      }
+
+      self->last_shown_frame_temporal_id = obu->header.obu_temporal_id;
+      self->last_shown_frame_spatial_id = obu->header.obu_spatial_id;
+    }
+
+    self->within_one_frame = TRUE;
+
+    /* if a show_existing_frame case, only update key frame.
+       otherwise, update all type of frame.  */
+    if (!fh->show_existing_frame || fh->frame_type == GST_AV1_KEY_FRAME)
+      res = gst_av1_parser_reference_frame_update (self->parser, fh);
+
+    if (res != GST_AV1_PARSER_OK)
+      GST_WARNING_OBJECT (self, "update frame get result %d", res);
+
+    if (fh->show_existing_frame) {
+      *frame_complete = TRUE;
+      self->within_one_frame = FALSE;
+    }
+
+    if (fh->frame_type == GST_AV1_KEY_FRAME)
+      self->keyframe = TRUE;
+  }
+
+  if (obu->obu_type == GST_AV1_OBU_TILE_GROUP
+      || obu->obu_type == GST_AV1_OBU_FRAME) {
+    GstAV1TileGroupOBU *tg = &tile_group;
+
+    self->within_one_frame = TRUE;
+
+    if (obu->obu_type == GST_AV1_OBU_FRAME)
+      tg = &frame.tile_group;
+
+    if (tg->tg_end == tg->num_tiles - 1) {
+      *frame_complete = TRUE;
+      self->within_one_frame = FALSE;
+    }
+  }
+
+out:
+  if (res != GST_AV1_PARSER_OK) {
+    /* Some verbose OBU can be skip */
+    if (obu->obu_type == GST_AV1_OBU_REDUNDANT_FRAME_HEADER) {
+      GST_WARNING_OBJECT (self, "Ignore a verbose %s OBU parsing error",
+          _obu_name (obu->obu_type));
+      gst_av1_parse_reset_obu_data_state (self);
+      res = GST_AV1_PARSER_OK;
+    }
+  }
+
+  return res;
+}
+
+static GstFlowReturn
+gst_av1_parse_handle_obu_to_obu (GstBaseParse * parse,
+    GstBaseParseFrame * frame, gint * skipsize)
+{
+  GstAV1Parse *self = GST_AV1_PARSE (parse);
+  GstMapInfo map_info;
+  GstAV1OBU obu;
+  GstFlowReturn ret = GST_FLOW_OK;
+  GstAV1ParserResult res;
+  GstBuffer *buffer = gst_buffer_ref (frame->buffer);
+  guint32 consumed;
+  gboolean frame_complete;
+
+  if (!gst_buffer_map (buffer, &map_info, GST_MAP_READ)) {
+    *skipsize = 0;
+    GST_ERROR_OBJECT (parse, "Couldn't map incoming buffer");
+    return GST_FLOW_ERROR;
+  }
+
+  consumed = 0;
+  frame_complete = FALSE;
+  res = gst_av1_parser_identify_one_obu (self->parser, map_info.data,
+      map_info.size, &obu, &consumed);
+  if (res == GST_AV1_PARSER_OK)
+    res = gst_av1_parse_handle_one_obu (self, &obu, &frame_complete, NULL);
+
+  g_assert (consumed <= map_info.size);
+
+  if (res == GST_AV1_PARSER_BITSTREAM_ERROR ||
+      res == GST_AV1_PARSER_MISSING_OBU_REFERENCE) {
+    if (consumed) {
+      *skipsize = consumed;
+    } else {
+      *skipsize = map_info.size;
+    }
+    GST_WARNING_OBJECT (parse, "Parse obu error, discard %d.", *skipsize);
+    gst_av1_parse_reset_obu_data_state (self);
+    ret = GST_FLOW_OK;
+    goto out;
+  } else if (res == GST_AV1_PARSER_NO_MORE_DATA) {
+    *skipsize = 0;
+
+    if (self->in_align == GST_AV1_PARSE_ALIGN_OBU) {
+      /* The buffer is already aligned to OBU, should not happen. */
+      if (consumed) {
+        *skipsize = consumed;
+      } else {
+        *skipsize = map_info.size;
+      }
+      GST_WARNING_OBJECT (parse, "Parse obu need more data, discard %d.",
+          *skipsize);
+      gst_av1_parse_reset_obu_data_state (self);
+    }
+    ret = GST_FLOW_OK;
+    goto out;
+  } else if (res == GST_AV1_PARSER_DROP) {
+    GST_DEBUG_OBJECT (parse, "Drop %d data", consumed);
+    *skipsize = consumed;
+    gst_av1_parse_reset_obu_data_state (self);
+    ret = GST_FLOW_OK;
+    goto out;
+  } else if (res != GST_AV1_PARSER_OK) {
+    GST_ERROR_OBJECT (parse, "Parse obu get unexpect error %d", res);
+    *skipsize = 0;
+    ret = GST_FLOW_ERROR;
+    goto out;
+  }
+
+  g_assert (consumed);
+
+  gst_av1_parse_update_src_caps (self, NULL);
+  if (self->discont) {
+    GST_BUFFER_FLAG_SET (buffer, GST_BUFFER_FLAG_DISCONT);
+    self->discont = FALSE;
+  }
+  if (self->header) {
+    GST_BUFFER_FLAG_SET (buffer, GST_BUFFER_FLAG_HEADER);
+    self->header = FALSE;
+  }
+  /* happen to be a frame boundary */
+  if (frame_complete)
+    GST_BUFFER_FLAG_SET (buffer, GST_BUFFER_FLAG_MARKER);
+
+  GST_LOG_OBJECT (self, "Output one buffer with size %d", consumed);
+  ret = gst_base_parse_finish_frame (parse, frame, consumed);
+  *skipsize = 0;
+
+out:
+  gst_buffer_unmap (buffer, &map_info);
+  gst_buffer_unref (buffer);
+  return ret;
+}
+
+static void
+gst_av1_parse_create_subframe (GstBaseParseFrame * frame,
+    GstBaseParseFrame * subframe, GstBuffer * buffer)
+{
+  gst_base_parse_frame_init (subframe);
+  subframe->flags |= frame->flags;
+  subframe->offset = frame->offset;
+  subframe->overhead = frame->overhead;
+  /* Just ref the input buffer. The base parse will check that
+     pointer, and it will be replaced by its out_buffer later. */
+  subframe->buffer = gst_buffer_ref (buffer);
+}
+
+static GstFlowReturn
+gst_av1_parse_handle_to_small_and_equal_align (GstBaseParse * parse,
+    GstBaseParseFrame * frame, gint * skipsize)
+{
+  GstAV1Parse *self = GST_AV1_PARSE (parse);
+  GstMapInfo map_info;
+  GstAV1OBU obu;
+  GstFlowReturn ret = GST_FLOW_OK;
+  GstAV1ParserResult res = GST_AV1_PARSER_INVALID_OPERATION;
+  GstBuffer *buffer = gst_buffer_ref (frame->buffer);
+  guint32 offset, consumed_before_push, consumed;
+  gboolean frame_complete;
+  GstBaseParseFrame subframe;
+
+  if (!gst_buffer_map (buffer, &map_info, GST_MAP_READ)) {
+    GST_ERROR_OBJECT (parse, "Couldn't map incoming buffer");
+    return GST_FLOW_ERROR;
+  }
+
+  self->buffer_pts = GST_BUFFER_PTS (buffer);
+  self->buffer_dts = GST_BUFFER_DTS (buffer);
+  self->buffer_duration = GST_BUFFER_DURATION (buffer);
+
+  consumed_before_push = 0;
+  offset = 0;
+  frame_complete = FALSE;
+again:
+  while (offset < map_info.size) {
+    GST_BUFFER_OFFSET (buffer) = offset;
+
+    res = gst_av1_parser_identify_one_obu (self->parser,
+        map_info.data + offset, map_info.size - offset, &obu, &consumed);
+    if (res == GST_AV1_PARSER_OK)
+      res = gst_av1_parse_handle_one_obu (self, &obu, &frame_complete, NULL);
+    if (res != GST_AV1_PARSER_OK)
+      break;
+
+    if (obu.obu_type == GST_AV1_OBU_TEMPORAL_DELIMITER
+        && consumed_before_push > 0) {
+      GST_DEBUG_OBJECT (self, "Encounter TD inside one %s aligned"
+          " buffer, should not happen normally.",
+          gst_av1_parse_alignment_to_string (self->in_align));
+
+      if (self->in_align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B)
+        gst_av1_parser_reset_annex_b (self->parser);
+
+      /* Not include this TD obu, it should belong to the next TU or frame,
+         we push all the data we already got. */
+      gst_av1_parse_create_subframe (frame, &subframe, buffer);
+      ret = gst_av1_parse_push_data (self, &subframe,
+          consumed_before_push, TRUE);
+      if (ret != GST_FLOW_OK)
+        goto out;
+
+      /* Begin to find the next. */
+      frame_complete = FALSE;
+      consumed_before_push = 0;
+      continue;
+    }
+
+    gst_av1_parse_cache_one_obu (self, buffer, &obu,
+        map_info.data + offset, consumed, frame_complete);
+
+    offset += consumed;
+    consumed_before_push += consumed;
+
+    if ((self->align == GST_AV1_PARSE_ALIGN_OBU) ||
+        (self->align == GST_AV1_PARSE_ALIGN_FRAME && frame_complete)) {
+      gst_av1_parse_create_subframe (frame, &subframe, buffer);
+      ret = gst_av1_parse_push_data (self, &subframe,
+          consumed_before_push, frame_complete);
+      if (ret != GST_FLOW_OK)
+        goto out;
+
+      /* Begin to find the next. */
+      frame_complete = FALSE;
+      consumed_before_push = 0;
+      continue;
+    }
+  }
+
+  if (res == GST_AV1_PARSER_BITSTREAM_ERROR ||
+      res == GST_AV1_PARSER_MISSING_OBU_REFERENCE) {
+    /* Discard the whole frame */
+    *skipsize = map_info.size;
+    GST_WARNING_OBJECT (parse, "Parse obu error, discard %d", *skipsize);
+    if (self->in_align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B)
+      gst_av1_parser_reset_annex_b (self->parser);
+    gst_av1_parse_reset_obu_data_state (self);
+    ret = GST_FLOW_OK;
+    goto out;
+  } else if (res == GST_AV1_PARSER_NO_MORE_DATA) {
+    /* Discard the whole buffer */
+    *skipsize = map_info.size;
+    GST_WARNING_OBJECT (parse, "Parse obu need more data, discard %d.",
+        *skipsize);
+    if (self->in_align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B)
+      gst_av1_parser_reset_annex_b (self->parser);
+
+    gst_av1_parse_reset_obu_data_state (self);
+    ret = GST_FLOW_OK;
+    goto out;
+  } else if (res == GST_AV1_PARSER_DROP) {
+    GST_DEBUG_OBJECT (parse, "Drop %d data", consumed);
+    offset += consumed;
+    gst_av1_parse_reset_obu_data_state (self);
+    res = GST_AV1_PARSER_OK;
+    goto again;
+  } else if (res != GST_AV1_PARSER_OK) {
+    GST_ERROR_OBJECT (parse, "Parse obu get unexpect error %d", res);
+    *skipsize = 0;
+    ret = GST_FLOW_ERROR;
+    goto out;
+  }
+
+  /* If the total buffer exhausted but frame is not complete, we just
+     push the left data and consider it as a frame. */
+  if (consumed_before_push > 0 && !frame_complete
+      && self->align == GST_AV1_PARSE_ALIGN_FRAME) {
+    g_assert (offset >= map_info.size);
+    /* Warning and still consider the frame is complete */
+    GST_WARNING_OBJECT (self, "Exhaust the buffer but still incomplete frame,"
+        " should not happend in %s alignment",
+        gst_av1_parse_alignment_to_string (self->in_align));
+  }
+
+  ret = gst_av1_parse_push_data (self, frame, consumed_before_push, TRUE);
+
+out:
+  gst_buffer_unmap (buffer, &map_info);
+  gst_buffer_unref (buffer);
+  gst_av1_parse_reset_tu_timestamp (self);
+  return ret;
+}
+
+static GstFlowReturn
+gst_av1_parse_handle_to_big_align (GstBaseParse * parse,
+    GstBaseParseFrame * frame, gint * skipsize)
+{
+  GstAV1Parse *self = GST_AV1_PARSE (parse);
+  GstMapInfo map_info;
+  GstAV1OBU obu;
+  GstFlowReturn ret = GST_FLOW_OK;
+  GstAV1ParserResult res = GST_AV1_PARSER_OK;
+  GstBuffer *buffer = gst_buffer_ref (frame->buffer);
+  guint32 consumed;
+  gboolean frame_complete;
+  gboolean check_new_tu;
+  gboolean complete;
+
+  g_assert (self->in_align <= GST_AV1_PARSE_ALIGN_FRAME);
+
+  if (!gst_buffer_map (buffer, &map_info, GST_MAP_READ)) {
+    *skipsize = 0;
+    GST_ERROR_OBJECT (parse, "Couldn't map incoming buffer");
+    return GST_FLOW_ERROR;
+  }
+
+  complete = FALSE;
+again:
+  while (self->last_parsed_offset < map_info.size) {
+    res = gst_av1_parser_identify_one_obu (self->parser,
+        map_info.data + self->last_parsed_offset,
+        map_info.size - self->last_parsed_offset, &obu, &consumed);
+    if (res != GST_AV1_PARSER_OK)
+      break;
+
+    check_new_tu = FALSE;
+    if (self->align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT
+        || self->align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B) {
+      res = gst_av1_parse_handle_one_obu (self, &obu, &frame_complete,
+          &check_new_tu);
+    } else {
+      res = gst_av1_parse_handle_one_obu (self, &obu, &frame_complete, NULL);
+    }
+    if (res != GST_AV1_PARSER_OK)
+      break;
+
+    if (check_new_tu && (gst_adapter_available (self->cache_out) ||
+            gst_adapter_available (self->frame_cache))) {
+      complete = TRUE;
+      break;
+    }
+
+    if (self->align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT ||
+        self->align == GST_AV1_PARSE_ALIGN_FRAME) {
+      GstBuffer *buf = gst_buffer_copy_region (buffer, GST_BUFFER_COPY_ALL,
+          self->last_parsed_offset, consumed);
+      gst_adapter_push (self->cache_out, buf);
+    } else if (self->align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B) {
+      gst_av1_parse_convert_to_annexb (self, buffer, &obu, frame_complete);
+    } else {
+      g_assert_not_reached ();
+    }
+    self->last_parsed_offset += consumed;
+
+    if (self->align == GST_AV1_PARSE_ALIGN_FRAME && frame_complete)
+      complete = TRUE;
+
+    if (complete)
+      break;
+  }
+
+  /* Finish a complete frame anyway */
+  if (complete || GST_BASE_PARSE_DRAINING (parse)) {
+    *skipsize = 0;
+
+    /* push the left anyway if no error */
+    if (res == GST_AV1_PARSER_OK)
+      ret = gst_av1_parse_push_data (self, frame,
+          self->last_parsed_offset, TRUE);
+
+    self->last_parsed_offset = 0;
+
+    goto out;
+  }
+
+  if (res == GST_AV1_PARSER_BITSTREAM_ERROR ||
+      res == GST_AV1_PARSER_MISSING_OBU_REFERENCE) {
+    *skipsize = map_info.size;
+    GST_WARNING_OBJECT (parse, "Parse obu error, discard whole buffer %d.",
+        *skipsize);
+    /* The adapter will be cleared in next loop because of
+       GST_BASE_PARSE_FRAME_FLAG_NEW_FRAME flag */
+    gst_av1_parse_reset_obu_data_state (self);
+    ret = GST_FLOW_OK;
+  } else if (res == GST_AV1_PARSER_NO_MORE_DATA) {
+    *skipsize = 0;
+
+    if (self->in_align >= GST_AV1_PARSE_ALIGN_OBU) {
+      /* The buffer is already aligned to OBU, should not happen.
+         The adapter will be cleared in next loop because of
+         GST_BASE_PARSE_FRAME_FLAG_NEW_FRAME flag */
+      *skipsize = map_info.size;
+      gst_av1_parse_reset_obu_data_state (self);
+      GST_WARNING_OBJECT (parse,
+          "Parse obu need more data, discard whole buffer %d.", *skipsize);
+    }
+    ret = GST_FLOW_OK;
+  } else if (res == GST_AV1_PARSER_DROP) {
+    GST_DEBUG_OBJECT (parse, "Drop %d data", consumed);
+    self->last_parsed_offset += consumed;
+    gst_av1_parse_reset_obu_data_state (self);
+    res = GST_AV1_PARSER_OK;
+    goto again;
+  } else if (res == GST_AV1_PARSER_OK) {
+    /* Everything is correct but still not get a frame or tu,
+       need more data */
+    GST_DEBUG_OBJECT (parse, "Need more data");
+    *skipsize = 0;
+    ret = GST_FLOW_OK;
+  } else {
+    GST_ERROR_OBJECT (parse, "Parse obu get unexpect error %d", res);
+    *skipsize = 0;
+    ret = GST_FLOW_ERROR;
+  }
+
+out:
+  gst_buffer_unmap (buffer, &map_info);
+  gst_buffer_unref (buffer);
+  return ret;
+}
+
+/* Try to recognize whether the input is annex-b format.
+   return TRUE if we decide, FALSE if we can not decide or
+   encounter some error. */
+static gboolean
+gst_av1_parse_detect_stream_format (GstBaseParse * parse,
+    GstBaseParseFrame * frame)
+{
+  GstAV1Parse *self = GST_AV1_PARSE (parse);
+  GstMapInfo map_info;
+  GstAV1OBU obu;
+  GstAV1ParserResult res = GST_AV1_PARSER_INVALID_OPERATION;
+  GstBuffer *buffer = gst_buffer_ref (frame->buffer);
+  gboolean got_seq, got_frame;
+  gboolean frame_complete;
+  guint32 consumed;
+  guint32 total_consumed;
+  guint32 tu_sz;
+  gboolean ret = FALSE;
+
+  g_assert (self->in_align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT);
+  g_assert (self->detect_annex_b == TRUE);
+
+  if (!gst_buffer_map (buffer, &map_info, GST_MAP_READ)) {
+    GST_ERROR_OBJECT (parse, "Couldn't map incoming buffer");
+    return FALSE;
+  }
+
+  gst_av1_parser_reset (self->parser, FALSE);
+
+  got_seq = FALSE;
+  got_frame = FALSE;
+  total_consumed = 0;
+
+again:
+  while (total_consumed < map_info.size) {
+    res = gst_av1_parser_identify_one_obu (self->parser,
+        map_info.data + total_consumed, map_info.size - total_consumed,
+        &obu, &consumed);
+    if (res == GST_AV1_PARSER_OK) {
+      total_consumed += consumed;
+      res = gst_av1_parse_handle_one_obu (self, &obu, &frame_complete, NULL);
+    }
+
+    if (res != GST_AV1_PARSER_OK)
+      break;
+
+    if (obu.obu_type == GST_AV1_OBU_SEQUENCE_HEADER)
+      got_seq = TRUE;
+
+    if (obu.obu_type == GST_AV1_OBU_REDUNDANT_FRAME_HEADER ||
+        obu.obu_type == GST_AV1_OBU_FRAME ||
+        obu.obu_type == GST_AV1_OBU_FRAME_HEADER)
+      got_frame = TRUE;
+
+    if (got_seq || got_frame)
+      break;
+  }
+
+  gst_av1_parser_reset (self->parser, FALSE);
+
+  /* If succeed recognize seq or frame, it's done.
+     otherwise, just need to get more data. */
+  if (got_seq || got_frame) {
+    ret = TRUE;
+    self->detect_annex_b = FALSE;
+    goto out;
+  }
+
+  if (res == GST_AV1_PARSER_DROP) {
+    total_consumed += consumed;
+    res = GST_AV1_PARSER_OK;
+    gst_av1_parse_reset_obu_data_state (self);
+    goto again;
+  }
+
+  /* Try the annex b format. The buffer should contain the whole TU,
+     and the buffer start with the TU size in leb128() format. */
+  if (map_info.size < 8) {
+    /* Too small. */
+    goto out;
+  }
+
+  tu_sz = _read_leb128 (map_info.data, &res, &consumed);
+  if (tu_sz == 0 || res != GST_AV1_PARSER_OK) {
+    /* error to get the TU size, should not be annex b. */
+    goto out;
+  }
+
+  if (tu_sz + consumed != map_info.size) {
+    GST_DEBUG_OBJECT (self, "Buffer size %" G_GSSIZE_FORMAT ", TU size %d,"
+        " do not match.", map_info.size, tu_sz);
+    goto out;
+  }
+
+  GST_INFO_OBJECT (self, "Detect the annex-b format");
+  self->in_align = GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B;
+  self->detect_annex_b = FALSE;
+  gst_av1_parser_reset (self->parser, TRUE);
+  ret = TRUE;
+
+out:
+  gst_av1_parse_reset_obu_data_state (self);
+  gst_buffer_unmap (buffer, &map_info);
+  gst_buffer_unref (buffer);
+  return ret;
+}
+
+static GstFlowReturn
+gst_av1_parse_handle_frame (GstBaseParse * parse,
+    GstBaseParseFrame * frame, gint * skipsize)
+{
+  GstAV1Parse *self = GST_AV1_PARSE (parse);
+  GstFlowReturn ret = GST_FLOW_OK;
+  guint in_level, out_level;
+
+  if (GST_BUFFER_FLAG_IS_SET (frame->buffer, GST_BUFFER_FLAG_DISCONT)) {
+    self->discont = TRUE;
+
+    if (frame->flags & GST_BASE_PARSE_FRAME_FLAG_NEW_FRAME)
+      gst_av1_parse_reset_obu_data_state (self);
+  } else {
+    self->discont = FALSE;
+  }
+
+  GST_LOG_OBJECT (self, "Input frame size %" G_GSSIZE_FORMAT,
+      gst_buffer_get_size (frame->buffer));
+
+  /* avoid stale cached parsing state */
+  if (frame->flags & GST_BASE_PARSE_FRAME_FLAG_NEW_FRAME) {
+    GST_LOG_OBJECT (self, "parsing new frame");
+    gst_adapter_clear (self->cache_out);
+    gst_adapter_clear (self->frame_cache);
+    self->last_parsed_offset = 0;
+    self->header = FALSE;
+    self->keyframe = FALSE;
+    self->show_frame = FALSE;
+  } else {
+    GST_LOG_OBJECT (self, "resuming frame parsing");
+  }
+
+  /* When in pull mode, the sink pad has no caps, we may get the
+     caps by query the upstream element */
+  if (self->in_align == GST_AV1_PARSE_ALIGN_NONE) {
+    GstCaps *upstream_caps;
+
+    upstream_caps =
+        gst_pad_peer_query_caps (GST_BASE_PARSE_SINK_PAD (self), NULL);
+    if (upstream_caps) {
+      if (!gst_caps_is_empty (upstream_caps)
+          && !gst_caps_is_any (upstream_caps)) {
+        GstAV1ParseAligment align;
+
+        GST_LOG_OBJECT (self, "upstream caps: %" GST_PTR_FORMAT, upstream_caps);
+
+        /* fixate to avoid ambiguity with lists when parsing */
+        upstream_caps = gst_caps_fixate (upstream_caps);
+        align = gst_av1_parse_alignment_from_caps (upstream_caps);
+        if (align == GST_AV1_PARSE_ALIGN_ERROR) {
+          GST_ERROR_OBJECT (self, "upstream caps %" GST_PTR_FORMAT
+              " set stream-format and alignment conflict.", upstream_caps);
+
+          gst_caps_unref (upstream_caps);
+          return GST_FLOW_ERROR;
+        }
+
+        self->in_align = align;
+      }
+
+      gst_caps_unref (upstream_caps);
+
+      gst_av1_parser_reset (self->parser,
+          self->in_align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B);
+    }
+
+    if (self->in_align != GST_AV1_PARSE_ALIGN_NONE) {
+      GST_LOG_OBJECT (self, "Query the upstream get the alignment %s",
+          gst_av1_parse_alignment_to_string (self->in_align));
+    } else {
+      self->in_align = GST_AV1_PARSE_ALIGN_BYTE;
+      GST_DEBUG_OBJECT (self, "alignment set to default %s",
+          gst_av1_parse_alignment_to_string (GST_AV1_PARSE_ALIGN_BYTE));
+    }
+  }
+
+  if (self->in_align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT
+      && self->detect_annex_b) {
+    /* Only happend at the first time of handle_frame, try to
+       recognize the annex b stream format. */
+    if (gst_av1_parse_detect_stream_format (parse, frame)) {
+      GST_INFO_OBJECT (self, "Input alignment %s",
+          gst_av1_parse_alignment_to_string (self->in_align));
+    } else {
+      /* Because the input is already TU aligned, we should skip
+         the whole problematic TU and check the next one. */
+      *skipsize = gst_buffer_get_size (frame->buffer);
+      GST_WARNING_OBJECT (self, "Fail to detect the stream format for TU,"
+          " skip the whole TU %d", *skipsize);
+      return GST_FLOW_OK;
+    }
+  }
+
+  /* We may in pull mode and no caps is set */
+  if (self->align == GST_AV1_PARSE_ALIGN_NONE)
+    gst_av1_parse_negotiate (self, NULL);
+
+  in_level = self->in_align;
+  if (self->in_align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B)
+    in_level = GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT;
+  out_level = self->align;
+  if (self->align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B)
+    out_level = GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT;
+
+  if (self->in_align <= GST_AV1_PARSE_ALIGN_OBU
+      && self->align == GST_AV1_PARSE_ALIGN_OBU) {
+    ret = gst_av1_parse_handle_obu_to_obu (parse, frame, skipsize);
+  } else if (in_level < out_level) {
+    ret = gst_av1_parse_handle_to_big_align (parse, frame, skipsize);
+  } else {
+    ret = gst_av1_parse_handle_to_small_and_equal_align (parse,
+        frame, skipsize);
+  }
+
+  return ret;
+}
+
+static GstFlowReturn
+gst_av1_parse_pre_push_frame (GstBaseParse * parse, GstBaseParseFrame * frame)
+{
+  GstAV1Parse *self = GST_AV1_PARSE (parse);
+
+  frame->flags |= GST_BASE_PARSE_FRAME_FLAG_CLIP;
+
+  if (!frame->buffer)
+    return GST_FLOW_OK;
+
+  if (self->align == GST_AV1_PARSE_ALIGN_FRAME) {
+    /* When the input align to TU, it may may contain more than one frames
+       inside its buffer. When splitting a TU into frames, the base parse
+       class only assign the PTS to the first frame and leave the others'
+       PTS invalid. But in fact, all decode only frames should have invalid
+       PTS while showable frames should have correct PTS setting. */
+    if (self->in_align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT
+        || self->in_align == GST_AV1_PARSE_ALIGN_TEMPORAL_UNIT_ANNEX_B) {
+      if (GST_BUFFER_FLAG_IS_SET (frame->buffer, GST_BUFFER_FLAG_DECODE_ONLY)) {
+        GST_BUFFER_PTS (frame->buffer) = GST_CLOCK_TIME_NONE;
+        GST_BUFFER_DURATION (frame->buffer) = GST_CLOCK_TIME_NONE;
+      } else {
+        GST_BUFFER_PTS (frame->buffer) = self->buffer_pts;
+        GST_BUFFER_DURATION (frame->buffer) = self->buffer_duration;
+      }
+
+      GST_BUFFER_DTS (frame->buffer) = self->buffer_dts;
+    } else {
+      if (GST_BUFFER_FLAG_IS_SET (frame->buffer, GST_BUFFER_FLAG_DECODE_ONLY)) {
+        GST_BUFFER_PTS (frame->buffer) = GST_CLOCK_TIME_NONE;
+        GST_BUFFER_DURATION (frame->buffer) = GST_CLOCK_TIME_NONE;
+      }
+    }
+  } else if (self->align == GST_AV1_PARSE_ALIGN_OBU) {
+    /* When we split a big frame or TU into OBUs, all OBUs should have the
+       same PTS and DTS of the input buffer, and should not have duration. */
+    if (self->in_align >= GST_AV1_PARSE_ALIGN_FRAME) {
+      GST_BUFFER_PTS (frame->buffer) = self->buffer_pts;
+      GST_BUFFER_DTS (frame->buffer) = self->buffer_dts;
+      GST_BUFFER_DURATION (frame->buffer) = GST_CLOCK_TIME_NONE;
+    }
+  }
+
+  GST_LOG_OBJECT (parse, "Adjust the frame buffer PTS/DTS/duration."
+      " The buffer of size %" G_GSIZE_FORMAT " now with dts %"
+      GST_TIME_FORMAT ", pts %" GST_TIME_FORMAT ", duration %"
+      GST_TIME_FORMAT, gst_buffer_get_size (frame->buffer),
+      GST_TIME_ARGS (GST_BUFFER_DTS (frame->buffer)),
+      GST_TIME_ARGS (GST_BUFFER_PTS (frame->buffer)),
+      GST_TIME_ARGS (GST_BUFFER_DURATION (frame->buffer)));
+
+  return GST_FLOW_OK;
+}
diff --git a/gst/videoparsers/gstav1parse.h b/gst/videoparsers/gstav1parse.h
new file mode 100644
index 000000000..464658e1b
--- /dev/null
+++ b/gst/videoparsers/gstav1parse.h
@@ -0,0 +1,34 @@
+/* GStreamer
+ * Copyright (C) 2020 He Junyan <junyan.he@intel.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef __GST_AV1_PARSE_H__
+#define __GST_AV1_PARSE_H__
+
+#include <gst/gst.h>
+#include <gst/base/gstbaseparse.h>
+
+G_BEGIN_DECLS
+
+#define GST_TYPE_AV1_PARSE (gst_av1_parse_get_type())
+G_DECLARE_FINAL_TYPE (GstAV1Parse,
+    gst_av1_parse, GST, AV1_PARSE, GstBaseParse);
+
+G_END_DECLS
+
+#endif /* __GST_AV1_PARSE_H__ */
diff --git a/gst/videoparsers/gstdiracparse.c b/gst/videoparsers/gstdiracparse.c
index 105f4f499..d7a0c92fd 100644
--- a/gst/videoparsers/gstdiracparse.c
+++ b/gst/videoparsers/gstdiracparse.c
@@ -38,6 +38,7 @@
 #include <gst/base/base.h>
 #include <gst/pbutils/pbutils.h>
 #include <string.h>
+#include "gstvideoparserselements.h"
 #include "gstdiracparse.h"
 #include "dirac_parse.h"
 
@@ -96,6 +97,8 @@ GST_STATIC_PAD_TEMPLATE ("src",
 
 #define parent_class gst_dirac_parse_parent_class
 G_DEFINE_TYPE (GstDiracParse, gst_dirac_parse, GST_TYPE_BASE_PARSE);
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (diracparse, "diracparse", GST_RANK_NONE,
+    GST_TYPE_DIRAC_PARSE, videoparsers_element_init (plugin));
 
 static void
 gst_dirac_parse_class_init (GstDiracParseClass * klass)
diff --git a/gst/videoparsers/gsth263parse.c b/gst/videoparsers/gsth263parse.c
index 0f4d42ee7..d2c1e4954 100644
--- a/gst/videoparsers/gsth263parse.c
+++ b/gst/videoparsers/gsth263parse.c
@@ -31,6 +31,7 @@
 
 #include <gst/base/base.h>
 #include <gst/pbutils/pbutils.h>
+#include "gstvideoparserselements.h"
 #include "gsth263parse.h"
 
 #include <string.h>
@@ -53,6 +54,9 @@ GST_STATIC_PAD_TEMPLATE ("sink", GST_PAD_SINK,
 
 #define parent_class gst_h263_parse_parent_class
 G_DEFINE_TYPE (GstH263Parse, gst_h263_parse, GST_TYPE_BASE_PARSE);
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (h263parse, "h263parse",
+    GST_RANK_PRIMARY + 1, GST_TYPE_H263_PARSE,
+    videoparsers_element_init (plugin));
 
 static gboolean gst_h263_parse_start (GstBaseParse * parse);
 static gboolean gst_h263_parse_stop (GstBaseParse * parse);
diff --git a/gst/videoparsers/gsth264parse.c b/gst/videoparsers/gsth264parse.c
index 6260a5f23..e08e3f00f 100644
--- a/gst/videoparsers/gsth264parse.c
+++ b/gst/videoparsers/gsth264parse.c
@@ -29,6 +29,7 @@
 #include <gst/base/base.h>
 #include <gst/pbutils/pbutils.h>
 #include <gst/video/video.h>
+#include "gstvideoparserselements.h"
 #include "gsth264parse.h"
 
 #include <string.h>
@@ -98,6 +99,9 @@ static GstStaticPadTemplate srctemplate = GST_STATIC_PAD_TEMPLATE ("src",
 
 #define parent_class gst_h264_parse_parent_class
 G_DEFINE_TYPE (GstH264Parse, gst_h264_parse, GST_TYPE_BASE_PARSE);
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (h264parse, "h264parse",
+    GST_RANK_PRIMARY + 1, GST_TYPE_H264_PARSE,
+    videoparsers_element_init (plugin));
 
 static void gst_h264_parse_finalize (GObject * object);
 
@@ -167,7 +171,7 @@ gst_h264_parse_class_init (GstH264ParseClass * klass)
           "is attached to incoming buffer and also Picture Timing SEI exists "
           "in the bitstream. To make this property work, SPS must contain "
           "VUI and pic_struct_present_flag of VUI must be non-zero",
-          DEFAULT_CONFIG_INTERVAL, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+          DEFAULT_UPDATE_TIMECODE, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
 
   /* Override BaseParse vfuncs */
   parse_class->start = GST_DEBUG_FUNCPTR (gst_h264_parse_start);
@@ -200,7 +204,7 @@ gst_h264_parse_init (GstH264Parse * h264parse)
 
   h264parse->aud_needed = TRUE;
   h264parse->aud_insert = TRUE;
-  h264parse->update_timecode = FALSE;
+  h264parse->update_timecode = DEFAULT_UPDATE_TIMECODE;
 }
 
 static void
@@ -208,6 +212,8 @@ gst_h264_parse_finalize (GObject * object)
 {
   GstH264Parse *h264parse = GST_H264_PARSE (object);
 
+  gst_video_user_data_unregistered_clear (&h264parse->user_data_unregistered);
+
   g_object_unref (h264parse->frame_out);
 
   G_OBJECT_CLASS (parent_class)->finalize (object);
@@ -233,6 +239,7 @@ gst_h264_parse_reset_frame (GstH264Parse * h264parse)
   h264parse->frame_start = FALSE;
   h264parse->have_sps_in_frame = FALSE;
   h264parse->have_pps_in_frame = FALSE;
+  h264parse->have_aud_in_frame = FALSE;
   gst_adapter_clear (h264parse->frame_out);
 }
 
@@ -601,6 +608,21 @@ gst_h264_parse_process_sei_user_data (GstH264Parse * h264parse,
 
 }
 
+static void
+gst_h264_parse_process_sei_user_data_unregistered (GstH264Parse * h264parse,
+    GstH264UserDataUnregistered * urud)
+{
+  GstByteReader br;
+
+  if (urud->data == NULL || urud->size < 1)
+    return;
+
+  gst_byte_reader_init (&br, urud->data, urud->size);
+
+  gst_video_parse_user_data_unregistered ((GstElement *) h264parse,
+      &h264parse->user_data_unregistered, &br, urud->uuid);
+}
+
 static void
 gst_h264_parse_process_sei (GstH264Parse * h264parse, GstH264NalUnit * nalu)
 {
@@ -659,6 +681,10 @@ gst_h264_parse_process_sei (GstH264Parse * h264parse, GstH264NalUnit * nalu)
         gst_h264_parse_process_sei_user_data (h264parse,
             &sei.payload.registered_user_data);
         break;
+      case GST_H264_SEI_USER_DATA_UNREGISTERED:
+        gst_h264_parse_process_sei_user_data_unregistered (h264parse,
+            &sei.payload.user_data_unregistered);
+        break;
       case GST_H264_SEI_BUF_PERIOD:
         if (h264parse->ts_trn_nb == GST_CLOCK_TIME_NONE ||
             h264parse->dts == GST_CLOCK_TIME_NONE)
@@ -1126,6 +1152,7 @@ gst_h264_parse_process_nal (GstH264Parse * h264parse, GstH264NalUnit * nalu)
       if (pres != GST_H264_PARSER_OK)
         return FALSE;
       h264parse->aud_needed = FALSE;
+      h264parse->have_aud_in_frame = TRUE;
       break;
     default:
       /* drop anything before the initial SPS */
@@ -1227,8 +1254,9 @@ gst_h264_parse_handle_frame_packetized (GstBaseParse * parse,
   parse_res = gst_h264_parser_identify_nalu_avc (h264parse->nalparser,
       map.data, 0, map.size, nl, &nalu);
 
-  /* there is no AUD in AVC, always enable insertion, the pre_push function
-   * will only add it once, and will only add it for byte-stream output. */
+  /* Always enable AUD insertion per frame here. The pre_push function
+   * will only add it once, and will only add it for byte-stream output
+   * if AUD doesn't exist in the current frame */
   h264parse->aud_insert = TRUE;
 
   while (parse_res == GST_H264_PARSER_OK) {
@@ -1247,6 +1275,10 @@ gst_h264_parse_handle_frame_packetized (GstBaseParse * parse,
       tmp_frame.overhead = frame->overhead;
       tmp_frame.buffer = gst_buffer_copy_region (buffer, GST_BUFFER_COPY_ALL,
           nalu.offset, nalu.size);
+      /* Don't lose timestamp when offset is not 0. */
+      GST_BUFFER_PTS (tmp_frame.buffer) = GST_BUFFER_PTS (buffer);
+      GST_BUFFER_DTS (tmp_frame.buffer) = GST_BUFFER_DTS (buffer);
+      GST_BUFFER_DURATION (tmp_frame.buffer) = GST_BUFFER_DURATION (buffer);
 
       /* Set marker on last packet */
       if (nl + nalu.size == left) {
@@ -2114,16 +2146,20 @@ gst_h264_parse_update_src_caps (GstH264Parse * h264parse, GstCaps * caps)
       GstVideoColorimetry ci = { 0, };
       gchar *old_colorimetry = NULL;
 
-      if (vui->video_full_range_flag)
-        ci.range = GST_VIDEO_COLOR_RANGE_0_255;
-      else
-        ci.range = GST_VIDEO_COLOR_RANGE_16_235;
-
       ci.matrix = gst_video_color_matrix_from_iso (vui->matrix_coefficients);
       ci.transfer =
           gst_video_transfer_function_from_iso (vui->transfer_characteristics);
       ci.primaries = gst_video_color_primaries_from_iso (vui->colour_primaries);
 
+      if (ci.matrix != GST_VIDEO_COLOR_MATRIX_UNKNOWN
+          && ci.transfer != GST_VIDEO_TRANSFER_UNKNOWN
+          && ci.primaries != GST_VIDEO_COLOR_PRIMARIES_UNKNOWN) {
+        if (vui->video_full_range_flag)
+          ci.range = GST_VIDEO_COLOR_RANGE_0_255;
+        else
+          ci.range = GST_VIDEO_COLOR_RANGE_16_235;
+      }
+
       old_colorimetry =
           gst_video_colorimetry_to_string (&h264parse->parsed_colorimetry);
       colorimetry = gst_video_colorimetry_to_string (&ci);
@@ -2148,6 +2184,7 @@ gst_h264_parse_update_src_caps (GstH264Parse * h264parse, GstCaps * caps)
       GstVideoMultiviewFlags mview_flags = h264parse->multiview_flags;
       const gchar *chroma_format = NULL;
       guint bit_depth_chroma;
+      const gchar *coded_picture_structure;
 
       fps_num = h264parse->fps_num;
       fps_den = h264parse->fps_den;
@@ -2213,8 +2250,6 @@ gst_h264_parse_update_src_caps (GstH264Parse * h264parse, GstCaps * caps)
         s2 = gst_caps_get_structure (caps, 0);
         gst_structure_get_fraction (s2, "framerate", &h264parse->parsed_fps_n,
             &h264parse->parsed_fps_d);
-        gst_base_parse_set_frame_rate (GST_BASE_PARSE (h264parse), fps_num,
-            fps_den, 0, 0);
 
         /* If we know the frame duration, and if we are not in one of the zero
          * latency pattern, add one frame of latency */
@@ -2228,6 +2263,15 @@ gst_h264_parse_update_src_caps (GstH264Parse * h264parse, GstCaps * caps)
             latency);
       }
 
+      if (sps->frame_mbs_only_flag == 1) {
+        coded_picture_structure = "frame";
+      } else {
+        coded_picture_structure = "field";
+      }
+
+      gst_caps_set_simple (caps, "coded-picture-structure", G_TYPE_STRING,
+          coded_picture_structure, NULL);
+
       bit_depth_chroma = sps->bit_depth_chroma_minus8 + 8;
 
       switch (sps->chroma_format_idc) {
@@ -2401,6 +2445,96 @@ gst_h264_parse_update_src_caps (GstH264Parse * h264parse, GstCaps * caps)
     gst_buffer_unref (buf);
 }
 
+static GstClockTime
+gst_h264_parse_get_duration (GstH264Parse * h264parse, gboolean frame)
+{
+  GstClockTime ret = GST_CLOCK_TIME_NONE;
+  GstH264SPS *sps = h264parse->nalparser->last_sps;
+  gint duration = 1;
+
+  if (!frame) {
+    GST_LOG_OBJECT (h264parse, "no frame data -> 0 duration");
+    ret = 0;
+    goto done;
+  }
+
+  if (!sps) {
+    GST_DEBUG_OBJECT (h264parse, "referred SPS invalid");
+    goto fps_duration;
+  } else if (!sps->vui_parameters_present_flag) {
+    GST_DEBUG_OBJECT (h264parse, "unable to compute duration: VUI not present");
+    goto fps_duration;
+  } else if (!sps->vui_parameters.timing_info_present_flag) {
+    GST_DEBUG_OBJECT (h264parse,
+        "unable to compute duration: timing info not present");
+    goto fps_duration;
+  } else if (sps->vui_parameters.time_scale == 0) {
+    GST_DEBUG_OBJECT (h264parse,
+        "unable to compute duration: time_scale = 0 "
+        "(this is forbidden in spec; bitstream probably contains error)");
+    goto fps_duration;
+  }
+
+  if (h264parse->sei_pic_struct_pres_flag &&
+      h264parse->sei_pic_struct != (guint8) - 1) {
+    /* Note that when h264parse->sei_pic_struct == -1 (unspecified), there
+     * are ways to infer its value. This is related to computing the
+     * TopFieldOrderCnt and BottomFieldOrderCnt, which looks
+     * complicated and thus not implemented for the time being. Yet
+     * the value we have here is correct for many applications
+     */
+    switch (h264parse->sei_pic_struct) {
+      case GST_H264_SEI_PIC_STRUCT_TOP_FIELD:
+      case GST_H264_SEI_PIC_STRUCT_BOTTOM_FIELD:
+        duration = 1;
+        break;
+      case GST_H264_SEI_PIC_STRUCT_FRAME:
+      case GST_H264_SEI_PIC_STRUCT_TOP_BOTTOM:
+      case GST_H264_SEI_PIC_STRUCT_BOTTOM_TOP:
+        duration = 2;
+        break;
+      case GST_H264_SEI_PIC_STRUCT_TOP_BOTTOM_TOP:
+      case GST_H264_SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM:
+        duration = 3;
+        break;
+      case GST_H264_SEI_PIC_STRUCT_FRAME_DOUBLING:
+        duration = 4;
+        break;
+      case GST_H264_SEI_PIC_STRUCT_FRAME_TRIPLING:
+        duration = 6;
+        break;
+      default:
+        GST_DEBUG_OBJECT (h264parse,
+            "h264parse->sei_pic_struct of unknown value %d. Not parsed",
+            h264parse->sei_pic_struct);
+        break;
+    }
+  } else {
+    duration = h264parse->field_pic_flag ? 1 : 2;
+  }
+
+  GST_LOG_OBJECT (h264parse, "frame tick duration %d", duration);
+
+  ret = gst_util_uint64_scale (duration * GST_SECOND,
+      sps->vui_parameters.num_units_in_tick, sps->vui_parameters.time_scale);
+  /* sanity check */
+  if (ret < GST_MSECOND) {
+    GST_DEBUG_OBJECT (h264parse, "discarding dur %" GST_TIME_FORMAT,
+        GST_TIME_ARGS (ret));
+    goto fps_duration;
+  }
+
+done:
+  return ret;
+
+fps_duration:
+  if (h264parse->parsed_fps_d > 0 && h264parse->parsed_fps_n > 0)
+    ret =
+        gst_util_uint64_scale (GST_SECOND, h264parse->parsed_fps_d,
+        h264parse->parsed_fps_n);
+  goto done;
+}
+
 static void
 gst_h264_parse_get_timestamp (GstH264Parse * h264parse,
     GstClockTime * out_ts, GstClockTime * out_dur, gboolean frame)
@@ -2547,10 +2681,19 @@ gst_h264_parse_parse_frame (GstBaseParse * parse, GstBaseParseFrame * frame)
 
   /* don't mess with timestamps if provided by upstream,
    * particularly since our ts not that good they handle seeking etc */
-  if (h264parse->do_ts)
+  if (h264parse->do_ts) {
     gst_h264_parse_get_timestamp (h264parse,
         &GST_BUFFER_DTS (buffer), &GST_BUFFER_DURATION (buffer),
         h264parse->frame_start);
+  }
+
+  /* We don't want to let baseparse select a duration itself based
+   * solely on the framerate, as we have more per-frame information
+   * available */
+  if (!GST_CLOCK_TIME_IS_VALID (GST_BUFFER_DURATION (buffer))) {
+    GST_BUFFER_DURATION (buffer) =
+        gst_h264_parse_get_duration (h264parse, h264parse->frame_start);
+  }
 
   if (h264parse->keyframe)
     GST_BUFFER_FLAG_UNSET (buffer, GST_BUFFER_FLAG_DELTA_UNIT);
@@ -2841,16 +2984,16 @@ gst_h264_parse_create_pic_timing_sei (GstH264Parse * h264parse,
 
   num_clock_ts = num_clock_ts_table[h264parse->sei_pic_struct];
 
-  if (num_meta != num_clock_ts) {
+  if (num_meta > num_clock_ts) {
     GST_LOG_OBJECT (h264parse,
-        "The number of timecode meta %d is not equal to required %d",
+        "The number of timecode meta %d is superior to required %d",
         num_meta, num_clock_ts);
 
     return NULL;
   }
 
   GST_LOG_OBJECT (h264parse,
-      "The number of timecode meta %d is equal", num_meta);
+      "The number of timecode meta %d is compatible", num_meta);
 
   memset (&sei, 0, sizeof (GstH264SEIMessage));
   sei.payloadType = GST_H264_SEI_PIC_TIMING;
@@ -3014,7 +3157,8 @@ gst_h264_parse_pre_push_frame (GstBaseParse * parse, GstBaseParseFrame * frame)
 
   /* In case of byte-stream, insert au delimiter by default
    * if it doesn't exist */
-  if (h264parse->aud_insert && h264parse->format == GST_H264_PARSE_FORMAT_BYTE) {
+  if (h264parse->aud_insert && !h264parse->have_aud_in_frame &&
+      h264parse->format == GST_H264_PARSE_FORMAT_BYTE) {
     GST_DEBUG_OBJECT (h264parse, "Inserting AUD into the stream.");
     if (h264parse->align == GST_H264_PARSE_ALIGN_AU) {
       GstMemory *mem =
@@ -3134,7 +3278,14 @@ gst_h264_parse_pre_push_frame (GstBaseParse * parse, GstBaseParseFrame * frame)
   }
 #endif
 
-  if (!gst_buffer_get_video_time_code_meta (buffer)) {
+  if (frame->out_buffer) {
+    parse_buffer = frame->out_buffer =
+        gst_buffer_make_writable (frame->out_buffer);
+  } else {
+    parse_buffer = frame->buffer = gst_buffer_make_writable (frame->buffer);
+  }
+
+  if (!gst_buffer_get_video_time_code_meta (parse_buffer)) {
     guint i = 0;
 
     for (i = 0; i < 3 && h264parse->num_clock_timestamp; i++) {
@@ -3197,7 +3348,7 @@ gst_h264_parse_pre_push_frame (GstBaseParse * parse, GstBaseParseFrame * frame)
           "Add time code meta %02u:%02u:%02u:%02u",
           tim->hours_value, tim->minutes_value, tim->seconds_value, n_frames);
 
-      gst_buffer_add_video_time_code_meta_full (buffer,
+      gst_buffer_add_video_time_code_meta_full (parse_buffer,
           h264parse->parsed_fps_n,
           h264parse->parsed_fps_d,
           NULL,
@@ -3210,13 +3361,6 @@ gst_h264_parse_pre_push_frame (GstBaseParse * parse, GstBaseParseFrame * frame)
     h264parse->num_clock_timestamp = 0;
   }
 
-  if (frame->out_buffer) {
-    parse_buffer = frame->out_buffer =
-        gst_buffer_make_writable (frame->out_buffer);
-  } else {
-    parse_buffer = frame->buffer = gst_buffer_make_writable (frame->buffer);
-  }
-
   if (is_interlaced) {
     GST_BUFFER_FLAG_SET (parse_buffer, GST_VIDEO_BUFFER_FLAG_INTERLACED);
     if (h264parse->sei_pic_struct == GST_H264_SEI_PIC_STRUCT_TOP_FIELD)
@@ -3226,6 +3370,9 @@ gst_h264_parse_pre_push_frame (GstBaseParse * parse, GstBaseParseFrame * frame)
   gst_video_push_user_data ((GstElement *) h264parse, &h264parse->user_data,
       parse_buffer);
 
+  gst_video_push_user_data_unregistered ((GstElement *) h264parse,
+      &h264parse->user_data_unregistered, parse_buffer);
+
   gst_h264_parse_reset_frame (h264parse);
 
   return GST_FLOW_OK;
@@ -3238,11 +3385,11 @@ gst_h264_parse_set_caps (GstBaseParse * parse, GstCaps * caps)
   GstStructure *str;
   const GValue *codec_data_value;
   GstBuffer *codec_data = NULL;
-  gsize size;
-  guint format, align, off;
-  GstH264NalUnit nalu;
+  guint format, align;
+  GstH264NalUnit *nalu;
   GstH264ParserResult parseres;
   GstCaps *old_caps;
+  GstH264DecoderConfigRecord *config = NULL;
 
   h264parse = GST_H264_PARSE (parse);
 
@@ -3307,12 +3454,7 @@ gst_h264_parse_set_caps (GstBaseParse * parse, GstCaps * caps)
   /* packetized video has codec_data (required for AVC, optional for AVC3) */
   if (codec_data_value != NULL) {
     GstMapInfo map;
-    guint8 *data;
-    guint num_sps, num_pps;
-#ifndef GST_DISABLE_GST_DEBUG
-    guint profile;
-#endif
-    gint i;
+    guint i;
 
     GST_DEBUG_OBJECT (h264parse, "have packetized h264");
     /* make note for optional split processing */
@@ -3326,67 +3468,36 @@ gst_h264_parse_set_caps (GstBaseParse * parse, GstCaps * caps)
     if (!codec_data)
       goto avc_caps_codec_data_missing;
     gst_buffer_map (codec_data, &map, GST_MAP_READ);
-    data = map.data;
-    size = map.size;
 
-    /* parse the avcC data */
-    if (size < 7) {             /* when numSPS==0 and numPPS==0, length is 7 bytes */
-      gst_buffer_unmap (codec_data, &map);
-      goto avcc_too_small;
-    }
-    /* parse the version, this must be 1 */
-    if (data[0] != 1) {
+    parseres =
+        gst_h264_parser_parse_decoder_config_record (h264parse->nalparser,
+        map.data, map.size, &config);
+    if (parseres != GST_H264_PARSER_OK) {
       gst_buffer_unmap (codec_data, &map);
-      goto wrong_version;
+      goto avcC_failed;
     }
-#ifndef GST_DISABLE_GST_DEBUG
-    /* AVCProfileIndication */
-    /* profile_compat */
-    /* AVCLevelIndication */
-    profile = (data[1] << 16) | (data[2] << 8) | data[3];
-    GST_DEBUG_OBJECT (h264parse, "profile %06x", profile);
-#endif
 
-    /* 6 bits reserved | 2 bits lengthSizeMinusOne */
-    /* this is the number of bytes in front of the NAL units to mark their
-     * length */
-    h264parse->nal_length_size = (data[4] & 0x03) + 1;
+    h264parse->nal_length_size = config->length_size_minus_one + 1;
     GST_DEBUG_OBJECT (h264parse, "nal length size %u",
         h264parse->nal_length_size);
+    GST_DEBUG_OBJECT (h264parse, "AVCProfileIndication %d",
+        config->profile_indication);
+    GST_DEBUG_OBJECT (h264parse, "profile_compatibility %d",
+        config->profile_compatibility);
+    GST_DEBUG_OBJECT (h264parse, "AVCLevelIndication %d",
+        config->level_indication);
 
-    num_sps = data[5] & 0x1f;
-    off = 6;
-    for (i = 0; i < num_sps; i++) {
-      parseres = gst_h264_parser_identify_nalu_avc (h264parse->nalparser,
-          data, off, size, 2, &nalu);
-      if (parseres != GST_H264_PARSER_OK) {
-        gst_buffer_unmap (codec_data, &map);
-        goto avcc_too_small;
-      }
-
-      gst_h264_parse_process_nal (h264parse, &nalu);
-      off = nalu.offset + nalu.size;
+    for (i = 0; i < config->sps->len; i++) {
+      nalu = &g_array_index (config->sps, GstH264NalUnit, i);
+      gst_h264_parse_process_nal (h264parse, nalu);
     }
 
-    if (off >= size) {
-      gst_buffer_unmap (codec_data, &map);
-      goto avcc_too_small;
-    }
-    num_pps = data[off];
-    off++;
-
-    for (i = 0; i < num_pps; i++) {
-      parseres = gst_h264_parser_identify_nalu_avc (h264parse->nalparser,
-          data, off, size, 2, &nalu);
-      if (parseres != GST_H264_PARSER_OK) {
-        gst_buffer_unmap (codec_data, &map);
-        goto avcc_too_small;
-      }
-
-      gst_h264_parse_process_nal (h264parse, &nalu);
-      off = nalu.offset + nalu.size;
+    for (i = 0; i < config->pps->len; i++) {
+      nalu = &g_array_index (config->pps, GstH264NalUnit, i);
+      gst_h264_parse_process_nal (h264parse, nalu);
     }
 
+    gst_h264_decoder_config_record_free (config);
     gst_buffer_unmap (codec_data, &map);
 
     gst_buffer_replace (&h264parse->codec_data_in, codec_data);
@@ -3461,14 +3572,9 @@ bytestream_caps_with_codec_data:
         "expected, send SPS/PPS in-band with data or in streamheader field");
     goto refuse_caps;
   }
-avcc_too_small:
-  {
-    GST_DEBUG_OBJECT (h264parse, "avcC size %" G_GSIZE_FORMAT " < 8", size);
-    goto refuse_caps;
-  }
-wrong_version:
+avcC_failed:
   {
-    GST_DEBUG_OBJECT (h264parse, "wrong avcC version");
+    GST_DEBUG_OBJECT (h264parse, "Failed to parse avcC data");
     goto refuse_caps;
   }
 refuse_caps:
diff --git a/gst/videoparsers/gsth264parse.h b/gst/videoparsers/gsth264parse.h
index c526defdd..1275dddf5 100644
--- a/gst/videoparsers/gsth264parse.h
+++ b/gst/videoparsers/gsth264parse.h
@@ -92,6 +92,16 @@ struct _GstH264Parse
   gboolean have_sps_in_frame;
   gboolean have_pps_in_frame;
 
+  /* per frame AU Delimiter check used when in_format == avc or avc3 */
+  gboolean have_aud_in_frame;
+
+  /* tracing state whether h264parse needs to insert AUD or not.
+   * Used when in_format == byte-stream */
+  gboolean aud_needed;
+
+  /* For insertion of AU Delimiter */
+  gboolean aud_insert;
+
   gboolean first_frame;
 
   /* collected SPS and PPS NALUs */
@@ -146,11 +156,8 @@ struct _GstH264Parse
   GstVideoMultiviewFlags multiview_flags;
   gboolean first_in_bundle;
 
-  /* For insertion of AU Delimiter */
-  gboolean aud_needed;
-  gboolean aud_insert;
-
   GstVideoParseUserData user_data;
+  GstVideoParseUserDataUnregistered user_data_unregistered;
 
   GstVideoMasteringDisplayInfo mastering_display_info;
   guint mastering_display_info_state;
diff --git a/gst/videoparsers/gsth265parse.c b/gst/videoparsers/gsth265parse.c
index 32f23d875..356385c37 100644
--- a/gst/videoparsers/gsth265parse.c
+++ b/gst/videoparsers/gsth265parse.c
@@ -24,6 +24,7 @@
 
 #include <gst/base/base.h>
 #include <gst/pbutils/pbutils.h>
+#include "gstvideoparserselements.h"
 #include "gsth265parse.h"
 
 #include <string.h>
@@ -91,6 +92,9 @@ static GstStaticPadTemplate srctemplate = GST_STATIC_PAD_TEMPLATE ("src",
 
 #define parent_class gst_h265_parse_parent_class
 G_DEFINE_TYPE (GstH265Parse, gst_h265_parse, GST_TYPE_BASE_PARSE);
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (h265parse, "h265parse",
+    GST_RANK_SECONDARY, GST_TYPE_H265_PARSE,
+    videoparsers_element_init (plugin));
 
 static void gst_h265_parse_finalize (GObject * object);
 
@@ -793,14 +797,8 @@ gst_h265_parse_process_nal (GstH265Parse * h265parse, GstH265NalUnit * nalu)
       h265parse->state |= GST_H265_PARSE_STATE_GOT_SPS;
       break;
     case GST_H265_NAL_PPS:
-      /* expected state: got-sps */
-      h265parse->state &= GST_H265_PARSE_STATE_GOT_SPS;
-      if (!GST_H265_PARSE_STATE_VALID (h265parse, GST_H265_PARSE_STATE_GOT_SPS))
-        return FALSE;
-
       pres = gst_h265_parser_parse_pps (nalparser, nalu, &pps);
 
-
       /* arranged for a fallback pps.id, so use that one and only warn */
       if (pres != GST_H265_PARSER_OK) {
         GST_WARNING_OBJECT (h265parse, "failed to parse PPS:");
@@ -956,16 +954,8 @@ gst_h265_parse_process_nal (GstH265Parse * h265parse, GstH265NalUnit * nalu)
       break;
     }
     case GST_H265_NAL_AUD:
-      /* Just accumulate AU Delimiter, whether it's before SPS or not */
-      pres = gst_h265_parser_parse_nal (nalparser, nalu);
-      if (pres != GST_H265_PARSER_OK)
-        return FALSE;
-      break;
     default:
-      /* drop anything before the initial SPS */
-      if (!GST_H265_PARSE_STATE_VALID (h265parse, GST_H265_PARSE_STATE_GOT_SPS))
-        return FALSE;
-
+      /* Just accumulate AU Delimiter, whether it's before SPS or not */
       pres = gst_h265_parser_parse_nal (nalparser, nalu);
       if (pres != GST_H265_PARSER_OK)
         return FALSE;
@@ -1071,6 +1061,10 @@ gst_h265_parse_handle_frame_packetized (GstBaseParse * parse,
       tmp_frame.overhead = frame->overhead;
       tmp_frame.buffer = gst_buffer_copy_region (buffer, GST_BUFFER_COPY_ALL,
           nalu.offset, nalu.size);
+      /* Don't lose timestamp when offset is not 0. */
+      GST_BUFFER_PTS (tmp_frame.buffer) = GST_BUFFER_PTS (buffer);
+      GST_BUFFER_DTS (tmp_frame.buffer) = GST_BUFFER_DTS (buffer);
+      GST_BUFFER_DURATION (tmp_frame.buffer) = GST_BUFFER_DURATION (buffer);
 
       /* Set marker on last packet */
       if (nl + nalu.size == left) {
@@ -1846,6 +1840,106 @@ get_compatible_profile_caps (GstH265SPS * sps, GstH265Profile profile)
           (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_14);
       break;
     }
+      /* All the -intra profiles can map to non-intra profiles, except
+         the monochrome case for main and main-10. */
+    case GST_H265_PROFILE_MAIN_INTRA:
+    {
+      if (sps->chroma_format_idc == 1) {
+        profiles |= profile_to_flag (GST_H265_PROFILE_MAIN);
+
+        /* Add all main compatible profiles without monochrome. */
+        /* A.3.3 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_10);
+
+        /* A.3.5 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_10);
+        profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_12);
+
+        /* A.3.7 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN);
+        profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_10);
+        profiles |=
+            profile_to_flag
+            (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444);
+        profiles |=
+            profile_to_flag
+            (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_10);
+        profiles |=
+            profile_to_flag
+            (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_14);
+
+        /* G.11.1.1 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_MULTIVIEW_MAIN);
+
+        /* H.11.1.1 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_SCALABLE_MAIN);
+        profiles |= profile_to_flag (GST_H265_PROFILE_SCALABLE_MAIN_10);
+
+        /* I.11.1.1 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_3D_MAIN);
+      }
+
+      /* Add all main compatible profiles with monochrome. */
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_12);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_10);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_12);
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444);
+      profiles |=
+          profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444_10);
+      break;
+    }
+    case GST_H265_PROFILE_MAIN_10_INTRA:
+    {
+      if (sps->chroma_format_idc == 1) {
+        profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_10);
+
+        /* Add all main-10 compatible profiles without monochrome. */
+        /* A.3.5 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_10);
+        profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_12);
+
+        /* A.3.7 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_10);
+
+        /* H.11.1.1 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_SCALABLE_MAIN_10);
+      }
+
+      /* Add all main-10 compatible profiles with monochrome. */
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_12);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_10);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_12);
+      break;
+    }
+    case GST_H265_PROFILE_MAIN_12_INTRA:
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_12);
+      break;
+    case GST_H265_PROFILE_MAIN_422_10_INTRA:
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_10);
+      break;
+    case GST_H265_PROFILE_MAIN_422_12_INTRA:
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_12);
+      break;
+    case GST_H265_PROFILE_MAIN_444_INTRA:
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444);
+
+      /* Add all main444 compatible profiles. */
+      /* A.3.7 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444);
+      profiles |=
+          profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444_10);
+      break;
+    case GST_H265_PROFILE_MAIN_444_10_INTRA:
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_10);
+
+      /* Add all main444-10 compatible profiles. */
+      /* A.3.7 */
+      profiles |=
+          profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444_10);
+      break;
+    case GST_H265_PROFILE_MAIN_444_12_INTRA:
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_12);
+      break;
     default:
       break;
   }
@@ -1878,6 +1972,22 @@ get_compatible_profile_caps (GstH265SPS * sps, GstH265Profile profile)
   return caps;
 }
 
+static void
+fix_invalid_profile (GstH265Parse * h265parse, GstCaps * caps, GstH265SPS * sps)
+{
+  /* HACK: This is a work-around to identify some main profile streams
+   * having wrong profile_idc. There are some wrongly encoded main profile
+   * streams which doesn't have any of the profile_idc values mentioned in
+   * Annex-A. Just assuming them as MAIN profile for now if they meet the
+   * A.3.2 requirement. */
+  if (sps->chroma_format_idc == 1 && sps->bit_depth_luma_minus8 == 0 &&
+      sps->bit_depth_chroma_minus8 == 0 && sps->sps_extension_flag == 0) {
+    gst_caps_set_simple (caps, "profile", G_TYPE_STRING, "main", NULL);
+    GST_WARNING_OBJECT (h265parse,
+        "Wrong profile_idc = 0, setting it as main profile !!");
+  }
+}
+
 /* if downstream didn't support the exact profile indicated in sps header,
  * check for the compatible profiles also */
 static void
@@ -1886,6 +1996,9 @@ ensure_caps_profile (GstH265Parse * h265parse, GstCaps * caps, GstH265SPS * sps,
 {
   GstCaps *peer_caps, *compat_caps;
 
+  if (profile == GST_H265_PROFILE_INVALID)
+    fix_invalid_profile (h265parse, caps, sps);
+
   peer_caps = gst_pad_get_current_caps (GST_BASE_PARSE_SRC_PAD (h265parse));
   if (!peer_caps || !gst_caps_can_intersect (caps, peer_caps)) {
     GstCaps *filter_caps = gst_caps_new_empty_simple ("video/x-h265");
@@ -1930,6 +2043,31 @@ ensure_caps_profile (GstH265Parse * h265parse, GstCaps * caps, GstH265SPS * sps,
     gst_caps_unref (peer_caps);
 }
 
+static gboolean
+gst_h265_parse_is_field_interlaced (GstH265Parse * h265parse)
+{
+  /* FIXME: The SEI is optional, so theoretically there could be files with
+   * the interlaced_source_flag set to TRUE but no SEI present, or SEI present
+   * but no pic_struct. Haven't seen any such files in practice, and we don't
+   * know how to interpret the data without the pic_struct, so we'll treat
+   * them as progressive */
+
+  switch (h265parse->sei_pic_struct) {
+    case GST_H265_SEI_PIC_STRUCT_TOP_FIELD:
+    case GST_H265_SEI_PIC_STRUCT_TOP_PAIRED_PREVIOUS_BOTTOM:
+    case GST_H265_SEI_PIC_STRUCT_TOP_PAIRED_NEXT_BOTTOM:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_FIELD:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_PAIRED_PREVIOUS_TOP:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_PAIRED_NEXT_TOP:
+      return TRUE;
+      break;
+    default:
+      break;
+  }
+
+  return FALSE;
+}
+
 static void
 gst_h265_parse_update_src_caps (GstH265Parse * h265parse, GstCaps * caps)
 {
@@ -1938,6 +2076,7 @@ gst_h265_parse_update_src_caps (GstH265Parse * h265parse, GstCaps * caps)
   gboolean modified = FALSE;
   GstBuffer *buf = NULL;
   GstStructure *s = NULL;
+  gint width, height;
 
   if (G_UNLIKELY (!gst_pad_has_current_caps (GST_BASE_PARSE_SRC_PAD
               (h265parse))))
@@ -2002,12 +2141,14 @@ gst_h265_parse_update_src_caps (GstH265Parse * h265parse, GstCaps * caps)
       crop_width = sps->width;
       crop_height = sps->height;
     }
+    if (gst_h265_parse_is_field_interlaced (h265parse)) {
+      crop_height *= 2;
+    }
 
     if (G_UNLIKELY (h265parse->width != crop_width ||
             h265parse->height != crop_height)) {
       h265parse->width = crop_width;
-      h265parse->height = sps->profile_tier_level.interlaced_source_flag ?
-          crop_height * 2 : crop_height;
+      h265parse->height = crop_height;
       GST_INFO_OBJECT (h265parse, "resolution changed %dx%d",
           h265parse->width, h265parse->height);
       modified = TRUE;
@@ -2025,8 +2166,16 @@ gst_h265_parse_update_src_caps (GstH265Parse * h265parse, GstCaps * caps)
         fps_num = sps->vui_params.time_scale;
         fps_den = sps->vui_params.num_units_in_tick;
 
-        if (sps->profile_tier_level.interlaced_source_flag)
-          fps_num /= 2;
+        if (gst_h265_parse_is_field_interlaced (h265parse)
+            && h265parse->parsed_framerate) {
+          gint new_fps_num, new_fps_den;
+
+          gst_util_fraction_multiply (fps_num, fps_den, 1, 2, &new_fps_num,
+              &new_fps_den);
+          fps_num = new_fps_num;
+          fps_den = new_fps_den;
+          h265parse->parsed_framerate = FALSE;
+        }
       }
 
       if (G_UNLIKELY (h265parse->fps_num != fps_num
@@ -2084,7 +2233,6 @@ gst_h265_parse_update_src_caps (GstH265Parse * h265parse, GstCaps * caps)
     if (G_UNLIKELY (modified || h265parse->update_caps)) {
       gint fps_num = h265parse->fps_num;
       gint fps_den = h265parse->fps_den;
-      gint width, height;
       GstClockTime latency = 0;
 
       caps = gst_caps_copy (sink_caps);
@@ -2103,6 +2251,7 @@ gst_h265_parse_update_src_caps (GstH265Parse * h265parse, GstCaps * caps)
       gst_caps_set_simple (caps, "width", G_TYPE_INT, width,
           "height", G_TYPE_INT, height, NULL);
 
+      h265parse->parsed_framerate = FALSE;
       /* upstream overrides */
       if (s && gst_structure_has_field (s, "framerate"))
         gst_structure_get_fraction (s, "framerate", &fps_num, &fps_den);
@@ -2122,6 +2271,7 @@ gst_h265_parse_update_src_caps (GstH265Parse * h265parse, GstCaps * caps)
             fps_num, fps_den, 0, 0);
         val = sps->profile_tier_level.interlaced_source_flag ? GST_SECOND / 2 :
             GST_SECOND;
+        h265parse->parsed_framerate = TRUE;
 
         /* If we know the frame duration, and if we are not in one of the zero
          * latency pattern, add one frame of latency */
@@ -2175,6 +2325,7 @@ gst_h265_parse_update_src_caps (GstH265Parse * h265parse, GstCaps * caps)
     const gchar *mdi_str = NULL;
     const gchar *cll_str = NULL;
     gboolean codec_data_modified = FALSE;
+    GstStructure *st;
 
     gst_caps_set_simple (caps, "parsed", G_TYPE_BOOLEAN, TRUE,
         "stream-format", G_TYPE_STRING,
@@ -2183,11 +2334,32 @@ gst_h265_parse_update_src_caps (GstH265Parse * h265parse, GstCaps * caps)
         gst_h265_parse_get_string (h265parse, FALSE, h265parse->align), NULL);
 
     gst_h265_parse_get_par (h265parse, &par_n, &par_d);
-    if (par_n != 0 && par_d != 0 &&
+
+    width = 0;
+    height = 0;
+    st = gst_caps_get_structure (caps, 0);
+    gst_structure_get_int (st, "width", &width);
+    gst_structure_get_int (st, "height", &height);
+
+    /* If no resolution info, do not consider aspect ratio */
+    if (par_n != 0 && par_d != 0 && width > 0 && height > 0 &&
         (!s || !gst_structure_has_field (s, "pixel-aspect-ratio"))) {
-      GST_INFO_OBJECT (h265parse, "PAR %d/%d", par_n, par_d);
+      gint new_par_d = par_d;
+      /* Special case for some encoders which provide an 1:2 pixel aspect ratio
+       * for HEVC interlaced content, possibly to work around decoders that don't
+       * support field-based interlacing. Add some defensive checks to check for
+       * a "common" aspect ratio. */
+      if (par_n == 1 && par_d == 2
+          && gst_h265_parse_is_field_interlaced (h265parse)
+          && !gst_video_is_common_aspect_ratio (width, height, par_n, par_d)
+          && gst_video_is_common_aspect_ratio (width, height, 1, 1)) {
+        GST_WARNING_OBJECT (h265parse, "PAR 1/2 makes the aspect ratio of "
+            "a %d x %d frame uncommon. Switching to 1/1", width, height);
+        new_par_d = 1;
+      }
+      GST_INFO_OBJECT (h265parse, "PAR %d/%d", par_n, new_par_d);
       gst_caps_set_simple (caps, "pixel-aspect-ratio", GST_TYPE_FRACTION,
-          par_n, par_d, NULL);
+          par_n, new_par_d, NULL);
     }
 
     /* set profile and level in caps */
@@ -2195,15 +2367,28 @@ gst_h265_parse_update_src_caps (GstH265Parse * h265parse, GstCaps * caps)
       const gchar *profile, *tier, *level;
       GstH265Profile p;
 
-      p = gst_h265_profile_tier_level_get_profile (&sps->profile_tier_level);
+      p = gst_h265_get_profile_from_sps (sps);
       profile = gst_h265_profile_to_string (p);
+
+      if (s && gst_structure_has_field (s, "profile")) {
+        const gchar *profile_sink = gst_structure_get_string (s, "profile");
+        GstH265Profile p_sink = gst_h265_profile_from_string (profile_sink);
+
+        if (p != p_sink) {
+          const gchar *profile_src;
+
+          p = MAX (p, p_sink);
+          profile_src = (p == p_sink) ? profile_sink : profile;
+          GST_INFO_OBJECT (h265parse,
+              "Upstream profile (%s) is different than in SPS (%s). "
+              "Using %s.", profile_sink, profile, profile_src);
+          profile = profile_src;
+        }
+      }
+
       if (profile != NULL)
         gst_caps_set_simple (caps, "profile", G_TYPE_STRING, profile, NULL);
 
-      if (sps->profile_tier_level.interlaced_source_flag)
-        gst_caps_set_simple (caps, "interlace-mode", G_TYPE_STRING,
-            "interleaved", NULL);
-
       tier = get_tier_string (sps->profile_tier_level.tier_flag);
       if (tier != NULL)
         gst_caps_set_simple (caps, "tier", G_TYPE_STRING, tier, NULL);
@@ -2342,11 +2527,10 @@ gst_h265_parse_parse_frame (GstBaseParse * parse, GstBaseParseFrame * frame)
   gst_h265_parse_update_src_caps (h265parse, NULL);
 
   if (h265parse->fps_num > 0 && h265parse->fps_den > 0) {
-    GstH265SPS *sps = h265parse->nalparser->last_sps;
-    GstClockTime val;
+    GstClockTime val =
+        gst_h265_parse_is_field_interlaced (h265parse) ? GST_SECOND /
+        2 : GST_SECOND;
 
-    val = (sps != NULL && sps->profile_tier_level.interlaced_source_flag) ?
-        GST_SECOND / 2 : GST_SECOND;
     GST_BUFFER_DURATION (buffer) = gst_util_uint64_scale (val,
         h265parse->fps_den, h265parse->fps_num);
   }
@@ -2748,6 +2932,37 @@ gst_h265_parse_pre_push_frame (GstBaseParse * parse, GstBaseParseFrame * frame)
     }
   }
 
+  if (frame->out_buffer) {
+    parse_buffer = frame->out_buffer =
+        gst_buffer_make_writable (frame->out_buffer);
+  } else {
+    parse_buffer = frame->buffer = gst_buffer_make_writable (frame->buffer);
+  }
+
+  /* see section D.3.3 of the spec */
+  switch (h265parse->sei_pic_struct) {
+    case GST_H265_SEI_PIC_STRUCT_TOP_BOTTOM:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_TOP:
+    case GST_H265_SEI_PIC_STRUCT_TOP_BOTTOM_TOP:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM:
+      GST_BUFFER_FLAG_SET (parse_buffer, GST_VIDEO_BUFFER_FLAG_INTERLACED);
+      break;
+    case GST_H265_SEI_PIC_STRUCT_TOP_FIELD:
+    case GST_H265_SEI_PIC_STRUCT_TOP_PAIRED_NEXT_BOTTOM:
+    case GST_H265_SEI_PIC_STRUCT_TOP_PAIRED_PREVIOUS_BOTTOM:
+      GST_BUFFER_FLAG_SET (parse_buffer, GST_VIDEO_BUFFER_FLAG_INTERLACED);
+      GST_BUFFER_FLAG_SET (parse_buffer, GST_VIDEO_BUFFER_FLAG_TOP_FIELD);
+      break;
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_FIELD:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_PAIRED_PREVIOUS_TOP:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_PAIRED_NEXT_TOP:
+      GST_BUFFER_FLAG_SET (parse_buffer, GST_VIDEO_BUFFER_FLAG_INTERLACED);
+      GST_BUFFER_FLAG_SET (parse_buffer, GST_VIDEO_BUFFER_FLAG_BOTTOM_FIELD);
+      break;
+    default:
+      break;
+  }
+
   {
     guint i = 0;
 
@@ -2809,7 +3024,7 @@ gst_h265_parse_pre_push_frame (GstBaseParse * parse, GstBaseParseFrame * frame)
           gst_util_uint64_scale_int (h265parse->time_code.n_frames[i], 1,
           2 - h265parse->time_code.units_field_based_flag[i]);
 
-      gst_buffer_add_video_time_code_meta_full (buffer,
+      gst_buffer_add_video_time_code_meta_full (parse_buffer,
           h265parse->parsed_fps_n,
           h265parse->parsed_fps_d,
           NULL,
@@ -2823,19 +3038,6 @@ gst_h265_parse_pre_push_frame (GstBaseParse * parse, GstBaseParseFrame * frame)
     }
   }
 
-  if (frame->out_buffer) {
-    parse_buffer = frame->out_buffer =
-        gst_buffer_make_writable (frame->out_buffer);
-  } else {
-    parse_buffer = frame->buffer = gst_buffer_make_writable (frame->buffer);
-  }
-
-  if (h265parse->sei_pic_struct != GST_H265_SEI_PIC_STRUCT_FRAME) {
-    GST_BUFFER_FLAG_SET (parse_buffer, GST_VIDEO_BUFFER_FLAG_INTERLACED);
-    if (h265parse->sei_pic_struct == GST_H265_SEI_PIC_STRUCT_TOP_FIELD)
-      GST_BUFFER_FLAG_SET (parse_buffer, GST_VIDEO_BUFFER_FLAG_TFF);
-  }
-
   gst_video_push_user_data ((GstElement *) h265parse, &h265parse->user_data,
       parse_buffer);
 
diff --git a/gst/videoparsers/gsth265parse.h b/gst/videoparsers/gsth265parse.h
index d3f588c20..fb9454252 100644
--- a/gst/videoparsers/gsth265parse.h
+++ b/gst/videoparsers/gsth265parse.h
@@ -110,6 +110,7 @@ struct _GstH265Parse
   gboolean predicted;
   gboolean bidirectional;
   gboolean header;
+  gboolean parsed_framerate;
   /* AU state */
   gboolean picture_start;
 
diff --git a/gst/videoparsers/gstmpeg4videoparse.c b/gst/videoparsers/gstmpeg4videoparse.c
index 50413d0e0..1214a2655 100644
--- a/gst/videoparsers/gstmpeg4videoparse.c
+++ b/gst/videoparsers/gstmpeg4videoparse.c
@@ -33,6 +33,7 @@
 #include <gst/pbutils/pbutils.h>
 #include <gst/video/video.h>
 
+#include "gstvideoparserselements.h"
 #include "gstmpeg4videoparse.h"
 
 GST_DEBUG_CATEGORY (mpeg4v_parse_debug);
@@ -71,6 +72,9 @@ enum
 
 #define gst_mpeg4vparse_parent_class parent_class
 G_DEFINE_TYPE (GstMpeg4VParse, gst_mpeg4vparse, GST_TYPE_BASE_PARSE);
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (mpeg4videoparse, "mpeg4videoparse",
+    GST_RANK_PRIMARY + 1, GST_TYPE_MPEG4VIDEO_PARSE,
+    videoparsers_element_init (plugin));
 
 static gboolean gst_mpeg4vparse_start (GstBaseParse * parse);
 static gboolean gst_mpeg4vparse_stop (GstBaseParse * parse);
@@ -300,7 +304,7 @@ gst_mpeg4vparse_process_config (GstMpeg4VParse * mp4vparse,
   if (mp4vparse->config != NULL)
     gst_buffer_unref (mp4vparse->config);
 
-  mp4vparse->config = gst_buffer_new_wrapped (g_memdup (data, size), size);
+  mp4vparse->config = gst_buffer_new_memdup (data, size);
 
   /* trigger src caps update */
   mp4vparse->update_caps = TRUE;
diff --git a/gst/videoparsers/gstmpegvideoparse.c b/gst/videoparsers/gstmpegvideoparse.c
index 6e27deec2..f8ef31a1b 100644
--- a/gst/videoparsers/gstmpegvideoparse.c
+++ b/gst/videoparsers/gstmpegvideoparse.c
@@ -31,6 +31,7 @@
 #include <gst/pbutils/pbutils.h>
 #include <gst/codecparsers/gstmpegvideometa.h>
 
+#include "gstvideoparserselements.h"
 #include "gstmpegvideoparse.h"
 
 GST_DEBUG_CATEGORY (mpegv_parse_debug);
@@ -64,6 +65,9 @@ enum
 
 #define parent_class gst_mpegv_parse_parent_class
 G_DEFINE_TYPE (GstMpegvParse, gst_mpegv_parse, GST_TYPE_BASE_PARSE);
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (mpegvideoparse, "mpegvideoparse",
+    GST_RANK_PRIMARY + 1, GST_TYPE_MPEGVIDEO_PARSE,
+    videoparsers_element_init (plugin));
 
 static gboolean gst_mpegv_parse_start (GstBaseParse * parse);
 static gboolean gst_mpegv_parse_stop (GstBaseParse * parse);
diff --git a/gst/videoparsers/gstpngparse.c b/gst/videoparsers/gstpngparse.c
index 6df53bd51..81621d993 100644
--- a/gst/videoparsers/gstpngparse.c
+++ b/gst/videoparsers/gstpngparse.c
@@ -22,6 +22,7 @@
 #  include "config.h"
 #endif
 
+#include "gstvideoparserselements.h"
 #include "gstpngparse.h"
 
 #include <gst/base/base.h>
@@ -47,6 +48,8 @@ GST_STATIC_PAD_TEMPLATE ("sink", GST_PAD_SINK,
 
 #define parent_class gst_png_parse_parent_class
 G_DEFINE_TYPE (GstPngParse, gst_png_parse, GST_TYPE_BASE_PARSE);
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (pngparse, "pngparse", GST_RANK_PRIMARY,
+    GST_TYPE_PNG_PARSE, videoparsers_element_init (plugin));
 
 static gboolean gst_png_parse_start (GstBaseParse * parse);
 static gboolean gst_png_parse_event (GstBaseParse * parse, GstEvent * event);
diff --git a/gst/videoparsers/gstvc1parse.c b/gst/videoparsers/gstvc1parse.c
index 68033dfd9..74f3b961e 100644
--- a/gst/videoparsers/gstvc1parse.c
+++ b/gst/videoparsers/gstvc1parse.c
@@ -79,6 +79,7 @@
 #include "config.h"
 #endif
 
+#include "gstvideoparserselements.h"
 #include "gstvc1parse.h"
 
 #include <gst/base/base.h>
@@ -186,6 +187,8 @@ static GstStaticPadTemplate srctemplate = GST_STATIC_PAD_TEMPLATE ("src",
 
 #define parent_class gst_vc1_parse_parent_class
 G_DEFINE_TYPE (GstVC1Parse, gst_vc1_parse, GST_TYPE_BASE_PARSE);
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (vc1parse, "vc1parse", GST_RANK_NONE,
+    GST_TYPE_VC1_PARSE, videoparsers_element_init (plugin));
 
 static void gst_vc1_parse_finalize (GObject * object);
 
diff --git a/gst/videoparsers/gstvideoparserselement.c b/gst/videoparsers/gstvideoparserselement.c
new file mode 100644
index 000000000..d55564165
--- /dev/null
+++ b/gst/videoparsers/gstvideoparserselement.c
@@ -0,0 +1,39 @@
+/* GStreamer video parsers
+ * Copyright (C) 2011 Mark Nauwelaerts <mark.nauwelaerts@collabora.co.uk>
+ * Copyright (C) 2009 Tim-Philipp Müller <tim centricular net>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include "gstvideoparserselements.h"
+
+GST_DEBUG_CATEGORY (videoparseutils_debug);
+
+void
+videoparsers_element_init (GstPlugin * plugin)
+{
+  static gsize res = FALSE;
+
+  if (g_once_init_enter (&res)) {
+    GST_DEBUG_CATEGORY_INIT (videoparseutils_debug, "videoparseutils", 0,
+        "video parse utilities");
+    g_once_init_leave (&res, TRUE);
+  }
+}
diff --git a/gst/videoparsers/gstvideoparserselements.h b/gst/videoparsers/gstvideoparserselements.h
new file mode 100644
index 000000000..a8d40c91f
--- /dev/null
+++ b/gst/videoparsers/gstvideoparserselements.h
@@ -0,0 +1,46 @@
+/* GStreamer
+ * Copyright (C) 2020 Huawei Technologies Co., Ltd.
+ *   @Author: Stéphane Cerveau <stephane.cerveau@collabora.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+
+#ifndef __GST_VIDEOPARSERS_ELEMENTS_H__
+#define __GST_VIDEOPARSERS_ELEMENTS_H__
+
+#ifdef HAVE_CONFIG_H
+#include <config.h>
+#endif
+
+#include <gst/gst.h>
+
+
+void videoparsers_element_init (GstPlugin * plugin);
+
+GST_ELEMENT_REGISTER_DECLARE (av1parse);
+GST_ELEMENT_REGISTER_DECLARE (diracparse);
+GST_ELEMENT_REGISTER_DECLARE (h263parse);
+GST_ELEMENT_REGISTER_DECLARE (h264parse);
+GST_ELEMENT_REGISTER_DECLARE (h265parse);
+GST_ELEMENT_REGISTER_DECLARE (jpeg2000parse);
+GST_ELEMENT_REGISTER_DECLARE (mpeg4videoparse);
+GST_ELEMENT_REGISTER_DECLARE (mpegvideoparse);
+GST_ELEMENT_REGISTER_DECLARE (pngparse);
+GST_ELEMENT_REGISTER_DECLARE (vc1parse);
+GST_ELEMENT_REGISTER_DECLARE (vp9parse);
+
+#endif /* __GST_VIDEOPARSERS_ELEMENTS_H__ */
diff --git a/gst/videoparsers/gstvideoparseutils.c b/gst/videoparsers/gstvideoparseutils.c
index 4e94d21b5..729fe054c 100644
--- a/gst/videoparsers/gstvideoparseutils.c
+++ b/gst/videoparsers/gstvideoparseutils.c
@@ -26,6 +26,7 @@
 #include <gst/base/base.h>
 #include <gst/pbutils/pbutils.h>
 #include <gst/video/video.h>
+#include <gst/video/video-sei.h>
 #include <gst/base/gstbitreader.h>
 #include <gstvideoparseutils.h>
 
@@ -436,3 +437,58 @@ gst_video_parse_utils_parse_afd (const guint8 data, GstVideoAFD * afd,
   afd->afd = (GstVideoAFDValue) afd_data;
   return TRUE;
 }
+
+/*
+ * gst_video_parse_user_data_unregistered:
+ * @elt: #GstElement that is parsing user data
+ * @user_data: #GstVideoParseUserDataUnregistered struct to hold parsed data
+ * @br: #GstByteReader attached to buffer of user data
+ * @uuid: User Data Unregistered UUID
+ *
+ * Parse user data and store in @user_data
+ */
+void
+gst_video_parse_user_data_unregistered (GstElement * elt,
+    GstVideoParseUserDataUnregistered * user_data,
+    GstByteReader * br, guint8 uuid[16])
+{
+  gst_video_user_data_unregistered_clear (user_data);
+
+  memcpy (&user_data->uuid, uuid, 16);
+  user_data->size = gst_byte_reader_get_size (br);
+  gst_byte_reader_dup_data (br, user_data->size, &user_data->data);
+}
+
+/*
+ * gst_video_user_data_unregistered_clear:
+ * @user_data: #GstVideoParseUserDataUnregistered holding SEI User Data Unregistered
+ *
+ * Clears the user data unregistered
+ */
+void
+gst_video_user_data_unregistered_clear (GstVideoParseUserDataUnregistered *
+    user_data)
+{
+  g_free (user_data->data);
+  user_data->data = NULL;
+  user_data->size = 0;
+}
+
+/*
+ * gst_video_push_user_data_unregistered:
+ * @elt: #GstElement that is pushing user data
+ * @user_data: #GstVideoParseUserDataUnregistered holding SEI User Data Unregistered
+ * @buf: #GstBuffer that receives the parsed data
+ *
+ * After user data has been parsed, add the data to @buf
+ */
+void
+gst_video_push_user_data_unregistered (GstElement * elt,
+    GstVideoParseUserDataUnregistered * user_data, GstBuffer * buf)
+{
+  if (user_data->data != NULL) {
+    gst_buffer_add_video_sei_user_data_unregistered_meta (buf, user_data->uuid,
+        user_data->data, user_data->size);
+    gst_video_user_data_unregistered_clear (user_data);
+  }
+}
diff --git a/gst/videoparsers/gstvideoparseutils.h b/gst/videoparsers/gstvideoparseutils.h
index 603cc7170..c2d14dc57 100644
--- a/gst/videoparsers/gstvideoparseutils.h
+++ b/gst/videoparsers/gstvideoparseutils.h
@@ -174,13 +174,33 @@ typedef struct
 
 } GstVideoParseUserData;
 
+/*
+ * GstVideoParseUserDataUnregistered
+ *
+ * Holds unparsed User Data Unregistered.
+ */
+typedef struct
+{
+  guint8 uuid[16];
+  guint8 *data;
+  gsize size;
+} GstVideoParseUserDataUnregistered;
+
 G_BEGIN_DECLS
 
 void gst_video_parse_user_data(GstElement * elt, GstVideoParseUserData * user_data,
 			GstByteReader * br, guint8 field, guint16 provider_code);
 
+void gst_video_parse_user_data_unregistered(GstElement * elt, GstVideoParseUserDataUnregistered * user_data,
+			GstByteReader * br, guint8 uuid[16]);
+
+void gst_video_user_data_unregistered_clear(GstVideoParseUserDataUnregistered * user_data);
+
 void gst_video_push_user_data(GstElement * elt, GstVideoParseUserData * user_data,
 			 GstBuffer * buf);
 
+void gst_video_push_user_data_unregistered(GstElement * elt, GstVideoParseUserDataUnregistered * user_data,
+			 GstBuffer * buf);
+
 G_END_DECLS
 #endif /* __VIDEO_PARSE_UTILS_H__ */
diff --git a/gst/videoparsers/gstvp9parse.c b/gst/videoparsers/gstvp9parse.c
new file mode 100644
index 000000000..c859054c0
--- /dev/null
+++ b/gst/videoparsers/gstvp9parse.c
@@ -0,0 +1,896 @@
+/* GStreamer
+ * Copyright (C) 2020 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include <gst/codecparsers/gstvp9parser.h>
+#include <gst/video/video.h>
+#include "gstvideoparserselements.h"
+#include "gstvp9parse.h"
+
+#include <string.h>
+
+GST_DEBUG_CATEGORY (vp9_parse_debug);
+#define GST_CAT_DEFAULT vp9_parse_debug
+
+typedef enum
+{
+  GST_VP9_PARSE_ALIGN_NONE = 0,
+  GST_VP9_PARSE_ALIGN_SUPER_FRAME,
+  GST_VP9_PARSE_ALIGN_FRAME,
+} GstVp9ParseAligment;
+
+struct _GstVp9Parse
+{
+  GstBaseParse parent;
+
+  /* parsed from the last keyframe */
+  gint width;
+  gint height;
+  gint subsampling_x;
+  gint subsampling_y;
+  GstVp9ColorSpace color_space;
+  GstVp9ColorRange color_range;
+  GstVP9Profile profile;
+  GstVp9BitDepth bit_depth;
+  gboolean codec_alpha;
+
+  GstVp9ParseAligment in_align;
+  GstVp9ParseAligment align;
+
+  GstVp9Parser *parser;
+  gboolean update_caps;
+
+  /* per frame status */
+  gboolean discont;
+
+  GstClockTime super_frame_pts;
+  GstClockTime super_frame_dts;
+  GstClockTime super_frame_duration;
+};
+
+static GstStaticPadTemplate sinktemplate = GST_STATIC_PAD_TEMPLATE ("sink",
+    GST_PAD_SINK,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS ("video/x-vp9"));
+
+static GstStaticPadTemplate srctemplate = GST_STATIC_PAD_TEMPLATE ("src",
+    GST_PAD_SRC,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS ("video/x-vp9, parsed = (boolean) true, "
+        "alignment=(string) { super-frame, frame }"));
+
+#define parent_class gst_vp9_parse_parent_class
+G_DEFINE_TYPE (GstVp9Parse, gst_vp9_parse, GST_TYPE_BASE_PARSE);
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (vp9parse, "vp9parse", GST_RANK_SECONDARY,
+    GST_TYPE_VP9_PARSE, videoparsers_element_init (plugin));
+
+static gboolean gst_vp9_parse_start (GstBaseParse * parse);
+static gboolean gst_vp9_parse_stop (GstBaseParse * parse);
+static GstFlowReturn gst_vp9_parse_handle_frame (GstBaseParse * parse,
+    GstBaseParseFrame * frame, gint * skipsize);
+static gboolean gst_vp9_parse_set_sink_caps (GstBaseParse * parse,
+    GstCaps * caps);
+static GstCaps *gst_vp9_parse_get_sink_caps (GstBaseParse * parse,
+    GstCaps * filter);
+static void gst_vp9_parse_update_src_caps (GstVp9Parse * self, GstCaps * caps);
+static GstFlowReturn gst_vp9_parse_parse_frame (GstVp9Parse * self,
+    GstBaseParseFrame * frame, GstVp9FrameHdr * frame_hdr);
+static GstFlowReturn gst_vp9_parse_pre_push_frame (GstBaseParse * parse,
+    GstBaseParseFrame * frame);
+
+static void
+gst_vp9_parse_class_init (GstVp9ParseClass * klass)
+{
+  GstBaseParseClass *parse_class = GST_BASE_PARSE_CLASS (klass);
+  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);
+
+  parse_class->start = GST_DEBUG_FUNCPTR (gst_vp9_parse_start);
+  parse_class->stop = GST_DEBUG_FUNCPTR (gst_vp9_parse_stop);
+  parse_class->handle_frame = GST_DEBUG_FUNCPTR (gst_vp9_parse_handle_frame);
+  parse_class->pre_push_frame =
+      GST_DEBUG_FUNCPTR (gst_vp9_parse_pre_push_frame);
+  parse_class->set_sink_caps = GST_DEBUG_FUNCPTR (gst_vp9_parse_set_sink_caps);
+  parse_class->get_sink_caps = GST_DEBUG_FUNCPTR (gst_vp9_parse_get_sink_caps);
+
+  gst_element_class_add_static_pad_template (element_class, &srctemplate);
+  gst_element_class_add_static_pad_template (element_class, &sinktemplate);
+
+  gst_element_class_set_static_metadata (element_class, "VP9 parser",
+      "Codec/Parser/Converter/Video",
+      "Parses VP9 streams", "Seungha Yang <seungha@centricular.com>");
+
+  GST_DEBUG_CATEGORY_INIT (vp9_parse_debug, "vp9parse", 0, "vp9 parser");
+}
+
+static void
+gst_vp9_parse_init (GstVp9Parse * self)
+{
+  gst_base_parse_set_pts_interpolation (GST_BASE_PARSE (self), FALSE);
+  gst_base_parse_set_infer_ts (GST_BASE_PARSE (self), FALSE);
+
+  GST_PAD_SET_ACCEPT_INTERSECT (GST_BASE_PARSE_SINK_PAD (self));
+  GST_PAD_SET_ACCEPT_TEMPLATE (GST_BASE_PARSE_SINK_PAD (self));
+}
+
+static void
+gst_vp9_parse_reset_super_frame (GstVp9Parse * self)
+{
+  self->super_frame_pts = GST_CLOCK_TIME_NONE;
+  self->super_frame_dts = GST_CLOCK_TIME_NONE;
+  self->super_frame_duration = GST_CLOCK_TIME_NONE;
+}
+
+static void
+gst_vp9_parse_reset (GstVp9Parse * self)
+{
+  self->width = 0;
+  self->height = 0;
+  self->subsampling_x = -1;
+  self->subsampling_y = -1;
+  self->color_space = GST_VP9_CS_UNKNOWN;
+  self->color_range = GST_VP9_CR_LIMITED;
+  self->profile = GST_VP9_PROFILE_UNDEFINED;
+  self->bit_depth = (GstVp9BitDepth) 0;
+  self->codec_alpha = FALSE;
+  gst_vp9_parse_reset_super_frame (self);
+}
+
+static gboolean
+gst_vp9_parse_start (GstBaseParse * parse)
+{
+  GstVp9Parse *self = GST_VP9_PARSE (parse);
+
+  GST_DEBUG_OBJECT (self, "start");
+
+  self->parser = gst_vp9_parser_new ();
+  gst_vp9_parse_reset (self);
+
+  /* short frame header with one byte */
+  gst_base_parse_set_min_frame_size (parse, 1);
+
+  return TRUE;
+}
+
+static gboolean
+gst_vp9_parse_stop (GstBaseParse * parse)
+{
+  GstVp9Parse *self = GST_VP9_PARSE (parse);
+
+  GST_DEBUG_OBJECT (self, "stop");
+  g_clear_pointer (&self->parser, gst_vp9_parser_free);
+
+  return TRUE;
+}
+
+static const gchar *
+gst_vp9_parse_profile_to_string (GstVP9Profile profile)
+{
+  switch (profile) {
+    case GST_VP9_PROFILE_0:
+      return "0";
+    case GST_VP9_PROFILE_1:
+      return "1";
+    case GST_VP9_PROFILE_2:
+      return "2";
+    case GST_VP9_PROFILE_3:
+      return "3";
+    default:
+      break;
+  }
+
+  return NULL;
+}
+
+static GstVP9Profile
+gst_vp9_parse_profile_from_string (const gchar * profile)
+{
+  if (!profile)
+    return GST_VP9_PROFILE_UNDEFINED;
+
+  if (g_strcmp0 (profile, "0") == 0)
+    return GST_VP9_PROFILE_0;
+  else if (g_strcmp0 (profile, "1") == 0)
+    return GST_VP9_PROFILE_1;
+  else if (g_strcmp0 (profile, "2") == 0)
+    return GST_VP9_PROFILE_2;
+  else if (g_strcmp0 (profile, "3") == 0)
+    return GST_VP9_PROFILE_3;
+
+  return GST_VP9_PROFILE_UNDEFINED;
+}
+
+static const gchar *
+gst_vp9_parse_alignment_to_string (GstVp9ParseAligment align)
+{
+  switch (align) {
+    case GST_VP9_PARSE_ALIGN_SUPER_FRAME:
+      return "super-frame";
+    case GST_VP9_PARSE_ALIGN_FRAME:
+      return "frame";
+    default:
+      break;
+  }
+
+  return NULL;
+}
+
+static GstVp9ParseAligment
+gst_vp9_parse_alignment_from_string (const gchar * align)
+{
+  if (!align)
+    return GST_VP9_PARSE_ALIGN_NONE;
+
+  if (g_strcmp0 (align, "super-frame") == 0)
+    return GST_VP9_PARSE_ALIGN_SUPER_FRAME;
+  else if (g_strcmp0 (align, "frame") == 0)
+    return GST_VP9_PARSE_ALIGN_FRAME;
+
+  return GST_VP9_PARSE_ALIGN_NONE;
+}
+
+static void
+gst_vp9_parse_alignment_from_caps (GstCaps * caps, GstVp9ParseAligment * align)
+{
+  *align = GST_VP9_PARSE_ALIGN_NONE;
+
+  GST_DEBUG ("parsing caps: %" GST_PTR_FORMAT, caps);
+
+  if (caps && gst_caps_get_size (caps) > 0) {
+    GstStructure *s = gst_caps_get_structure (caps, 0);
+    const gchar *str = NULL;
+
+    if ((str = gst_structure_get_string (s, "alignment"))) {
+      *align = gst_vp9_parse_alignment_from_string (str);
+    }
+  }
+}
+
+/* implement custom semantic for codec-alpha */
+static gboolean
+gst_vp9_parse_check_codec_alpha (GstStructure * s, gboolean codec_alpha)
+{
+  gboolean value;
+
+  if (gst_structure_get_boolean (s, "codec-alpha", &value))
+    return value == codec_alpha;
+
+  return codec_alpha == FALSE;
+}
+
+/* check downstream caps to configure format and alignment */
+static void
+gst_vp9_parse_negotiate (GstVp9Parse * self, GstVp9ParseAligment in_align,
+    GstCaps * in_caps)
+{
+  GstCaps *caps;
+  GstVp9ParseAligment align = self->align;
+
+  caps = gst_pad_get_allowed_caps (GST_BASE_PARSE_SRC_PAD (self));
+  GST_DEBUG_OBJECT (self, "allowed caps: %" GST_PTR_FORMAT, caps);
+
+  /* concentrate on leading structure, since decodebin parser
+   * capsfilter always includes parser template caps */
+  if (caps) {
+    while (gst_caps_get_size (caps) > 0) {
+      GstStructure *s = gst_caps_get_structure (caps, 0);
+
+      if (gst_vp9_parse_check_codec_alpha (s, self->codec_alpha))
+        break;
+
+      gst_caps_remove_structure (caps, 0);
+    }
+
+    /* this may happen if there is simply no codec alpha decoder in the
+     * gstreamer installation, in this case, pick the first non-alpha decoder.
+     */
+    if (gst_caps_is_empty (caps)) {
+      gst_caps_unref (caps);
+      caps = gst_pad_get_allowed_caps (GST_BASE_PARSE_SRC_PAD (self));
+    }
+
+    caps = gst_caps_truncate (caps);
+    GST_DEBUG_OBJECT (self, "negotiating with caps: %" GST_PTR_FORMAT, caps);
+  }
+
+  if (in_caps && caps) {
+    if (gst_caps_can_intersect (in_caps, caps)) {
+      GST_DEBUG_OBJECT (self, "downstream accepts upstream caps");
+      gst_vp9_parse_alignment_from_caps (in_caps, &align);
+      gst_clear_caps (&caps);
+    }
+  }
+
+  /* FIXME We could fail the negotiation immediately if caps are empty */
+  if (caps && !gst_caps_is_empty (caps)) {
+    /* fixate to avoid ambiguity with lists when parsing */
+    caps = gst_caps_fixate (caps);
+    gst_vp9_parse_alignment_from_caps (caps, &align);
+  }
+
+  /* default */
+  if (align == GST_VP9_PARSE_ALIGN_NONE)
+    align = GST_VP9_PARSE_ALIGN_SUPER_FRAME;
+
+  GST_DEBUG_OBJECT (self, "selected alignment %s",
+      gst_vp9_parse_alignment_to_string (align));
+
+  self->align = align;
+
+  gst_clear_caps (&caps);
+}
+
+static gboolean
+gst_vp9_parse_is_info_valid (GstVp9Parse * self)
+{
+  if (self->width <= 0 || self->height <= 0)
+    return FALSE;
+
+  if (self->subsampling_x < 0 || self->subsampling_y < 0)
+    return FALSE;
+
+  if (self->profile == GST_VP9_PROFILE_UNDEFINED)
+    return FALSE;
+
+  if (self->bit_depth < (GstVp9BitDepth) GST_VP9_BIT_DEPTH_8)
+    return FALSE;
+
+  return TRUE;
+}
+
+static gboolean
+gst_vp9_parse_process_frame (GstVp9Parse * self, GstVp9FrameHdr * frame_hdr)
+{
+  GstVp9Parser *parser = self->parser;
+  gint width, height;
+
+  /* the resolution might be varying. Update our status per key frame */
+  if (frame_hdr->frame_type != GST_VP9_KEY_FRAME ||
+      frame_hdr->show_existing_frame) {
+    /* Need to continue to get some valid info. */
+    if (gst_vp9_parse_is_info_valid (self))
+      return TRUE;
+  }
+
+  width = frame_hdr->width;
+  height = frame_hdr->height;
+  if (frame_hdr->display_size_enabled &&
+      frame_hdr->display_width > 0 && frame_hdr->display_height) {
+    width = frame_hdr->display_width;
+    height = frame_hdr->display_height;
+  }
+
+  if (width != self->width || height != self->height) {
+    GST_DEBUG_OBJECT (self, "resolution change from %dx%d to %dx%d",
+        self->width, self->height, width, height);
+    self->width = width;
+    self->height = height;
+    self->update_caps = TRUE;
+  }
+
+  if (self->subsampling_x != parser->subsampling_x ||
+      self->subsampling_y != parser->subsampling_y) {
+    GST_DEBUG_OBJECT (self,
+        "subsampling changed from x: %d, y: %d to x: %d, y: %d",
+        self->subsampling_x, self->subsampling_y,
+        parser->subsampling_x, parser->subsampling_y);
+    self->subsampling_x = parser->subsampling_x;
+    self->subsampling_y = parser->subsampling_y;
+    self->update_caps = TRUE;
+  }
+
+  if (parser->color_space != GST_VP9_CS_UNKNOWN &&
+      parser->color_space != GST_VP9_CS_RESERVED_2 &&
+      parser->color_space != self->color_space) {
+    GST_DEBUG_OBJECT (self, "colorspace changed from %d to %d",
+        self->color_space, parser->color_space);
+    self->color_space = parser->color_space;
+    self->update_caps = TRUE;
+  }
+
+  if (parser->color_range != self->color_range) {
+    GST_DEBUG_OBJECT (self, "color range changed from %d to %d",
+        self->color_range, parser->color_range);
+    self->color_range = parser->color_range;
+    self->update_caps = TRUE;
+  }
+
+  if (frame_hdr->profile != GST_VP9_PROFILE_UNDEFINED &&
+      frame_hdr->profile != self->profile) {
+    GST_DEBUG_OBJECT (self, "profile changed from %d to %d", self->profile,
+        frame_hdr->profile);
+    self->profile = frame_hdr->profile;
+    self->update_caps = TRUE;
+  }
+
+  if (parser->bit_depth != self->bit_depth) {
+    GST_DEBUG_OBJECT (self, "bit-depth changed from %d to %d",
+        self->bit_depth, parser->bit_depth);
+    self->bit_depth = parser->bit_depth;
+    self->update_caps = TRUE;
+  }
+
+  return TRUE;
+}
+
+static GstFlowReturn
+gst_vp9_parse_pre_push_frame (GstBaseParse * parse, GstBaseParseFrame * frame)
+{
+  GstVp9Parse *self = GST_VP9_PARSE (parse);
+
+  frame->flags |= GST_BASE_PARSE_FRAME_FLAG_CLIP;
+
+  if (!frame->buffer)
+    return GST_FLOW_OK;
+
+  /* The super frame may contain more than one frames inside its buffer.
+     When splitting a super frame into frames, the base parse class only
+     assign the PTS to the first frame and leave the others' PTS invalid.
+     But in fact, all decode only frames should have invalid PTS while
+     showable frames should have correct PTS setting. */
+  if (self->align != GST_VP9_PARSE_ALIGN_FRAME)
+    return GST_FLOW_OK;
+
+  if (GST_BUFFER_FLAG_IS_SET (frame->buffer, GST_BUFFER_FLAG_DECODE_ONLY)) {
+    GST_BUFFER_PTS (frame->buffer) = GST_CLOCK_TIME_NONE;
+    GST_BUFFER_DURATION (frame->buffer) = GST_CLOCK_TIME_NONE;
+  } else {
+    GST_BUFFER_PTS (frame->buffer) = self->super_frame_pts;
+    GST_BUFFER_DURATION (frame->buffer) = self->super_frame_duration;
+  }
+  GST_BUFFER_DTS (frame->buffer) = self->super_frame_dts;
+
+  return GST_FLOW_OK;
+}
+
+static GstFlowReturn
+gst_vp9_parse_handle_frame (GstBaseParse * parse, GstBaseParseFrame * frame,
+    gint * skipsize)
+{
+  GstVp9Parse *self = GST_VP9_PARSE (parse);
+  GstBuffer *buffer = frame->buffer;
+  GstFlowReturn ret = GST_FLOW_OK;
+  GstVp9ParserResult parse_res = GST_VP9_PARSER_ERROR;
+  GstMapInfo map;
+  gsize offset = 0;
+  GstVp9SuperframeInfo superframe_info;
+  guint i;
+  GstVp9FrameHdr frame_hdr;
+
+  if (GST_BUFFER_FLAG_IS_SET (frame->buffer, GST_BUFFER_FLAG_DISCONT))
+    self->discont = TRUE;
+  else
+    self->discont = FALSE;
+
+  /* need to save buffer from invalidation upon _finish_frame */
+  if (self->align == GST_VP9_PARSE_ALIGN_FRAME)
+    buffer = gst_buffer_copy (frame->buffer);
+
+  if (!gst_buffer_map (buffer, &map, GST_MAP_READ)) {
+    GST_ELEMENT_ERROR (parse, CORE, NOT_IMPLEMENTED, (NULL),
+        ("Couldn't map incoming buffer"));
+
+    return GST_FLOW_ERROR;
+  }
+
+  GST_TRACE_OBJECT (self, "processing buffer of size %" G_GSIZE_FORMAT,
+      map.size);
+
+  /* superframe_info will be zero initialized by GstVp9Parser */
+  parse_res = gst_vp9_parser_parse_superframe_info (self->parser,
+      &superframe_info, map.data, map.size);
+
+  if (parse_res != GST_VP9_PARSER_OK) {
+    /* just finish this frame anyway, so that we don't too strict
+     * regarding parsing vp9 stream.
+     * Downstream might be able to handle this stream even though
+     * it's very unlikely */
+    GST_WARNING_OBJECT (self, "Couldn't parse superframe res: %d", parse_res);
+    goto done;
+  }
+
+  self->super_frame_pts = GST_BUFFER_PTS (buffer);
+  self->super_frame_dts = GST_BUFFER_DTS (buffer);
+  self->super_frame_duration = GST_BUFFER_DURATION (buffer);
+
+  for (i = 0; i < superframe_info.frames_in_superframe; i++) {
+    guint32 frame_size;
+
+    frame_size = superframe_info.frame_sizes[i];
+    parse_res = gst_vp9_parser_parse_frame_header (self->parser,
+        &frame_hdr, map.data + offset, frame_size);
+
+    if (parse_res != GST_VP9_PARSER_OK) {
+      GST_WARNING_OBJECT (self, "Parsing error %d", parse_res);
+      break;
+    }
+
+    gst_vp9_parse_process_frame (self, &frame_hdr);
+
+    if (self->align == GST_VP9_PARSE_ALIGN_FRAME) {
+      GstBaseParseFrame subframe;
+
+      gst_base_parse_frame_init (&subframe);
+      subframe.flags |= frame->flags;
+      subframe.offset = frame->offset;
+      subframe.overhead = frame->overhead;
+      subframe.buffer = gst_buffer_copy_region (buffer, GST_BUFFER_COPY_ALL,
+          offset, frame_size);
+
+      /* note we don't need to come up with a sub-buffer, since
+       * subsequent code only considers input buffer's metadata.
+       * Real data is either taken from input by baseclass or
+       * a replacement output buffer is provided anyway. */
+      gst_vp9_parse_parse_frame (self, &subframe, &frame_hdr);
+
+      ret = gst_base_parse_finish_frame (parse, &subframe, frame_size);
+    } else {
+      /* FIXME: need to parse all frames belong to this superframe? */
+      break;
+    }
+
+    offset += frame_size;
+  }
+
+  gst_vp9_parse_reset_super_frame (self);
+
+done:
+  gst_buffer_unmap (buffer, &map);
+
+  if (self->align != GST_VP9_PARSE_ALIGN_FRAME) {
+    if (parse_res == GST_VP9_PARSER_OK)
+      gst_vp9_parse_parse_frame (self, frame, &frame_hdr);
+    ret = gst_base_parse_finish_frame (parse, frame, map.size);
+  } else {
+    gst_buffer_unref (buffer);
+    if (offset != map.size) {
+      gsize left = map.size - offset;
+      if (left != superframe_info.superframe_index_size) {
+        GST_WARNING_OBJECT (parse,
+            "Skipping leftover frame data %" G_GSIZE_FORMAT, left);
+      }
+      frame->flags |= GST_BASE_PARSE_FRAME_FLAG_DROP;
+      ret = gst_base_parse_finish_frame (parse, frame, left);
+    }
+  }
+
+  return ret;
+}
+
+static void
+gst_vp9_parse_update_src_caps (GstVp9Parse * self, GstCaps * caps)
+{
+  GstCaps *sink_caps, *src_caps;
+  GstCaps *final_caps = NULL;
+  GstStructure *s = NULL;
+  gint width, height;
+  gint par_n = 0, par_d = 0;
+  gint fps_n = 0, fps_d = 0;
+  gint bitdepth = 0;
+  gchar *colorimetry = NULL;
+  const gchar *chroma_format = NULL;
+  const gchar *profile = NULL;
+
+  if (!self->update_caps)
+    return;
+
+  /* if this is being called from the first _setcaps call, caps on the sinkpad
+   * aren't set yet and so they need to be passed as an argument */
+  if (caps)
+    sink_caps = gst_caps_ref (caps);
+  else
+    sink_caps = gst_pad_get_current_caps (GST_BASE_PARSE_SINK_PAD (self));
+
+  /* carry over input caps as much as possible; override with our own stuff */
+  if (!sink_caps)
+    sink_caps = gst_caps_new_empty_simple ("video/x-vp9");
+  else
+    s = gst_caps_get_structure (sink_caps, 0);
+
+  final_caps = gst_caps_copy (sink_caps);
+
+  /* frame header should give this but upstream overrides */
+  if (s && gst_structure_has_field (s, "width") &&
+      gst_structure_has_field (s, "height")) {
+    gst_structure_get_int (s, "width", &width);
+    gst_structure_get_int (s, "height", &height);
+  } else {
+    width = self->width;
+    height = self->height;
+  }
+
+  if (width > 0 && height > 0)
+    gst_caps_set_simple (final_caps, "width", G_TYPE_INT, width,
+        "height", G_TYPE_INT, height, NULL);
+
+  if (s && gst_structure_get_fraction (s, "pixel-aspect-ratio", &par_n, &par_d)) {
+    if (par_n != 0 && par_d != 0) {
+      gst_caps_set_simple (final_caps, "pixel-aspect-ratio",
+          GST_TYPE_FRACTION, par_n, par_d, NULL);
+    }
+  }
+
+  if (s && gst_structure_has_field (s, "framerate")) {
+    gst_structure_get_fraction (s, "framerate", &fps_n, &fps_d);
+  }
+
+  if (fps_n > 0 && fps_d > 0) {
+    gst_caps_set_simple (final_caps, "framerate",
+        GST_TYPE_FRACTION, fps_n, fps_d, NULL);
+    gst_base_parse_set_frame_rate (GST_BASE_PARSE (self), fps_n, fps_d, 0, 0);
+  }
+
+  if (self->color_space != GST_VP9_CS_UNKNOWN &&
+      self->color_space != GST_VP9_CS_RESERVED_2) {
+    GstVideoColorimetry cinfo;
+    gboolean have_cinfo = TRUE;
+
+    memset (&cinfo, 0, sizeof (GstVideoColorimetry));
+
+    switch (self->parser->color_space) {
+      case GST_VP9_CS_BT_601:
+        gst_video_colorimetry_from_string (&cinfo, GST_VIDEO_COLORIMETRY_BT601);
+        break;
+      case GST_VP9_CS_BT_709:
+        gst_video_colorimetry_from_string (&cinfo, GST_VIDEO_COLORIMETRY_BT709);
+        break;
+      case GST_VP9_CS_SMPTE_170:
+        gst_video_colorimetry_from_string (&cinfo, GST_VIDEO_COLORIMETRY_BT601);
+        break;
+      case GST_VP9_CS_SMPTE_240:
+        gst_video_colorimetry_from_string (&cinfo,
+            GST_VIDEO_COLORIMETRY_SMPTE240M);
+        break;
+      case GST_VP9_CS_BT_2020:
+        if (self->parser->bit_depth == GST_VP9_BIT_DEPTH_12) {
+          gst_video_colorimetry_from_string (&cinfo,
+              GST_VIDEO_COLORIMETRY_BT2020);
+        } else {
+          gst_video_colorimetry_from_string (&cinfo,
+              GST_VIDEO_COLORIMETRY_BT2020_10);
+        }
+        break;
+      case GST_VP9_CS_SRGB:
+        gst_video_colorimetry_from_string (&cinfo, GST_VIDEO_COLORIMETRY_SRGB);
+        break;
+      default:
+        have_cinfo = FALSE;
+        break;
+    }
+
+    if (have_cinfo) {
+      if (self->parser->color_range == GST_VP9_CR_LIMITED)
+        cinfo.range = GST_VIDEO_COLOR_RANGE_16_235;
+      else
+        cinfo.range = GST_VIDEO_COLOR_RANGE_0_255;
+
+      colorimetry = gst_video_colorimetry_to_string (&cinfo);
+    }
+  }
+
+  if (self->parser->subsampling_x == 1 && self->parser->subsampling_y == 1)
+    chroma_format = "4:2:0";
+  else if (self->parser->subsampling_x == 1 && self->parser->subsampling_y == 0)
+    chroma_format = "4:2:2";
+  else if (self->parser->subsampling_x == 0 && self->parser->subsampling_y == 1)
+    chroma_format = "4:4:0";
+  else if (self->parser->subsampling_x == 0 && self->parser->subsampling_y == 0)
+    chroma_format = "4:4:4";
+
+  if (chroma_format)
+    gst_caps_set_simple (final_caps,
+        "chroma-format", G_TYPE_STRING, chroma_format, NULL);
+
+  switch (self->bit_depth) {
+    case GST_VP9_BIT_DEPTH_8:
+      bitdepth = 8;
+      break;
+    case GST_VP9_BIT_DEPTH_10:
+      bitdepth = 10;
+      break;
+    case GST_VP9_BIT_DEPTH_12:
+      bitdepth = 12;
+      break;
+    default:
+      break;
+  }
+
+  if (bitdepth) {
+    gst_caps_set_simple (final_caps,
+        "bit-depth-luma", G_TYPE_UINT, bitdepth,
+        "bit-depth-chroma", G_TYPE_UINT, bitdepth, NULL);
+  }
+
+  if (colorimetry && (!s || !gst_structure_has_field (s, "colorimetry"))) {
+    gst_caps_set_simple (final_caps,
+        "colorimetry", G_TYPE_STRING, colorimetry, NULL);
+  }
+
+  g_free (colorimetry);
+
+  gst_caps_set_simple (final_caps, "parsed", G_TYPE_BOOLEAN, TRUE,
+      "alignment", G_TYPE_STRING,
+      gst_vp9_parse_alignment_to_string (self->align), NULL);
+
+  profile = gst_vp9_parse_profile_to_string (self->profile);
+  if (profile)
+    gst_caps_set_simple (final_caps, "profile", G_TYPE_STRING, profile, NULL);
+
+  gst_caps_set_simple (final_caps, "codec-alpha", G_TYPE_BOOLEAN,
+      self->codec_alpha, NULL);
+
+  src_caps = gst_pad_get_current_caps (GST_BASE_PARSE_SRC_PAD (self));
+
+  if (!(src_caps && gst_caps_is_strictly_equal (src_caps, final_caps))) {
+    GST_DEBUG_OBJECT (self, "Update src caps %" GST_PTR_FORMAT, final_caps);
+    gst_pad_set_caps (GST_BASE_PARSE_SRC_PAD (self), final_caps);
+  }
+
+  gst_clear_caps (&src_caps);
+  gst_caps_unref (final_caps);
+  gst_caps_unref (sink_caps);
+
+  self->update_caps = FALSE;
+}
+
+static GstFlowReturn
+gst_vp9_parse_parse_frame (GstVp9Parse * self, GstBaseParseFrame * frame,
+    GstVp9FrameHdr * frame_hdr)
+{
+  GstBuffer *buffer;
+
+  buffer = frame->buffer;
+
+  gst_vp9_parse_update_src_caps (self, NULL);
+
+  if (frame_hdr->frame_type == GST_VP9_KEY_FRAME)
+    GST_BUFFER_FLAG_UNSET (buffer, GST_BUFFER_FLAG_DELTA_UNIT);
+  else
+    GST_BUFFER_FLAG_SET (buffer, GST_BUFFER_FLAG_DELTA_UNIT);
+
+  if (self->align == GST_VP9_PARSE_ALIGN_FRAME) {
+    if (!frame_hdr->show_frame && !frame_hdr->show_existing_frame)
+      GST_BUFFER_FLAG_SET (buffer, GST_BUFFER_FLAG_DECODE_ONLY);
+    else
+      GST_BUFFER_FLAG_UNSET (buffer, GST_BUFFER_FLAG_DECODE_ONLY);
+  }
+
+  if (self->discont) {
+    GST_BUFFER_FLAG_SET (buffer, GST_BUFFER_FLAG_DISCONT);
+    self->discont = FALSE;
+  }
+
+  return GST_FLOW_OK;
+}
+
+static gboolean
+gst_vp9_parse_set_sink_caps (GstBaseParse * parse, GstCaps * caps)
+{
+  GstVp9Parse *self = GST_VP9_PARSE (parse);
+  GstStructure *str;
+  GstVp9ParseAligment align;
+  GstCaps *in_caps = NULL;
+  const gchar *profile;
+
+  str = gst_caps_get_structure (caps, 0);
+
+  /* accept upstream info if provided */
+  gst_structure_get_int (str, "width", &self->width);
+  gst_structure_get_int (str, "height", &self->height);
+  profile = gst_structure_get_string (str, "profile");
+  if (profile)
+    self->profile = gst_vp9_parse_profile_from_string (profile);
+  gst_structure_get_boolean (str, "codec-alpha", &self->codec_alpha);
+
+  /* get upstream align from caps */
+  gst_vp9_parse_alignment_from_caps (caps, &align);
+
+  /* default */
+  if (align == GST_VP9_PARSE_ALIGN_NONE)
+    align = GST_VP9_PARSE_ALIGN_SUPER_FRAME;
+
+  /* prefer alignment type determined above */
+  in_caps = gst_caps_copy (caps);
+  gst_caps_set_simple (in_caps, "alignment", G_TYPE_STRING,
+      gst_vp9_parse_alignment_to_string (align), NULL);
+
+  /* negotiate with downstream, set output align */
+  gst_vp9_parse_negotiate (self, align, in_caps);
+
+  self->update_caps = TRUE;
+
+  /* if all of decoder's capability related values are provided
+   * by upstream, update src caps now */
+  if (self->width > 0 && self->height > 0 && profile &&
+      /* Other profiles defines multiple bitdepth/subsampling
+       * Delaying src caps update for non profile-0 streams */
+      self->profile == GST_VP9_PROFILE_0) {
+    gst_vp9_parse_update_src_caps (self, in_caps);
+  }
+
+  gst_caps_unref (in_caps);
+
+  self->in_align = align;
+
+  return TRUE;
+}
+
+static void
+remove_fields (GstCaps * caps, gboolean all)
+{
+  guint i, n;
+
+  n = gst_caps_get_size (caps);
+  for (i = 0; i < n; i++) {
+    GstStructure *s = gst_caps_get_structure (caps, i);
+
+    if (all) {
+      gst_structure_remove_field (s, "alignment");
+    }
+    gst_structure_remove_field (s, "parsed");
+  }
+}
+
+static GstCaps *
+gst_vp9_parse_get_sink_caps (GstBaseParse * parse, GstCaps * filter)
+{
+  GstCaps *peercaps, *templ;
+  GstCaps *res, *tmp, *pcopy;
+
+  templ = gst_pad_get_pad_template_caps (GST_BASE_PARSE_SINK_PAD (parse));
+  if (filter) {
+    GstCaps *fcopy = gst_caps_copy (filter);
+    /* Remove the fields we convert */
+    remove_fields (fcopy, TRUE);
+    peercaps = gst_pad_peer_query_caps (GST_BASE_PARSE_SRC_PAD (parse), fcopy);
+    gst_caps_unref (fcopy);
+  } else {
+    peercaps = gst_pad_peer_query_caps (GST_BASE_PARSE_SRC_PAD (parse), NULL);
+  }
+
+  pcopy = gst_caps_copy (peercaps);
+  remove_fields (pcopy, TRUE);
+
+  res = gst_caps_intersect_full (pcopy, templ, GST_CAPS_INTERSECT_FIRST);
+  gst_caps_unref (pcopy);
+  gst_caps_unref (templ);
+
+  if (filter) {
+    GstCaps *tmp = gst_caps_intersect_full (res, filter,
+        GST_CAPS_INTERSECT_FIRST);
+    gst_caps_unref (res);
+    res = tmp;
+  }
+
+  /* Try if we can put the downstream caps first */
+  pcopy = gst_caps_copy (peercaps);
+  remove_fields (pcopy, FALSE);
+  tmp = gst_caps_intersect_full (pcopy, res, GST_CAPS_INTERSECT_FIRST);
+  gst_caps_unref (pcopy);
+  if (!gst_caps_is_empty (tmp))
+    res = gst_caps_merge (tmp, res);
+  else
+    gst_caps_unref (tmp);
+
+  gst_caps_unref (peercaps);
+
+  return res;
+}
diff --git a/gst/videoparsers/gstvp9parse.h b/gst/videoparsers/gstvp9parse.h
new file mode 100644
index 000000000..3ec4d356a
--- /dev/null
+++ b/gst/videoparsers/gstvp9parse.h
@@ -0,0 +1,34 @@
+/* GStreamer
+ * Copyright (C) 2020 Seungha Yang <seungha@centricular.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef __GST_VP9_PARSE_H__
+#define __GST_VP9_PARSE_H__
+
+#include <gst/gst.h>
+#include <gst/base/gstbaseparse.h>
+
+G_BEGIN_DECLS
+
+#define GST_TYPE_VP9_PARSE (gst_vp9_parse_get_type())
+G_DECLARE_FINAL_TYPE (GstVp9Parse,
+    gst_vp9_parse, GST, VP9_PARSE, GstBaseParse);
+
+G_END_DECLS
+
+#endif /* __GST_VP9_PARSE_H__ */
diff --git a/gst/videoparsers/meson.build b/gst/videoparsers/meson.build
index 2fd164fc3..37b783346 100644
--- a/gst/videoparsers/meson.build
+++ b/gst/videoparsers/meson.build
@@ -1,5 +1,6 @@
 vparse_sources = [
   'plugin.c',
+  'gstvideoparserselement.c',
   'h263parse.c',
   'gsth263parse.c',
   'gstdiracparse.c',
@@ -12,6 +13,8 @@ vparse_sources = [
   'gsth265parse.c',
   'gstvideoparseutils.c',
   'gstjpeg2000parse.c',
+  'gstvp9parse.c',
+  'gstav1parse.c',
 ]
 
 gstvideoparsersbad = library('gstvideoparsersbad',
@@ -22,5 +25,4 @@ gstvideoparsersbad = library('gstvideoparsersbad',
   install : true,
   install_dir : plugins_install_dir,
 )
-pkgconfig.generate(gstvideoparsersbad, install_dir : plugins_pkgconfig_install_dir)
 plugins += [gstvideoparsersbad]
diff --git a/gst/videoparsers/plugin.c b/gst/videoparsers/plugin.c
index f4690c466..256fd94a1 100644
--- a/gst/videoparsers/plugin.c
+++ b/gst/videoparsers/plugin.c
@@ -22,44 +22,33 @@
 #include "config.h"
 #endif
 
-#include "gsth263parse.h"
-#include "gsth264parse.h"
-#include "gstdiracparse.h"
-#include "gstmpegvideoparse.h"
-#include "gstmpeg4videoparse.h"
-#include "gstpngparse.h"
-#include "gstjpeg2000parse.h"
-#include "gstvc1parse.h"
-#include "gsth265parse.h"
-
-GST_DEBUG_CATEGORY (videoparseutils_debug);
+#include "gstvideoparserselements.h"
 
 static gboolean
 plugin_init (GstPlugin * plugin)
 {
   gboolean ret = FALSE;
 
-  GST_DEBUG_CATEGORY_INIT (videoparseutils_debug, "videoparseutils", 0,
-      "video parse utilities");
-
-  ret |= gst_element_register (plugin, "h263parse",
-      GST_RANK_PRIMARY + 1, GST_TYPE_H263_PARSE);
-  ret |= gst_element_register (plugin, "h264parse",
-      GST_RANK_PRIMARY + 1, GST_TYPE_H264_PARSE);
-  ret |= gst_element_register (plugin, "diracparse",
-      GST_RANK_NONE, GST_TYPE_DIRAC_PARSE);
-  ret |= gst_element_register (plugin, "mpegvideoparse",
-      GST_RANK_PRIMARY + 1, GST_TYPE_MPEGVIDEO_PARSE);
-  ret |= gst_element_register (plugin, "mpeg4videoparse",
-      GST_RANK_PRIMARY + 1, GST_TYPE_MPEG4VIDEO_PARSE);
-  ret |= gst_element_register (plugin, "pngparse",
-      GST_RANK_PRIMARY, GST_TYPE_PNG_PARSE);
-  ret |= gst_element_register (plugin, "jpeg2000parse",
-      GST_RANK_PRIMARY, GST_TYPE_JPEG2000_PARSE);
-  ret |= gst_element_register (plugin, "h265parse",
-      GST_RANK_SECONDARY, GST_TYPE_H265_PARSE);
-  ret |= gst_element_register (plugin, "vc1parse",
-      GST_RANK_NONE, GST_TYPE_VC1_PARSE);
+  ret |= GST_ELEMENT_REGISTER (h263parse, plugin);
+  ret |= GST_ELEMENT_REGISTER (h264parse, plugin);
+  ret |= GST_ELEMENT_REGISTER (diracparse, plugin);
+  ret |= GST_ELEMENT_REGISTER (mpegvideoparse, plugin);
+  ret |= GST_ELEMENT_REGISTER (mpeg4videoparse, plugin);
+  ret |= GST_ELEMENT_REGISTER (pngparse, plugin);
+  ret |= GST_ELEMENT_REGISTER (h265parse, plugin);
+  ret |= GST_ELEMENT_REGISTER (vc1parse, plugin);
+  /**
+   * element-vp9parse:
+   *
+   * Since: 1.20
+   */
+  ret |= GST_ELEMENT_REGISTER (vp9parse, plugin);
+  /**
+   * element-av1parse:
+   *
+   * Since: 1.20
+   */
+  ret |= GST_ELEMENT_REGISTER (av1parse, plugin);
 
   return ret;
 }
-- 
2.38.1

